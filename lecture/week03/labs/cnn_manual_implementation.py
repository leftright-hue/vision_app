"""
CNN ìˆ˜ë™ êµ¬í˜„ ì˜ˆì œ
Week 2: CNN ì›ë¦¬ + Hugging Face ìƒíƒœê³„

ì´ íŒŒì¼ì€ CNNì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬
ë‚´ë¶€ ì‘ë™ ì›ë¦¬ë¥¼ ì´í•´í•˜ê¸° ìœ„í•œ ì˜ˆì œì…ë‹ˆë‹¤.
"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
from PIL import Image
import cv2

class ManualCNN:
    """CNN êµ¬ì„± ìš”ì†Œë“¤ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„í•œ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {self.device}")
    
    def manual_convolution_2d(self, input_tensor, kernel, stride=1, padding=0):
        """
        2D Convolution ì—°ì‚°ì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ (batch, channels, height, width)
            kernel: ì»¤ë„ í…ì„œ (out_channels, in_channels, kernel_height, kernel_width)
            stride: ìŠ¤íŠ¸ë¼ì´ë“œ
            padding: íŒ¨ë”©
        
        Returns:
            output_tensor: ì¶œë ¥ í…ì„œ
        """
        batch_size, in_channels, in_height, in_width = input_tensor.shape
        out_channels, _, kernel_height, kernel_width = kernel.shape
        
        # íŒ¨ë”© ì ìš©
        if padding > 0:
            padded_input = torch.zeros(batch_size, in_channels, 
                                     in_height + 2*padding, in_width + 2*padding)
            padded_input[:, :, padding:padding+in_height, padding:padding+in_width] = input_tensor
        else:
            padded_input = input_tensor
        
        # ì¶œë ¥ í¬ê¸° ê³„ì‚°
        out_height = (in_height + 2*padding - kernel_height) // stride + 1
        out_width = (in_width + 2*padding - kernel_width) // stride + 1
        
        # ì¶œë ¥ í…ì„œ ì´ˆê¸°í™”
        output = torch.zeros(batch_size, out_channels, out_height, out_width)
        
        # Convolution ì—°ì‚° ìˆ˜í–‰
        for b in range(batch_size):
            for oc in range(out_channels):
                for oh in range(out_height):
                    for ow in range(out_width):
                        # í˜„ì¬ ìœˆë„ìš°ì˜ ì‹œì‘ ìœ„ì¹˜
                        h_start = oh * stride
                        w_start = ow * stride
                        h_end = h_start + kernel_height
                        w_end = w_start + kernel_width
                        
                        # ìœˆë„ìš° ì¶”ì¶œ
                        window = padded_input[b, :, h_start:h_end, w_start:w_end]
                        
                        # ì»¤ë„ê³¼ ìœˆë„ìš°ì˜ ê³±ì…ˆ ë° í•©ê³„
                        output[b, oc, oh, ow] = torch.sum(window * kernel[oc])
        
        return output
    
    def manual_max_pooling_2d(self, input_tensor, kernel_size=2, stride=2):
        """
        2D Max Poolingì„ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ
            kernel_size: í’€ë§ ì»¤ë„ í¬ê¸°
            stride: ìŠ¤íŠ¸ë¼ì´ë“œ
        
        Returns:
            output_tensor: ì¶œë ¥ í…ì„œ
        """
        batch_size, channels, in_height, in_width = input_tensor.shape
        
        # ì¶œë ¥ í¬ê¸° ê³„ì‚°
        out_height = (in_height - kernel_size) // stride + 1
        out_width = (in_width - kernel_size) // stride + 1
        
        # ì¶œë ¥ í…ì„œ ì´ˆê¸°í™”
        output = torch.zeros(batch_size, channels, out_height, out_width)
        
        # Max Pooling ì—°ì‚° ìˆ˜í–‰
        for b in range(batch_size):
            for c in range(channels):
                for oh in range(out_height):
                    for ow in range(out_width):
                        # í˜„ì¬ ìœˆë„ìš°ì˜ ì‹œì‘ ìœ„ì¹˜
                        h_start = oh * stride
                        w_start = ow * stride
                        h_end = h_start + kernel_size
                        w_end = w_start + kernel_size
                        
                        # ìœˆë„ìš° ì¶”ì¶œ
                        window = input_tensor[b, c, h_start:h_end, w_start:w_end]
                        
                        # ìµœëŒ€ê°’ ê³„ì‚°
                        output[b, c, oh, ow] = torch.max(window)
        
        return output
    
    def manual_relu(self, input_tensor):
        """
        ReLU í™œì„±í™” í•¨ìˆ˜ë¥¼ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ
        
        Returns:
            output_tensor: ReLU ì ìš©ëœ í…ì„œ
        """
        return torch.maximum(input_tensor, torch.tensor(0.0))
    
    def manual_flatten(self, input_tensor):
        """
        í…ì„œë¥¼ í‰ë©´í™”í•˜ëŠ” í•¨ìˆ˜
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ (batch, channels, height, width)
        
        Returns:
            flattened_tensor: í‰ë©´í™”ëœ í…ì„œ (batch, channels*height*width)
        """
        batch_size = input_tensor.shape[0]
        return input_tensor.view(batch_size, -1)
    
    def manual_linear(self, input_tensor, weight, bias):
        """
        ì„ í˜• ë ˆì´ì–´ë¥¼ ìˆ˜ë™ìœ¼ë¡œ êµ¬í˜„
        
        Args:
            input_tensor: ì…ë ¥ í…ì„œ
            weight: ê°€ì¤‘ì¹˜ í–‰ë ¬
            bias: í¸í–¥ ë²¡í„°
        
        Returns:
            output_tensor: ì¶œë ¥ í…ì„œ
        """
        return torch.matmul(input_tensor, weight.T) + bias

class CNNArchitectureComparison:
    """ë‹¤ì–‘í•œ CNN ì•„í‚¤í…ì²˜ ë¹„êµ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def create_lenet5(self):
        """LeNet-5 ì•„í‚¤í…ì²˜ êµ¬í˜„"""
        class LeNet5(nn.Module):
            def __init__(self):
                super(LeNet5, self).__init__()
                # Convolutional layers
                self.conv1 = nn.Conv2d(1, 6, 5, padding=2)  # 28x28 â†’ 28x28
                self.conv2 = nn.Conv2d(6, 16, 5)            # 28x28 â†’ 24x24
                self.conv3 = nn.Conv2d(16, 120, 5)          # 24x24 â†’ 20x20
                
                # Pooling layer
                self.pool = nn.MaxPool2d(2, 2)
                
                # Fully connected layers
                self.fc1 = nn.Linear(120 * 5 * 5, 84)
                self.fc2 = nn.Linear(84, 10)
                
            def forward(self, x):
                # Convolutional layers
                x = self.pool(F.relu(self.conv1(x)))  # 28x28 â†’ 14x14
                x = self.pool(F.relu(self.conv2(x)))  # 14x14 â†’ 7x7
                x = F.relu(self.conv3(x))             # 7x7 â†’ 3x3
                
                # Flatten
                x = x.view(-1, 120 * 5 * 5)
                
                # Fully connected layers
                x = F.relu(self.fc1(x))
                x = self.fc2(x)
                
                return x
        
        return LeNet5()
    
    def create_alexnet(self):
        """AlexNet ì•„í‚¤í…ì²˜ êµ¬í˜„ (ê°„ì†Œí™” ë²„ì „)"""
        class AlexNet(nn.Module):
            def __init__(self, num_classes=1000):
                super(AlexNet, self).__init__()
                
                # Convolutional layers
                self.features = nn.Sequential(
                    nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=3, stride=2),
                    
                    nn.Conv2d(64, 192, kernel_size=5, padding=2),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=3, stride=2),
                    
                    nn.Conv2d(192, 384, kernel_size=3, padding=1),
                    nn.ReLU(inplace=True),
                    
                    nn.Conv2d(384, 256, kernel_size=3, padding=1),
                    nn.ReLU(inplace=True),
                    
                    nn.Conv2d(256, 256, kernel_size=3, padding=1),
                    nn.ReLU(inplace=True),
                    nn.MaxPool2d(kernel_size=3, stride=2),
                )
                
                # Fully connected layers
                self.classifier = nn.Sequential(
                    nn.Dropout(),
                    nn.Linear(256 * 6 * 6, 4096),
                    nn.ReLU(inplace=True),
                    nn.Dropout(),
                    nn.Linear(4096, 4096),
                    nn.ReLU(inplace=True),
                    nn.Linear(4096, num_classes),
                )
                
            def forward(self, x):
                x = self.features(x)
                x = x.view(x.size(0), 256 * 6 * 6)
                x = self.classifier(x)
                return x
        
        return AlexNet()
    
    def compare_architectures(self):
        """ë‹¤ì–‘í•œ CNN ì•„í‚¤í…ì²˜ ë¹„êµ"""
        print("=== CNN ì•„í‚¤í…ì²˜ ë¹„êµ ===")
        
        # ëª¨ë¸ ìƒì„±
        lenet5 = self.create_lenet5()
        alexnet = self.create_alexnet()
        
        # íŒŒë¼ë¯¸í„° ìˆ˜ ê³„ì‚°
        lenet5_params = sum(p.numel() for p in lenet5.parameters())
        alexnet_params = sum(p.numel() for p in alexnet.parameters())
        
        print(f"LeNet-5 íŒŒë¼ë¯¸í„° ìˆ˜: {lenet5_params:,}")
        print(f"AlexNet íŒŒë¼ë¯¸í„° ìˆ˜: {alexnet_params:,}")
        print(f"ë¹„ìœ¨: {alexnet_params/lenet5_params:.1f}ë°°")
        
        # ë ˆì´ì–´ ìˆ˜ ë¹„êµ
        lenet5_layers = len(list(lenet5.modules()))
        alexnet_layers = len(list(alexnet.modules()))
        
        print(f"LeNet-5 ë ˆì´ì–´ ìˆ˜: {lenet5_layers}")
        print(f"AlexNet ë ˆì´ì–´ ìˆ˜: {alexnet_layers}")
        
        return lenet5, alexnet

class ConvolutionVisualization:
    """Convolution ì—°ì‚° ì‹œê°í™” í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.fig_size = (15, 10)
    
    def create_sample_image(self, size=28):
        """ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±"""
        # ê°„ë‹¨í•œ íŒ¨í„´ ìƒì„±
        image = np.zeros((size, size))
        
        # ì› ê·¸ë¦¬ê¸°
        center = size // 2
        radius = size // 4
        y, x = np.ogrid[:size, :size]
        mask = (x - center)**2 + (y - center)**2 <= radius**2
        image[mask] = 1
        
        # ì‚¬ê°í˜• ê·¸ë¦¬ê¸°
        image[5:10, 5:10] = 0.5
        
        return image
    
    def create_kernels(self):
        """ë‹¤ì–‘í•œ ì»¤ë„ ìƒì„±"""
        kernels = {
            'edge_detection': np.array([
                [-1, -1, -1],
                [-1,  8, -1],
                [-1, -1, -1]
            ]),
            'blur': np.array([
                [1/9, 1/9, 1/9],
                [1/9, 1/9, 1/9],
                [1/9, 1/9, 1/9]
            ]),
            'sharpen': np.array([
                [0, -1, 0],
                [-1, 5, -1],
                [0, -1, 0]
            ]),
            'sobel_x': np.array([
                [-1, 0, 1],
                [-2, 0, 2],
                [-1, 0, 1]
            ]),
            'sobel_y': np.array([
                [-1, -2, -1],
                [0, 0, 0],
                [1, 2, 1]
            ])
        }
        return kernels
    
    def visualize_convolution_effects(self):
        """ë‹¤ì–‘í•œ ì»¤ë„ì˜ íš¨ê³¼ ì‹œê°í™”"""
        print("=== Convolution íš¨ê³¼ ì‹œê°í™” ===")
        
        # ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±
        image = self.create_sample_image()
        kernels = self.create_kernels()
        
        # ê²°ê³¼ ì €ì¥
        results = {'original': image}
        
        # ê° ì»¤ë„ ì ìš©
        for kernel_name, kernel in kernels.items():
            # Convolution ì ìš©
            result = cv2.filter2D(image, -1, kernel)
            results[kernel_name] = result
        
        # ì‹œê°í™”
        fig, axes = plt.subplots(2, 3, figsize=self.fig_size)
        axes = axes.flatten()
        
        # ì›ë³¸ ì´ë¯¸ì§€
        axes[0].imshow(results['original'], cmap='gray')
        axes[0].set_title('Original Image')
        axes[0].axis('off')
        
        # ì»¤ë„ íš¨ê³¼ë“¤
        plot_idx = 1
        for kernel_name, result in results.items():
            if kernel_name != 'original':
                axes[plot_idx].imshow(result, cmap='gray')
                axes[plot_idx].set_title(f'{kernel_name.replace("_", " ").title()}')
                axes[plot_idx].axis('off')
                plot_idx += 1
        
        plt.tight_layout()
        plt.show()
        
        return results

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸ”§ CNN ìˆ˜ë™ êµ¬í˜„ ì˜ˆì œ")
    print("=" * 50)
    
    # 1. ìˆ˜ë™ CNN êµ¬í˜„
    print("\n1. ìˆ˜ë™ CNN êµ¬í˜„")
    manual_cnn = ManualCNN()
    
    # ìƒ˜í”Œ ì…ë ¥ ìƒì„±
    input_tensor = torch.randn(1, 1, 28, 28)
    kernel = torch.randn(6, 1, 5, 5)
    
    # ìˆ˜ë™ Convolution í…ŒìŠ¤íŠ¸
    output = manual_cnn.manual_convolution_2d(input_tensor, kernel, padding=2)
    print(f"ì…ë ¥ í¬ê¸°: {input_tensor.shape}")
    print(f"ì»¤ë„ í¬ê¸°: {kernel.shape}")
    print(f"ì¶œë ¥ í¬ê¸°: {output.shape}")
    
    # PyTorch Convolutionê³¼ ë¹„êµ
    conv_layer = nn.Conv2d(1, 6, 5, padding=2, bias=False)
    conv_layer.weight.data = kernel
    pytorch_output = conv_layer(input_tensor)
    
    # ê²°ê³¼ ë¹„êµ
    diff = torch.abs(output - pytorch_output).max()
    print(f"ìˆ˜ë™ êµ¬í˜„ê³¼ PyTorch êµ¬í˜„ ì°¨ì´: {diff:.6f}")
    
    # 2. ì•„í‚¤í…ì²˜ ë¹„êµ
    print("\n2. CNN ì•„í‚¤í…ì²˜ ë¹„êµ")
    arch_comparison = CNNArchitectureComparison()
    lenet5, alexnet = arch_comparison.compare_architectures()
    
    # 3. Convolution íš¨ê³¼ ì‹œê°í™”
    print("\n3. Convolution íš¨ê³¼ ì‹œê°í™”")
    viz = ConvolutionVisualization()
    results = viz.visualize_convolution_effects()
    
    print("\nâœ… CNN ìˆ˜ë™ êµ¬í˜„ ì˜ˆì œ ì™„ë£Œ!")
    print("\nğŸ“‹ í•™ìŠµ í¬ì¸íŠ¸:")
    print("- Convolution ì—°ì‚°ì˜ ìˆ˜í•™ì  ì›ë¦¬")
    print("- ë‹¤ì–‘í•œ ì»¤ë„ì˜ íš¨ê³¼ ì´í•´")
    print("- CNN ì•„í‚¤í…ì²˜ì˜ ë°œì „ ê³¼ì •")
    print("- ìˆ˜ë™ êµ¬í˜„ê³¼ ë¼ì´ë¸ŒëŸ¬ë¦¬ êµ¬í˜„ì˜ ì°¨ì´")

if __name__ == "__main__":
    main()
