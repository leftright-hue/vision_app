"""
SAM (Segment Anything Model) API í™œìš©
Metaì˜ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ í™œìš©ë²•
"""

import torch
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from typing import List, Dict, Optional, Tuple, Union
import cv2
import requests
from io import BytesIO
import gradio as gr


class SAMSegmentation:
    """SAMì„ í™œìš©í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
    
    def __init__(self, model_type: str = "vit_h"):
        """
        Args:
            model_type: SAM ëª¨ë¸ íƒ€ì… ('vit_h', 'vit_l', 'vit_b')
        """
        self.model_type = model_type
        self.device = 'cuda' if torch.cuda.is_available() else 'cpu'
        
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” segment-anything ì„¤ì¹˜ í•„ìš”
        try:
            from segment_anything import sam_model_registry, SamPredictor, SamAutomaticMaskGenerator
            
            # ëª¨ë¸ ì²´í¬í¬ì¸íŠ¸ ê²½ë¡œ (ì‹¤ì œ í™˜ê²½ì—ì„œ ë‹¤ìš´ë¡œë“œ í•„ìš”)
            checkpoint_paths = {
                'vit_h': 'sam_vit_h_4b8939.pth',
                'vit_l': 'sam_vit_l_0b3195.pth',
                'vit_b': 'sam_vit_b_01ec64.pth'
            }
            
            # SAM ëª¨ë¸ ë¡œë“œ
            self.sam = sam_model_registry[model_type](checkpoint=checkpoint_paths[model_type])
            self.sam.to(device=self.device)
            
            # ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
            self.predictor = SamPredictor(self.sam)
            
            # ìë™ ë§ˆìŠ¤í¬ ìƒì„±ê¸°
            self.mask_generator = SamAutomaticMaskGenerator(
                model=self.sam,
                points_per_side=32,
                pred_iou_thresh=0.86,
                stability_score_thresh=0.92,
                crop_n_layers=1,
                crop_n_points_downscale_factor=2,
                min_mask_region_area=100,
            )
            
            self.initialized = True
        except ImportError:
            print("Note: segment-anything not installed. Using mock implementation for demo.")
            self.initialized = False
    
    def set_image(self, image: Union[np.ndarray, Image.Image]):
        """
        ì„¸ê·¸ë©˜í…Œì´ì…˜í•  ì´ë¯¸ì§€ ì„¤ì •
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
        """
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        self.current_image = image
        
        if self.initialized:
            self.predictor.set_image(image)
    
    def segment_with_points(
        self,
        point_coords: np.ndarray,
        point_labels: np.ndarray,
        multimask_output: bool = False
    ) -> Dict:
        """
        í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜
        
        Args:
            point_coords: í¬ì¸íŠ¸ ì¢Œí‘œ [[x, y], ...]
            point_labels: í¬ì¸íŠ¸ ë¼ë²¨ (1: ì „ê²½, 0: ë°°ê²½)
            multimask_output: ì—¬ëŸ¬ ë§ˆìŠ¤í¬ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
        """
        if not self.initialized:
            # ë°ëª¨ìš© ë”ë¯¸ ê²°ê³¼
            h, w = self.current_image.shape[:2]
            return {
                'masks': [np.random.rand(h, w) > 0.5],
                'scores': [0.95],
                'logits': [np.random.randn(h, w)]
            }
        
        masks, scores, logits = self.predictor.predict(
            point_coords=point_coords,
            point_labels=point_labels,
            multimask_output=multimask_output,
        )
        
        return {
            'masks': masks,
            'scores': scores,
            'logits': logits
        }
    
    def segment_with_box(
        self,
        box: np.ndarray,
        multimask_output: bool = False
    ) -> Dict:
        """
        ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜
        
        Args:
            box: ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
            multimask_output: ì—¬ëŸ¬ ë§ˆìŠ¤í¬ ì¶œë ¥ ì—¬ë¶€
        
        Returns:
            ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
        """
        if not self.initialized:
            # ë°ëª¨ìš© ë”ë¯¸ ê²°ê³¼
            h, w = self.current_image.shape[:2]
            mask = np.zeros((h, w), dtype=bool)
            x1, y1, x2, y2 = box.astype(int)
            mask[y1:y2, x1:x2] = True
            return {
                'masks': [mask],
                'scores': [0.98],
                'logits': [np.random.randn(h, w)]
            }
        
        masks, scores, logits = self.predictor.predict(
            box=box,
            multimask_output=multimask_output
        )
        
        return {
            'masks': masks,
            'scores': scores,
            'logits': logits
        }
    
    def segment_everything(self, image: Union[np.ndarray, Image.Image]) -> List[Dict]:
        """
        ì „ì²´ ì´ë¯¸ì§€ ìë™ ì„¸ê·¸ë©˜í…Œì´ì…˜
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
        
        Returns:
            ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        if isinstance(image, Image.Image):
            image = np.array(image)
        
        if not self.initialized:
            # ë°ëª¨ìš© ë”ë¯¸ ê²°ê³¼
            h, w = image.shape[:2]
            segments = []
            for i in range(5):  # 5ê°œì˜ ë”ë¯¸ ì„¸ê·¸ë¨¼íŠ¸
                mask = np.zeros((h, w), dtype=bool)
                # ëœë¤í•œ ì›í˜• ì˜ì—­ ìƒì„±
                cx, cy = np.random.randint(0, w), np.random.randint(0, h)
                radius = np.random.randint(20, 50)
                y, x = np.ogrid[:h, :w]
                mask = ((x - cx)**2 + (y - cy)**2) <= radius**2
                
                segments.append({
                    'segmentation': mask,
                    'area': mask.sum(),
                    'bbox': [cx-radius, cy-radius, radius*2, radius*2],
                    'predicted_iou': np.random.rand(),
                    'stability_score': np.random.rand()
                })
            return segments
        
        masks = self.mask_generator.generate(image)
        return masks
    
    def visualize_mask(
        self,
        image: np.ndarray,
        mask: np.ndarray,
        score: float = None,
        point_coords: np.ndarray = None,
        box: np.ndarray = None
    ) -> np.ndarray:
        """
        ë§ˆìŠ¤í¬ ì‹œê°í™”
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            mask: ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬
            score: ì‹ ë¢°ë„ ì ìˆ˜
            point_coords: í¬ì¸íŠ¸ ì¢Œí‘œ
            box: ë°”ìš´ë”© ë°•ìŠ¤
        
        Returns:
            ì‹œê°í™”ëœ ì´ë¯¸ì§€
        """
        # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
        masked_image = image.copy()
        mask_color = np.array([30, 144, 255])  # íŒŒë€ìƒ‰
        masked_image[mask] = masked_image[mask] * 0.5 + mask_color * 0.5
        
        # í¬ì¸íŠ¸ í‘œì‹œ
        if point_coords is not None:
            for point in point_coords:
                cv2.circle(masked_image, tuple(point.astype(int)), 5, (255, 0, 0), -1)
        
        # ë°•ìŠ¤ í‘œì‹œ
        if box is not None:
            x1, y1, x2, y2 = box.astype(int)
            cv2.rectangle(masked_image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        
        # ì ìˆ˜ í‘œì‹œ
        if score is not None:
            cv2.putText(masked_image, f"Score: {score:.2f}", (10, 30),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        return masked_image.astype(np.uint8)


class InteractiveSAMDemo:
    """ì¸í„°ë™í‹°ë¸Œ SAM ë°ëª¨"""
    
    def __init__(self):
        self.sam = SAMSegmentation()
        self.current_image = None
        self.points = []
        self.labels = []
        
    def reset(self):
        """ìƒíƒœ ì´ˆê¸°í™”"""
        self.points = []
        self.labels = []
    
    def add_point(self, image, x, y, is_positive):
        """í¬ì¸íŠ¸ ì¶”ê°€"""
        if image is None:
            return None
        
        if self.current_image is None or not np.array_equal(self.current_image, image):
            self.current_image = image
            self.sam.set_image(image)
            self.reset()
        
        # í¬ì¸íŠ¸ ì¶”ê°€
        self.points.append([x, y])
        self.labels.append(1 if is_positive else 0)
        
        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
        if len(self.points) > 0:
            point_coords = np.array(self.points)
            point_labels = np.array(self.labels)
            
            results = self.sam.segment_with_points(
                point_coords=point_coords,
                point_labels=point_labels,
                multimask_output=False
            )
            
            # ìµœê³  ì ìˆ˜ ë§ˆìŠ¤í¬ ì„ íƒ
            best_mask = results['masks'][0]
            best_score = results['scores'][0]
            
            # ì‹œê°í™”
            vis_image = self.sam.visualize_mask(
                image,
                best_mask,
                best_score,
                point_coords
            )
            
            return vis_image
        
        return image
    
    def segment_with_box(self, image, x1, y1, x2, y2):
        """ë°•ìŠ¤ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        if image is None:
            return None
        
        self.sam.set_image(image)
        
        # ë°•ìŠ¤ ì„¸ê·¸ë©˜í…Œì´ì…˜
        box = np.array([x1, y1, x2, y2])
        results = self.sam.segment_with_box(box, multimask_output=False)
        
        # ì‹œê°í™”
        best_mask = results['masks'][0]
        best_score = results['scores'][0]
        
        vis_image = self.sam.visualize_mask(
            image,
            best_mask,
            best_score,
            box=box
        )
        
        return vis_image
    
    def segment_everything(self, image):
        """ì „ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜"""
        if image is None:
            return None
        
        # ìë™ ì„¸ê·¸ë©˜í…Œì´ì…˜
        masks = self.sam.segment_everything(image)
        
        # ëª¨ë“  ë§ˆìŠ¤í¬ ì‹œê°í™”
        vis_image = image.copy()
        for i, mask_data in enumerate(masks):
            mask = mask_data['segmentation']
            color = np.random.randint(0, 255, size=3)
            vis_image[mask] = vis_image[mask] * 0.5 + color * 0.5
        
        return vis_image.astype(np.uint8)


def create_gradio_interface():
    """Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    demo = InteractiveSAMDemo()
    
    def process_point_prompt(image, x, y, is_positive):
        """í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬"""
        return demo.add_point(image, int(x), int(y), is_positive)
    
    def process_box_prompt(image, x1, y1, x2, y2):
        """ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬"""
        return demo.segment_with_box(image, x1, y1, x2, y2)
    
    def process_auto_segment(image):
        """ìë™ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬"""
        return demo.segment_everything(image)
    
    def reset_points():
        """í¬ì¸íŠ¸ ë¦¬ì…‹"""
        demo.reset()
        return None
    
    with gr.Blocks(title="SAM Segmentation Demo") as app:
        gr.Markdown("# ğŸ¯ SAM (Segment Anything Model) Demo")
        
        with gr.Tab("Point Prompts"):
            with gr.Row():
                with gr.Column():
                    point_image = gr.Image(label="Input Image", type="numpy")
                    with gr.Row():
                        x_coord = gr.Number(label="X Coordinate", value=100)
                        y_coord = gr.Number(label="Y Coordinate", value=100)
                    is_positive = gr.Checkbox(label="Positive Point (Include)", value=True)
                    with gr.Row():
                        add_point_btn = gr.Button("Add Point")
                        reset_btn = gr.Button("Reset Points")
                
                point_output = gr.Image(label="Segmentation Result")
            
            add_point_btn.click(
                process_point_prompt,
                inputs=[point_image, x_coord, y_coord, is_positive],
                outputs=point_output
            )
            reset_btn.click(reset_points, outputs=point_output)
        
        with gr.Tab("Box Prompt"):
            with gr.Row():
                with gr.Column():
                    box_image = gr.Image(label="Input Image", type="numpy")
                    with gr.Row():
                        x1 = gr.Number(label="X1", value=50)
                        y1 = gr.Number(label="Y1", value=50)
                    with gr.Row():
                        x2 = gr.Number(label="X2", value=200)
                        y2 = gr.Number(label="Y2", value=200)
                    box_segment_btn = gr.Button("Segment with Box")
                
                box_output = gr.Image(label="Segmentation Result")
            
            box_segment_btn.click(
                process_box_prompt,
                inputs=[box_image, x1, y1, x2, y2],
                outputs=box_output
            )
        
        with gr.Tab("Automatic Segmentation"):
            with gr.Row():
                with gr.Column():
                    auto_image = gr.Image(label="Input Image", type="numpy")
                    auto_segment_btn = gr.Button("Segment Everything")
                
                auto_output = gr.Image(label="All Segments")
            
            auto_segment_btn.click(
                process_auto_segment,
                inputs=auto_image,
                outputs=auto_output
            )
        
        gr.Markdown("""
        ## About SAM
        
        SAM (Segment Anything Model)ì€ Metaì—ì„œ ê°œë°œí•œ ë²”ìš© ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì…ë‹ˆë‹¤.
        
        ### Features
        - **Zero-shot Segmentation**: ì¶”ê°€ í•™ìŠµ ì—†ì´ ë‹¤ì–‘í•œ ê°ì²´ ì„¸ê·¸ë©˜í…Œì´ì…˜
        - **Prompt Engineering**: í¬ì¸íŠ¸, ë°•ìŠ¤, í…ìŠ¤íŠ¸ ë“± ë‹¤ì–‘í•œ í”„ë¡¬í”„íŠ¸ ì§€ì›
        - **High Quality**: ê³ í’ˆì§ˆ ë§ˆìŠ¤í¬ ìƒì„±
        
        ### Usage
        1. **Point Prompts**: í´ë¦­ìœ¼ë¡œ ê°ì²´ ì„ íƒ
        2. **Box Prompt**: ë°”ìš´ë”© ë°•ìŠ¤ë¡œ ì˜ì—­ ì§€ì •
        3. **Automatic**: ì „ì²´ ì´ë¯¸ì§€ ìë™ ë¶„í• 
        
        ### Tips
        - Positive points: í¬í•¨í•  ì˜ì—­ ì§€ì •
        - Negative points: ì œì™¸í•  ì˜ì—­ ì§€ì •
        - Multiple points: ë” ì •í™•í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜
        """)
    
    return app


# ì‹¤ì œ SAM API ì‚¬ìš© ì˜ˆì œ (Hugging Face Inference API)
class SAMHuggingFaceAPI:
    """Hugging Face Inference APIë¥¼ í†µí•œ SAM ì‚¬ìš©"""
    
    def __init__(self, api_key: str = None):
        self.api_url = "https://api-inference.huggingface.co/models/facebook/sam-vit-huge"
        self.headers = {"Authorization": f"Bearer {api_key}"} if api_key else {}
    
    def segment_image(self, image_path: str) -> Dict:
        """
        ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ (HF API)
        
        Args:
            image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        
        Returns:
            ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼
        """
        with open(image_path, "rb") as f:
            data = f.read()
        
        response = requests.post(self.api_url, headers=self.headers, data=data)
        
        if response.status_code == 200:
            return response.json()
        else:
            return {"error": f"API request failed with status {response.status_code}"}


if __name__ == "__main__":
    print("SAM Segmentation Module")
    print("-" * 50)
    
    # SAM ì´ˆê¸°í™”
    sam = SAMSegmentation()
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_image = np.ones((224, 224, 3), dtype=np.uint8) * 255
    cv2.rectangle(test_image, (50, 50), (150, 150), (0, 0, 255), -1)
    cv2.circle(test_image, (180, 180), 30, (0, 255, 0), -1)
    
    # ì´ë¯¸ì§€ ì„¤ì •
    sam.set_image(test_image)
    
    # í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
    points = np.array([[100, 100], [180, 180]])
    labels = np.array([1, 1])  # ëª¨ë‘ ì „ê²½
    
    results = sam.segment_with_points(points, labels)
    print(f"Point segmentation - Masks shape: {results['masks'][0].shape}")
    print(f"Point segmentation - Score: {results['scores'][0]:.3f}")
    
    # ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ í…ŒìŠ¤íŠ¸
    box = np.array([50, 50, 150, 150])
    results = sam.segment_with_box(box)
    print(f"\nBox segmentation - Masks shape: {results['masks'][0].shape}")
    print(f"Box segmentation - Score: {results['scores'][0]:.3f}")
    
    # ìë™ ì„¸ê·¸ë©˜í…Œì´ì…˜ í…ŒìŠ¤íŠ¸
    segments = sam.segment_everything(test_image)
    print(f"\nAutomatic segmentation - Found {len(segments)} segments")
    
    # Gradio ì•± ì‹¤í–‰ (ì‹¤ì œ í™˜ê²½ì—ì„œ)
    # app = create_gradio_interface()
    # app.launch()
    
    print("\nSAM segmentation setup complete!")