# Week 8: ê³ ê¸‰ ê°ì • ì¸ì‹ (Advanced Emotion Recognition)

## ê°•ì˜ ìŠ¬ë¼ì´ë“œ

---

# ğŸ“š 8ì£¼ì°¨ í•™ìŠµ ëª©í‘œ

## ì˜¤ëŠ˜ ë°°ìš¸ ë‚´ìš©

1. **ê°ì • ì¸ì‹ì˜ ê¸°ì´ˆì™€ ë°œì „**
2. **VAD 3ì°¨ì› ê°ì • ëª¨ë¸**
3. **ë©€í‹°ëª¨ë‹¬ API í™œìš© (Gemini + GPT-4o)**
4. **ì‹œê³„ì—´ ê°ì • ë³€í™” ì¶”ì **

---

# Part 1: ê°ì • ì¸ì‹ ê¸°ì´ˆ

## ğŸ­ ê°ì • ì¸ì‹ì´ë€?

### ì •ì˜
> "ì¸ê°„ì˜ ê°ì • ìƒíƒœë¥¼ ì–¼êµ´ í‘œì •, ìŒì„±, í…ìŠ¤íŠ¸ ë“±ì—ì„œ ìë™ìœ¼ë¡œ ì¸ì‹í•˜ëŠ” ê¸°ìˆ "

### ì™œ ì¤‘ìš”í•œê°€?
- **Human-AI Interaction**: ê°ì • ì¸ì‹ ì±—ë´‡, ê°€ìƒ ë¹„ì„œ
- **ë©˜íƒˆ í—¬ìŠ¤**: ìš°ìš¸ì¦, ë¶ˆì•ˆ ê°ì§€
- **ë§ˆì¼€íŒ…**: ê´‘ê³  ë°˜ì‘ ë¶„ì„
- **êµìœ¡**: í•™ìŠµì ëª°ì…ë„ ì¸¡ì •
- **ë³´ì•ˆ**: ìŠ¤íŠ¸ë ˆìŠ¤, ê±°ì§“ë§ ê°ì§€

---

## ğŸ“Š ê°ì • ì´ë¡ ì˜ ë°œì „

### Ekmanì˜ 6ê°€ì§€ ê¸°ë³¸ ê°ì • (1970s)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Paul Ekman - ë¬¸í™” ë³´í¸ì  ê°ì •          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  ğŸ˜Š Happy (í–‰ë³µ)                        â”‚
â”‚  ğŸ˜¢ Sad (ìŠ¬í””)                          â”‚
â”‚  ğŸ˜  Angry (ë¶„ë…¸)                        â”‚
â”‚  ğŸ˜¨ Fear (ê³µí¬)                         â”‚
â”‚  ğŸ˜² Surprise (ë†€ëŒ)                     â”‚
â”‚  ğŸ¤¢ Disgust (í˜ì˜¤)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**íŠ¹ì§•**:
- ë¬¸í™”ê¶Œì„ ì´ˆì›”í•œ ë³´í¸ì  í‘œì •
- ì–¼êµ´ ê·¼ìœ¡ ì›€ì§ì„(FACS) ê¸°ë°˜
- ì´ì‚°ì (discrete) ê°ì • ëª¨ë¸

**ì¥ì **: ëª…í™•í•˜ê³  êµ¬ë¶„ì´ ì‰¬ì›€
**ë‹¨ì **: ë³µì¡í•œ ê°ì • í‘œí˜„ ë¶ˆê°€ (ì˜ˆ: ì§ˆíˆ¬, ìë¶€ì‹¬)

---

### Plutchikì˜ ê°ì • ë°”í€´ (1980)

```
            ê¸°ì¨ (Joy)
               â†‘
      ì‚¬ë‘ â†   â”‚   â†’ ë‚™ê´€
   (ê¸°ì¨+ì‹ ë¢°)  â”‚  (ê¸°ì¨+ì˜ˆìƒ)
               â”‚
ì‹ ë¢° â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ì˜ˆìƒ
   â†                    â†’
ê²½ì™¸       ì¤‘ë¦½       ê³µê²©ì„±
(ì‹ ë¢°+ë‘ë ¤ì›€)       (ë¶„ë…¸+ì˜ˆìƒ)
   â†                    â†’
ë‘ë ¤ì›€ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ ë¶„ë…¸
               â”‚
      ë³µì¢… â†   â”‚   â†’ ê²½ë©¸
   (ë‘ë ¤ì›€+ìŠ¬í””) â”‚  (ë¶„ë…¸+í˜ì˜¤)
               â†“
            ìŠ¬í”” (Sadness)
```

**í•µì‹¬ ì•„ì´ë””ì–´**:
- 8ê°€ì§€ ê¸°ë³¸ ê°ì • + ê°•ë„ ë³€í™”
- ë³µí•© ê°ì • = ê¸°ë³¸ ê°ì •ì˜ ì¡°í•©
- ì˜ˆ: ì‚¬ë‘ = ê¸°ì¨ + ì‹ ë¢°

**ì¥ì **: ë³µì¡í•œ ê°ì • í‘œí˜„ ê°€ëŠ¥
**ë‹¨ì **: ì—¬ì „íˆ ì´ì‚°ì  ëª¨ë¸ì˜ í•œê³„

---

## ğŸ¯ VAD 3ì°¨ì› ê°ì • ëª¨ë¸

### Russellì˜ Circumplex Model (1980)

```
         ê°ì„± (Arousal)
              â†‘
              â”‚   ê¸´ì¥
              â”‚
ë¶„ë…¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€ í¥ë¶„
      â”‚       â”‚       â”‚
      â”‚       â”‚       â”‚
ë¶€ì • â”€â”¼â”€â”€â”€â”€â”€â”€â”€0â”€â”€â”€â”€â”€â”€â”€â”¼â”€ ê¸ì •
(Valence)     â”‚    (Valence)
      â”‚       â”‚       â”‚
      â”‚       â”‚       â”‚
ìŠ¬í”” â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€ í‰ì˜¨
              â”‚
              â”‚   ì´ì™„
              â†“
```

**3ê°€ì§€ ì°¨ì›**:
1. **Valence (ì›ìê°€)**: ê¸ì • â†” ë¶€ì • (-1.0 ~ 1.0)
2. **Arousal (ê°ì„±)**: ì°¨ë¶„ â†” í¥ë¶„ (-1.0 ~ 1.0)
3. **Dominance (ì§€ë°°)**: ë³µì¢… â†” ì§€ë°° (-1.0 ~ 1.0)

---

## ğŸ“ VAD ëª¨ë¸ì˜ ì¥ì 

### 1. ì—°ì†ì  í‘œí˜„

```
ì´ì‚°ì  ëª¨ë¸:
â”Œâ”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”
â”‚í–‰ë³µâ”‚ìŠ¬í””â”‚ë¶„ë…¸â”‚ê³µí¬â”‚ë†€ëŒâ”‚
â””â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”´â”€â”€â”€â”€â”˜

ì—°ì†ì  ëª¨ë¸ (VAD):
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  â—        â—      â—      â”‚  ë¬´í•œí•œ ê°ì • ìƒíƒœ í‘œí˜„ ê°€ëŠ¥
â”‚     â—  â—     â—     â—    â”‚
â”‚  â—     â—        â—    â—  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2. ê°ì • ìœ ì‚¬ë„ ê³„ì‚°

```python
# ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜ ìœ ì‚¬ë„
def similarity(vad1, vad2):
    distance = sqrt((v1-v2)Â² + (a1-a2)Â² + (d1-d2)Â²)
    max_distance = sqrt(3 * 2Â²)  # sqrt(12) = 3.46
    return 1.0 - (distance / max_distance)
```

### 3. ì„¸ë°€í•œ ê°ì • êµ¬ë¶„

```
Happy (í–‰ë³µ):
  Valence: +0.8 (ê¸ì •ì )
  Arousal: +0.5 (ì¤‘ê°„ ê°ì„±)
  Dominance: +0.6 (ì•½ê°„ ì§€ë°°ì )

Excited (í¥ë¶„):
  Valence: +0.7 (ê¸ì •ì )
  Arousal: +0.9 (ë§¤ìš° ë†’ì€ ê°ì„±)
  Dominance: +0.5 (ì¤‘ë¦½)

Calm (í‰ì˜¨):
  Valence: +0.3 (ì•½ê°„ ê¸ì •)
  Arousal: -0.5 (ë‚®ì€ ê°ì„±)
  Dominance: +0.2 (ì•½ê°„ ì§€ë°°ì )
```

---

## ğŸ¨ ê¸°ë³¸ ê°ì •ì˜ VAD ì¢Œí‘œ

### 7ê°€ì§€ ê°ì • ë§¤í•‘

| ê°ì • | Valence | Arousal | Dominance |
|-----|---------|---------|-----------|
| Happy | +0.8 | +0.5 | +0.6 |
| Sad | -0.7 | -0.6 | -0.5 |
| Angry | -0.5 | +0.7 | +0.8 |
| Fear | -0.6 | +0.7 | -0.6 |
| Surprise | +0.2 | +0.8 | 0.0 |
| Disgust | -0.6 | +0.4 | +0.3 |
| Neutral | 0.0 | 0.0 | 0.0 |

### 3D ê³µê°„ ì‹œê°í™”

```
           Dominance
              â†‘
              â”‚
          Angry
            â—
           /â”‚\
          / â”‚ \
         /  â”‚  \
    Fear   â”‚   Happy
      â—    â”‚    â—
       \   â”‚   /
        \  â”‚  /
         \ â”‚ /
          \â”‚/
           â—
         Sad
```

---

# Part 2: ë©€í‹°ëª¨ë‹¬ API í™œìš©

## ğŸ¤– Google Gemini API

### Gemini 2.5 Pro íŠ¹ì§•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Google Gemini 2.5 Pro              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… ë©€í‹°ëª¨ë‹¬ ì…ë ¥ (í…ìŠ¤íŠ¸+ì´ë¯¸ì§€)   â”‚
â”‚  âœ… ë³µì¡í•œ ì¶”ë¡  ëŠ¥ë ¥                â”‚
â”‚  âœ… ê¸´ ì»¨í…ìŠ¤íŠ¸ (2M í† í°)          â”‚
â”‚  âœ… êµ¬ì¡°í™”ëœ JSON ì¶œë ¥              â”‚
â”‚  âœ… ë¬´ë£Œ tier ì œê³µ                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API í‚¤ ë°œê¸‰ ë°©ë²•

1. [ai.google.dev](https://ai.google.dev) ì ‘ì†
2. Google ê³„ì • ë¡œê·¸ì¸
3. "Get API key" í´ë¦­
4. ìƒˆ í”„ë¡œì íŠ¸ ìƒì„± ë˜ëŠ” ì„ íƒ
5. API í‚¤ ë³µì‚¬ (í˜•ì‹: `AIza...`)

**ë¬´ë£Œ í• ë‹¹ëŸ‰**:
- ë¶„ë‹¹ 60ê±´ ìš”ì²­
- ì¼ì¼ 1,500ê±´ ìš”ì²­
- ì‹ ìš©ì¹´ë“œ ë¶ˆí•„ìš”

---

## ğŸ”§ Gemini API ì‹¤ì „ ì½”ë“œ

### ê¸°ë³¸ ê°ì • ì¸ì‹

```python
import google.generativeai as genai
from PIL import Image

# API ì„¤ì •
genai.configure(api_key="YOUR_API_KEY")
model = genai.GenerativeModel('gemini-2.5-pro')

# ì´ë¯¸ì§€ ë¡œë“œ
image = Image.open("face.jpg")

# í”„ë¡¬í”„íŠ¸ êµ¬ì„±
prompt = '''ì´ë¯¸ì§€ ì† ì‚¬ëŒì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:
{
  "happy": 0.0, "sad": 0.0, "angry": 0.0, "fear": 0.0,
  "surprise": 0.0, "disgust": 0.0, "neutral": 0.0
}'''

# ê°ì • ë¶„ì„
response = model.generate_content([prompt, image])
result = json.loads(response.text)

print(result)
# {'happy': 0.8, 'sad': 0.1, 'angry': 0.0, ...}
```

---

## ğŸš€ OpenAI GPT-4o API

### GPT-4o Vision íŠ¹ì§•

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  OpenAI GPT-4o                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  âœ… ê³ í’ˆì§ˆ ì´ë¯¸ì§€ ì´í•´              â”‚
â”‚  âœ… ìƒì„¸í•œ ì„¤ëª… ìƒì„±                â”‚
â”‚  âœ… Base64 ì¸ì½”ë”© ì§€ì›              â”‚
â”‚  âœ… ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ ê°€ëŠ¥              â”‚
â”‚  âš ï¸  ìœ ë£Œ (ì‹ ìš©ì¹´ë“œ í•„ìš”)           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### API í‚¤ ë°œê¸‰

1. [platform.openai.com](https://platform.openai.com) ì ‘ì†
2. ê³„ì • ìƒì„± ë° ë¡œê·¸ì¸
3. API Keys â†’ Create new secret key
4. í‚¤ ë³µì‚¬ (í˜•ì‹: `sk-...`)
5. ê²°ì œ ì •ë³´ ë“±ë¡ ($5 ìµœì†Œ)

**ë¹„ìš©**:
- GPT-4o: $2.50 / 1M tokens (ì…ë ¥)
- GPT-4o: $10.00 / 1M tokens (ì¶œë ¥)

---

## ğŸ”‘ GPT-4o Vision ì½”ë“œ

### Base64 ì¸ì½”ë”© ë°©ì‹

```python
import base64
from openai import OpenAI
from PIL import Image
import io

# API í´ë¼ì´ì–¸íŠ¸
client = OpenAI(api_key="YOUR_API_KEY")

# ì´ë¯¸ì§€ë¥¼ Base64ë¡œ ì¸ì½”ë”©
def image_to_base64(image: Image.Image) -> str:
    # RGBA â†’ RGB ë³€í™˜
    if image.mode in ('RGBA', 'LA', 'P'):
        rgb = Image.new('RGB', image.size, (255, 255, 255))
        if image.mode == 'P':
            image = image.convert('RGBA')
        rgb.paste(image, mask=image.split()[-1])
        image = rgb

    # Base64 ì¸ì½”ë”©
    buffered = io.BytesIO()
    image.save(buffered, format="JPEG", quality=85)
    return base64.b64encode(buffered.getvalue()).decode('utf-8')

# ê°ì • ë¶„ì„
image = Image.open("face.jpg")
image_base64 = image_to_base64(image)

response = client.chat.completions.create(
    model="gpt-4o",
    messages=[{
        "role": "user",
        "content": [
            {"type": "text", "text": "ê°ì •ì„ JSONìœ¼ë¡œ ë¶„ì„í•˜ì„¸ìš”"},
            {"type": "image_url", "image_url": {
                "url": f"data:image/jpeg;base64,{image_base64}"
            }}
        ]
    }],
    max_tokens=500
)

result = response.choices[0].message.content
```

---

## ğŸ¯ 3-tier Fallback íŒ¨í„´

### ì•ˆì •ì ì¸ API í†µí•©

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 1: Google Gemini              â”‚
â”‚  - ë¹ ë¥¸ ì‘ë‹µ (~1-2ì´ˆ)               â”‚
â”‚  - ë¬´ë£Œ                              â”‚
â”‚  - ìš°ì„  ì‚¬ìš©                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ (ì‹¤íŒ¨ ì‹œ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 2: OpenAI GPT-4o              â”‚
â”‚  - ê³ í’ˆì§ˆ ë¶„ì„                       â”‚
â”‚  - ìœ ë£Œ (ë¹„ìš© ë°œìƒ)                  â”‚
â”‚  - ë°±ì—… API                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“ (ì‹¤íŒ¨ ì‹œ)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Tier 3: Simulation                 â”‚
â”‚  - ëœë¤ ê°ì • ìƒì„±                    â”‚
â”‚  - í…ŒìŠ¤íŠ¸/ë°ëª¨ìš©                     â”‚
â”‚  - ìµœì¢… fallback                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### êµ¬í˜„ ì½”ë“œ

```python
class EmotionHelper:
    def __init__(self):
        self.mode = None
        self._initialize_apis()

    def _initialize_apis(self):
        # Tier 1: Gemini ì‹œë„
        if self._try_gemini():
            self.mode = 'gemini'
            return

        # Tier 2: OpenAI ì‹œë„
        if self._try_openai():
            self.mode = 'openai'
            return

        # Tier 3: Simulation
        self.mode = 'simulation'

    def analyze_basic_emotion(self, image):
        if self.mode == 'gemini':
            return self._analyze_with_gemini(image)
        elif self.mode == 'openai':
            return self._analyze_with_openai(image)
        else:
            return self._simulate_emotion()
```

---

# Part 3: ë©€í‹°ëª¨ë‹¬ ë¶„ì„

## ğŸ¨ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•©

### ì™œ ë©€í‹°ëª¨ë‹¬ì¸ê°€?

```
ì´ë¯¸ì§€ë§Œ ë¶„ì„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ˜Š ì›ƒëŠ” ì–¼êµ´     â”‚  â†’ "happy" (90%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸:
"ì˜¤ëŠ˜ ì‹œí—˜ì— ë–¨ì–´ì¡Œì–´ìš”..."

í†µí•© ë¶„ì„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ˜Š ì–µì§€ ë¯¸ì†Œ     â”‚  â†’ "sad" (80%)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**í•µì‹¬**: ì–¼êµ´ í‘œì •ë§Œìœ¼ë¡œëŠ” ê°ì •ì„ ì™„ì „íˆ ì´í•´í•  ìˆ˜ ì—†ë‹¤!

---

## ğŸ“Š ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê³¼ì •

### 3ë‹¨ê³„ ë¶„ì„

```
Step 1: ì´ë¯¸ì§€ ë‹¨ë… ë¶„ì„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Image â†’ API â†’ Base Emotions      â”‚
â”‚  {'happy': 0.6, 'sad': 0.2, ...} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 2: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Image + Text â†’ API â†’ Combined    â”‚
â”‚  {'happy': 0.2, 'sad': 0.7, ...} â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Step 3: ì°¨ì´ ë¶„ì„
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Combined - Image Only = Î”        â”‚
â”‚  {'happy': -0.4, 'sad': +0.5}    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ” ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€

### ë¶ˆì¼ì¹˜ ì„ê³„ê°’

```python
def detect_conflict(image_emotions, combined_emotions,
                   threshold=0.3):
    """
    ì´ë¯¸ì§€ì™€ í†µí•© ë¶„ì„ ê°„ ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€
    """
    # ì§€ë°°ì  ê°ì • ì°¾ê¸°
    dominant_image = max(image_emotions.items(),
                        key=lambda x: x[1])[0]
    dominant_combined = max(combined_emotions.items(),
                          key=lambda x: x[1])[0]

    # ê°ì •ì´ ë‹¤ë¥´ê³  ì‹ ë¢°ë„ ì°¨ì´ê°€ í° ê²½ìš°
    if dominant_image != dominant_combined:
        diff = abs(image_emotions[dominant_image] -
                  combined_emotions.get(dominant_image, 0))

        if diff > threshold:
            return True, f"ë¶ˆì¼ì¹˜ ê°ì§€: {dominant_image} â†’ {dominant_combined}"

    return False, None
```

---

## ğŸ’¡ ë©€í‹°ëª¨ë‹¬ í™œìš© ì‚¬ë¡€

### 1. SNS ê°ì • ë¶„ì„

```
ê²Œì‹œë¬¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“· ì´ë¯¸ì§€: ì›ƒëŠ” ì–¼êµ´             â”‚
â”‚  ğŸ“ ìº¡ì…˜: "ë“œë””ì–´ í•©ê²©í–ˆì–´ìš”!"   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
ê²°ê³¼: happy (95%) âœ… ì¼ì¹˜
```

### 2. ì–µì§€ ë¯¸ì†Œ ê°ì§€

```
ê²Œì‹œë¬¼:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“· ì´ë¯¸ì§€: ì›ƒëŠ” í‘œì •             â”‚
â”‚  ğŸ“ ìº¡ì…˜: "ì˜¤ëŠ˜ í•´ê³ ë‹¹í–ˆìŠµë‹ˆë‹¤"  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
ê²°ê³¼: sad (85%) âš ï¸ ë¶ˆì¼ì¹˜
```

### 3. ë‰´ìŠ¤ ê¸°ì‚¬ ë¶„ì„

```
ê¸°ì‚¬:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“· ì´ë¯¸ì§€: ì •ì¹˜ì¸ í‘œì •           â”‚
â”‚  ğŸ“ í…ìŠ¤íŠ¸: ìŠ¤ìº”ë“¤ ê´€ë ¨ ê¸°ì‚¬     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“
ê²°ê³¼: anger (70%) âš ï¸ ë¶ˆì¼ì¹˜
```

---

# Part 4: ì‹œê³„ì—´ ê°ì • ë¶„ì„

## ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„ì´ë€?

### ì •ì˜
> "ì‹œê°„ì— ë”°ë¥¸ ê°ì • ë³€í™”ë¥¼ ì¶”ì í•˜ê³  íŒ¨í„´ì„ ì°¾ëŠ” ë¶„ì„"

### ì‘ìš© ë¶„ì•¼

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. ë¹„ë””ì˜¤ ë¶„ì„                         â”‚
â”‚     - ì˜í™”/ë“œë¼ë§ˆì˜ ê°ì • íë¦„           â”‚
â”‚     - ì¸í„°ë·° ì¤‘ ê°ì • ë³€í™”               â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  2. ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§                     â”‚
â”‚     - ì˜¨ë¼ì¸ ìˆ˜ì—… ëª°ì…ë„                â”‚
â”‚     - ìš´ì „ì í”¼ë¡œë„ ê°ì§€                â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  3. ë©˜íƒˆ í—¬ìŠ¤                           â”‚
â”‚     - ìš°ìš¸ì¦ íŒ¨í„´ ì¶”ì                   â”‚
â”‚     - ì¹˜ë£Œ íš¨ê³¼ ëª¨ë‹ˆí„°ë§                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¢ ì‹œê³„ì—´ ë¶„ì„ êµ¬ì„± ìš”ì†Œ

### 1. í”„ë ˆì„ë³„ ê°ì • ì¶”ì¶œ

```
ë¹„ë””ì˜¤ â†’ í”„ë ˆì„ ì¶”ì¶œ â†’ ê°ì • ë¶„ì„
â”Œâ”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”
â”‚ F1  â”‚ F2  â”‚ F3  â”‚ F4  â”‚ F5  â”‚
â””â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”˜
  â†“     â†“     â†“     â†“     â†“
happy  happy  sad   sad   angry
0.8    0.7    0.6   0.8   0.7
```

### 2. íŠ¸ë Œë“œ ë¶„ì„

```python
def get_trend(emotion_values):
    """
    ì„ í˜• íšŒê·€ë¡œ íŠ¸ë Œë“œ ê³„ì‚°
    """
    x = np.arange(len(emotion_values))
    slope = np.polyfit(x, emotion_values, 1)[0]

    if slope > 0.05:
        return 'increasing'  # â†‘ ìƒìŠ¹
    elif slope < -0.05:
        return 'decreasing'  # â†“ í•˜ë½
    else:
        return 'stable'      # â†’ ì•ˆì •
```

---

## ğŸ“Š ë³€í™”ì  ê°ì§€

### Change Point Detection

```
ê°ì • ë³€í™” ê·¸ë˜í”„:

Happy
1.0 â”‚     â—â—â—
    â”‚    â—   â—
0.8 â”‚   â—     â—
    â”‚  â—       â—â—â—
0.6 â”‚ â—           â—
    â”‚â—             â—
0.4 â”‚               â—â—â—  â† ë³€í™”ì !
    â”‚                  â—
0.2 â”‚                   â—â—â—
0.0 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
    0  2  4  6  8 10 12 14  Time
```

### ì•Œê³ ë¦¬ì¦˜

```python
def detect_change_points(history, threshold=0.3):
    """
    í”„ë ˆì„ ê°„ ê°ì • ë³€í™”ê°€ í° ì§€ì  íƒì§€
    """
    change_points = []

    for i in range(1, len(history)):
        # ê° ê°ì •ë³„ ë³€í™”ëŸ‰ ê³„ì‚°
        max_change = max(
            abs(history[i]['emotions'][e] -
                history[i-1]['emotions'][e])
            for e in history[i]['emotions']
        )

        # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ë³€í™”ì ìœ¼ë¡œ ê¸°ë¡
        if max_change > threshold:
            change_points.append(i)

    return change_points
```

---

## ğŸ“‰ ì‹œê³„ì—´ ì‹œê°í™”

### Matplotlib íƒ€ì„ë¼ì¸

```python
import matplotlib.pyplot as plt

def visualize_timeline(history):
    """
    ê°ì • ë³€í™”ë¥¼ íƒ€ì„ë¼ì¸ìœ¼ë¡œ ì‹œê°í™”
    """
    # ê°ì •ë³„ ë°ì´í„° ì¶”ì¶œ
    emotions = ['happy', 'sad', 'angry', 'fear']
    data = {e: [] for e in emotions}

    for frame in history:
        for emotion in emotions:
            data[emotion].append(frame['emotions'][emotion])

    # ê·¸ë˜í”„ ìƒì„±
    fig, ax = plt.subplots(figsize=(12, 6))

    for emotion in emotions:
        ax.plot(data[emotion], label=emotion.capitalize(),
               marker='o', linewidth=2)

    ax.set_xlabel('Frame')
    ax.set_ylabel('Confidence')
    ax.set_title('Emotion Timeline')
    ax.legend()
    ax.grid(True, alpha=0.3)

    return fig
```

---

## ğŸ’¾ CSV ë°ì´í„° ì €ì¥

### êµ¬ì¡°í™”ëœ ì €ì¥

```python
def export_to_csv(history, output_path):
    """
    ì‹œê³„ì—´ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥
    """
    import pandas as pd

    # ë°ì´í„° êµ¬ì¡°í™”
    rows = []
    for i, frame in enumerate(history):
        row = {'frame': i, 'timestamp': frame['timestamp']}
        row.update(frame['emotions'])
        rows.append(row)

    # DataFrame ìƒì„± ë° ì €ì¥
    df = pd.DataFrame(rows)
    df.to_csv(output_path, index=False, encoding='utf-8')
```

**ì¶œë ¥ ì˜ˆì‹œ**:
```csv
frame,timestamp,happy,sad,angry,fear,surprise,disgust,neutral
0,0,0.8,0.1,0.0,0.0,0.0,0.0,0.1
1,1,0.7,0.2,0.0,0.0,0.0,0.0,0.1
2,2,0.5,0.3,0.1,0.0,0.0,0.0,0.1
```

---

# ì‹¤ìŠµ ì‹œê°„

## ğŸ§ª Lab 01: ê¸°ë³¸ ê°ì • ì¸ì‹

### ëª©í‘œ
- Gemini APIë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ê°ì • ì¸ì‹
- ë‹¨ì¼ ì´ë¯¸ì§€ ë° ë°°ì¹˜ ì²˜ë¦¬
- JSON ê²°ê³¼ ì¶œë ¥

### ì‹¤ìŠµ ì½”ë“œ

```python
#!/usr/bin/env python
"""
Lab 01: ê¸°ë³¸ ê°ì • ì¸ì‹
"""

import argparse
from PIL import Image
import sys
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent.parent))
from modules.week08.emotion_helpers import EmotionHelper

def analyze_single_image(helper, image_path, verbose=True):
    """ë‹¨ì¼ ì´ë¯¸ì§€ ê°ì • ë¶„ì„"""
    if verbose:
        print(f"ğŸ“· ì´ë¯¸ì§€ ë¶„ì„: {image_path}")

    image = Image.open(image_path)
    result = helper.analyze_basic_emotion(image)

    if verbose:
        # ìƒìœ„ 3ê°œ ê°ì • í‘œì‹œ
        sorted_emotions = sorted(result.items(),
                                key=lambda x: x[1],
                                reverse=True)

        print("\nğŸ† Top 3 ê°ì •:")
        for i, (emotion, score) in enumerate(sorted_emotions[:3], 1):
            bar = "â–ˆ" * int(score * 30)
            print(f"  {i}. {emotion.capitalize():<10} "
                  f"{bar} {score:.2%}")

    return result

def main():
    parser = argparse.ArgumentParser(
        description="Lab 01: ê¸°ë³¸ ê°ì • ì¸ì‹"
    )
    parser.add_argument("--input", required=True,
                       help="ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--output", help="JSON ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--quiet", action="store_true")

    args = parser.parse_args()

    # EmotionHelper ì´ˆê¸°í™”
    print("ğŸ¤– ê°ì • ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
    helper = EmotionHelper()
    print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {helper.mode} ëª¨ë“œ\n")

    # ë¶„ì„ ì‹¤í–‰
    result = analyze_single_image(helper, args.input,
                                  verbose=not args.quiet)

    # JSON ì €ì¥
    if args.output:
        import json
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {args.output}")

if __name__ == "__main__":
    main()
```

### ì‚¬ìš©ë²•

```bash
# ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„
python lab01_basic_emotion.py --input face.jpg

# JSON ì €ì¥
python lab01_basic_emotion.py --input face.jpg --output result.json

# ìµœì†Œ ì¶œë ¥
python lab01_basic_emotion.py --input face.jpg --quiet
```

---

## ğŸ§ª Lab 02: VAD ëª¨ë¸ ë¶„ì„

### ëª©í‘œ
- VAD ì¢Œí‘œ ê³„ì‚°
- 3D ê³µê°„ ì‹œê°í™”
- ê°ì • ìœ ì‚¬ë„ ë¶„ì„

### í•µì‹¬ ì½”ë“œ

```python
#!/usr/bin/env python
"""
Lab 02: VAD 3ì°¨ì› ê°ì • ëª¨ë¸
"""

import argparse
import numpy as np
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D

from modules.week08.emotion_helpers import (
    EmotionHelper, VADModel
)

def analyze_vad(helper, image_path):
    """VAD ë¶„ì„"""
    # ê°ì • ë¶„ì„
    image = Image.open(image_path)
    emotions = helper.analyze_basic_emotion(image)

    # ì§€ë°°ì  ê°ì •
    dominant = max(emotions.items(), key=lambda x: x[1])
    emotion_name, confidence = dominant

    # VAD ì¢Œí‘œ ê³„ì‚°
    vad = VADModel.emotion_to_vad(emotion_name)

    print(f"\nğŸ¯ ê°ì • ë¶„ì„ ê²°ê³¼:")
    print(f"  ì£¼ìš” ê°ì •: {emotion_name.upper()}")
    print(f"  ì‹ ë¢°ë„: {confidence:.2%}")
    print(f"\nğŸ“Š VAD ì¢Œí‘œ:")
    print(f"  Valence: {vad[0]:+.2f}")
    print(f"  Arousal: {vad[1]:+.2f}")
    print(f"  Dominance: {vad[2]:+.2f}")

    return emotion_name, vad

def find_similar_emotions(target_emotion, top_n=3):
    """ìœ ì‚¬ ê°ì • ì°¾ê¸°"""
    target_vad = VADModel.emotion_to_vad(target_emotion)

    similarities = []
    for emotion in VADModel.EMOTION_VAD_MAP.keys():
        if emotion != target_emotion:
            emotion_vad = VADModel.emotion_to_vad(emotion)
            similarity = VADModel.calculate_similarity(
                target_vad, emotion_vad
            )
            similarities.append((emotion, similarity))

    similarities.sort(key=lambda x: x[1], reverse=True)
    return similarities[:top_n]

def plot_vad_3d(emotions_vad, output_path, highlight=None):
    """3D ì‹œê°í™”"""
    fig = plt.figure(figsize=(12, 9))
    ax = fig.add_subplot(111, projection='3d')

    for emotion, (v, a, d) in emotions_vad.items():
        if highlight and emotion == highlight:
            ax.scatter(v, a, d, c='red', s=300,
                      marker='*', label=f'{emotion.upper()} (ë¶„ì„)',
                      edgecolors='darkred', linewidths=2,
                      zorder=5)
        else:
            ax.scatter(v, a, d, s=100, alpha=0.6,
                      label=emotion.capitalize())

        ax.text(v, a, d, f'  {emotion}', fontsize=9)

    ax.set_xlabel('Valence (ê¸ì • â†” ë¶€ì •)', fontsize=11)
    ax.set_ylabel('Arousal (ì°¨ë¶„ â†” í¥ë¶„)', fontsize=11)
    ax.set_zlabel('Dominance (ë³µì¢… â†” ì§€ë°°)', fontsize=11)
    ax.set_title('VAD 3ì°¨ì› ê°ì • ê³µê°„', fontsize=14)
    ax.legend(loc='upper left', fontsize=9)

    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    print(f"\nğŸ’¾ 3D í”Œë¡¯ ì €ì¥: {output_path}")

def main():
    parser = argparse.ArgumentParser(
        description="Lab 02: VAD ëª¨ë¸ ë¶„ì„"
    )
    parser.add_argument("--input", help="ì…ë ¥ ì´ë¯¸ì§€")
    parser.add_argument("--plot", help="3D í”Œë¡¯ ì €ì¥ ê²½ë¡œ")
    parser.add_argument("--similarity-matrix",
                       action="store_true",
                       help="ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±")

    args = parser.parse_args()

    if args.input:
        # ê°ì • ë¶„ì„
        helper = EmotionHelper()
        emotion_name, vad = analyze_vad(helper, args.input)

        # ìœ ì‚¬ ê°ì • ì°¾ê¸°
        print("\nğŸ” ìœ ì‚¬í•œ ê°ì •:")
        similar = find_similar_emotions(emotion_name, 3)
        for i, (emotion, score) in enumerate(similar, 1):
            print(f"  {i}. {emotion.capitalize()}: {score:.2%}")

        # 3D ì‹œê°í™”
        if args.plot:
            emotions_vad = {
                emotion: VADModel.emotion_to_vad(emotion)
                for emotion in VADModel.EMOTION_VAD_MAP.keys()
            }
            plot_vad_3d(emotions_vad, args.plot,
                       highlight=emotion_name)

if __name__ == "__main__":
    main()
```

### ì‚¬ìš©ë²•

```bash
# VAD ë¶„ì„
python lab02_vad_model.py --input face.jpg

# 3D ì‹œê°í™”
python lab02_vad_model.py --input face.jpg --plot vad_3d.png

# ìœ ì‚¬ë„ ë§¤íŠ¸ë¦­ìŠ¤
python lab02_vad_model.py --similarity-matrix --output matrix.png
```

---

## ğŸ§ª Lab 03: ë©€í‹°ëª¨ë‹¬ ë¶„ì„

### ëª©í‘œ
- ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„
- ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€
- ì»¨í…ìŠ¤íŠ¸ ì˜í–¥ ë¶„ì„

### í•µì‹¬ ì½”ë“œ

```python
#!/usr/bin/env python
"""
Lab 03: ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„
"""

def analyze_multimodal(helper, image_path, text):
    """ë©€í‹°ëª¨ë‹¬ ë¶„ì„"""
    image = Image.open(image_path)
    result = helper.analyze_multimodal(image, text)

    # ê²°ê³¼ ë¹„êµ
    image_only = result['image_only']
    combined = result['combined']
    difference = result['difference']

    dominant_image = max(image_only.items(),
                        key=lambda x: x[1])[0]
    dominant_combined = max(combined.items(),
                           key=lambda x: x[1])[0]

    print("\nğŸ“Š ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼")
    print("=" * 50)
    print(f"\nğŸ–¼ï¸  ì´ë¯¸ì§€ë§Œ: {dominant_image.upper()}")
    print(f"ğŸ¨ í†µí•© ë¶„ì„: {dominant_combined.upper()}")

    # ì°¨ì´ ë¶„ì„
    print("\nğŸ” í…ìŠ¤íŠ¸ ì˜í–¥:")
    significant = [(e, d) for e, d in difference.items()
                  if abs(d) > 0.05]
    for emotion, diff in significant:
        direction = "â†‘" if diff > 0 else "â†“"
        print(f"  {emotion.capitalize()}: "
              f"{diff:+.2%} {direction}")

    return result

def detect_conflict(result, threshold=0.3):
    """ë¶ˆì¼ì¹˜ ê°ì§€"""
    image_only = result['image_only']
    combined = result['combined']

    dominant_image = max(image_only.items(),
                        key=lambda x: x[1])[0]
    dominant_combined = max(combined.items(),
                           key=lambda x: x[1])[0]

    if dominant_image != dominant_combined:
        diff = abs(image_only[dominant_image] -
                  combined.get(dominant_image, 0))

        if diff > threshold:
            return True, (f"ë¶ˆì¼ì¹˜ ê°ì§€: "
                         f"{dominant_image} â†’ {dominant_combined}")

    return False, None

def main():
    parser = argparse.ArgumentParser(
        description="Lab 03: ë©€í‹°ëª¨ë‹¬ ë¶„ì„"
    )
    parser.add_argument("--input", required=True)
    parser.add_argument("--text", required=True)
    parser.add_argument("--detect-conflict",
                       action="store_true")
    parser.add_argument("--threshold", type=float,
                       default=0.3)

    args = parser.parse_args()

    # ë¶„ì„
    helper = EmotionHelper()
    result = analyze_multimodal(helper, args.input,
                                args.text)

    # ë¶ˆì¼ì¹˜ ê°ì§€
    if args.detect_conflict:
        has_conflict, msg = detect_conflict(result,
                                           args.threshold)
        if has_conflict:
            print(f"\nğŸš¨ {msg}")
        else:
            print("\nâœ… ê°ì • ì¼ì¹˜")

if __name__ == "__main__":
    main()
```

### ì‚¬ìš©ë²•

```bash
# ë©€í‹°ëª¨ë‹¬ ë¶„ì„
python lab03_multimodal.py \
  --input face.jpg \
  --text "ì˜¤ëŠ˜ ì‹œí—˜ì— ë–¨ì–´ì¡Œì–´ìš”"

# ë¶ˆì¼ì¹˜ ê°ì§€
python lab03_multimodal.py \
  --input face.jpg \
  --text "ë“œë””ì–´ í•©ê²©í–ˆìŠµë‹ˆë‹¤" \
  --detect-conflict
```

---

## ğŸ§ª Lab 04: ì‹œê³„ì—´ ë¶„ì„

### ëª©í‘œ
- ì—¬ëŸ¬ ì´ë¯¸ì§€ ì‹œê³„ì—´ ë¶„ì„
- ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ
- ë³€í™”ì  ê°ì§€ ë° CSV ì €ì¥

### í•µì‹¬ ì½”ë“œ (ê°„ëµ)

```python
#!/usr/bin/env python
"""
Lab 04: ì‹œê³„ì—´ ê°ì • ë¶„ì„
"""

def analyze_timeseries(helper, images):
    """ì‹œê³„ì—´ ë¶„ì„"""
    from modules.week08.emotion_helpers import EmotionTimeSeries

    timeseries = EmotionTimeSeries(window_size=len(images))

    for i, image in enumerate(images):
        emotions = helper.analyze_basic_emotion(image)
        timeseries.add_frame(emotions, timestamp=i)

    # ìš”ì•½
    summary = timeseries.get_summary()
    print(f"\nğŸ“Š ë¶„ì„ ìš”ì•½:")
    print(f"  í”„ë ˆì„ ìˆ˜: {summary['total_frames']}")
    print(f"  ì§€ë°°ì  ê°ì •: {summary['dominant_emotion'].upper()}")
    print(f"  í‰ê·  ì‹ ë¢°ë„: {summary['avg_confidence']:.2%}")

    # íŠ¸ë Œë“œ
    print("\nğŸ“ˆ ê°ì • íŠ¸ë Œë“œ:")
    for emotion in ['happy', 'sad', 'angry', 'fear']:
        trend = timeseries.get_trend(emotion)
        symbols = {'increasing': 'â†‘', 'decreasing': 'â†“',
                  'stable': 'â†’'}
        print(f"  {emotion.capitalize()}: {symbols[trend]}")

    # ë³€í™”ì 
    changes = timeseries.detect_change_points()
    if changes:
        print(f"\nâš ï¸  ë³€í™”ì : {len(changes)}ê°œ ë°œê²¬")
        print(f"  í”„ë ˆì„: {changes}")

    return timeseries
```

### ì‚¬ìš©ë²•

```bash
# ì—¬ëŸ¬ ì´ë¯¸ì§€ ë¶„ì„
python lab04_timeseries.py --images img1.jpg img2.jpg img3.jpg

# ë””ë ‰í† ë¦¬ ë¶„ì„
python lab04_timeseries.py --input-dir frames/

# ë¹„ë””ì˜¤ ë¶„ì„
python lab04_timeseries.py --video video.mp4 --sample-rate 30

# CSV ì €ì¥
python lab04_timeseries.py --images *.jpg --csv results.csv
```

---

## ğŸ§ª Lab 05: API ì„±ëŠ¥ ë¹„êµ

### ëª©í‘œ
- Gemini vs GPT-4o vs Simulation ë¹„êµ
- ì†ë„, ì¼ê´€ì„±, ë¹„ìš© ì¸¡ì •
- ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶œë ¥

### í•µì‹¬ ì½”ë“œ (ê°„ëµ)

```python
#!/usr/bin/env python
"""
Lab 05: API ì„±ëŠ¥ ë¹„êµ ë²¤ì¹˜ë§ˆí¬
"""

import time

def benchmark_api(api_mode, image, runs=3):
    """API ë²¤ì¹˜ë§ˆí¬"""
    helper = EmotionHelper()
    helper.mode = api_mode

    times = []
    results = []

    for _ in range(runs):
        start = time.time()
        result = helper.analyze_basic_emotion(image)
        elapsed = time.time() - start

        times.append(elapsed)
        results.append(result)

    # í†µê³„
    return {
        'mode': api_mode,
        'avg_time': statistics.mean(times),
        'min_time': min(times),
        'max_time': max(times),
        'consistency': calculate_consistency(results),
        'cost_per_1k': API_COSTS[api_mode]['per_1k_images']
    }

def print_comparison_table(benchmarks):
    """ë¹„êµ í…Œì´ë¸” ì¶œë ¥"""
    print("\nğŸ“Š API ì„±ëŠ¥ ë¹„êµ")
    print("=" * 70)
    print(f"{'API':<20} {'í‰ê·  ì‹œê°„':<12} {'ì¼ê´€ì„±':<10} "
          f"{'ë¹„ìš©(1K)':<12}")
    print("-" * 70)

    for bench in benchmarks:
        print(f"{bench['name']:<20} "
              f"{bench['avg_time']:<12.3f}ì´ˆ "
              f"{bench['consistency']:<10.2%} "
              f"${bench['cost_per_1k']:<11.4f}")
```

### ì‚¬ìš©ë²•

```bash
# ë‹¨ì¼ ì´ë¯¸ì§€ ë²¤ì¹˜ë§ˆí¬
python lab05_comparison.py --input face.jpg --runs 5

# ëª¨ë“  API ë¹„êµ
python lab05_comparison.py --input face.jpg

# íŠ¹ì • APIë§Œ í…ŒìŠ¤íŠ¸
python lab05_comparison.py --input face.jpg --modes gemini openai
```

---

# ğŸ¯ í•µì‹¬ ì •ë¦¬

## ì˜¤ëŠ˜ ë°°ìš´ ë‚´ìš©

âœ… **ê°ì • ì¸ì‹ ê¸°ì´ˆ**
- Ekman 6ê°€ì§€ â†’ Plutchik ë³µí•© â†’ VAD 3ì°¨ì›
- ì—°ì†ì  ê°ì • ëª¨ë¸ì˜ ì¥ì 

âœ… **VAD 3ì°¨ì› ëª¨ë¸**
- Valence, Arousal, Dominance
- ê°ì • ìœ ì‚¬ë„ ê³„ì‚°
- ì„¸ë°€í•œ ê°ì • êµ¬ë¶„

âœ… **ë©€í‹°ëª¨ë‹¬ API**
- Google Gemini vs OpenAI GPT-4o
- 3-tier Fallback íŒ¨í„´
- ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•©

âœ… **ì‹œê³„ì—´ ë¶„ì„**
- í”„ë ˆì„ë³„ ê°ì • ì¶”ì¶œ
- íŠ¸ë Œë“œ ë¶„ì„ (ì„ í˜• íšŒê·€)
- ë³€í™”ì  ê°ì§€

---

## ğŸ’¡ ì‹¤ì „ íŒ

### API ì„ íƒ ê°€ì´ë“œ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ì†ë„ ì¤‘ìš” â†’ Simulation (í…ŒìŠ¤íŠ¸ìš©)   â”‚
â”‚  í’ˆì§ˆ ì¤‘ìš” â†’ Gemini (ë¬´ë£Œ)          â”‚
â”‚  ìµœê³  í’ˆì§ˆ â†’ GPT-4o (ìœ ë£Œ)          â”‚
â”‚  ë¹„ìš© ì ˆì•½ â†’ 3-tier Fallback        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ì„±ëŠ¥ ìµœì í™”

1. **ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •**: API ë¹„ìš© ì ˆê°
2. **ë°°ì¹˜ ì²˜ë¦¬**: ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
3. **ìºì‹±**: ë™ì¼ ì´ë¯¸ì§€ ì¬ë¶„ì„ ë°©ì§€
4. **ë¹„ë™ê¸° ì²˜ë¦¬**: ë³‘ë ¬ API í˜¸ì¶œ

---

## ğŸš€ ë‹¤ìŒ ë‹¨ê³„

### ì¶”ê°€ í•™ìŠµ ì£¼ì œ

1. **ì˜¤ë””ì˜¤ ê°ì • ì¸ì‹**
   - ìŒì„± í†¤, í”¼ì¹˜, í…œí¬ ë¶„ì„
   - OpenSmile ë¼ì´ë¸ŒëŸ¬ë¦¬

2. **ì‹¤ì‹œê°„ ê°ì • ì¸ì‹**
   - ì›¹ìº  ìŠ¤íŠ¸ë¦¬ë°
   - ì‹¤ì‹œê°„ ì²˜ë¦¬ ìµœì í™”

3. **Transformer ëª¨ë¸**
   - BERT for Emotion Classification
   - Fine-tuning ê¸°ë²•

4. **ê°ì • ìƒì„±**
   - Text-to-Emotion
   - Emotion-conditional Image Generation

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ë…¼ë¬¸
- Russell (1980): A Circumplex Model of Affect
- Ekman & Friesen (1971): Constants across cultures
- Mehrabian (1996): PAD Emotion Scales

### API ë¬¸ì„œ
- [Google Gemini](https://ai.google.dev)
- [OpenAI GPT-4o](https://platform.openai.com/docs)
- [Hugging Face Transformers](https://huggingface.co/docs)

### ë¼ì´ë¸ŒëŸ¬ë¦¬
- `google-generativeai`: Gemini API
- `openai`: GPT-4o API
- `transformers`: ì‚¬ì „í›ˆë ¨ ëª¨ë¸
- `matplotlib`: ë°ì´í„° ì‹œê°í™”

---

## â“ Q&A

### ìì£¼ ë¬»ëŠ” ì§ˆë¬¸

**Q1: Geminiì™€ GPT-4o ì¤‘ ì–´ëŠ ê²ƒì´ ë” ì¢‹ë‚˜ìš”?**
A: ë¬´ë£Œë¡œ ì‚¬ìš©í•˜ë ¤ë©´ Gemini, ìµœê³  í’ˆì§ˆì´ í•„ìš”í•˜ë©´ GPT-4oë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.

**Q2: VAD ëª¨ë¸ì´ ì´ì‚° ëª¨ë¸ë³´ë‹¤ í•­ìƒ ì¢‹ë‚˜ìš”?**
A: ì•„ë‹™ë‹ˆë‹¤. ëª…í™•í•œ ë¶„ë¥˜ê°€ í•„ìš”í•œ ê²½ìš° ì´ì‚° ëª¨ë¸ì´ ë” ì§ê´€ì ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

**Q3: ì‹œê³„ì—´ ë¶„ì„ì— ìµœì†Œ ëª‡ ê°œì˜ í”„ë ˆì„ì´ í•„ìš”í•œê°€ìš”?**
A: ìµœì†Œ 3-5ê°œ ì´ìƒì„ ê¶Œì¥í•˜ë©°, íŠ¸ë Œë“œ ë¶„ì„ì€ 10ê°œ ì´ìƒì´ ì¢‹ìŠµë‹ˆë‹¤.

**Q4: ë©€í‹°ëª¨ë‹¬ ë¶„ì„ì´ í•­ìƒ ë” ì •í™•í•œê°€ìš”?**
A: í…ìŠ¤íŠ¸ê°€ ê´€ë ¨ì„±ì´ ë†’ì„ ë•Œë§Œ ë„ì›€ì´ ë©ë‹ˆë‹¤. ë¬´ê´€í•œ í…ìŠ¤íŠ¸ëŠ” ì˜¤íˆë ¤ ë°©í•´ê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

# ğŸ‰ ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤!

Week 8 ê°•ì˜ë¥¼ ë§ˆì¹˜ë©°, ê³ ê¸‰ ê°ì • ì¸ì‹ì˜ í•µì‹¬ ê°œë…ê³¼ ì‹¤ì „ êµ¬í˜„ì„ ëª¨ë‘ ë‹¤ë¤˜ìŠµë‹ˆë‹¤.

**ë‹¤ìŒ ì£¼ ì˜ˆê³ **: ìµœì¢… í”„ë¡œì íŠ¸ ë° í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶•! ğŸš€
