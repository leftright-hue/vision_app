"""
Week 8: ê³ ê¸‰ ê°ì • ì¸ì‹ (Advanced Emotion Recognition)

ë©€í‹°ëª¨ë‹¬ APIë¥¼ í™œìš©í•œ ê³ ê¸‰ ê°ì • ì¸ì‹ Streamlit ëª¨ë“ˆ
"""

import streamlit as st
from typing import Dict, List, Optional, Any
from PIL import Image
import numpy as np

from core.base_processor import BaseImageProcessor
from .emotion_helpers import get_emotion_helper, VADModel, EmotionTimeSeries


class EmotionRecognitionModule(BaseImageProcessor):
    """
    ê³ ê¸‰ ê°ì • ì¸ì‹ ëª¨ë“ˆ

    Google Gemini, OpenAI GPT-4o APIë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤:
    - 7ê°€ì§€ ê¸°ë³¸ ê°ì • ì¸ì‹
    - VAD 3ì°¨ì› ê°ì • ëª¨ë¸
    - ë©€í‹°ëª¨ë‹¬ ë¶„ì„ (ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸)
    - ì‹œê³„ì—´ ê°ì • ì¶”ì 
    """

    def __init__(self):
        """EmotionRecognitionModule ì´ˆê¸°í™”"""
        super().__init__()
        self.name = 'Week 8: Emotion Recognition'

    def render(self):
        """ë©”ì¸ ë Œë”ë§ ë©”ì„œë“œ"""
        st.title('ğŸ­ Week 8: ê³ ê¸‰ ê°ì • ì¸ì‹')

        st.markdown("""
        Google Geminiì™€ OpenAI GPT-4o APIë¥¼ ì‚¬ìš©í•œ ê³ ê¸‰ ê°ì • ì¸ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤.
        """)

        # í™˜ê²½ ì²´í¬
        self._display_environment_status()

        # 5ê°œ íƒ­ ìƒì„±
        tabs = st.tabs([
            'ğŸ“š ê°œë… ì†Œê°œ',
            'ğŸ˜Š ê¸°ë³¸ ê°ì • ì¸ì‹',
            'ğŸ“Š VAD ëª¨ë¸',
            'ğŸ¨ ë©€í‹°ëª¨ë‹¬ ë¶„ì„',
            'ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„'
        ])

        with tabs[0]:
            self.render_theory()

        with tabs[1]:
            self.render_basic_emotion()

        with tabs[2]:
            self.render_vad_model()

        with tabs[3]:
            self.render_multimodal()

        with tabs[4]:
            self.render_timeseries()

    def _display_environment_status(self):
        """í™˜ê²½ ìƒíƒœ í‘œì‹œ"""
        status = self._check_environment()

        cols = st.columns(3)

        with cols[0]:
            if status.get('gemini'):
                st.success('âœ… Google Gemini ì‚¬ìš© ê°€ëŠ¥')
            else:
                st.warning('âš ï¸ Gemini íŒ¨í‚¤ì§€ ì—†ìŒ')

        with cols[1]:
            if status.get('openai'):
                st.success('âœ… OpenAI ì‚¬ìš© ê°€ëŠ¥')
            else:
                st.warning('âš ï¸ OpenAI íŒ¨í‚¤ì§€ ì—†ìŒ')

        with cols[2]:
            if status.get('plotly'):
                st.success('âœ… Plotly ì‚¬ìš© ê°€ëŠ¥')
            else:
                st.warning('âš ï¸ Plotly íŒ¨í‚¤ì§€ ì—†ìŒ')

    def _check_environment(self) -> Dict[str, bool]:
        """íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì—¬ë¶€ í™•ì¸"""
        status = {}

        # Google Gemini
        try:
            import google.generativeai
            status['gemini'] = True
        except ImportError:
            status['gemini'] = False

        # OpenAI
        try:
            import openai
            status['openai'] = True
        except ImportError:
            status['openai'] = False

        # Plotly
        try:
            import plotly
            status['plotly'] = True
        except ImportError:
            status['plotly'] = False

        return status

    def render_theory(self):
        """Tab 1: ê°œë… ì†Œê°œ"""
        st.header('ğŸ“š ê³ ê¸‰ ê°ì • ì¸ì‹ ê°œë…')

        st.markdown("""
        ### ğŸ­ ê°ì • ì¸ì‹ì˜ ë°œì „

        ê°ì • ì¸ì‹ì€ ë‹¨ìˆœí•œ ë¶„ë¥˜ì—ì„œ ì—°ì†ì  ëª¨ë¸ë¡œ ë°œì „í•´ì™”ìŠµë‹ˆë‹¤.
        """)

        # ê¸°ë³¸ ê°ì • vs ë³µì¡í•œ ê°ì •
        col1, col2 = st.columns(2)

        with col1:
            st.subheader('ğŸ“ Ekmanì˜ 6ê°€ì§€ ê¸°ë³¸ ê°ì •')
            st.markdown("""
            Paul Ekmanì´ ì œì•ˆí•œ ë¬¸í™” ë³´í¸ì  ê°ì •:
            - ğŸ˜Š **Happy** (í–‰ë³µ)
            - ğŸ˜¢ **Sad** (ìŠ¬í””)
            - ğŸ˜  **Angry** (ë¶„ë…¸)
            - ğŸ˜¨ **Fear** (ê³µí¬)
            - ğŸ˜² **Surprise** (ë†€ëŒ)
            - ğŸ¤¢ **Disgust** (í˜ì˜¤)

            **ì¥ì **: ë‹¨ìˆœí•˜ê³  ëª…í™•
            **ë‹¨ì **: ë³µì¡í•œ ê°ì • í‘œí˜„ ë¶ˆê°€
            """)

        with col2:
            st.subheader('ğŸŒˆ Plutchikì˜ ê°ì • ë°”í€´')
            st.markdown("""
            Robert Plutchikì˜ 8ê°€ì§€ ê¸°ë³¸ + 24ê°€ì§€ ë³µí•© ê°ì •:
            - 8ê°€ì§€ ê¸°ë³¸ ê°ì •
            - ê°•ë„ì— ë”°ë¥¸ ë³€í™”
            - ë³µí•© ê°ì • (ì˜ˆ: ì‚¬ë‘ = ê¸°ì¨ + ì‹ ë¢°)

            **ì¥ì **: ë³µì¡í•œ ê°ì • í‘œí˜„ ê°€ëŠ¥
            **ë‹¨ì **: ì—¬ì „íˆ ì´ì‚°ì 
            """)

        st.markdown('---')

        # VAD ëª¨ë¸ ì„¤ëª…
        st.subheader('ğŸ¯ VAD 3ì°¨ì› ê°ì • ëª¨ë¸')

        st.markdown("""
        **VAD (Valence-Arousal-Dominance)** ëª¨ë¸ì€ ê°ì •ì„ 3ì°¨ì› ì—°ì† ê³µê°„ìœ¼ë¡œ í‘œí˜„í•©ë‹ˆë‹¤:

        - **Valence (ì›ìê°€)**: ê¸ì •ì  â†” ë¶€ì •ì  (-1.0 ~ 1.0)
        - **Arousal (ê°ì„±)**: ì°¨ë¶„í•¨ â†” í¥ë¶„ (-1.0 ~ 1.0)
        - **Dominance (ì§€ë°°)**: ë³µì¢… â†” ì§€ë°° (-1.0 ~ 1.0)

        **ì¥ì **:
        - ì—°ì†ì ì´ê³  ë¯¸ë¬˜í•œ ê°ì • í‘œí˜„
        - ë¬´í•œí•œ ê°ì • ìƒíƒœ í‘œí˜„ ê°€ëŠ¥
        - ê°ì • ê°„ ìœ ì‚¬ë„ ê³„ì‚° ê°€ëŠ¥
        """)

        # VAD 3D ì‹œê°í™”
        st.subheader('ğŸ”¬ VAD ê³µê°„ ì‹œê°í™”')

        emotions_to_show = st.multiselect(
            'í‘œì‹œí•  ê°ì • ì„ íƒ',
            ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust', 'neutral', 'calm'],
            default=['happy', 'sad', 'angry', 'fear']
        )

        if emotions_to_show:
            vad_points = [VADModel.emotion_to_vad(e) for e in emotions_to_show]
            fig = VADModel.visualize_3d(vad_points, emotions_to_show, 'ê¸°ë³¸ ê°ì •ì˜ VAD ì¢Œí‘œ')
            st.pyplot(fig)

            # ê°ì • ì„¤ëª…
            st.markdown('#### ì„ íƒí•œ ê°ì •ì˜ ì„¤ëª…')
            for emotion in emotions_to_show:
                st.write(VADModel.get_emotion_description(emotion))

        st.markdown('---')

        # ë©€í‹°ëª¨ë‹¬ ë¶„ì„
        st.subheader('ğŸ¨ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„')

        st.markdown("""
        **ë©€í‹°ëª¨ë‹¬ ë¶„ì„**ì€ ì—¬ëŸ¬ ì •ë³´ ì†ŒìŠ¤ë¥¼ í†µí•©í•˜ì—¬ ë” ì •í™•í•œ ê°ì • ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤:

        - ğŸ–¼ï¸ **ì´ë¯¸ì§€**: ì–¼êµ´ í‘œì •, ëª¸ì§“
        - ğŸ“ **í…ìŠ¤íŠ¸**: ì»¨í…ìŠ¤íŠ¸, ìƒí™© ì„¤ëª…
        - ğŸ¤ **ìŒì„±**: í†¤, ì–µì–‘ (ë¯¸êµ¬í˜„)
        - ğŸ¬ **ë¹„ë””ì˜¤**: ì‹œê°„ì  ë³€í™” (ì‹œê³„ì—´ ë¶„ì„)

        ì´ë¯¸ì§€ë§Œìœ¼ë¡œëŠ” ì• ë§¤í•œ ê°ì •ë„ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ ë¶„ì„í•˜ë©´ ì •í™•ë„ê°€ í–¥ìƒë©ë‹ˆë‹¤.

        **ì˜ˆì‹œ**:
        - ì´ë¯¸ì§€: ì›ƒëŠ” ì–¼êµ´ â†’ "í–‰ë³µ"
        - í…ìŠ¤íŠ¸: "ì˜¤ëŠ˜ ì‹œí—˜ì— ë–¨ì–´ì¡Œì–´ìš”" â†’ "ìŠ¬í””"
        - í†µí•©: ì–µì§€ë¡œ ì›ƒëŠ” "ìŠ¬í”” + ê°•ìš”ëœ í–‰ë³µ"
        """)

    def render_basic_emotion(self):
        """Tab 2: ê¸°ë³¸ ê°ì • ì¸ì‹"""
        st.header('ğŸ˜Š ê¸°ë³¸ ê°ì • ì¸ì‹')

        st.markdown("""
        ì´ë¯¸ì§€ì—ì„œ 7ê°€ì§€ ê¸°ë³¸ ê°ì •ì„ ì¸ì‹í•©ë‹ˆë‹¤.
        """)

        # EmotionHelper ê°€ì ¸ì˜¤ê¸°
        helper = get_emotion_helper()
        st.info(f'ğŸ¤– {helper.get_status_message()}')

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            'ê°ì •ì„ ë¶„ì„í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”',
            type=['png', 'jpg', 'jpeg', 'webp'],
            help='ì–¼êµ´ì´ ëª…í™•íˆ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”'
        )

        if uploaded_file is not None:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(uploaded_file)

            # 2ì—´ ë ˆì´ì•„ì›ƒ
            col1, col2 = st.columns([1, 1])

            with col1:
                st.subheader('ì…ë ¥ ì´ë¯¸ì§€')
                st.image(image, use_container_width=True)

                # ì´ë¯¸ì§€ ì •ë³´
                with st.expander('ì´ë¯¸ì§€ ì •ë³´'):
                    stats = self.get_image_stats(image)
                    st.write(f"**í¬ê¸°**: {stats['width']} x {stats['height']}")
                    st.write(f"**ëª¨ë“œ**: {stats['mode']}")

            with col2:
                st.subheader('ê°ì • ë¶„ì„ ê²°ê³¼')

                # ë¶„ì„ ë²„íŠ¼
                if st.button('ğŸ” ê°ì • ë¶„ì„ ì‹œì‘', type='primary', use_container_width=True):
                    with st.spinner('AIê°€ ê°ì •ì„ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                        result = helper.analyze_basic_emotion(image)

                    # ê²°ê³¼ ì €ì¥
                    st.session_state['emotion_result'] = result

                # ê²°ê³¼ í‘œì‹œ
                if 'emotion_result' in st.session_state:
                    result = st.session_state['emotion_result']

                    # ìƒìœ„ 3ê°œ ê°ì •
                    st.markdown('#### ğŸ† Top 3 ê°ì •')
                    sorted_emotions = sorted(result.items(), key=lambda x: x[1], reverse=True)

                    for i, (emotion, score) in enumerate(sorted_emotions[:3], 1):
                        st.metric(
                            label=f"{i}. {emotion.capitalize()}",
                            value=f"{score:.2%}"
                        )

                    # ë°” ì°¨íŠ¸
                    st.markdown('#### ğŸ“Š ì „ì²´ ê°ì • ë¶„ì„')

                    try:
                        import plotly.graph_objects as go

                        fig = go.Figure([
                            go.Bar(
                                x=list(result.keys()),
                                y=list(result.values()),
                                marker_color='lightblue',
                                text=[f'{v:.2%}' for v in result.values()],
                                textposition='outside'
                            )
                        ])

                        fig.update_layout(
                            title='7ê°€ì§€ ê°ì • ì‹ ë¢°ë„',
                            xaxis_title='ê°ì •',
                            yaxis_title='ì‹ ë¢°ë„',
                            yaxis=dict(range=[0, 1]),
                            height=400
                        )

                        st.plotly_chart(fig, use_container_width=True)

                    except ImportError:
                        # Plotly ì—†ìœ¼ë©´ streamlit bar_chart ì‚¬ìš©
                        st.bar_chart(result)

                    # VAD ì¢Œí‘œ
                    st.markdown('#### ğŸ¯ VAD ì¢Œí‘œ')
                    dominant_emotion = max(result.items(), key=lambda x: x[1])[0]
                    v, a, d = VADModel.emotion_to_vad(dominant_emotion)

                    vad_cols = st.columns(3)
                    vad_cols[0].metric('Valence', f'{v:.2f}')
                    vad_cols[1].metric('Arousal', f'{a:.2f}')
                    vad_cols[2].metric('Dominance', f'{d:.2f}')

        else:
            st.info('ğŸ‘† ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ê°ì • ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”')

    def render_vad_model(self):
        """Tab 3: VAD ëª¨ë¸"""
        st.header('ğŸ“Š VAD 3ì°¨ì› ê°ì • ëª¨ë¸')

        st.markdown("""
        VAD ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ê°ì •ì„ 3ì°¨ì› ê³µê°„ì— ë§¤í•‘í•©ë‹ˆë‹¤.
        ì´ë¯¸ì§€ì˜ ì£¼ìš” ê°ì •ì„ VAD ì¢Œí‘œë¡œ ë³€í™˜í•˜ê³  ìœ ì‚¬í•œ ê°ì •ì„ ì°¾ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        """)

        # EmotionHelper ê°€ì ¸ì˜¤ê¸°
        helper = get_emotion_helper()
        st.info(f'ğŸ¤– {helper.get_status_message()}')

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded_file = st.file_uploader(
            'VAD ë¶„ì„í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”',
            type=['png', 'jpg', 'jpeg', 'webp'],
            key='vad_upload'
        )

        if uploaded_file is not None:
            image = Image.open(uploaded_file)

            col1, col2 = st.columns([1, 1])

            with col1:
                st.subheader('ì…ë ¥ ì´ë¯¸ì§€')
                st.image(image, use_container_width=True)

            with col2:
                st.subheader('VAD ë¶„ì„')

                if st.button('ğŸ¯ VAD ë¶„ì„ ì‹œì‘', type='primary', use_container_width=True):
                    with st.spinner('ê°ì •ì„ ë¶„ì„í•˜ê³  VAD ì¢Œí‘œë¥¼ ê³„ì‚° ì¤‘...'):
                        # ê¸°ë³¸ ê°ì • ë¶„ì„
                        emotions = helper.analyze_basic_emotion(image)

                        # ì§€ë°°ì  ê°ì • ì°¾ê¸°
                        dominant_emotion = max(emotions.items(), key=lambda x: x[1])[0]
                        dominant_score = emotions[dominant_emotion]

                        # VAD ì¢Œí‘œ ê³„ì‚°
                        vad = VADModel.emotion_to_vad(dominant_emotion)

                        # ê²°ê³¼ ì €ì¥
                        st.session_state['vad_result'] = {
                            'emotions': emotions,
                            'dominant': dominant_emotion,
                            'score': dominant_score,
                            'vad': vad
                        }

            # ê²°ê³¼ í‘œì‹œ
            if 'vad_result' in st.session_state:
                result = st.session_state['vad_result']

                st.markdown('---')

                # ì£¼ìš” ì •ë³´
                info_col1, info_col2 = st.columns(2)

                with info_col1:
                    st.markdown('#### ğŸ† ì£¼ìš” ê°ì •')
                    st.success(f"**{result['dominant'].upper()}** ({result['score']:.2%})")
                    st.write(VADModel.get_emotion_description(result['dominant']))

                with info_col2:
                    st.markdown('#### ğŸ¯ VAD ì¢Œí‘œ')
                    v, a, d = result['vad']

                    vad_metrics = st.columns(3)
                    vad_metrics[0].metric('Valence', f'{v:+.2f}')
                    vad_metrics[1].metric('Arousal', f'{a:+.2f}')
                    vad_metrics[2].metric('Dominance', f'{d:+.2f}')

                # 3D ì‹œê°í™”
                st.markdown('#### ğŸ”¬ 3D VAD ê³µê°„ ì‹œê°í™”')

                # ê¸°ë³¸ ê°ì •ë“¤ê³¼ í•¨ê»˜ í‘œì‹œ
                base_emotions = ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust', 'neutral']
                base_vad_points = [VADModel.emotion_to_vad(e) for e in base_emotions]
                base_vad_points.append(result['vad'])

                labels = base_emotions + [f"{result['dominant']} (ë¶„ì„ ê²°ê³¼)"]

                fig = VADModel.visualize_3d(
                    base_vad_points,
                    labels,
                    f"{result['dominant'].capitalize()} ê°ì •ì˜ VAD ê³µê°„ ìœ„ì¹˜"
                )
                st.pyplot(fig)

                # ìœ ì‚¬ ê°ì • ì°¾ê¸°
                st.markdown('#### ğŸ” ìœ ì‚¬í•œ ê°ì •')

                similarities = []
                for emotion in VADModel.EMOTION_VAD_MAP.keys():
                    if emotion != result['dominant']:
                        emotion_vad = VADModel.emotion_to_vad(emotion)
                        similarity = VADModel.calculate_similarity(result['vad'], emotion_vad)
                        similarities.append((emotion, similarity))

                # ìƒìœ„ 3ê°œ ìœ ì‚¬ ê°ì •
                similarities.sort(key=lambda x: x[1], reverse=True)

                sim_cols = st.columns(3)
                for i, (emotion, sim) in enumerate(similarities[:3]):
                    with sim_cols[i]:
                        st.metric(
                            label=emotion.capitalize(),
                            value=f'{sim:.1%} ìœ ì‚¬',
                            help=VADModel.get_emotion_description(emotion)
                        )

        else:
            st.info('ğŸ‘† ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ VAD ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”')

    def render_multimodal(self):
        """Tab 4: ë©€í‹°ëª¨ë‹¬ ë¶„ì„"""
        st.header('ğŸ¨ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„')

        st.markdown("""
        ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¶„ì„í•˜ì—¬ ë” ì •í™•í•œ ê°ì • ì¸ì‹ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        **ì‚¬ìš© ì‚¬ë¡€**:
        - ì´ë¯¸ì§€ë§Œìœ¼ë¡œëŠ” ì• ë§¤í•œ ê°ì •ì„ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¡œ ëª…í™•íˆ
        - SNS ê²Œì‹œë¬¼ (ì´ë¯¸ì§€ + ìº¡ì…˜) ê°ì • ë¶„ì„
        - ìƒí™© ì„¤ëª…ê³¼ í•¨ê»˜ í‘œì • í•´ì„
        """)

        # EmotionHelper ê°€ì ¸ì˜¤ê¸°
        helper = get_emotion_helper()
        st.info(f'ğŸ¤– {helper.get_status_message()}')

        # ì…ë ¥ ì˜ì—­
        st.subheader('ğŸ“¥ ì…ë ¥')

        uploaded_file = st.file_uploader(
            'ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”',
            type=['png', 'jpg', 'jpeg', 'webp'],
            key='multimodal_upload'
        )

        text_context = st.text_area(
            'ì¶”ê°€ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ (ì„ íƒ ì‚¬í•­)',
            placeholder='ì˜ˆ: "ì˜¤ëŠ˜ ì‹œí—˜ì— í•©ê²©í–ˆì–´ìš”!" ë˜ëŠ” "ë©´ì ‘ì—ì„œ ë–¨ì–´ì¡ŒìŠµë‹ˆë‹¤..."',
            help='ì´ë¯¸ì§€ì™€ í•¨ê»˜ ê³ ë ¤í•  ìƒí™©ì´ë‚˜ í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”',
            height=100
        )

        if uploaded_file is not None:
            image = Image.open(uploaded_file)

            col1, col2 = st.columns([1, 1])

            with col1:
                st.subheader('ì…ë ¥ ì´ë¯¸ì§€')
                st.image(image, use_container_width=True)

                if text_context:
                    st.info(f'ğŸ“ í…ìŠ¤íŠ¸: "{text_context}"')

            with col2:
                st.subheader('ë¶„ì„ ì˜µì…˜')

                analysis_mode = st.radio(
                    'ë¶„ì„ ëª¨ë“œ ì„ íƒ',
                    ['ì´ë¯¸ì§€ë§Œ ë¶„ì„', 'ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„', 'ë¹„êµ ë¶„ì„ (ì–‘ìª½ ëª¨ë‘)'],
                    help='ì›í•˜ëŠ” ë¶„ì„ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”'
                )

                if st.button('ğŸš€ ë¶„ì„ ì‹œì‘', type='primary', use_container_width=True):
                    with st.spinner('ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì¤‘...'):
                        if analysis_mode == 'ì´ë¯¸ì§€ë§Œ ë¶„ì„' or not text_context:
                            # ì´ë¯¸ì§€ë§Œ ë¶„ì„
                            result = helper.analyze_basic_emotion(image)
                            st.session_state['multimodal_result'] = {
                                'mode': 'image_only',
                                'image_only': result
                            }

                        elif analysis_mode == 'ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„':
                            # í†µí•© ë¶„ì„
                            result = helper.analyze_multimodal(image, text_context)
                            st.session_state['multimodal_result'] = {
                                'mode': 'combined',
                                'combined': result['combined'],
                                'text': text_context
                            }

                        else:  # ë¹„êµ ë¶„ì„
                            # ì–‘ìª½ ëª¨ë‘
                            result = helper.analyze_multimodal(image, text_context)
                            st.session_state['multimodal_result'] = {
                                'mode': 'compare',
                                **result
                            }

            # ê²°ê³¼ í‘œì‹œ
            if 'multimodal_result' in st.session_state:
                result = st.session_state['multimodal_result']

                st.markdown('---')
                st.subheader('ğŸ“Š ë¶„ì„ ê²°ê³¼')

                if result['mode'] == 'image_only':
                    # ì´ë¯¸ì§€ë§Œ
                    st.markdown('#### ì´ë¯¸ì§€ ê°ì • ë¶„ì„')
                    emotions = result['image_only']

                    top3 = sorted(emotions.items(), key=lambda x: x[1], reverse=True)[:3]
                    cols = st.columns(3)
                    for i, (emotion, score) in enumerate(top3):
                        cols[i].metric(f"{i+1}. {emotion.capitalize()}", f"{score:.2%}")

                    try:
                        import plotly.graph_objects as go
                        fig = go.Figure([go.Bar(x=list(emotions.keys()), y=list(emotions.values()))])
                        fig.update_layout(title='ê°ì • ë¶„ì„ ê²°ê³¼', yaxis_title='ì‹ ë¢°ë„')
                        st.plotly_chart(fig, use_container_width=True)
                    except ImportError:
                        st.bar_chart(emotions)

                elif result['mode'] == 'combined':
                    # í†µí•© ë¶„ì„
                    st.markdown('#### ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„')
                    st.caption(f'í…ìŠ¤íŠ¸: "{result["text"]}"')

                    emotions = result['combined']

                    top3 = sorted(emotions.items(), key=lambda x: x[1], reverse=True)[:3]
                    cols = st.columns(3)
                    for i, (emotion, score) in enumerate(top3):
                        cols[i].metric(f"{i+1}. {emotion.capitalize()}", f"{score:.2%}")

                    try:
                        import plotly.graph_objects as go
                        fig = go.Figure([go.Bar(x=list(emotions.keys()), y=list(emotions.values()))])
                        fig.update_layout(title='í†µí•© ê°ì • ë¶„ì„', yaxis_title='ì‹ ë¢°ë„')
                        st.plotly_chart(fig, use_container_width=True)
                    except ImportError:
                        st.bar_chart(emotions)

                else:  # ë¹„êµ ë¶„ì„
                    st.markdown('#### ğŸ“Š ë¹„êµ ë¶„ì„: ì´ë¯¸ì§€ vs í†µí•©')

                    comp_col1, comp_col2 = st.columns(2)

                    with comp_col1:
                        st.markdown('**ğŸ–¼ï¸ ì´ë¯¸ì§€ë§Œ**')
                        image_emotions = result['image_only']
                        top_image = max(image_emotions.items(), key=lambda x: x[1])
                        st.success(f"**{top_image[0].upper()}** ({top_image[1]:.2%})")

                        for emotion, score in sorted(image_emotions.items(), key=lambda x: x[1], reverse=True)[:3]:
                            st.write(f"- {emotion}: {score:.2%}")

                    with comp_col2:
                        st.markdown('**ğŸ¨ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸**')
                        st.caption(f'"{result["text"]}"')
                        combined_emotions = result['combined']
                        top_combined = max(combined_emotions.items(), key=lambda x: x[1])
                        st.success(f"**{top_combined[0].upper()}** ({top_combined[1]:.2%})")

                        for emotion, score in sorted(combined_emotions.items(), key=lambda x: x[1], reverse=True)[:3]:
                            st.write(f"- {emotion}: {score:.2%}")

                    # ì°¨ì´ ë¶„ì„
                    st.markdown('#### ğŸ” ì°¨ì´ ë¶„ì„')

                    difference = result.get('difference', {})
                    if difference:
                        st.write('í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ë¡œ ì¸í•œ ë³€í™”:')

                        # ê°€ì¥ í° ë³€í™”
                        sorted_diff = sorted(difference.items(), key=lambda x: abs(x[1]), reverse=True)

                        diff_cols = st.columns(3)
                        for i, (emotion, diff) in enumerate(sorted_diff[:3]):
                            if abs(diff) > 0.01:
                                with diff_cols[i]:
                                    delta_color = "normal" if diff > 0 else "inverse"
                                    st.metric(
                                        emotion.capitalize(),
                                        f"{diff:+.2%}",
                                        delta=f"{'ì¦ê°€' if diff > 0 else 'ê°ì†Œ'}"
                                    )

        else:
            st.info('ğŸ‘† ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”')

        # ì˜ˆì‹œ
        with st.expander('ğŸ’¡ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ì˜ˆì‹œ'):
            st.markdown("""
            **ì˜ˆì‹œ 1: ì–µì§€ ë¯¸ì†Œ**
            - ì´ë¯¸ì§€: ì›ƒëŠ” í‘œì • â†’ "happy"
            - í…ìŠ¤íŠ¸: "ì˜¤ëŠ˜ ì§ì¥ì—ì„œ í•´ê³ ë‹¹í–ˆì–´ìš”..."
            - í†µí•©: "sad" (í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ê°€ ì‹¤ì œ ê°ì •ì„ ë“œëŸ¬ëƒ„)

            **ì˜ˆì‹œ 2: ê¸ì •ì  ë¬¸ë§¥**
            - ì´ë¯¸ì§€: í‰ë²”í•œ í‘œì • â†’ "neutral"
            - í…ìŠ¤íŠ¸: "ë“œë””ì–´ í•©ê²© í†µì§€ë¥¼ ë°›ì•˜ìŠµë‹ˆë‹¤!"
            - í†µí•©: "happy" (ê¸ì •ì  ìƒí™© ë°˜ì˜)
            """)

    def render_timeseries(self):
        """Tab 5: ì‹œê³„ì—´ ë¶„ì„"""
        st.header('ğŸ“ˆ ì‹œê³„ì—´ ê°ì • ë¶„ì„')

        st.markdown("""
        ì—¬ëŸ¬ ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ê°ì • ë³€í™”ë¥¼ ì¶”ì í•©ë‹ˆë‹¤.

        **ì‚¬ìš© ì‚¬ë¡€**:
        - ë¹„ë””ì˜¤ í”„ë ˆì„ë³„ ê°ì • ë³€í™” ì¶”ì 
        - ì‹œê°„ì— ë”°ë¥¸ ê°ì • íŠ¸ë Œë“œ ë¶„ì„
        - ê¸‰ê²©í•œ ê°ì • ë³€í™” ì‹œì  íƒì§€
        """)

        # EmotionHelper ê°€ì ¸ì˜¤ê¸°
        helper = get_emotion_helper()
        st.info(f'ğŸ¤– {helper.get_status_message()}')

        # ì…ë ¥ íƒ€ì… ì„ íƒ
        input_type = st.radio(
            'ì…ë ¥ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”',
            ['ğŸ“ ì´ë¯¸ì§€ íŒŒì¼ (ì—¬ëŸ¬ ê°œ)', 'ğŸ¬ ë¹„ë””ì˜¤ íŒŒì¼'],
            horizontal=True
        )

        uploaded_files = None
        video_frames = None

        if input_type == 'ğŸ“ ì´ë¯¸ì§€ íŒŒì¼ (ì—¬ëŸ¬ ê°œ)':
            # ë‹¤ì¤‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ
            uploaded_files = st.file_uploader(
                'ì´ë¯¸ì§€ ì—¬ëŸ¬ ê°œë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš” (ì‹œê°„ ìˆœì„œëŒ€ë¡œ)',
                type=['png', 'jpg', 'jpeg', 'webp'],
                accept_multiple_files=True,
                key='timeseries_upload',
                help='ë¶„ì„í•  ì´ë¯¸ì§€ë“¤ì„ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì„ íƒí•˜ì„¸ìš”'
            )

        else:  # ë¹„ë””ì˜¤ íŒŒì¼
            # OpenCV ì²´í¬
            try:
                import cv2
                HAS_OPENCV = True
            except ImportError:
                HAS_OPENCV = False
                st.error('âš ï¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install opencv-python`ì„ ì‹¤í–‰í•˜ì„¸ìš”.')

            if HAS_OPENCV:
                uploaded_video = st.file_uploader(
                    'ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”',
                    type=['mp4', 'avi', 'mov', 'mkv'],
                    key='video_upload',
                    help='ê°ì • ë³€í™”ë¥¼ ë¶„ì„í•  ë¹„ë””ì˜¤ íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”'
                )

                if uploaded_video is not None:
                    # ë¹„ë””ì˜¤ ì˜µì…˜
                    st.subheader('ğŸ¬ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì˜µì…˜')

                    col1, col2 = st.columns(2)
                    with col1:
                        sample_rate = st.slider(
                            'ìƒ˜í”Œë§ ë¹„ìœ¨ (N í”„ë ˆì„ë§ˆë‹¤ 1ê°œ)',
                            min_value=1,
                            max_value=60,
                            value=30,
                            help='30ì´ë©´ 30í”„ë ˆì„ë§ˆë‹¤ 1ê°œì”© ì¶”ì¶œ (FPS 30ì¼ ë•Œ 1ì´ˆë§ˆë‹¤ 1ì¥)'
                        )

                    with col2:
                        max_frames = st.number_input(
                            'ìµœëŒ€ í”„ë ˆì„ ìˆ˜',
                            min_value=10,
                            max_value=500,
                            value=100,
                            help='ì¶”ì¶œí•  ìµœëŒ€ í”„ë ˆì„ ê°œìˆ˜ (API ë¹„ìš© ì ˆê°)'
                        )

                    if st.button('ğŸ¬ ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ', type='primary'):
                        with st.spinner('ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤...'):
                            try:
                                import tempfile
                                import os

                                # ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
                                with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp_file:
                                    tmp_file.write(uploaded_video.read())
                                    tmp_path = tmp_file.name

                                # OpenCVë¡œ í”„ë ˆì„ ì¶”ì¶œ
                                cap = cv2.VideoCapture(tmp_path)

                                if not cap.isOpened():
                                    st.error('ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤')
                                else:
                                    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
                                    fps = cap.get(cv2.CAP_PROP_FPS)

                                    st.info(f'ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: ì´ {total_frames} í”„ë ˆì„, {fps:.2f} FPS')

                                    frames = []
                                    frame_idx = 0
                                    saved_count = 0

                                    progress_bar = st.progress(0)
                                    status_text = st.empty()

                                    while True:
                                        ret, frame = cap.read()
                                        if not ret:
                                            break

                                        # ìƒ˜í”Œë§
                                        if frame_idx % sample_rate == 0:
                                            # BGR â†’ RGB ë³€í™˜
                                            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                                            pil_image = Image.fromarray(rgb_frame)
                                            frames.append(pil_image)
                                            saved_count += 1

                                            status_text.text(f'í”„ë ˆì„ ì¶”ì¶œ ì¤‘... {saved_count}ê°œ')
                                            progress_bar.progress(min(1.0, saved_count / max_frames))

                                            if saved_count >= max_frames:
                                                break

                                        frame_idx += 1

                                    cap.release()
                                    os.unlink(tmp_path)  # ì„ì‹œ íŒŒì¼ ì‚­ì œ

                                    status_text.empty()
                                    progress_bar.empty()

                                    video_frames = frames
                                    st.session_state['video_frames'] = frames
                                    st.success(f'âœ… ì´ {len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ!')

                            except Exception as e:
                                st.error(f'ë¹„ë””ì˜¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}')
                                import traceback
                                st.text(traceback.format_exc())

                # ì„¸ì…˜ ìƒíƒœì—ì„œ í”„ë ˆì„ ê°€ì ¸ì˜¤ê¸°
                if 'video_frames' in st.session_state:
                    video_frames = st.session_state['video_frames']

        # ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ë°ì´í„° í™•ì¸
        images_to_analyze = None

        if uploaded_files:
            images_to_analyze = uploaded_files
            st.success(f'âœ… {len(uploaded_files)}ê°œ ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤')

            # ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸°
            with st.expander(f'ğŸ“ ì—…ë¡œë“œëœ ì´ë¯¸ì§€ ë¯¸ë¦¬ë³´ê¸° ({len(uploaded_files)}ê°œ)'):
                preview_cols = st.columns(min(5, len(uploaded_files)))
                for i, file in enumerate(uploaded_files[:5]):
                    with preview_cols[i]:
                        image = Image.open(file)
                        st.image(image, caption=f'ì´ë¯¸ì§€ {i+1}', use_container_width=True)
                if len(uploaded_files) > 5:
                    st.caption(f'... ì™¸ {len(uploaded_files) - 5}ê°œ ì´ë¯¸ì§€')

        elif video_frames:
            images_to_analyze = video_frames
            st.success(f'âœ… ë¹„ë””ì˜¤ì—ì„œ {len(video_frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œë¨')

            # ì¶”ì¶œëœ í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸°
            with st.expander(f'ğŸ¬ ì¶”ì¶œëœ í”„ë ˆì„ ë¯¸ë¦¬ë³´ê¸° ({len(video_frames)}ê°œ)'):
                preview_cols = st.columns(min(5, len(video_frames)))
                for i, frame in enumerate(video_frames[:5]):
                    with preview_cols[i]:
                        st.image(frame, caption=f'í”„ë ˆì„ {i+1}', use_container_width=True)
                if len(video_frames) > 5:
                    st.caption(f'... ì™¸ {len(video_frames) - 5}ê°œ í”„ë ˆì„')

        # ë¶„ì„ ë²„íŠ¼
        if images_to_analyze:
            if st.button('ğŸ” ì‹œê³„ì—´ ë¶„ì„ ì‹œì‘', type='primary', use_container_width=True):
                # EmotionTimeSeries ê°ì²´ ìƒì„±
                timeseries = EmotionTimeSeries(window_size=len(images_to_analyze))

                # í”„ë¡œê·¸ë ˆìŠ¤ ë°”
                progress_bar = st.progress(0)
                status_text = st.empty()

                # ê° ì´ë¯¸ì§€/í”„ë ˆì„ ë¶„ì„
                for i, item in enumerate(images_to_analyze):
                    status_text.text(f'í”„ë ˆì„ {i+1}/{len(images_to_analyze)} ë¶„ì„ ì¤‘...')

                    # ì´ë¯¸ì§€ ë¡œë“œ
                    if isinstance(item, Image.Image):
                        # ë¹„ë””ì˜¤ í”„ë ˆì„ (ì´ë¯¸ PIL Image)
                        image = item
                    else:
                        # ì—…ë¡œë“œëœ íŒŒì¼
                        image = Image.open(item)

                    # ê°ì • ë¶„ì„
                    emotions = helper.analyze_basic_emotion(image)

                    # íƒ€ì„ìŠ¤íƒ¬í”„ì™€ í•¨ê»˜ ì¶”ê°€
                    timeseries.add_frame(emotions, timestamp=i)

                    # í”„ë¡œê·¸ë ˆìŠ¤ ì—…ë°ì´íŠ¸
                    progress_bar.progress((i + 1) / len(images_to_analyze))

                status_text.empty()
                progress_bar.empty()

                # ê²°ê³¼ ì €ì¥
                st.session_state['timeseries_result'] = timeseries

                st.success(f'âœ… {len(images_to_analyze)}ê°œ í”„ë ˆì„ ë¶„ì„ ì™„ë£Œ!')

            # ê²°ê³¼ í‘œì‹œ
            if 'timeseries_result' in st.session_state:
                timeseries = st.session_state['timeseries_result']

                st.markdown('---')

                # ìš”ì•½ ì •ë³´
                st.subheader('ğŸ“Š ë¶„ì„ ìš”ì•½')

                summary = timeseries.get_summary()

                summary_cols = st.columns(4)
                summary_cols[0].metric('ì´ í”„ë ˆì„ ìˆ˜', summary['total_frames'])
                summary_cols[1].metric('ì§€ë°°ì  ê°ì •', summary['dominant_emotion'].capitalize())
                summary_cols[2].metric('í‰ê·  ì‹ ë¢°ë„', f"{summary['avg_confidence']:.2%}")
                summary_cols[3].metric('ê°ì • ë³€í™”ì ', len(summary['change_points']))

                # ì‹œê³„ì—´ ê·¸ë˜í”„
                st.subheader('ğŸ“ˆ ê°ì • ë³€í™” íƒ€ì„ë¼ì¸')

                try:
                    fig = timeseries.visualize_timeline()
                    st.pyplot(fig)
                except Exception as e:
                    st.error(f'ì‹œê°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}')

                # íŠ¸ë Œë“œ ë¶„ì„
                st.subheader('ğŸ“‰ ê°ì • íŠ¸ë Œë“œ')

                trend_cols = st.columns(4)
                emotions_to_check = ['happy', 'sad', 'angry', 'fear']

                for i, emotion in enumerate(emotions_to_check):
                    trend = timeseries.get_trend(emotion)
                    trend_emoji = {
                        'increasing': 'ğŸ“ˆ ìƒìŠ¹',
                        'decreasing': 'ğŸ“‰ í•˜ë½',
                        'stable': 'â¡ï¸ ì•ˆì •'
                    }
                    with trend_cols[i]:
                        st.write(f"**{emotion.capitalize()}**")
                        st.write(trend_emoji.get(trend, trend))

                # ë³€í™”ì  ë¶„ì„
                st.subheader('ğŸ” ê°ì • ë³€í™”ì  íƒì§€')

                change_points = timeseries.detect_change_points(threshold=0.3)

                if change_points:
                    st.write(f'ê°ì •ì´ í¬ê²Œ ë³€í™”í•œ ì‹œì : **{len(change_points)}ê°œ ë°œê²¬**')

                    # ë³€í™”ì  ìƒì„¸ ì •ë³´
                    with st.expander('ë³€í™”ì  ìƒì„¸ ì •ë³´ ë³´ê¸°'):
                        for idx in change_points:
                            if idx < len(timeseries.history):
                                frame = timeseries.history[idx]
                                prev_frame = timeseries.history[idx - 1] if idx > 0 else None

                                st.markdown(f'**í”„ë ˆì„ {idx + 1}ë²ˆ**')

                                if prev_frame:
                                    # ì´ì „ í”„ë ˆì„ê³¼ ë¹„êµ
                                    prev_dominant = max(prev_frame['emotions'].items(), key=lambda x: x[1])[0]
                                    curr_dominant = max(frame['emotions'].items(), key=lambda x: x[1])[0]

                                    change_cols = st.columns(2)
                                    with change_cols[0]:
                                        st.write(f'ì´ì „: {prev_dominant.capitalize()}')
                                    with change_cols[1]:
                                        st.write(f'â†’ {curr_dominant.capitalize()}')

                                st.markdown('---')
                else:
                    st.info('ê°ì • ë³€í™”ê°€ ì•ˆì •ì ì…ë‹ˆë‹¤ (í° ë³€í™”ì  ì—†ìŒ)')

                # CSV ë‚´ë³´ë‚´ê¸°
                st.subheader('ğŸ’¾ ë°ì´í„° ë‚´ë³´ë‚´ê¸°')

                if st.button('ğŸ“¥ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°'):
                    import tempfile

                    try:
                        # ì„ì‹œ íŒŒì¼ ìƒì„±
                        with tempfile.NamedTemporaryFile(delete=False, suffix='.csv', mode='w') as f:
                            timeseries.export_to_csv(f.name)

                            # íŒŒì¼ ì½ê¸°
                            with open(f.name, 'r', encoding='utf-8') as csv_file:
                                csv_content = csv_file.read()

                            # ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
                            st.download_button(
                                label='ğŸ“¥ CSV ë‹¤ìš´ë¡œë“œ',
                                data=csv_content,
                                file_name='emotion_timeseries.csv',
                                mime='text/csv',
                                use_container_width=True
                            )

                            st.success('âœ… CSV íŒŒì¼ì´ ì¤€ë¹„ë˜ì—ˆìŠµë‹ˆë‹¤!')

                    except Exception as e:
                        st.error(f'CSV ë‚´ë³´ë‚´ê¸° ì‹¤íŒ¨: {e}')

        else:
            st.info('ğŸ‘† ì—¬ëŸ¬ ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ë¥¼ ì—…ë¡œë“œí•˜ì—¬ ì‹œê³„ì—´ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”')

            # ì‚¬ìš© íŒ
            with st.expander('ğŸ’¡ ì‹œê³„ì—´ ë¶„ì„ ì‚¬ìš© íŒ'):
                st.markdown("""
                **ìµœì ì˜ ê²°ê³¼ë¥¼ ìœ„í•œ íŒ**:

                **ì´ë¯¸ì§€ íŒŒì¼ ëª¨ë“œ**:
                1. **ì´ë¯¸ì§€ ìˆœì„œ**: ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”
                2. **í”„ë ˆì„ ìˆ˜**: ìµœì†Œ 3ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ì„¸ìš”
                3. **ì¼ê´€ì„±**: ë¹„ìŠ·í•œ ì¡°ëª…ê³¼ ê°ë„ì˜ ì´ë¯¸ì§€ê°€ ì¢‹ìŠµë‹ˆë‹¤
                4. **ì–¼êµ´ ê°€ì‹œì„±**: ì–¼êµ´ì´ ëª…í™•íˆ ë³´ì´ëŠ” ì´ë¯¸ì§€ë¥¼ ì„ íƒí•˜ì„¸ìš”

                **ë¹„ë””ì˜¤ íŒŒì¼ ëª¨ë“œ**:
                1. **ìƒ˜í”Œë§ ë¹„ìœ¨**: FPSê°€ 30ì´ë©´ sample_rate=30ìœ¼ë¡œ ì„¤ì • ì‹œ 1ì´ˆë§ˆë‹¤ 1í”„ë ˆì„ ì¶”ì¶œ
                2. **ìµœëŒ€ í”„ë ˆì„**: API ë¹„ìš©ì„ ê³ ë ¤í•˜ì—¬ ì ì ˆí•œ í”„ë ˆì„ ìˆ˜ ì„¤ì • (ê¶Œì¥: 50-100ê°œ)
                3. **ë¹„ë””ì˜¤ í˜•ì‹**: MP4, AVI, MOV, MKV ì§€ì› (H.264 ì½”ë± ê¶Œì¥)
                4. **ë¹„ë””ì˜¤ ê¸¸ì´**: ê¸´ ë¹„ë””ì˜¤ëŠ” ìƒ˜í”Œë§ ë¹„ìœ¨ì„ ë†’ì—¬ì„œ í”„ë ˆì„ ìˆ˜ ì¡°ì ˆ

                **ì‚¬ìš© ì˜ˆì‹œ**:
                - ì¸í„°ë·° ë¹„ë””ì˜¤ì—ì„œ ê°ì • ë³€í™” ì¶”ì 
                - í”„ë ˆì  í…Œì´ì…˜ ì¤‘ ì²­ì¤‘ ë°˜ì‘ ë¶„ì„
                - ê°•ì˜ ì˜ìƒì—ì„œ í•™ìƒë“¤ì˜ ì§‘ì¤‘ë„ ì¸¡ì •
                - ìƒë‹´ ì„¸ì…˜ ì¤‘ ë‚´ë‹´ì ê°ì • ë³€í™” ëª¨ë‹ˆí„°ë§
                - ìœ íŠœë¸Œ ì˜ìƒì—ì„œ ì¸ë¬¼ì˜ ê°ì • íƒ€ì„ë¼ì¸ ìƒì„±
                """)

