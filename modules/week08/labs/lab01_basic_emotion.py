"""
Lab 01: ê¸°ë³¸ ê°ì • ì¸ì‹ (Basic Emotion Recognition)

ì´ ì‹¤ìŠµì—ì„œëŠ” Google Gemini APIë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ê°ì • ì¸ì‹ì„ í•™ìŠµí•©ë‹ˆë‹¤:
- 7ê°€ì§€ ê¸°ë³¸ ê°ì • ì¸ì‹ (happy, sad, angry, fear, surprise, disgust, neutral)
- ë‹¨ì¼ ì´ë¯¸ì§€ ë¶„ì„
- ë°°ì¹˜ ì´ë¯¸ì§€ ì²˜ë¦¬
- JSON í˜•ì‹ ê²°ê³¼ ì¶œë ¥

ì‚¬ìš©ë²•:
    python lab01_basic_emotion.py --input image.jpg
    python lab01_basic_emotion.py --input images/ --batch
    python lab01_basic_emotion.py --input image.jpg --output result.json
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Optional
from PIL import Image

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from modules.week08.emotion_helpers import EmotionHelper


def analyze_single_image(
    helper: EmotionHelper,
    image_path: str,
    verbose: bool = True
) -> Dict[str, float]:
    """
    ë‹¨ì¼ ì´ë¯¸ì§€ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        helper: EmotionHelper ì¸ìŠ¤í„´ìŠ¤
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if verbose:
        print(f"ğŸ“· ì´ë¯¸ì§€ ë¶„ì„: {image_path}")

    try:
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = Image.open(image_path)

        if verbose:
            print(f"  - í¬ê¸°: {image.width}x{image.height}")
            print(f"  - ëª¨ë“œ: {image.mode}")

        # ê°ì • ë¶„ì„
        result = helper.analyze_basic_emotion(image)

        if verbose:
            print(f"  - API ëª¨ë“œ: {helper.mode}")
            print()

        return result

    except Exception as e:
        print(f"âŒ ë¶„ì„ ì‹¤íŒ¨: {e}")
        return {}


def analyze_batch_images(
    helper: EmotionHelper,
    input_dir: str,
    extensions: List[str] = ['.jpg', '.jpeg', '.png', '.webp'],
    verbose: bool = True
) -> Dict[str, Dict[str, float]]:
    """
    ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ë¥¼ ë°°ì¹˜ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        helper: EmotionHelper ì¸ìŠ¤í„´ìŠ¤
        input_dir: ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        extensions: ì²˜ë¦¬í•  íŒŒì¼ í™•ì¥ì ëª©ë¡
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        íŒŒì¼ëª…ì„ í‚¤ë¡œ í•˜ëŠ” ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    results = {}

    # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
    image_files = []
    for ext in extensions:
        image_files.extend(Path(input_dir).glob(f"*{ext}"))
        image_files.extend(Path(input_dir).glob(f"*{ext.upper()}"))

    image_files = sorted(set(image_files))

    if not image_files:
        print(f"âš ï¸ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {input_dir}")
        return results

    print(f"ğŸ“ ë°°ì¹˜ ì²˜ë¦¬: {len(image_files)}ê°œ ì´ë¯¸ì§€")
    print(f"  - API ëª¨ë“œ: {helper.mode}")
    print()

    # ê° ì´ë¯¸ì§€ ì²˜ë¦¬
    for i, image_path in enumerate(image_files, 1):
        if verbose:
            print(f"[{i}/{len(image_files)}] {image_path.name}")

        result = analyze_single_image(helper, str(image_path), verbose=False)

        if result:
            results[image_path.name] = result

            # ì§€ë°°ì  ê°ì • í‘œì‹œ
            if verbose:
                dominant = max(result.items(), key=lambda x: x[1])
                print(f"  â†’ {dominant[0].upper()} ({dominant[1]:.2%})")

    print()
    print(f"âœ… ë°°ì¹˜ ë¶„ì„ ì™„ë£Œ: {len(results)}ê°œ ì´ë¯¸ì§€")

    return results


def print_emotion_results(
    results: Dict[str, float],
    title: str = "ê°ì • ë¶„ì„ ê²°ê³¼",
    top_n: int = 3
):
    """
    ê°ì • ë¶„ì„ ê²°ê³¼ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        results: ê°ì • ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        title: ì¶œë ¥ ì œëª©
        top_n: ìƒìœ„ Nê°œ ê°ì •ë§Œ í‘œì‹œ
    """
    print(f"\n{title}")
    print("=" * 50)

    # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_emotions = sorted(results.items(), key=lambda x: x[1], reverse=True)

    # Top N í‘œì‹œ
    print(f"\nğŸ† ìƒìœ„ {top_n}ê°œ ê°ì •:")
    for i, (emotion, score) in enumerate(sorted_emotions[:top_n], 1):
        bar_length = int(score * 30)
        bar = "â–ˆ" * bar_length + "â–‘" * (30 - bar_length)
        print(f"  {i}. {emotion.capitalize():<10} {bar} {score:.2%}")

    # ì „ì²´ ëª©ë¡
    print(f"\nğŸ“Š ì „ì²´ ê°ì • ì‹ ë¢°ë„:")
    for emotion, score in sorted_emotions:
        print(f"  - {emotion.capitalize():<10} : {score:.4f}")


def save_results_to_json(
    results: Dict,
    output_path: str,
    pretty: bool = True
):
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        results: ì €ì¥í•  ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        pretty: ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ… ì—¬ë¶€
    """
    try:
        with open(output_path, 'w', encoding='utf-8') as f:
            if pretty:
                json.dump(results, f, indent=2, ensure_ascii=False)
            else:
                json.dump(results, f, ensure_ascii=False)

        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_path}")

    except Exception as e:
        print(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="Lab 01: Google Gemini APIë¥¼ ì‚¬ìš©í•œ ê¸°ë³¸ ê°ì • ì¸ì‹"
    )

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ ë˜ëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )

    parser.add_argument(
        "--batch",
        action="store_true",
        help="ë°°ì¹˜ ëª¨ë“œ (ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  ì´ë¯¸ì§€ ì²˜ë¦¬)"
    )

    parser.add_argument(
        "--output",
        type=str,
        help="ê²°ê³¼ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ê²½ë¡œ"
    )

    parser.add_argument(
        "--top",
        type=int,
        default=3,
        help="ìƒìœ„ Nê°œ ê°ì • í‘œì‹œ (ê¸°ë³¸ê°’: 3)"
    )

    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ"
    )

    args = parser.parse_args()

    # EmotionHelper ì´ˆê¸°í™”
    print("ğŸ¤– ê°ì • ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")
    helper = EmotionHelper()
    print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {helper.mode} ëª¨ë“œ")
    print()

    # ì…ë ¥ ê²½ë¡œ ê²€ì¦
    input_path = Path(args.input)

    if not input_path.exists():
        print(f"âŒ ì…ë ¥ ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        return

    # ì²˜ë¦¬ ëª¨ë“œ ê²°ì •
    results = None

    if args.batch or input_path.is_dir():
        # ë°°ì¹˜ ëª¨ë“œ
        results = analyze_batch_images(
            helper,
            str(input_path),
            verbose=not args.quiet
        )

        # ë°°ì¹˜ ê²°ê³¼ ìš”ì•½
        if results and not args.quiet:
            print("\nğŸ“ˆ ë°°ì¹˜ ë¶„ì„ ìš”ì•½:")

            # ì „ì²´ ì´ë¯¸ì§€ì—ì„œ ê°€ì¥ ë§ì´ ë‚˜íƒ€ë‚œ ê°ì •
            emotion_counts = {}
            for img_result in results.values():
                dominant = max(img_result.items(), key=lambda x: x[1])[0]
                emotion_counts[dominant] = emotion_counts.get(dominant, 0) + 1

            print("\nê°ì • ë¶„í¬:")
            for emotion, count in sorted(emotion_counts.items(), key=lambda x: x[1], reverse=True):
                percentage = count / len(results) * 100
                print(f"  - {emotion.capitalize():<10} : {count}ê°œ ({percentage:.1f}%)")

    else:
        # ë‹¨ì¼ ì´ë¯¸ì§€ ëª¨ë“œ
        result = analyze_single_image(
            helper,
            str(input_path),
            verbose=not args.quiet
        )

        if result:
            results = {input_path.name: result}

            # ê²°ê³¼ ì¶œë ¥
            if not args.quiet:
                print_emotion_results(result, top_n=args.top)

    # JSON ì €ì¥
    if args.output and results:
        save_results_to_json(results, args.output)

    # JSON ì¶œë ¥ (quiet ëª¨ë“œ)
    if args.quiet and results:
        print(json.dumps(results, ensure_ascii=False))


if __name__ == "__main__":
    main()
