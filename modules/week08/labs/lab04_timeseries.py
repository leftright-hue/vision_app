"""
Lab 04: ì‹œê³„ì—´ ê°ì • ë¶„ì„ (Time Series Emotion Analysis)

ì´ ì‹¤ìŠµì—ì„œëŠ” ì—¬ëŸ¬ ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ì—ì„œ ì‹œê³„ì—´ ê°ì • ë³€í™”ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤:
- ì—¬ëŸ¬ ì´ë¯¸ì§€ ìˆœì°¨ ë¶„ì„
- ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ ë° ë¶„ì„
- ì‹œê³„ì—´ ê·¸ë˜í”„ ì‹œê°í™”
- ê°ì • ë³€í™”ì  íƒì§€
- CSV íŒŒì¼ ì €ì¥

ì‚¬ìš©ë²•:
    python lab04_timeseries.py --images image1.jpg image2.jpg image3.jpg
    python lab04_timeseries.py --input-dir frames/
    python lab04_timeseries.py --video video.mp4 --sample-rate 30
    python lab04_timeseries.py --images *.jpg --output timeline.png --csv results.csv
"""

import os
import sys
import argparse
import time
from pathlib import Path
from typing import List, Optional
from PIL import Image
import matplotlib.pyplot as plt

# OpenCVëŠ” ì„ íƒì  ì˜ì¡´ì„±
try:
    import cv2
    HAS_OPENCV = True
except ImportError:
    HAS_OPENCV = False

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from modules.week08.emotion_helpers import EmotionHelper, EmotionTimeSeries


def extract_video_frames(
    video_path: str,
    sample_rate: int = 30,
    max_frames: Optional[int] = None
) -> List[Image.Image]:
    """
    ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
        sample_rate: N í”„ë ˆì„ë§ˆë‹¤ 1ê°œì”© ì¶”ì¶œ
        max_frames: ìµœëŒ€ ì¶”ì¶œ í”„ë ˆì„ ìˆ˜

    Returns:
        PIL Image ë¦¬ìŠ¤íŠ¸
    """
    if not HAS_OPENCV:
        raise ImportError("ë¹„ë””ì˜¤ ì²˜ë¦¬ë¥¼ ìœ„í•´ OpenCVê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install opencv-python")

    print(f"ğŸ“¹ ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ: {video_path}")
    print(f"   - ìƒ˜í”Œë§ ë¹„ìœ¨: {sample_rate} í”„ë ˆì„ë§ˆë‹¤ 1ê°œ")

    cap = cv2.VideoCapture(video_path)

    if not cap.isOpened():
        raise ValueError(f"ë¹„ë””ì˜¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

    # ë¹„ë””ì˜¤ ì •ë³´
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = cap.get(cv2.CAP_PROP_FPS)

    print(f"   - ì´ í”„ë ˆì„ ìˆ˜: {total_frames}")
    print(f"   - FPS: {fps:.2f}")

    frames = []
    frame_idx = 0
    saved_count = 0

    while True:
        ret, frame = cap.read()

        if not ret:
            break

        # ìƒ˜í”Œë§
        if frame_idx % sample_rate == 0:
            # OpenCV BGR -> RGB ë³€í™˜
            rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(rgb_frame)
            frames.append(pil_image)
            saved_count += 1

            if saved_count % 10 == 0:
                print(f"   ... {saved_count}ê°œ í”„ë ˆì„ ì¶”ì¶œë¨")

            if max_frames and saved_count >= max_frames:
                break

        frame_idx += 1

    cap.release()

    print(f"âœ… ì´ {len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")

    return frames


def load_images_from_paths(image_paths: List[str]) -> List[Image.Image]:
    """
    ì—¬ëŸ¬ ì´ë¯¸ì§€ íŒŒì¼ì„ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        image_paths: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸

    Returns:
        PIL Image ë¦¬ìŠ¤íŠ¸
    """
    print(f"ğŸ“ ì´ë¯¸ì§€ ë¡œë“œ ì¤‘... ({len(image_paths)}ê°œ)")

    images = []

    for i, path in enumerate(image_paths, 1):
        try:
            img = Image.open(path)
            images.append(img)

            if i % 10 == 0:
                print(f"   ... {i}ê°œ ë¡œë“œë¨")

        except Exception as e:
            print(f"âš ï¸ ì´ë¯¸ì§€ ë¡œë“œ ì‹¤íŒ¨: {path} - {e}")

    print(f"âœ… ì´ {len(images)}ê°œ ì´ë¯¸ì§€ ë¡œë“œ ì™„ë£Œ")

    return images


def analyze_timeseries(
    helper: EmotionHelper,
    images: List[Image.Image],
    verbose: bool = True
) -> EmotionTimeSeries:
    """
    ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ìˆœì°¨ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

    Args:
        helper: EmotionHelper ì¸ìŠ¤í„´ìŠ¤
        images: PIL Image ë¦¬ìŠ¤íŠ¸
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        EmotionTimeSeries ì¸ìŠ¤í„´ìŠ¤
    """
    timeseries = EmotionTimeSeries(window_size=len(images))

    print(f"\nğŸ” ê°ì • ë¶„ì„ ì‹œì‘ ({len(images)}ê°œ ì´ë¯¸ì§€)")
    print(f"   - API ëª¨ë“œ: {helper.mode}")

    start_time = time.time()

    for i, image in enumerate(images):
        if verbose and (i % 5 == 0 or i == len(images) - 1):
            print(f"   [{i+1}/{len(images)}] ë¶„ì„ ì¤‘...")

        # ê°ì • ë¶„ì„
        emotions = helper.analyze_basic_emotion(image)

        # ì‹œê³„ì—´ì— ì¶”ê°€
        timeseries.add_frame(emotions, timestamp=i)

    elapsed = time.time() - start_time

    print(f"âœ… ë¶„ì„ ì™„ë£Œ (ì†Œìš” ì‹œê°„: {elapsed:.2f}ì´ˆ)")
    print(f"   - í”„ë ˆì„ë‹¹ í‰ê· : {elapsed/len(images):.3f}ì´ˆ")

    return timeseries


def print_timeseries_summary(timeseries: EmotionTimeSeries):
    """
    ì‹œê³„ì—´ ë¶„ì„ ê²°ê³¼ ìš”ì•½ì„ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        timeseries: EmotionTimeSeries ì¸ìŠ¤í„´ìŠ¤
    """
    summary = timeseries.get_summary()

    print("\n" + "=" * 60)
    print("ğŸ“Š ì‹œê³„ì—´ ë¶„ì„ ìš”ì•½")
    print("=" * 60)

    print(f"\nì´ í”„ë ˆì„ ìˆ˜: {summary['total_frames']}")
    print(f"ì§€ë°°ì  ê°ì •: {summary['dominant_emotion'].upper()}")
    print(f"í‰ê·  ì‹ ë¢°ë„: {summary['avg_confidence']:.2%}")

    # ë³€í™”ì 
    change_points = summary['change_points']
    print(f"\nê°ì • ë³€í™”ì : {len(change_points)}ê°œ")

    if change_points:
        print("  ë³€í™” ë°œìƒ í”„ë ˆì„:")
        for idx in change_points[:5]:
            print(f"    - í”„ë ˆì„ {idx+1}")
        if len(change_points) > 5:
            print(f"    ... ì™¸ {len(change_points)-5}ê°œ")

    # íŠ¸ë Œë“œ ë¶„ì„
    print("\nğŸ“ˆ ê°ì • íŠ¸ë Œë“œ:")
    emotions_to_check = ['happy', 'sad', 'angry', 'fear']

    for emotion in emotions_to_check:
        trend = timeseries.get_trend(emotion)
        trend_symbols = {
            'increasing': 'â†‘ ìƒìŠ¹',
            'decreasing': 'â†“ í•˜ë½',
            'stable': 'â†’ ì•ˆì •'
        }
        print(f"  - {emotion.capitalize():<10} : {trend_symbols.get(trend, trend)}")


def save_timeline_plot(
    timeseries: EmotionTimeSeries,
    output_path: str
):
    """
    ì‹œê³„ì—´ ê·¸ë˜í”„ë¥¼ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        timeseries: EmotionTimeSeries ì¸ìŠ¤í„´ìŠ¤
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    print(f"\nğŸ“ˆ ì‹œê³„ì—´ ê·¸ë˜í”„ ìƒì„± ì¤‘...")

    try:
        fig = timeseries.visualize_timeline()
        plt.savefig(output_path, dpi=150, bbox_inches='tight')
        plt.close(fig)

        print(f"ğŸ’¾ ê·¸ë˜í”„ ì €ì¥: {output_path}")

    except Exception as e:
        print(f"âŒ ê·¸ë˜í”„ ì €ì¥ ì‹¤íŒ¨: {e}")


def save_csv_export(
    timeseries: EmotionTimeSeries,
    output_path: str
):
    """
    ì‹œê³„ì—´ ë°ì´í„°ë¥¼ CSVë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        timeseries: EmotionTimeSeries ì¸ìŠ¤í„´ìŠ¤
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    print(f"\nğŸ’¾ CSV ë‚´ë³´ë‚´ê¸°...")

    try:
        timeseries.export_to_csv(output_path)
        print(f"âœ… CSV ì €ì¥: {output_path}")

    except Exception as e:
        print(f"âŒ CSV ì €ì¥ ì‹¤íŒ¨: {e}")


def main():
    parser = argparse.ArgumentParser(
        description="Lab 04: ì‹œê³„ì—´ ê°ì • ë¶„ì„"
    )

    # ì…ë ¥ ì˜µì…˜
    input_group = parser.add_mutually_exclusive_group(required=True)

    input_group.add_argument(
        "--images",
        type=str,
        nargs='+',
        help="ë¶„ì„í•  ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ (ì—¬ëŸ¬ ê°œ)"
    )

    input_group.add_argument(
        "--input-dir",
        type=str,
        help="ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬ ê²½ë¡œ"
    )

    input_group.add_argument(
        "--video",
        type=str,
        help="ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ"
    )

    # ë¹„ë””ì˜¤ ì˜µì…˜
    parser.add_argument(
        "--sample-rate",
        type=int,
        default=30,
        help="ë¹„ë””ì˜¤ ìƒ˜í”Œë§ ë¹„ìœ¨ (N í”„ë ˆì„ë§ˆë‹¤ 1ê°œ, ê¸°ë³¸ê°’: 30)"
    )

    parser.add_argument(
        "--max-frames",
        type=int,
        help="ìµœëŒ€ ì¶”ì¶œ í”„ë ˆì„ ìˆ˜"
    )

    # ì¶œë ¥ ì˜µì…˜
    parser.add_argument(
        "--output",
        type=str,
        help="ì‹œê³„ì—´ ê·¸ë˜í”„ ì €ì¥ ê²½ë¡œ (ì˜ˆ: timeline.png)"
    )

    parser.add_argument(
        "--csv",
        type=str,
        help="CSV íŒŒì¼ ì €ì¥ ê²½ë¡œ (ì˜ˆ: results.csv)"
    )

    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ"
    )

    args = parser.parse_args()

    # EmotionHelper ì´ˆê¸°í™”
    if not args.quiet:
        print("ğŸ¤– ê°ì • ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    helper = EmotionHelper()

    if not args.quiet:
        print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {helper.mode} ëª¨ë“œ\n")

    # ì´ë¯¸ì§€ ìˆ˜ì§‘
    images = None

    if args.images:
        # ëª…ì‹œì  ì´ë¯¸ì§€ íŒŒì¼ ëª©ë¡
        images = load_images_from_paths(args.images)

    elif args.input_dir:
        # ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ ì°¾ê¸°
        input_dir = Path(args.input_dir)

        if not input_dir.exists():
            print(f"âŒ ë””ë ‰í† ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input_dir}")
            return

        # ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        extensions = ['.jpg', '.jpeg', '.png', '.webp']
        image_files = []

        for ext in extensions:
            image_files.extend(input_dir.glob(f"*{ext}"))
            image_files.extend(input_dir.glob(f"*{ext.upper()}"))

        image_files = sorted(set(image_files))

        if not image_files:
            print(f"âŒ ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input_dir}")
            return

        images = load_images_from_paths([str(f) for f in image_files])

    elif args.video:
        # ë¹„ë””ì˜¤ í”„ë ˆì„ ì¶”ì¶œ
        video_path = Path(args.video)

        if not video_path.exists():
            print(f"âŒ ë¹„ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.video}")
            return

        try:
            images = extract_video_frames(
                str(video_path),
                sample_rate=args.sample_rate,
                max_frames=args.max_frames
            )
        except Exception as e:
            print(f"âŒ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
            return

    if not images:
        print("âŒ ë¶„ì„í•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # ì‹œê³„ì—´ ë¶„ì„
    timeseries = analyze_timeseries(helper, images, verbose=not args.quiet)

    # ê²°ê³¼ ìš”ì•½
    if not args.quiet:
        print_timeseries_summary(timeseries)

    # ì‹œê³„ì—´ ê·¸ë˜í”„ ì €ì¥
    if args.output:
        save_timeline_plot(timeseries, args.output)

    # CSV ì €ì¥
    if args.csv:
        save_csv_export(timeseries, args.csv)

    if not args.quiet:
        print("\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ")


if __name__ == "__main__":
    main()
