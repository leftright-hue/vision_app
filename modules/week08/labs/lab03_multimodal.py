"""
Lab 03: ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„ (Multimodal Emotion Analysis)

ì´ ì‹¤ìŠµì—ì„œëŠ” ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•œ ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„ì„ í•™ìŠµí•©ë‹ˆë‹¤:
- ì´ë¯¸ì§€ ë‹¨ë… ë¶„ì„
- ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„
- ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€
- ì»¨í…ìŠ¤íŠ¸ ì˜í–¥ ë¶„ì„

ì‚¬ìš©ë²•:
    python lab03_multimodal.py --input image.jpg --text "ì˜¤ëŠ˜ ì‹œí—˜ì— ë–¨ì–´ì¡Œì–´ìš”"
    python lab03_multimodal.py --input image.jpg --text "í•©ê²©í–ˆì–´ìš”!" --output result.json
    python lab03_multimodal.py --input image.jpg --text "..." --detect-conflict
"""

import os
import sys
import json
import argparse
from pathlib import Path
from typing import Dict, List, Tuple, Optional
from PIL import Image

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent.parent.parent))

from modules.week08.emotion_helpers import EmotionHelper


def analyze_multimodal(
    helper: EmotionHelper,
    image_path: str,
    text: str,
    verbose: bool = True
) -> Dict:
    """
    ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ ê²°í•©í•œ ë©€í‹°ëª¨ë‹¬ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

    Args:
        helper: EmotionHelper ì¸ìŠ¤í„´ìŠ¤
        image_path: ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ
        text: í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
        verbose: ìƒì„¸ ì¶œë ¥ ì—¬ë¶€

    Returns:
        ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
    """
    if verbose:
        print(f"ğŸ“· ì´ë¯¸ì§€: {image_path}")
        print(f"ğŸ“ í…ìŠ¤íŠ¸: \"{text}\"")
        print()

    # ì´ë¯¸ì§€ ë¡œë“œ
    image = Image.open(image_path)

    # ë©€í‹°ëª¨ë‹¬ ë¶„ì„
    result = helper.analyze_multimodal(image, text)

    if verbose:
        print(f"ğŸ¤– ë¶„ì„ ëª¨ë“œ: {helper.mode}")

    return result


def print_comparison_results(result: Dict, detailed: bool = True):
    """
    ì´ë¯¸ì§€ vs í†µí•© ë¶„ì„ ê²°ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ì¶œë ¥í•©ë‹ˆë‹¤.

    Args:
        result: analyze_multimodal ê²°ê³¼
        detailed: ìƒì„¸ ì •ë³´ ì¶œë ¥ ì—¬ë¶€
    """
    image_only = result['image_only']
    combined = result['combined']
    difference = result['difference']

    # ê°ê°ì˜ ì§€ë°°ì  ê°ì •
    dominant_image = max(image_only.items(), key=lambda x: x[1])
    dominant_combined = max(combined.items(), key=lambda x: x[1])

    print("\n" + "=" * 60)
    print("ğŸ“Š ë©€í‹°ëª¨ë‹¬ ë¶„ì„ ê²°ê³¼")
    print("=" * 60)

    # 1. ì´ë¯¸ì§€ë§Œ ë¶„ì„
    print("\nğŸ–¼ï¸  ì´ë¯¸ì§€ë§Œ ë¶„ì„:")
    print(f"   ì£¼ìš” ê°ì •: {dominant_image[0].upper()} ({dominant_image[1]:.2%})")

    if detailed:
        print("   ì „ì²´ ê°ì •:")
        for emotion, score in sorted(image_only.items(), key=lambda x: x[1], reverse=True)[:3]:
            print(f"     - {emotion.capitalize():<10} : {score:.2%}")

    # 2. í†µí•© ë¶„ì„
    print("\nğŸ¨ ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•©:")
    print(f"   ì£¼ìš” ê°ì •: {dominant_combined[0].upper()} ({dominant_combined[1]:.2%})")

    if detailed:
        print("   ì „ì²´ ê°ì •:")
        for emotion, score in sorted(combined.items(), key=lambda x: x[1], reverse=True)[:3]:
            print(f"     - {emotion.capitalize():<10} : {score:.2%}")

    # 3. ì°¨ì´ ë¶„ì„
    print("\nğŸ” í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì˜í–¥:")

    # í° ë³€í™”ë§Œ í‘œì‹œ
    significant_changes = [(e, d) for e, d in difference.items() if abs(d) > 0.05]
    significant_changes.sort(key=lambda x: abs(x[1]), reverse=True)

    if significant_changes:
        for emotion, diff in significant_changes[:5]:
            direction = "â†‘ ì¦ê°€" if diff > 0 else "â†“ ê°ì†Œ"
            print(f"   {emotion.capitalize():<10} : {diff:+.2%} {direction}")
    else:
        print("   í° ë³€í™” ì—†ìŒ (Â±5% ì´ë‚´)")


def detect_emotion_conflict(
    result: Dict,
    threshold: float = 0.3
) -> Tuple[bool, Optional[str]]:
    """
    ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ê°„ ê°ì • ë¶ˆì¼ì¹˜ë¥¼ ê°ì§€í•©ë‹ˆë‹¤.

    Args:
        result: analyze_multimodal ê²°ê³¼
        threshold: ë¶ˆì¼ì¹˜ íŒë‹¨ ì„ê³„ê°’

    Returns:
        (ë¶ˆì¼ì¹˜ ì—¬ë¶€, ì„¤ëª…) íŠœí”Œ
    """
    image_only = result['image_only']
    combined = result['combined']

    # ê°ê°ì˜ ì§€ë°°ì  ê°ì •
    dominant_image = max(image_only.items(), key=lambda x: x[1])[0]
    dominant_combined = max(combined.items(), key=lambda x: x[1])[0]

    # ê°ì •ì´ ë‹¤ë¥¸ ê²½ìš°
    if dominant_image != dominant_combined:
        # ì‹ ë¢°ë„ ì°¨ì´ í™•ì¸
        image_confidence = image_only[dominant_image]
        combined_confidence = combined[dominant_combined]

        diff = abs(image_confidence - combined.get(dominant_image, 0))

        if diff > threshold:
            explanation = (
                f"ì´ë¯¸ì§€ëŠ” '{dominant_image}'ë¥¼ ë‚˜íƒ€ë‚´ì§€ë§Œ, "
                f"í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ëŠ” '{dominant_combined}'ë¡œ í•´ì„ë©ë‹ˆë‹¤. "
                f"(ì°¨ì´: {diff:.2%})"
            )
            return True, explanation

    return False, None


def analyze_context_impact(result: Dict) -> Dict[str, any]:
    """
    í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ê°€ ê°ì • ë¶„ì„ì— ë¯¸ì¹œ ì˜í–¥ì„ ë¶„ì„í•©ë‹ˆë‹¤.

    Args:
        result: analyze_multimodal ê²°ê³¼

    Returns:
        ì˜í–¥ ë¶„ì„ ê²°ê³¼
    """
    difference = result['difference']

    # ê°€ì¥ í° ë³€í™”
    max_increase = max(difference.items(), key=lambda x: x[1])
    max_decrease = min(difference.items(), key=lambda x: x[1])

    # í‰ê·  ì ˆëŒ€ ë³€í™”ëŸ‰
    avg_change = sum(abs(d) for d in difference.values()) / len(difference)

    # ë³€í™” ë°©í–¥
    increases = {e: d for e, d in difference.items() if d > 0.05}
    decreases = {e: d for e, d in difference.items() if d < -0.05}

    return {
        'max_increase': max_increase,
        'max_decrease': max_decrease,
        'avg_change': avg_change,
        'increases': increases,
        'decreases': decreases,
        'impact_level': 'high' if avg_change > 0.15 else 'medium' if avg_change > 0.08 else 'low'
    }


def save_detailed_report(
    result: Dict,
    image_path: str,
    text: str,
    output_path: str
):
    """
    ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œë¥¼ JSONìœ¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        result: analyze_multimodal ê²°ê³¼
        image_path: ì´ë¯¸ì§€ ê²½ë¡œ
        text: í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    # ë¶ˆì¼ì¹˜ ê°ì§€
    has_conflict, conflict_msg = detect_emotion_conflict(result)

    # ì˜í–¥ ë¶„ì„
    impact = analyze_context_impact(result)

    # ë³´ê³ ì„œ ì‘ì„±
    report = {
        'input': {
            'image': image_path,
            'text': text
        },
        'results': {
            'image_only': result['image_only'],
            'combined': result['combined'],
            'difference': result['difference']
        },
        'analysis': {
            'has_conflict': has_conflict,
            'conflict_message': conflict_msg,
            'context_impact': {
                'level': impact['impact_level'],
                'avg_change': f"{impact['avg_change']:.2%}",
                'max_increase': {
                    'emotion': impact['max_increase'][0],
                    'value': f"{impact['max_increase'][1]:+.2%}"
                },
                'max_decrease': {
                    'emotion': impact['max_decrease'][0],
                    'value': f"{impact['max_decrease'][1]:+.2%}"
                }
            }
        }
    }

    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ ìƒì„¸ ë³´ê³ ì„œ ì €ì¥: {output_path}")


def main():
    parser = argparse.ArgumentParser(
        description="Lab 03: ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„"
    )

    parser.add_argument(
        "--input",
        type=str,
        required=True,
        help="ì…ë ¥ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ"
    )

    parser.add_argument(
        "--text",
        type=str,
        required=True,
        help="í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸"
    )

    parser.add_argument(
        "--output",
        type=str,
        help="ê²°ê³¼ë¥¼ ì €ì¥í•  JSON íŒŒì¼ ê²½ë¡œ"
    )

    parser.add_argument(
        "--detect-conflict",
        action="store_true",
        help="ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€ í™œì„±í™”"
    )

    parser.add_argument(
        "--threshold",
        type=float,
        default=0.3,
        help="ë¶ˆì¼ì¹˜ íŒë‹¨ ì„ê³„ê°’ (ê¸°ë³¸ê°’: 0.3)"
    )

    parser.add_argument(
        "--quiet",
        action="store_true",
        help="ìµœì†Œí•œì˜ ì¶œë ¥ë§Œ í‘œì‹œ"
    )

    args = parser.parse_args()

    # ì…ë ¥ ê²€ì¦
    input_path = Path(args.input)

    if not input_path.exists():
        print(f"âŒ ì…ë ¥ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
        return

    # ê°ì • ì¸ì‹ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    if not args.quiet:
        print("ğŸ¤– ë©€í‹°ëª¨ë‹¬ ê°ì • ë¶„ì„ ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...")

    helper = EmotionHelper()

    if not args.quiet:
        print(f"âœ… ì´ˆê¸°í™” ì™„ë£Œ: {helper.mode} ëª¨ë“œ\n")

    # ë©€í‹°ëª¨ë‹¬ ë¶„ì„
    result = analyze_multimodal(
        helper,
        str(input_path),
        args.text,
        verbose=not args.quiet
    )

    # ê²°ê³¼ ì¶œë ¥
    if not args.quiet:
        print_comparison_results(result, detailed=True)

    # ë¶ˆì¼ì¹˜ ê°ì§€
    if args.detect_conflict:
        print("\n" + "=" * 60)
        print("âš ï¸  ê°ì • ë¶ˆì¼ì¹˜ ê°ì§€")
        print("=" * 60)

        has_conflict, conflict_msg = detect_emotion_conflict(result, args.threshold)

        if has_conflict:
            print(f"\nğŸš¨ ë¶ˆì¼ì¹˜ ê°ì§€ë¨!")
            print(f"   {conflict_msg}")
        else:
            print(f"\nâœ… ê°ì • ì¼ì¹˜ (ì„ê³„ê°’: {args.threshold:.0%})")

    # ì˜í–¥ ë¶„ì„
    if not args.quiet:
        print("\n" + "=" * 60)
        print("ğŸ“ˆ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ ì˜í–¥ ë¶„ì„")
        print("=" * 60)

        impact = analyze_context_impact(result)

        print(f"\nì˜í–¥ ìˆ˜ì¤€: {impact['impact_level'].upper()}")
        print(f"í‰ê·  ë³€í™”ëŸ‰: {impact['avg_change']:.2%}")
        print(f"\nê°€ì¥ ë§ì´ ì¦ê°€í•œ ê°ì •: {impact['max_increase'][0].capitalize()} ({impact['max_increase'][1]:+.2%})")
        print(f"ê°€ì¥ ë§ì´ ê°ì†Œí•œ ê°ì •: {impact['max_decrease'][0].capitalize()} ({impact['max_decrease'][1]:+.2%})")

        if impact['increases']:
            print(f"\nì¦ê°€í•œ ê°ì • ({len(impact['increases'])}ê°œ):")
            for emotion, diff in sorted(impact['increases'].items(), key=lambda x: x[1], reverse=True):
                print(f"  + {emotion.capitalize():<10} : {diff:+.2%}")

        if impact['decreases']:
            print(f"\nê°ì†Œí•œ ê°ì • ({len(impact['decreases'])}ê°œ):")
            for emotion, diff in sorted(impact['decreases'].items(), key=lambda x: x[1]):
                print(f"  - {emotion.capitalize():<10} : {diff:+.2%}")

    # ìƒì„¸ ë³´ê³ ì„œ ì €ì¥
    if args.output:
        save_detailed_report(result, str(input_path), args.text, args.output)

    # JSON ì¶œë ¥ (quiet ëª¨ë“œ)
    if args.quiet:
        print(json.dumps(result, ensure_ascii=False))


if __name__ == "__main__":
    main()
