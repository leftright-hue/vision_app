"""
Emotion Recognition Helper Classes

ì´ ëª¨ë“ˆì€ ê³ ê¸‰ ê°ì • ì¸ì‹ì„ ìœ„í•œ í—¬í¼ í´ë˜ìŠ¤ë“¤ì„ ì œê³µí•©ë‹ˆë‹¤:
- EmotionHelper: ë©€í‹°ëª¨ë‹¬ APIë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ (3-tier fallback)
- VADModel: Valence-Arousal-Dominance 3ì°¨ì› ê°ì • ëª¨ë¸
- EmotionTimeSeries: ì‹œê³„ì—´ ê°ì • ë¶„ì„ ë° ì¶”ì 
"""

import os
import io
import base64
import json
from collections import deque
from typing import Dict, List, Optional, Tuple, Any, Deque
import numpy as np
from PIL import Image
import streamlit as st
from dotenv import load_dotenv

from core.base_processor import BaseImageProcessor

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


class EmotionHelper(BaseImageProcessor):
    """
    ë©€í‹°ëª¨ë‹¬ APIë¥¼ ì‚¬ìš©í•œ ê°ì • ë¶„ì„ í—¬í¼ í´ë˜ìŠ¤

    3-tier fallback ì „ëµ:
    1. Google Gemini API (primary)
    2. OpenAI GPT-4o API (secondary)
    3. Simulation mode (fallback)
    """

    def __init__(self):
        """EmotionHelper ì´ˆê¸°í™”"""
        super().__init__()
        self.mode: Optional[str] = None  # 'gemini', 'openai', 'simulation'
        self.gemini_model = None
        self.openai_client = None

        # API ì´ˆê¸°í™”
        self._initialize_apis()

    def _initialize_apis(self):
        """
        3-tier fallbackìœ¼ë¡œ API ì´ˆê¸°í™”

        ìš°ì„ ìˆœìœ„:
        1. Gemini API
        2. OpenAI API
        3. Simulation mode
        """
        # Try Gemini first
        if self._try_gemini():
            self.mode = 'gemini'
            st.success('âœ… Google Gemini API ì—°ê²° ì„±ê³µ')
            return

        # Try OpenAI as fallback
        if self._try_openai():
            self.mode = 'openai'
            st.success('âœ… OpenAI GPT-4o API ì—°ê²° ì„±ê³µ')
            return

        # Use simulation mode as last resort
        self.mode = 'simulation'
        st.warning('âš ï¸ API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.')

    def _try_gemini(self) -> bool:
        """
        Google Gemini API ì—°ê²° ì‹œë„

        Returns:
            bool: ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            import google.generativeai as genai

            api_key = os.getenv('GOOGLE_API_KEY')
            if not api_key or api_key == 'your_api_key_here':
                return False

            # Gemini API ì„¤ì •
            genai.configure(api_key=api_key)

            # ëª¨ë¸ ìƒì„±
            model_name = os.getenv('GENERATION_MODEL', 'gemini-2.5-pro')
            self.gemini_model = genai.GenerativeModel(model_name)

            return True

        except ImportError:
            st.warning('âš ï¸ google-generativeai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
            return False
        except Exception as e:
            st.warning(f'âš ï¸ Gemini API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}')
            return False

    def _try_openai(self) -> bool:
        """
        OpenAI GPT-4o API ì—°ê²° ì‹œë„

        Returns:
            bool: ì—°ê²° ì„±ê³µ ì—¬ë¶€
        """
        try:
            from openai import OpenAI

            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key or api_key.startswith('your_'):
                return False

            # OpenAI í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            self.openai_client = OpenAI(api_key=api_key)

            return True

        except ImportError:
            st.warning('âš ï¸ openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.')
            return False
        except Exception as e:
            st.warning(f'âš ï¸ OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}')
            return False

    def get_mode(self) -> str:
        """
        í˜„ì¬ ë™ì‘ ëª¨ë“œ ë°˜í™˜

        Returns:
            str: 'gemini', 'openai', ë˜ëŠ” 'simulation'
        """
        return self.mode or 'unknown'

    def is_available(self) -> bool:
        """
        API ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

        Returns:
            bool: APIê°€ ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ True
        """
        return self.mode in ['gemini', 'openai']

    def get_status_message(self) -> str:
        """
        í˜„ì¬ ìƒíƒœ ë©”ì‹œì§€ ë°˜í™˜

        Returns:
            str: ìƒíƒœ ì„¤ëª… ë©”ì‹œì§€
        """
        if self.mode == 'gemini':
            return 'ğŸŸ¢ Google Gemini API ì‚¬ìš© ì¤‘'
        elif self.mode == 'openai':
            return 'ğŸŸ¡ OpenAI GPT-4o API ì‚¬ìš© ì¤‘'
        elif self.mode == 'simulation':
            return 'ğŸ”´ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (API í‚¤ í•„ìš”)'
        else:
            return 'âš« ì•Œ ìˆ˜ ì—†ëŠ” ìƒíƒœ'

    def analyze_basic_emotion(
        self,
        image: Image.Image,
        prompt: Optional[str] = None
    ) -> Dict[str, float]:
        """
        ì´ë¯¸ì§€ì—ì„œ ê¸°ë³¸ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤.

        7ê°€ì§€ ê¸°ë³¸ ê°ì •ì„ ë¶„ì„í•˜ì—¬ ê° ê°ì •ì˜ ì‹ ë¢°ë„ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤:
        - happy (í–‰ë³µ)
        - sad (ìŠ¬í””)
        - angry (ë¶„ë…¸)
        - fear (ê³µí¬)
        - surprise (ë†€ëŒ)
        - disgust (í˜ì˜¤)
        - neutral (ì¤‘ë¦½)

        Args:
            image: ë¶„ì„í•  PIL ì´ë¯¸ì§€
            prompt: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ (ì„ íƒ ì‚¬í•­)

        Returns:
            Dict[str, float]: ê°ì •ëª…: ì‹ ë¢°ë„ (0.0-1.0) ë”•ì…”ë„ˆë¦¬
        """
        if self.mode == 'gemini':
            return self._analyze_with_gemini(image, prompt)
        elif self.mode == 'openai':
            return self._analyze_with_openai(image, prompt)
        else:
            return self._simulate_emotion()

    def _analyze_with_gemini(
        self,
        image: Image.Image,
        prompt: Optional[str] = None
    ) -> Dict[str, float]:
        """
        Google Gemini APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„

        Args:
            image: ë¶„ì„í•  PIL ì´ë¯¸ì§€
            prompt: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸

        Returns:
            Dict[str, float]: ê°ì • ì‹ ë¢°ë„ ë”•ì…”ë„ˆë¦¬
        """
        import re

        try:
            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            analysis_prompt = '''ì´ë¯¸ì§€ ì† ì‚¬ëŒì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

{
  "happy": 0.0,
  "sad": 0.0,
  "angry": 0.0,
  "fear": 0.0,
  "surprise": 0.0,
  "disgust": 0.0,
  "neutral": 0.0
}

ê° ê°’ì€ 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ì…ë‹ˆë‹¤.'''

            if prompt:
                analysis_prompt += f'\n\nì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {prompt}'

            # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (API ë¹„ìš© ì ˆê°)
            max_size = 1024
            if image.width > max_size or image.height > max_size:
                image = self.resize_image(image, (max_size, max_size))

            # Gemini API í˜¸ì¶œ
            response = self.gemini_model.generate_content([analysis_prompt, image])

            # JSON íŒŒì‹±
            return self._parse_emotion_response(response.text)

        except Exception as e:
            st.error(f'âŒ Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}')
            return self._simulate_emotion()

    def _parse_emotion_response(self, text: str) -> Dict[str, float]:
        """
        API ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ê°ì • ë°ì´í„° íŒŒì‹±

        Args:
            text: API ì‘ë‹µ í…ìŠ¤íŠ¸

        Returns:
            Dict[str, float]: ê°ì • ì‹ ë¢°ë„ ë”•ì…”ë„ˆë¦¬
        """
        import re

        try:
            # JSON ë¸”ë¡ ì°¾ê¸° (```json ... ``` ë˜ëŠ” { ... } í˜•íƒœ)
            json_match = re.search(r'```json\s*(\{[^`]+\})\s*```', text, re.DOTALL)
            if not json_match:
                json_match = re.search(r'\{[^}]+\}', text, re.DOTALL)

            if json_match:
                json_str = json_match.group(1) if '```' in text else json_match.group(0)
                emotion_data = json.loads(json_str)

                # 7ê°€ì§€ ê¸°ë³¸ ê°ì •ì´ ëª¨ë‘ ìˆëŠ”ì§€ í™•ì¸
                required_emotions = ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust', 'neutral']
                if all(emotion in emotion_data for emotion in required_emotions):
                    # ê°’ì´ 0.0-1.0 ë²”ìœ„ì¸ì§€ í™•ì¸
                    for emotion in required_emotions:
                        if not isinstance(emotion_data[emotion], (int, float)):
                            raise ValueError(f'Invalid value type for {emotion}')
                        emotion_data[emotion] = max(0.0, min(1.0, float(emotion_data[emotion])))

                    return emotion_data

        except (json.JSONDecodeError, ValueError) as e:
            st.warning(f'âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {str(e)}')

        # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            'happy': 0.0,
            'sad': 0.0,
            'angry': 0.0,
            'fear': 0.0,
            'surprise': 0.0,
            'disgust': 0.0,
            'neutral': 1.0
        }

    def _analyze_with_openai(
        self,
        image: Image.Image,
        prompt: Optional[str] = None
    ) -> Dict[str, float]:
        """
        OpenAI GPT-4o APIë¥¼ ì‚¬ìš©í•˜ì—¬ ê°ì • ë¶„ì„

        Args:
            image: ë¶„ì„í•  PIL ì´ë¯¸ì§€
            prompt: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸

        Returns:
            Dict[str, float]: ê°ì • ì‹ ë¢°ë„ ë”•ì…”ë„ˆë¦¬
        """
        try:
            # ì´ë¯¸ì§€ë¥¼ base64ë¡œ ë³€í™˜
            image_base64 = self._image_to_base64(image)

            # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
            analysis_prompt = '''ì´ë¯¸ì§€ ì† ì‚¬ëŒì˜ ê°ì •ì„ ë¶„ì„í•˜ê³  ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë°˜í™˜í•˜ì„¸ìš”.
ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”:

{
  "happy": 0.0,
  "sad": 0.0,
  "angry": 0.0,
  "fear": 0.0,
  "surprise": 0.0,
  "disgust": 0.0,
  "neutral": 0.0
}

ê° ê°’ì€ 0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì‹ ë¢°ë„ì…ë‹ˆë‹¤.'''

            if prompt:
                analysis_prompt += f'\n\nì¶”ê°€ ì»¨í…ìŠ¤íŠ¸: {prompt}'

            # GPT-4o API í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model="gpt-4o",
                messages=[
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": analysis_prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                max_tokens=500
            )

            # JSON íŒŒì‹±
            return self._parse_emotion_response(response.choices[0].message.content)

        except Exception as e:
            st.error(f'âŒ OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}')
            return self._simulate_emotion()

    def _image_to_base64(self, image: Image.Image) -> str:
        """
        PIL ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜

        OpenAI APIëŠ” base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ë¥¼ ìš”êµ¬í•©ë‹ˆë‹¤.

        Args:
            image: ë³€í™˜í•  PIL ì´ë¯¸ì§€

        Returns:
            str: base64 ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´
        """
        # ì´ë¯¸ì§€ í¬ê¸° ìµœì í™” (API ë¹„ìš© ì ˆê°)
        max_size = 1024
        if image.width > max_size or image.height > max_size:
            # ë¹„ìœ¨ ìœ ì§€í•˜ë©° ë¦¬ì‚¬ì´ì¦ˆ
            ratio = max_size / max(image.width, image.height)
            new_width = int(image.width * ratio)
            new_height = int(image.height * ratio)
            image = image.resize((new_width, new_height), Image.Resampling.LANCZOS)

        # JPEGë¡œ ë³€í™˜í•˜ì—¬ base64 ì¸ì½”ë”©
        buffered = io.BytesIO()

        # RGBë¡œ ë³€í™˜ (JPEGëŠ” RGBA ì§€ì› ì•ˆ í•¨)
        if image.mode in ('RGBA', 'LA', 'P'):
            rgb_image = Image.new('RGB', image.size, (255, 255, 255))
            if image.mode == 'P':
                image = image.convert('RGBA')
            rgb_image.paste(image, mask=image.split()[-1] if image.mode in ('RGBA', 'LA') else None)
            image = rgb_image

        image.save(buffered, format="JPEG", quality=85)
        image_bytes = buffered.getvalue()

        return base64.b64encode(image_bytes).decode('utf-8')

    def _simulate_emotion(self) -> Dict[str, float]:
        """
        ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œ ëœë¤ ê°ì • ìƒì„±

        í…ŒìŠ¤íŠ¸ ë° ë°ëª¨ ëª©ì ìœ¼ë¡œ ì‚¬ìš©ë©ë‹ˆë‹¤.

        Returns:
            Dict[str, float]: ëœë¤ ê°ì • ì‹ ë¢°ë„ ë”•ì…”ë„ˆë¦¬
        """
        import random

        # ëœë¤ ê°ì • ìƒì„±
        emotions = ['happy', 'sad', 'angry', 'fear', 'surprise', 'disgust', 'neutral']
        values = [random.random() for _ in emotions]

        # ì •ê·œí™” (í•©ê³„ê°€ 1.0ì´ ë˜ë„ë¡)
        total = sum(values)
        normalized = {emotion: value / total for emotion, value in zip(emotions, values)}

        return normalized

    def analyze_multimodal(
        self,
        image: Image.Image,
        text: str
    ) -> Dict[str, Any]:
        """
        ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ë¶„ì„ (ë©€í‹°ëª¨ë‹¬ ë¶„ì„)

        ì´ë¯¸ì§€ë§Œ ë¶„ì„í•œ ê²°ê³¼ì™€ í…ìŠ¤íŠ¸ ì»¨í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ê³ ë ¤í•œ ê²°ê³¼ë¥¼ ë¹„êµí•©ë‹ˆë‹¤.

        Args:
            image: ë¶„ì„í•  PIL ì´ë¯¸ì§€
            text: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ í…ìŠ¤íŠ¸

        Returns:
            Dict[str, Any]: {
                'image_only': ì´ë¯¸ì§€ë§Œ ë¶„ì„í•œ ê°ì •,
                'combined': ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„,
                'text': ì…ë ¥ í…ìŠ¤íŠ¸,
                'difference': ë‘ ë¶„ì„ ê²°ê³¼ì˜ ì°¨ì´
            }
        """
        # 1. ì´ë¯¸ì§€ë§Œ ë¶„ì„
        image_only = self.analyze_basic_emotion(image)

        # 2. ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ í†µí•© ë¶„ì„
        if self.mode in ['gemini', 'openai']:
            prompt = f'''ì´ë¯¸ì§€ì™€ ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ í•¨ê»˜ ê³ ë ¤í•˜ì—¬ ê°ì •ì„ ë¶„ì„í•˜ì„¸ìš”.

í…ìŠ¤íŠ¸ ë‚´ìš©: "{text}"

ì´ë¯¸ì§€ì˜ ê°ì •ê³¼ í…ìŠ¤íŠ¸ì˜ ê°ì •ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… ê°ì •ì„ íŒë‹¨í•˜ì„¸ìš”.'''

            combined = self.analyze_basic_emotion(image, prompt)
        else:
            # ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œëŠ” ì´ë¯¸ì§€ ê²°ê³¼ ì¬ì‚¬ìš©
            combined = image_only.copy()

        # 3. ì°¨ì´ ê³„ì‚°
        difference = {}
        for emotion in image_only.keys():
            diff = combined.get(emotion, 0.0) - image_only.get(emotion, 0.0)
            difference[emotion] = diff

        return {
            'image_only': image_only,
            'combined': combined,
            'text': text,
            'difference': difference
        }


@st.cache_resource
def get_emotion_helper() -> EmotionHelper:
    """
    EmotionHelper ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜

    Streamlitì˜ @st.cache_resourceë¥¼ ì‚¬ìš©í•˜ì—¬
    ì„¸ì…˜ ì „ì²´ì—ì„œ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ë§Œ ìƒì„±í•©ë‹ˆë‹¤.

    Returns:
        EmotionHelper: ê°ì • ë¶„ì„ í—¬í¼ ì¸ìŠ¤í„´ìŠ¤
    """
    return EmotionHelper()


class VADModel:
    """
    VAD (Valence-Arousal-Dominance) 3ì°¨ì› ê°ì • ëª¨ë¸

    ê°ì •ì„ 3ì°¨ì› ê³µê°„ì— ë§¤í•‘í•˜ì—¬ í‘œí˜„í•©ë‹ˆë‹¤:
    - Valence (ê°€): ê¸ì •ì  â†” ë¶€ì •ì  (-1.0 ~ 1.0)
    - Arousal (ê°ì„±): ì°¨ë¶„í•¨ â†” í¥ë¶„ (-1.0 ~ 1.0)
    - Dominance (ì§€ë°°): ë³µì¢… â†” ì§€ë°° (-1.0 ~ 1.0)
    """

    # ê¸°ë³¸ ê°ì •ì˜ VAD ì¢Œí‘œ ë§¤í•‘
    EMOTION_VAD_MAP: Dict[str, Tuple[float, float, float]] = {
        'happy': (0.8, 0.5, 0.6),       # ê¸ì •ì , ì¤‘ê°„ ê°ì„±, ì•½ê°„ ì§€ë°°ì 
        'sad': (-0.7, -0.6, -0.5),      # ë¶€ì •ì , ë‚®ì€ ê°ì„±, ë³µì¢…ì 
        'angry': (-0.5, 0.7, 0.8),      # ë¶€ì •ì , ë†’ì€ ê°ì„±, ë§¤ìš° ì§€ë°°ì 
        'fear': (-0.6, 0.7, -0.6),      # ë¶€ì •ì , ë†’ì€ ê°ì„±, ë³µì¢…ì 
        'surprise': (0.2, 0.8, 0.0),    # ì•½ê°„ ê¸ì •, ë§¤ìš° ë†’ì€ ê°ì„±, ì¤‘ë¦½
        'disgust': (-0.6, 0.4, 0.3),    # ë¶€ì •ì , ì¤‘ê°„ ê°ì„±, ì•½ê°„ ì§€ë°°ì 
        'neutral': (0.0, 0.0, 0.0),     # ì¤‘ë¦½
        'calm': (0.3, -0.5, 0.2),       # ì•½ê°„ ê¸ì •, ë‚®ì€ ê°ì„±, ì•½ê°„ ì§€ë°°ì 
    }

    @staticmethod
    def emotion_to_vad(emotion: str) -> Tuple[float, float, float]:
        """
        ê°ì •ëª…ì„ VAD ì¢Œí‘œë¡œ ë³€í™˜

        Args:
            emotion: ê°ì •ëª… (ì˜ˆ: 'happy', 'sad')

        Returns:
            Tuple[float, float, float]: (valence, arousal, dominance)
        """
        return VADModel.EMOTION_VAD_MAP.get(emotion.lower(), (0.0, 0.0, 0.0))

    @staticmethod
    def vad_to_emotion(
        valence: float,
        arousal: float,
        dominance: float
    ) -> str:
        """
        VAD ì¢Œí‘œë¥¼ ê°€ì¥ ê°€ê¹Œìš´ ê°ì •ìœ¼ë¡œ ì—­ë³€í™˜

        Args:
            valence: Valence ê°’ (-1.0 ~ 1.0)
            arousal: Arousal ê°’ (-1.0 ~ 1.0)
            dominance: Dominance ê°’ (-1.0 ~ 1.0)

        Returns:
            str: ê°€ì¥ ê°€ê¹Œìš´ ê°ì •ëª…
        """
        min_distance = float('inf')
        closest_emotion = 'neutral'

        # ëª¨ë“  ê°ì •ê³¼ì˜ ê±°ë¦¬ ê³„ì‚°
        for emotion, (v, a, d) in VADModel.EMOTION_VAD_MAP.items():
            distance = np.sqrt(
                (valence - v) ** 2 +
                (arousal - a) ** 2 +
                (dominance - d) ** 2
            )

            if distance < min_distance:
                min_distance = distance
                closest_emotion = emotion

        return closest_emotion

    @staticmethod
    def calculate_similarity(
        vad1: Tuple[float, float, float],
        vad2: Tuple[float, float, float]
    ) -> float:
        """
        ë‘ VAD ì¢Œí‘œ ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°

        ìœ ì‚¬ë„ëŠ” ìœ í´ë¦¬ë“œ ê±°ë¦¬ë¥¼ ë°˜ì „ì‹œì¼œ 0.0-1.0 ë²”ìœ„ë¡œ ì •ê·œí™”í•©ë‹ˆë‹¤.

        Args:
            vad1: ì²« ë²ˆì§¸ VAD ì¢Œí‘œ
            vad2: ë‘ ë²ˆì§¸ VAD ì¢Œí‘œ

        Returns:
            float: ìœ ì‚¬ë„ (0.0 = ì™„ì „íˆ ë‹¤ë¦„, 1.0 = ë™ì¼)
        """
        # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê³„ì‚°
        distance = np.sqrt(sum((a - b) ** 2 for a, b in zip(vad1, vad2)))

        # 3ì°¨ì› ê³µê°„ì—ì„œ ìµœëŒ€ ê±°ë¦¬ëŠ” sqrt(3) * 2 = 3.46
        # ì •ê·œí™”: 1.0 - (distance / max_distance)
        max_distance = np.sqrt(3 * (2.0 ** 2))  # sqrt(12) = 3.46
        similarity = max(0.0, 1.0 - (distance / max_distance))

        return similarity

    @staticmethod
    def visualize_3d(
        vad_points: List[Tuple[float, float, float]],
        labels: Optional[List[str]] = None,
        title: str = 'VAD 3D Emotion Space'
    ):
        """
        VAD ì¢Œí‘œë¥¼ 3D ì‚°ì ë„ë¡œ ì‹œê°í™”

        Args:
            vad_points: VAD ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸
            labels: ê° ì ì˜ ë ˆì´ë¸” (ì„ íƒ ì‚¬í•­)
            title: ê·¸ë˜í”„ ì œëª©

        Returns:
            matplotlib.figure.Figure: ìƒì„±ëœ Figure ê°ì²´
        """
        import matplotlib.pyplot as plt
        from mpl_toolkits.mplot3d import Axes3D

        fig = plt.figure(figsize=(12, 10))
        ax = fig.add_subplot(111, projection='3d')

        # ì  ê·¸ë¦¬ê¸°
        for i, (v, a, d) in enumerate(vad_points):
            label = labels[i] if labels and i < len(labels) else f'Point {i+1}'
            ax.scatter(v, a, d, s=200, alpha=0.6, label=label)

        # ì¶• ì„¤ì •
        ax.set_xlabel('Valence (ê¸ì • â†” ë¶€ì •)', fontsize=12)
        ax.set_ylabel('Arousal (ê°ì„±)', fontsize=12)
        ax.set_zlabel('Dominance (ì§€ë°°)', fontsize=12)
        ax.set_xlim(-1, 1)
        ax.set_ylim(-1, 1)
        ax.set_zlim(-1, 1)

        # ì œëª© ë° ë²”ë¡€
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(loc='upper left', bbox_to_anchor=(1.05, 1))

        # ê·¸ë¦¬ë“œ
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        return fig

    @staticmethod
    def get_emotion_description(emotion: str) -> str:
        """
        ê°ì •ì— ëŒ€í•œ ì„¤ëª… ë°˜í™˜

        Args:
            emotion: ê°ì •ëª…

        Returns:
            str: ê°ì • ì„¤ëª…
        """
        descriptions = {
            'happy': 'ğŸ˜Š í–‰ë³µ: ê¸ì •ì ì´ê³  ì¦ê±°ìš´ ê°ì •',
            'sad': 'ğŸ˜¢ ìŠ¬í””: ë¶€ì •ì ì´ê³  ìš°ìš¸í•œ ê°ì •',
            'angry': 'ğŸ˜  ë¶„ë…¸: ë¶€ì •ì ì´ê³  ê²©ë ¬í•œ ê°ì •',
            'fear': 'ğŸ˜¨ ê³µí¬: ìœ„í˜‘ì„ ëŠë¼ëŠ” ë¶€ì •ì  ê°ì •',
            'surprise': 'ğŸ˜² ë†€ëŒ: ì˜ˆìƒì¹˜ ëª»í•œ ìê·¹ì— ëŒ€í•œ ë°˜ì‘',
            'disgust': 'ğŸ¤¢ í˜ì˜¤: ë¶ˆì¾Œí•˜ê³  ê±°ë¶€ê°ì´ ë“œëŠ” ê°ì •',
            'neutral': 'ğŸ˜ ì¤‘ë¦½: íŠ¹ë³„í•œ ê°ì •ì´ ì—†ëŠ” ìƒíƒœ',
            'calm': 'ğŸ˜Œ í‰ì˜¨: ì°¨ë¶„í•˜ê³  ì•ˆì •ëœ ê°ì •',
        }
        return descriptions.get(emotion.lower(), f'{emotion}: ì•Œ ìˆ˜ ì—†ëŠ” ê°ì •')


class EmotionTimeSeries:
    """
    ì‹œê³„ì—´ ê°ì • ë¶„ì„ ë° ì¶”ì  í´ë˜ìŠ¤

    ì—¬ëŸ¬ í”„ë ˆì„ì— ê±¸ì¹œ ê°ì • ë³€í™”ë¥¼ ì¶”ì í•˜ê³  ë¶„ì„í•©ë‹ˆë‹¤.
    """

    def __init__(self, window_size: int = 100):
        """
        EmotionTimeSeries ì´ˆê¸°í™”

        Args:
            window_size: ì €ì¥í•  ìµœëŒ€ í”„ë ˆì„ ìˆ˜ (ë©”ëª¨ë¦¬ ì œí•œ)
        """
        self.history: Deque[Dict[str, Any]] = deque(maxlen=window_size)
        self.window_size = window_size

    def add_frame(
        self,
        emotion_data: Dict[str, float],
        timestamp: Optional[float] = None
    ):
        """
        í”„ë ˆì„ë³„ ê°ì • ë°ì´í„° ì¶”ê°€

        Args:
            emotion_data: ê°ì • ì‹ ë¢°ë„ ë”•ì…”ë„ˆë¦¬
            timestamp: íƒ€ì„ìŠ¤íƒ¬í”„ (Noneì´ë©´ í˜„ì¬ ì‹œê°)
        """
        import time

        if timestamp is None:
            timestamp = time.time()

        self.history.append({
            'timestamp': timestamp,
            'emotions': emotion_data.copy()
        })

    def get_trend(self, emotion: str = 'happy') -> str:
        """
        íŠ¹ì • ê°ì •ì˜ ë³€í™” ì¶”ì„¸ ë¶„ì„

        ìµœê·¼ 5ê°œ í”„ë ˆì„ì˜ ì„ í˜• íšŒê·€ ê¸°ìš¸ê¸°ë¡œ ì¶”ì„¸ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.

        Args:
            emotion: ë¶„ì„í•  ê°ì •ëª…

        Returns:
            str: 'increasing', 'decreasing', ë˜ëŠ” 'stable'
        """
        if len(self.history) < 5:
            return 'stable'

        # ìµœê·¼ 5ê°œ í”„ë ˆì„ì˜ ê°ì • ê°’ ì¶”ì¶œ
        values = [frame['emotions'].get(emotion, 0.0) for frame in list(self.history)[-5:]]

        # ì„ í˜• íšŒê·€ë¡œ ê¸°ìš¸ê¸° ê³„ì‚°
        x = np.arange(len(values))
        slope = np.polyfit(x, values, 1)[0]

        # ê¸°ìš¸ê¸°ë¡œ ì¶”ì„¸ íŒë‹¨
        if slope > 0.05:
            return 'increasing'
        elif slope < -0.05:
            return 'decreasing'
        else:
            return 'stable'

    def detect_change_points(self, threshold: float = 0.3) -> List[int]:
        """
        ê¸‰ê²©í•œ ê°ì • ë³€í™” ì§€ì  ê°ì§€

        ì—°ì†ëœ í”„ë ˆì„ ê°„ ê°ì • ë³€í™”ê°€ thresholdë¥¼ ì´ˆê³¼í•˜ëŠ” ì§€ì ì„ ì°¾ìŠµë‹ˆë‹¤.

        Args:
            threshold: ë³€í™” ê°ì§€ ì„ê³„ê°’ (0.0-1.0)

        Returns:
            List[int]: ë³€í™” ì§€ì  ì¸ë±ìŠ¤ ë¦¬ìŠ¤íŠ¸
        """
        if len(self.history) < 2:
            return []

        change_points = []

        for i in range(1, len(self.history)):
            prev_emotions = self.history[i - 1]['emotions']
            curr_emotions = self.history[i]['emotions']

            # ëª¨ë“  ê°ì •ì˜ ë³€í™”ëŸ‰ ê³„ì‚°
            max_change = 0.0
            for emotion in prev_emotions.keys():
                change = abs(curr_emotions.get(emotion, 0.0) - prev_emotions.get(emotion, 0.0))
                max_change = max(max_change, change)

            # ì„ê³„ê°’ ì´ˆê³¼ ì‹œ ë³€í™”ì ìœ¼ë¡œ ê¸°ë¡
            if max_change > threshold:
                change_points.append(i)

        return change_points

    def visualize_timeline(
        self,
        emotions: Optional[List[str]] = None,
        title: str = 'Emotion Timeline'
    ):
        """
        ì‹œê³„ì—´ ê°ì • ê·¸ë˜í”„ ìƒì„±

        Args:
            emotions: í‘œì‹œí•  ê°ì • ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ì£¼ìš” 3ê°œ)
            title: ê·¸ë˜í”„ ì œëª©

        Returns:
            matplotlib.figure.Figure: ìƒì„±ëœ Figure ê°ì²´
        """
        import matplotlib.pyplot as plt

        if not self.history:
            return None

        if emotions is None:
            emotions = ['happy', 'sad', 'angry']

        fig, ax = plt.subplots(figsize=(14, 7))

        # ê° ê°ì •ì˜ ì‹œê³„ì—´ ë°ì´í„° í”Œë¡¯
        for emotion in emotions:
            values = [frame['emotions'].get(emotion, 0.0) for frame in self.history]
            ax.plot(values, label=emotion.capitalize(), linewidth=2, marker='o', markersize=4)

        # ë³€í™”ì  í‘œì‹œ
        change_points = self.detect_change_points()
        if change_points:
            for cp in change_points:
                ax.axvline(x=cp, color='red', linestyle='--', alpha=0.3, linewidth=1)

        # ì¶• ë° ë ˆì´ë¸” ì„¤ì •
        ax.set_xlabel('Frame Index', fontsize=12)
        ax.set_ylabel('Confidence (0-1)', fontsize=12)
        ax.set_title(title, fontsize=14, fontweight='bold')
        ax.legend(loc='upper left', fontsize=10)
        ax.grid(True, alpha=0.3)
        ax.set_ylim(-0.05, 1.05)

        plt.tight_layout()
        return fig

    def export_to_csv(self, filepath: str):
        """
        ê°ì • ë°ì´í„°ë¥¼ CSV íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸°

        Args:
            filepath: ì €ì¥í•  CSV íŒŒì¼ ê²½ë¡œ
        """
        if not self.history:
            raise ValueError("No data to export")

        # ë°ì´í„° ë³€í™˜
        data = []
        for frame in self.history:
            row = {'timestamp': frame['timestamp']}
            row.update(frame['emotions'])
            data.append(row)

        # pandas DataFrameìœ¼ë¡œ ë³€í™˜ í›„ CSV ì €ì¥
        try:
            import pandas as pd
            df = pd.DataFrame(data)
            df.to_csv(filepath, index=False)
        except ImportError:
            # pandas ì—†ìœ¼ë©´ ê¸°ë³¸ CSV ì‘ì„±
            import csv
            with open(filepath, 'w', newline='') as f:
                if data:
                    fieldnames = list(data[0].keys())
                    writer = csv.DictWriter(f, fieldnames=fieldnames)
                    writer.writeheader()
                    writer.writerows(data)

    def get_summary(self) -> Dict[str, Any]:
        """
        ì‹œê³„ì—´ ë°ì´í„° ìš”ì•½ í†µê³„

        Returns:
            Dict[str, Any]: í†µê³„ ì •ë³´ ë”•ì…”ë„ˆë¦¬
        """
        if not self.history:
            return {}

        # ëª¨ë“  ê°ì •ì˜ í‰ê· ê°’ ê³„ì‚°
        all_emotions = set()
        for frame in self.history:
            all_emotions.update(frame['emotions'].keys())

        summary = {}
        for emotion in all_emotions:
            values = [frame['emotions'].get(emotion, 0.0) for frame in self.history]
            summary[emotion] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values),
                'trend': self.get_trend(emotion)
            }

        return summary
