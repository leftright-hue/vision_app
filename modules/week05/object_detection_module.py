"""
Week 5: ê°ì²´ íƒì§€ì™€ YOLO ëª¨ë“ˆ
ê°ì²´ íƒì§€ ì´ë¡ , R-CNN ê³„ì—´, YOLO ì•„í‚¤í…ì²˜, ì‹¤ì „ í”„ë¡œì íŠ¸
"""

import streamlit as st
import numpy as np
import cv2
from PIL import Image
import matplotlib.pyplot as plt
import io
import os
import google.generativeai as genai

class ObjectDetectionModule:
    def __init__(self):
        self.name = "Week 5: Object Detection & YOLO"

    def render(self):
        st.title("ğŸ¯ Week 5: ê°ì²´ íƒì§€ì™€ YOLO")
        st.markdown("**ê°ì²´ íƒì§€ì˜ ì´ë¡ ë¶€í„° YOLO ì‹¤ì „ êµ¬í˜„ê¹Œì§€**")

        tabs = st.tabs([
            "ğŸ“– ì´ë¡ ",
            "ğŸ” IoU & mAP",
            "ğŸ—ï¸ R-CNN ê³„ì—´",
            "âš¡ YOLO ë°œì „ì‚¬",
            "ğŸ¨ NMS",
            "ğŸ’» ì‹¤ì „ í”„ë¡œì íŠ¸"
        ])

        with tabs[0]:
            self.render_theory()

        with tabs[1]:
            self.render_iou_map()

        with tabs[2]:
            self.render_rcnn()

        with tabs[3]:
            self.render_yolo()

        with tabs[4]:
            self.render_nms()

        with tabs[5]:
            self.render_projects()

    def render_theory(self):
        """ê°ì²´ íƒì§€ ê¸°ì´ˆ ì´ë¡ """
        st.header("ğŸ“– ê°ì²´ íƒì§€ ê¸°ì´ˆ ì´ë¡ ")

        theory_tabs = st.tabs(["ê°œìš”", "êµ¬ì„± ìš”ì†Œ", "í‰ê°€ ì§€í‘œ"])

        with theory_tabs[0]:
            st.subheader("1. ê°ì²´ íƒì§€ë€?")

            st.markdown("""
            ### ì •ì˜
            **ê°ì²´ íƒì§€(Object Detection)**: ì´ë¯¸ì§€ì—ì„œ ê´€ì‹¬ ìˆëŠ” ê°ì²´ë“¤ì„ ì°¾ì•„ë‚´ê³ ,
            ê° ê°ì²´ì˜ ìœ„ì¹˜ë¥¼ ë°”ìš´ë”© ë°•ìŠ¤ë¡œ í‘œì‹œí•˜ë©°, ê°ì²´ì˜ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ì‘ì—…

            ### ì´ë¯¸ì§€ ë¶„ë¥˜ vs ê°ì²´ íƒì§€
            """)

            col1, col2 = st.columns(2)

            with col1:
                st.info("""
                **ì´ë¯¸ì§€ ë¶„ë¥˜ (Classification)**
                - ì…ë ¥: ì´ë¯¸ì§€
                - ì¶œë ¥: í´ë˜ìŠ¤ ë¼ë²¨ (ì˜ˆ: "ê³ ì–‘ì´")
                - ëª©ì : "ë¬´ì—‡ì¸ê°€?"
                """)

            with col2:
                st.success("""
                **ê°ì²´ íƒì§€ (Detection)**
                - ì…ë ¥: ì´ë¯¸ì§€
                - ì¶œë ¥: í´ë˜ìŠ¤ + ìœ„ì¹˜ + ì‹ ë¢°ë„
                - ëª©ì : "ë¬´ì—‡ì´ ì–´ë””ì—?"
                """)

            st.markdown("### ê°ì²´ íƒì§€ì˜ ë„ì „ê³¼ì œ")

            challenges = {
                "ë‹¤ì¤‘ ê°ì²´": "í•˜ë‚˜ì˜ ì´ë¯¸ì§€ì— ì—¬ëŸ¬ ê°ì²´ê°€ ì¡´ì¬",
                "ë‹¤ì–‘í•œ í¬ê¸°": "ê°™ì€ í´ë˜ìŠ¤ë¼ë„ í¬ê¸°ê°€ ë‹¤ì–‘í•¨",
                "ê°€ë ¤ì§(Occlusion)": "ê°ì²´ë“¤ì´ ì„œë¡œ ê²¹ì³ìˆìŒ",
                "ë°°ê²½ ë³µì¡ì„±": "ë³µì¡í•œ ë°°ê²½ì—ì„œ ê°ì²´ êµ¬ë¶„",
                "ì‹¤ì‹œê°„ ì²˜ë¦¬": "ë¹ ë¥¸ ì¶”ë¡  ì†ë„ ìš”êµ¬"
            }

            for challenge, description in challenges.items():
                st.markdown(f"**{challenge}**: {description}")

        with theory_tabs[1]:
            st.subheader("2. í•µì‹¬ êµ¬ì„± ìš”ì†Œ")

            st.markdown("### 1) ë°”ìš´ë”© ë°•ìŠ¤ (Bounding Box)")

            st.code("""
# ë°”ìš´ë”© ë°•ìŠ¤ í‘œí˜„ ë°©ì‹ë“¤
bbox_formats = {
    "xyxy": [x_min, y_min, x_max, y_max],           # ì¢Œìƒë‹¨, ìš°í•˜ë‹¨
    "xywh": [x_center, y_center, width, height],    # ì¤‘ì‹¬ì ê³¼ í¬ê¸°
    "cxcywh": [cx, cy, w, h],                       # ì •ê·œí™”ëœ ì¤‘ì‹¬ì 
}
            """, language="python")

            st.markdown("### 2) ì‹ ë¢°ë„ ì ìˆ˜ (Confidence Score)")
            st.latex(r"\text{Confidence} = P(\text{object}) \times \text{IoU}(\text{pred}, \text{true})")

            st.markdown("""
            - **P(object)**: í•´ë‹¹ ìœ„ì¹˜ì— ê°ì²´ê°€ ìˆì„ í™•ë¥ 
            - **IoU**: ì˜ˆì¸¡ ë°•ìŠ¤ì™€ ì‹¤ì œ ë°•ìŠ¤ì˜ ê²¹ì¹¨ ì •ë„
            """)

            st.markdown("### 3) í´ë˜ìŠ¤ í™•ë¥  (Class Probability)")
            st.code("""
# ê° í´ë˜ìŠ¤ì— ëŒ€í•œ í™•ë¥  ë¶„í¬
class_probs = softmax([logit_cat, logit_dog, logit_car, ...])
# ì˜ˆ: [0.7, 0.2, 0.05, 0.03, 0.02]
            """, language="python")

        with theory_tabs[2]:
            st.subheader("3. í‰ê°€ ì§€í‘œ")

            st.markdown("### IoU (Intersection over Union)")

            st.latex(r"\text{IoU} = \frac{\text{Area of Overlap}}{\text{Area of Union}}")

            st.markdown("""
            **IoU í•´ì„:**
            - IoU > 0.5: "ì¢‹ì€" íƒì§€
            - IoU > 0.7: "ë§¤ìš° ì¢‹ì€" íƒì§€
            - IoU > 0.9: "ê±°ì˜ ì™„ë²½í•œ" íƒì§€
            """)

            # IoU ì‹œë®¬ë ˆì´ì…˜
            st.markdown("#### IoU ê³„ì‚° ì‹œë®¬ë ˆì´ì…˜")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("**Ground Truth Box**")
                gt_x1 = st.slider("GT X1", 0, 100, 20, key="gt_x1")
                gt_y1 = st.slider("GT Y1", 0, 100, 20, key="gt_y1")
                gt_x2 = st.slider("GT X2", 0, 100, 60, key="gt_x2")
                gt_y2 = st.slider("GT Y2", 0, 100, 60, key="gt_y2")

            with col2:
                st.markdown("**Predicted Box**")
                pred_x1 = st.slider("Pred X1", 0, 100, 25, key="pred_x1")
                pred_y1 = st.slider("Pred Y1", 0, 100, 25, key="pred_y1")
                pred_x2 = st.slider("Pred X2", 0, 100, 65, key="pred_x2")
                pred_y2 = st.slider("Pred Y2", 0, 100, 65, key="pred_y2")

            # IoU ê³„ì‚°
            iou = self.calculate_iou(
                [gt_x1, gt_y1, gt_x2, gt_y2],
                [pred_x1, pred_y1, pred_x2, pred_y2]
            )

            st.metric("IoU", f"{iou:.3f}")

            # ì‹œê°í™”
            fig, ax = plt.subplots(figsize=(6, 6))
            ax.set_xlim(0, 100)
            ax.set_ylim(0, 100)
            ax.set_aspect('equal')

            # Ground Truth (íŒŒë€ìƒ‰)
            gt_rect = plt.Rectangle((gt_x1, gt_y1), gt_x2-gt_x1, gt_y2-gt_y1,
                                    linewidth=2, edgecolor='blue', facecolor='none',
                                    label='Ground Truth')
            ax.add_patch(gt_rect)

            # Prediction (ë¹¨ê°„ìƒ‰)
            pred_rect = plt.Rectangle((pred_x1, pred_y1), pred_x2-pred_x1, pred_y2-pred_y1,
                                      linewidth=2, edgecolor='red', facecolor='none',
                                      label='Prediction')
            ax.add_patch(pred_rect)

            ax.legend()
            ax.set_title(f'IoU = {iou:.3f}')
            ax.grid(True, alpha=0.3)

            st.pyplot(fig)
            plt.close()

            st.markdown("### mAP (mean Average Precision)")
            st.markdown("""
            **mAP ë³€í˜•ë“¤:**
            - **mAP@0.5**: IoU ì„ê³„ê°’ 0.5ì—ì„œì˜ mAP
            - **mAP@0.5:0.95**: IoU 0.5ë¶€í„° 0.95ê¹Œì§€ 0.05 ê°„ê²©ìœ¼ë¡œ í‰ê· 
            - **mAP@small/medium/large**: ê°ì²´ í¬ê¸°ë³„ mAP
            """)

    def render_iou_map(self):
        """IoUì™€ mAP ìƒì„¸ ì„¤ëª…"""
        st.header("ğŸ” IoU & mAP ì‹¬í™”")

        iou_tabs = st.tabs(["IoU ê³„ì‚°", "Precision-Recall", "mAP"])

        with iou_tabs[0]:
            st.subheader("IoU ê³„ì‚° ì‹¤ìŠµ")

            st.code("""
def calculate_iou(box1, box2):
    # êµì§‘í•© ì˜ì—­ ê³„ì‚°
    x1 = max(box1[0], box2[0])
    y1 = max(box1[1], box2[1])
    x2 = min(box1[2], box2[2])
    y2 = min(box1[3], box2[3])

    intersection = max(0, x2 - x1) * max(0, y2 - y1)

    # ê° ë°•ìŠ¤ì˜ ë©´ì 
    area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
    area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])

    # í•©ì§‘í•© ë©´ì 
    union = area1 + area2 - intersection

    return intersection / union if union > 0 else 0
            """, language="python")

        with iou_tabs[1]:
            st.subheader("Precision-Recall ê³¡ì„ ")

            st.markdown("""
            ### Precisionê³¼ Recall
            """)

            col1, col2 = st.columns(2)

            with col1:
                st.latex(r"\text{Precision} = \frac{TP}{TP + FP}")
                st.info("ì •ë°€ë„: ì˜ˆì¸¡í•œ ê²ƒ ì¤‘ ì‹¤ì œë¡œ ë§ì€ ë¹„ìœ¨")

            with col2:
                st.latex(r"\text{Recall} = \frac{TP}{TP + FN}")
                st.info("ì¬í˜„ìœ¨: ì‹¤ì œ ê°ì²´ ì¤‘ ì°¾ì•„ë‚¸ ë¹„ìœ¨")

            # PR ê³¡ì„  ì‹œë®¬ë ˆì´ì…˜
            st.markdown("#### PR ê³¡ì„  ì˜ˆì‹œ")

            # ìƒ˜í”Œ ë°ì´í„° ìƒì„±
            recall = np.linspace(0, 1, 100)
            precision = 1 - recall * 0.3 + np.random.normal(0, 0.05, 100)
            precision = np.clip(precision, 0, 1)

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.plot(recall, precision, 'b-', linewidth=2)
            ax.fill_between(recall, 0, precision, alpha=0.3)
            ax.set_xlabel('Recall', fontsize=12)
            ax.set_ylabel('Precision', fontsize=12)
            ax.set_title('Precision-Recall Curve', fontsize=14)
            ax.grid(True, alpha=0.3)
            ax.set_xlim(0, 1)
            ax.set_ylim(0, 1)

            # AP ê³„ì‚° (ê³¡ì„  ì•„ë˜ ë©´ì )
            ap = np.trapz(precision, recall)
            ax.text(0.6, 0.9, f'AP = {ap:.3f}', fontsize=14,
                   bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

            st.pyplot(fig)
            plt.close()

        with iou_tabs[2]:
            st.subheader("mAP ê³„ì‚°")

            st.markdown("""
            ### Average Precision (AP)

            APëŠ” Precision-Recall ê³¡ì„  ì•„ë˜ì˜ ë©´ì ì…ë‹ˆë‹¤.
            """)

            st.code("""
def calculate_ap(precisions, recalls):
    # 11-point interpolation
    ap = 0
    for t in np.arange(0, 1.1, 0.1):  # 0.0, 0.1, ..., 1.0
        if np.sum(recalls >= t) == 0:
            p = 0
        else:
            p = np.max(precisions[recalls >= t])
        ap += p / 11
    return ap

def calculate_map(all_aps):
    # ëª¨ë“  í´ë˜ìŠ¤ì˜ AP í‰ê· 
    return np.mean(all_aps)
            """, language="python")

            st.markdown("### mAP@0.5:0.95")
            st.markdown("""
            COCO ë°ì´í„°ì…‹ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì£¼ìš” ì§€í‘œ:
            - IoU ì„ê³„ê°’ì„ 0.5ë¶€í„° 0.95ê¹Œì§€ 0.05 ê°„ê²©ìœ¼ë¡œ ë³€ê²½
            - ê° ì„ê³„ê°’ì—ì„œ AP ê³„ì‚°
            - ëª¨ë“  APì˜ í‰ê·  ê³„ì‚°
            """)

    def render_rcnn(self):
        """R-CNN ê³„ì—´ ì„¤ëª…"""
        st.header("ğŸ—ï¸ R-CNN ê³„ì—´ì˜ ë°œì „")

        rcnn_tabs = st.tabs(["R-CNN", "Fast R-CNN", "Faster R-CNN", "ë¹„êµ"])

        with rcnn_tabs[0]:
            st.subheader("R-CNN (2014)")

            st.markdown("""
            ### í•µì‹¬ ì•„ì´ë””ì–´
            1. **Region Proposal**: Selective Searchë¡œ ê°ì²´ê°€ ìˆì„ ë§Œí•œ ì˜ì—­ ì œì•ˆ
            2. **CNN Feature Extraction**: ê° ì˜ì—­ì—ì„œ CNNìœ¼ë¡œ íŠ¹ì§• ì¶”ì¶œ
            3. **Classification**: SVMìœ¼ë¡œ ê°ì²´ ë¶„ë¥˜
            """)

            st.image("https://via.placeholder.com/800x300/4CAF50/FFFFFF?text=R-CNN+Architecture",
                    caption="R-CNN êµ¬ì¡°")

            st.warning("""
            **R-CNNì˜ í•œê³„:**
            - â±ï¸ ì†ë„: ì´ë¯¸ì§€ë‹¹ 47ì´ˆ (GPU ê¸°ì¤€)
            - ğŸ’¾ ë©”ëª¨ë¦¬: ê° ì˜ì—­ë§ˆë‹¤ CNN ì—°ì‚° í•„ìš”
            - ğŸ”§ ë³µì¡ì„±: 3ë‹¨ê³„ íŒŒì´í”„ë¼ì¸
            """)

        with rcnn_tabs[1]:
            st.subheader("Fast R-CNN (2015)")

            st.markdown("""
            ### ì£¼ìš” ê°œì„ ì‚¬í•­
            1. **ì „ì²´ ì´ë¯¸ì§€ CNN**: ì´ë¯¸ì§€ ì „ì²´ì— í•œ ë²ˆë§Œ CNN ì ìš©
            2. **RoI Pooling**: ë‹¤ì–‘í•œ í¬ê¸°ì˜ ì˜ì—­ì„ ê³ ì • í¬ê¸°ë¡œ ë³€í™˜
            3. **Multi-task Loss**: ë¶„ë¥˜ì™€ ë°”ìš´ë”© ë°•ìŠ¤ íšŒê·€ë¥¼ ë™ì‹œì— í•™ìŠµ
            """)

            st.success("""
            **ì„±ëŠ¥ ê°œì„ :**
            - ì†ë„: ì´ë¯¸ì§€ë‹¹ 2.3ì´ˆ (9ë°° ë¹ ë¦„)
            - ì •í™•ë„: mAP 66% (R-CNN ëŒ€ë¹„ í–¥ìƒ)
            """)

            st.code("""
# RoI Pooling í•µì‹¬ ê°œë…
def roi_pooling(feature_map, roi, output_size=(7, 7)):
    x1, y1, x2, y2 = roi
    roi_feature = feature_map[:, :, y1:y2, x1:x2]
    pooled = adaptive_max_pool2d(roi_feature, output_size)
    return pooled
            """, language="python")

        with rcnn_tabs[2]:
            st.subheader("Faster R-CNN (2015)")

            st.markdown("""
            ### í˜ì‹ ì  ì•„ì´ë””ì–´: RPN (Region Proposal Network)

            Selective Searchë¥¼ ì‹ ê²½ë§ìœ¼ë¡œ ëŒ€ì²´!
            """)

            st.markdown("""
            #### ì•µì»¤ (Anchor) ê°œë…
            - íŠ¹ì§• ë§µì˜ ê° ìœ„ì¹˜ì— ë¯¸ë¦¬ ì •ì˜ëœ ë°•ìŠ¤ë“¤ì„ ë°°ì¹˜
            - 3ê°œ ìŠ¤ì¼€ì¼ Ã— 3ê°œ ë¹„ìœ¨ = 9ê°œ ì•µì»¤ per position
            """)

            col1, col2, col3 = st.columns(3)
            with col1:
                st.info("**ìŠ¤ì¼€ì¼**\n8, 16, 32")
            with col2:
                st.info("**ë¹„ìœ¨**\n0.5, 1.0, 2.0")
            with col3:
                st.info("**ì•µì»¤ ìˆ˜**\n9ê°œ/ìœ„ì¹˜")

            st.success("""
            **ì„±ëŠ¥ ê°œì„ :**
            - ì†ë„: ì´ë¯¸ì§€ë‹¹ 0.2ì´ˆ (ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥!)
            - ì •í™•ë„: mAP 73.2%
            - End-to-End: ì „ì²´ ë„¤íŠ¸ì›Œí¬ë¥¼ í•œ ë²ˆì— í•™ìŠµ
            """)

        with rcnn_tabs[3]:
            st.subheader("R-CNN ê³„ì—´ ë¹„êµ")

            comparison_data = {
                "ëª¨ë¸": ["R-CNN", "Fast R-CNN", "Faster R-CNN"],
                "ì†ë„ (ì´ˆ/ì´ë¯¸ì§€)": [47, 2.3, 0.2],
                "mAP (%)": [62, 66, 73.2],
                "Region Proposal": ["Selective Search", "Selective Search", "RPN"],
                "End-to-End": ["âŒ", "ë¶€ë¶„", "âœ…"]
            }

            st.table(comparison_data)

            st.markdown("### Two-stage Detectorì˜ íŠ¹ì§•")

            col1, col2 = st.columns(2)

            with col1:
                st.success("""
                **ì¥ì **
                - ë†’ì€ ì •í™•ë„
                - ì•ˆì •ì  ì„±ëŠ¥
                - ì‘ì€ ê°ì²´ íƒì§€
                """)

            with col2:
                st.warning("""
                **ë‹¨ì **
                - ëŠë¦° ì†ë„
                - ë³µì¡í•œ êµ¬ì¡°
                - ë†’ì€ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
                """)

    def render_yolo(self):
        """YOLO ì•„í‚¤í…ì²˜ ì„¤ëª…"""
        st.header("âš¡ YOLO (You Only Look Once)")

        yolo_tabs = st.tabs(["YOLOv1", "YOLOv2/v3", "YOLOv4/v5", "YOLOv8"])

        with yolo_tabs[0]:
            st.subheader("YOLOv1 (2016): í˜ì‹ ì˜ ì‹œì‘")

            st.markdown("""
            ### í•µì‹¬ ê°œë…
            > "ê°ì²´ íƒì§€ë¥¼ íšŒê·€ ë¬¸ì œë¡œ!"

            - ì´ë¯¸ì§€ë¥¼ SÃ—S ê·¸ë¦¬ë“œë¡œ ë¶„í•  (S=7)
            - ê° ê·¸ë¦¬ë“œ ì…€ì´ Bê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ ì˜ˆì¸¡ (B=2)
            - í•œ ë²ˆì˜ forward passë¡œ ëª¨ë“  ê°ì²´ íƒì§€
            """)

            # YOLO ê·¸ë¦¬ë“œ ì‹œê°í™”
            st.markdown("#### ê·¸ë¦¬ë“œ ë¶„í•  ì‹œê°í™”")

            grid_size = st.slider("ê·¸ë¦¬ë“œ í¬ê¸° (SÃ—S)", 3, 13, 7)

            fig, ax = plt.subplots(figsize=(8, 8))

            # ê·¸ë¦¬ë“œ ê·¸ë¦¬ê¸°
            for i in range(grid_size + 1):
                ax.axhline(i, color='gray', linewidth=0.5)
                ax.axvline(i, color='gray', linewidth=0.5)

            ax.set_xlim(0, grid_size)
            ax.set_ylim(0, grid_size)
            ax.set_aspect('equal')
            ax.set_title(f'{grid_size}Ã—{grid_size} Grid', fontsize=14)
            ax.invert_yaxis()

            st.pyplot(fig)
            plt.close()

            st.markdown("""
            ### YOLO ì¶œë ¥ í…ì„œ
            - í¬ê¸°: S Ã— S Ã— (B Ã— 5 + C)
            - 7 Ã— 7 Ã— 30 (S=7, B=2, C=20)
            - ê° ë°•ìŠ¤: [x, y, w, h, confidence]
            - ê° ì…€: Cê°œì˜ í´ë˜ìŠ¤ í™•ë¥ 
            """)

        with yolo_tabs[1]:
            st.subheader("YOLOv2/v3: ì„±ëŠ¥ ê°œì„ ")

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("### YOLOv2 (2017)")
                st.info("""
                **ì£¼ìš” ê°œì„ :**
                - Batch Normalization
                - High Resolution (448Ã—448)
                - Anchor Boxes ë„ì…
                - K-means ì•µì»¤ í´ëŸ¬ìŠ¤í„°ë§
                """)

            with col2:
                st.markdown("### YOLOv3 (2018)")
                st.success("""
                **ì£¼ìš” ê°œì„ :**
                - ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ (3ê°œ)
                - Darknet-53 ë°±ë³¸
                - Feature Pyramid Network
                - 9ê°œ ì•µì»¤ ë°•ìŠ¤
                """)

            st.markdown("#### ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ê²€ì¶œ")

            scales = {
                "13Ã—13": "í° ê°ì²´",
                "26Ã—26": "ì¤‘ê°„ ê°ì²´",
                "52Ã—52": "ì‘ì€ ê°ì²´"
            }

            cols = st.columns(3)
            for i, (scale, description) in enumerate(scales.items()):
                with cols[i]:
                    st.metric(scale, description)

        with yolo_tabs[2]:
            st.subheader("YOLOv4/v5: ìµœì í™”")

            st.markdown("### YOLOv4 (2020)")
            st.markdown("""
            **ì£¼ìš” ê¸°ìˆ :**
            1. **CSPDarknet53**: Cross Stage Partial ì—°ê²°
            2. **PANet**: Path Aggregation Network
            3. **Mosaic Augmentation**: 4ê°œ ì´ë¯¸ì§€ ì¡°í•©
            4. **CIoU Loss**: Complete IoU ì†ì‹¤
            """)

            st.markdown("### YOLOv5 (2020)")
            st.markdown("""
            **ì‹¤ìš©ì„± ê°•í™”:**
            - PyTorch êµ¬í˜„
            - AutoAnchor (ìë™ ì•µì»¤ ìµœì í™”)
            - Model Scaling (n, s, m, l, x)
            - ì‰¬ìš´ ì‚¬ìš©ì„±
            """)

            # YOLOv5 ëª¨ë¸ í¬ê¸° ë¹„êµ
            st.markdown("#### YOLOv5 ëª¨ë¸ ìŠ¤ì¼€ì¼")

            model_sizes = {
                "ëª¨ë¸": ["YOLOv5n", "YOLOv5s", "YOLOv5m", "YOLOv5l", "YOLOv5x"],
                "íŒŒë¼ë¯¸í„° (M)": [1.9, 7.2, 21.2, 46.5, 86.7],
                "FLOPs (G)": [4.5, 16.5, 49.0, 109.1, 205.7],
                "ì†ë„ (ms)": [6.3, 6.4, 8.2, 10.1, 12.1]
            }

            st.table(model_sizes)

        with yolo_tabs[3]:
            st.subheader("YOLOv8 (2023): ìµœì‹  ê¸°ìˆ ")

            st.markdown("""
            ### í˜ì‹ ì  ê°œì„ 
            1. **Anchor-Free**: ì•µì»¤ ë°•ìŠ¤ ì—†ì´ ì§ì ‘ ì˜ˆì¸¡
            2. **Decoupled Head**: ë¶„ë¥˜ì™€ íšŒê·€ í—¤ë“œ ë¶„ë¦¬
            3. **C2f ëª¨ë“ˆ**: ìƒˆë¡œìš´ ë°±ë³¸ êµ¬ì¡°
            4. **Advanced Augmentation**: MixUp, CutMix
            """)

            st.success("""
            **ì£¼ìš” íŠ¹ì§•:**
            - ë” ë¹ ë¥¸ ì†ë„
            - ë” ë†’ì€ ì •í™•ë„
            - ì‰¬ìš´ í•™ìŠµ ë° ë°°í¬
            - ë‹¤ì–‘í•œ íƒœìŠ¤í¬ ì§€ì› (Detection, Segmentation, Classification, Pose)
            """)

            st.code("""
from ultralytics import YOLO

# ëª¨ë¸ ë¡œë“œ
model = YOLO('yolov8n.pt')

# í•™ìŠµ
model.train(data='dataset.yaml', epochs=100)

# ì¶”ë¡ 
results = model.predict('image.jpg')
            """, language="python")

    def render_nms(self):
        """NMS ì„¤ëª… ë° ì‹œë®¬ë ˆì´ì…˜"""
        st.header("ğŸ¨ NMS (Non-Maximum Suppression)")

        st.markdown("""
        ### NMSì˜ í•„ìš”ì„±

        ê°ì²´ íƒì§€ ëª¨ë¸ì€ ê°™ì€ ê°ì²´ì— ëŒ€í•´ ì—¬ëŸ¬ ê°œì˜ ë°”ìš´ë”© ë°•ìŠ¤ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        NMSëŠ” ì¤‘ë³µëœ ê²€ì¶œì„ ì œê±°í•˜ì—¬ ìµœì„ ì˜ ë°•ìŠ¤ë§Œ ë‚¨ê¹ë‹ˆë‹¤.
        """)

        nms_tabs = st.tabs(["ê¸°ë³¸ NMS", "Soft NMS", "DIoU NMS"])

        with nms_tabs[0]:
            st.subheader("ê¸°ë³¸ NMS ì•Œê³ ë¦¬ì¦˜")

            st.code("""
def non_max_suppression(detections, iou_threshold=0.5):
    # 1. ì‹ ë¢°ë„ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
    detections.sort(key=lambda x: x['confidence'], reverse=True)

    keep = []
    while detections:
        # 2. ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì„ íƒ
        best = detections.pop(0)
        keep.append(best)

        # 3. IoUê°€ ì„ê³„ê°’ ì´ìƒì¸ ë°•ìŠ¤ ì œê±°
        remaining = []
        for det in detections:
            iou = calculate_iou(best['bbox'], det['bbox'])
            if iou <= iou_threshold:
                remaining.append(det)

        detections = remaining

    return keep
            """, language="python")

            st.markdown("#### NMS ì‹œë®¬ë ˆì´ì…˜")

            iou_threshold = st.slider("IoU ì„ê³„ê°’", 0.0, 1.0, 0.5, 0.05)

            # ìƒ˜í”Œ ê²€ì¶œ ê²°ê³¼ ìƒì„±
            detections = [
                {"bbox": [100, 100, 200, 200], "confidence": 0.9},
                {"bbox": [105, 95, 205, 195], "confidence": 0.85},
                {"bbox": [98, 102, 198, 202], "confidence": 0.8},
                {"bbox": [300, 150, 400, 250], "confidence": 0.95},
            ]

            st.write(f"ì›ë³¸ ê²€ì¶œ ê°œìˆ˜: {len(detections)}")

            # NMS ì ìš©
            filtered = self.apply_nms(detections, iou_threshold)
            st.write(f"NMS í›„ ê²€ì¶œ ê°œìˆ˜: {len(filtered)}")

            # ì‹œê°í™”
            fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

            # Before NMS
            ax1.set_xlim(0, 500)
            ax1.set_ylim(0, 300)
            ax1.set_title('Before NMS')
            for det in detections:
                x1, y1, x2, y2 = det['bbox']
                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                    linewidth=2, edgecolor='red', facecolor='none',
                                    label=f"conf={det['confidence']:.2f}")
                ax1.add_patch(rect)
            ax1.invert_yaxis()

            # After NMS
            ax2.set_xlim(0, 500)
            ax2.set_ylim(0, 300)
            ax2.set_title('After NMS')
            for det in filtered:
                x1, y1, x2, y2 = det['bbox']
                rect = plt.Rectangle((x1, y1), x2-x1, y2-y1,
                                    linewidth=2, edgecolor='green', facecolor='none',
                                    label=f"conf={det['confidence']:.2f}")
                ax2.add_patch(rect)
            ax2.invert_yaxis()

            st.pyplot(fig)
            plt.close()

        with nms_tabs[1]:
            st.subheader("Soft NMS")

            st.markdown("""
            ### ê¸°ë³¸ NMSì˜ ë¬¸ì œì 

            ê²¹ì³ìˆëŠ” ì—¬ëŸ¬ ê°ì²´ë¥¼ íƒì§€í•  ë•Œ, ì •ìƒì ì¸ ê²€ì¶œë„ ì œê±°ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

            ### Soft NMSì˜ í•´ê²°ì±…

            IoUê°€ ë†’ì€ ë°•ìŠ¤ì˜ ì‹ ë¢°ë„ë¥¼ 0ìœ¼ë¡œ ë§Œë“¤ì§€ ì•Šê³ ,
            ê°€ìš°ì‹œì•ˆ í•¨ìˆ˜ë¡œ **ë¶€ë“œëŸ½ê²Œ ê°ì†Œ**ì‹œí‚µë‹ˆë‹¤.
            """)

            st.code("""
def soft_nms(detections, sigma=0.5):
    for i in range(len(detections)):
        for j in range(i + 1, len(detections)):
            iou = calculate_iou(detections[i]['bbox'],
                              detections[j]['bbox'])

            if iou > threshold:
                # ê°€ìš°ì‹œì•ˆ ê°€ì¤‘ì¹˜ ì ìš©
                weight = np.exp(-(iou ** 2) / sigma)
                detections[j]['confidence'] *= weight

    return detections
            """, language="python")

        with nms_tabs[2]:
            st.subheader("DIoU NMS")

            st.markdown("""
            ### Distance-IoU NMS

            ê¸°ë³¸ IoUì— **ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬**ë¥¼ ì¶”ê°€ë¡œ ê³ ë ¤í•©ë‹ˆë‹¤.
            """)

            st.latex(r"\text{DIoU} = \text{IoU} - \frac{d^2}{c^2}")

            st.markdown("""
            - **d**: ë‘ ë°•ìŠ¤ ì¤‘ì‹¬ì  ê°„ ê±°ë¦¬
            - **c**: ë‘ ë°•ìŠ¤ë¥¼ í¬í•¨í•˜ëŠ” ìµœì†Œ ë°•ìŠ¤ì˜ ëŒ€ê°ì„  ê¸¸ì´
            """)

    def render_projects(self):
        """ì‹¤ì „ í”„ë¡œì íŠ¸"""
        st.header("ğŸ’» ì‹¤ì „ í”„ë¡œì íŠ¸")

        project_tabs = st.tabs([
            "êµì‹¤ ë¬¼ê±´ íƒì§€",
            "ì–¼êµ´ ê°ì§€",
            "ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹",
            "ì†ë™ì‘ ì¸ì‹"
        ])

        with project_tabs[0]:
            self.classroom_detector_project()

        with project_tabs[1]:
            self.face_detection_project()

        with project_tabs[2]:
            self.license_plate_project()

        with project_tabs[3]:
            self.hand_gesture_project()

    def classroom_detector_project(self):
        """êµì‹¤ ë¬¼ê±´ íƒì§€ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ« êµì‹¤ ë¬¼ê±´ íƒì§€ê¸°")

        st.markdown("""
        ### í”„ë¡œì íŠ¸ ê°œìš”

        êµì‹¤ì—ì„œ í”íˆ ë³¼ ìˆ˜ ìˆëŠ” ë¬¼ê±´ë“¤ì„ íƒì§€í•˜ëŠ” ì»¤ìŠ¤í…€ YOLO ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

        **íƒì§€ ëŒ€ìƒ:**
        - ğŸ“š ì±… (Book)
        - ğŸ’» ë…¸íŠ¸ë¶ (Laptop)
        - ğŸª‘ ì˜ì (Chair)
        - ğŸ–Šï¸ ì¹ íŒ (Whiteboard)
        - ğŸ’ ê°€ë°© (Bag)
        """)

        st.markdown("### API í™œìš© ê°ì²´ íƒì§€")

        use_api = st.checkbox("ì‹¤ì œ Gemini API ì‚¬ìš©", key="classroom_api")

        uploaded_file = st.file_uploader(
            "êµì‹¤ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="classroom_upload"
        )

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

            if st.button("ê°ì²´ íƒì§€ ì‹¤í–‰", key="classroom_detect"):
                if use_api:
                    api_key = os.getenv('GOOGLE_API_KEY')
                    if api_key and api_key != 'your_api_key_here':
                        with st.spinner("Geminië¡œ ê°ì²´ íƒì§€ ì¤‘..."):
                            try:
                                genai.configure(api_key=api_key)
                                model = genai.GenerativeModel('gemini-2.5-pro')

                                prompt = """
ì´ êµì‹¤ ì´ë¯¸ì§€ì—ì„œ ë‹¤ìŒ ë¬¼ê±´ë“¤ì„ ì°¾ì•„ì£¼ì„¸ìš”:
- ì±… (Book)
- ë…¸íŠ¸ë¶ (Laptop)
- ì˜ì (Chair)
- ì¹ íŒ/í™”ì´íŠ¸ë³´ë“œ (Whiteboard)
- ê°€ë°© (Bag)

ê° ë¬¼ê±´ì— ëŒ€í•´:
1. ë¬¼ê±´ ì´ë¦„
2. ëŒ€ëµì ì¸ ìœ„ì¹˜ (ì™¼ìª½/ì¤‘ì•™/ì˜¤ë¥¸ìª½, ìœ„/ì¤‘ê°„/ì•„ë˜)
3. ì‹ ë¢°ë„ (ë†’ìŒ/ì¤‘ê°„/ë‚®ìŒ)

í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
                                """

                                response = model.generate_content([prompt, image])

                                st.success("âœ… íƒì§€ ì™„ë£Œ!")
                                st.markdown("### íƒì§€ ê²°ê³¼")
                                st.write(response.text)

                            except Exception as e:
                                st.error(f"API ì˜¤ë¥˜: {str(e)}")
                    else:
                        st.warning("âš ï¸ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    # ì‹œë®¬ë ˆì´ì…˜
                    with st.spinner("ì‹œë®¬ë ˆì´ì…˜ íƒì§€ ì¤‘..."):
                        st.success("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
                        st.markdown("### íƒì§€ ê²°ê³¼ (ì‹œë®¬ë ˆì´ì…˜)")

                        detections = [
                            {"class": "ì±…", "confidence": 0.92, "location": "ì¤‘ì•™-ìœ„"},
                            {"class": "ë…¸íŠ¸ë¶", "confidence": 0.88, "location": "ì™¼ìª½-ì¤‘ê°„"},
                            {"class": "ì˜ì", "confidence": 0.95, "location": "ì˜¤ë¥¸ìª½-ì•„ë˜"},
                        ]

                        for det in detections:
                            st.info(f"**{det['class']}** - ì‹ ë¢°ë„: {det['confidence']:.2f} - ìœ„ì¹˜: {det['location']}")

        st.markdown("### í•™ìŠµ ì½”ë“œ")
        st.code("""
from ultralytics import YOLO

# ëª¨ë¸ í•™ìŠµ
model = YOLO('yolov8n.pt')

results = model.train(
    data='classroom.yaml',
    epochs=100,
    imgsz=640,
    batch=16,
    project='classroom_detector',
    name='yolov8n_classroom'
)

# ì¶”ë¡ 
model = YOLO('best.pt')
results = model.predict('classroom.jpg')
        """, language="python")

    def face_detection_project(self):
        """ì–¼êµ´ ê°ì§€ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ˜Š ì–¼êµ´ ê°ì§€ ì‹œìŠ¤í…œ")

        st.markdown("""
        ### í”„ë¡œì íŠ¸ ê°œìš”

        ì´ë¯¸ì§€ ë˜ëŠ” ë¹„ë””ì˜¤ì—ì„œ ì‚¬ëŒì˜ ì–¼êµ´ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ê°ì§€í•©ë‹ˆë‹¤.

        **ê¸°ëŠ¥:**
        - ë‹¤ì¤‘ ì–¼êµ´ ê°ì§€
        - ì–¼êµ´ ëœë“œë§ˆí¬ (ëˆˆ, ì½”, ì…)
        - ë‚˜ì´/ì„±ë³„ ì¶”ì • (ì„ íƒ)
        """)

        use_api = st.checkbox("ì‹¤ì œ Gemini API ì‚¬ìš©", key="face_api")

        uploaded_file = st.file_uploader(
            "ì–¼êµ´ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="face_upload"
        )

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

            if st.button("ì–¼êµ´ ê°ì§€ ì‹¤í–‰", key="face_detect"):
                if use_api:
                    api_key = os.getenv('GOOGLE_API_KEY')
                    if api_key and api_key != 'your_api_key_here':
                        with st.spinner("ì–¼êµ´ ê°ì§€ ì¤‘..."):
                            try:
                                genai.configure(api_key=api_key)
                                model = genai.GenerativeModel('gemini-2.5-pro')

                                prompt = """
ì´ ì´ë¯¸ì§€ì—ì„œ ëª¨ë“  ì–¼êµ´ì„ ê°ì§€í•˜ê³  ê° ì–¼êµ´ì— ëŒ€í•´:
1. ìœ„ì¹˜ (ì™¼ìª½/ì¤‘ì•™/ì˜¤ë¥¸ìª½, ìœ„/ì¤‘ê°„/ì•„ë˜)
2. ëŒ€ëµì ì¸ ë‚˜ì´ëŒ€
3. í‘œì •/ê°ì •

ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
                                """

                                response = model.generate_content([prompt, image])

                                st.success("âœ… ê°ì§€ ì™„ë£Œ!")
                                st.write(response.text)

                            except Exception as e:
                                st.error(f"API ì˜¤ë¥˜: {str(e)}")
                    else:
                        st.warning("âš ï¸ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ê°ì§€ ì¤‘..."):
                        st.success("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
                        st.info("""
**ê°ì§€ëœ ì–¼êµ´: 2ê°œ**

ì–¼êµ´ 1:
- ìœ„ì¹˜: ì¤‘ì•™-ìœ„
- ì—°ë ¹ëŒ€: 20-30ëŒ€
- í‘œì •: ë¯¸ì†Œ

ì–¼êµ´ 2:
- ìœ„ì¹˜: ì˜¤ë¥¸ìª½-ì¤‘ê°„
- ì—°ë ¹ëŒ€: 30-40ëŒ€
- í‘œì •: ì¤‘ë¦½
                        """)

    def license_plate_project(self):
        """ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹"""
        st.subheader("ğŸš— ì°¨ëŸ‰ ë²ˆí˜¸íŒ ì¸ì‹")

        st.markdown("""
        ### í”„ë¡œì íŠ¸ ê°œìš”

        ì°¨ëŸ‰ ë²ˆí˜¸íŒì„ íƒì§€í•˜ê³  OCRë¡œ ë²ˆí˜¸ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.

        **íŒŒì´í”„ë¼ì¸:**
        1. ì°¨ëŸ‰ íƒì§€ (Vehicle Detection)
        2. ë²ˆí˜¸íŒ ì˜ì—­ íƒì§€ (License Plate Detection)
        3. OCRë¡œ ë²ˆí˜¸ ì¸ì‹ (Text Recognition)
        """)

        use_api = st.checkbox("ì‹¤ì œ Gemini API ì‚¬ìš©", key="plate_api")

        uploaded_file = st.file_uploader(
            "ì°¨ëŸ‰ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="plate_upload"
        )

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

            if st.button("ë²ˆí˜¸íŒ ì¸ì‹ ì‹¤í–‰", key="plate_detect"):
                if use_api:
                    api_key = os.getenv('GOOGLE_API_KEY')
                    if api_key and api_key != 'your_api_key_here':
                        with st.spinner("ë²ˆí˜¸íŒ ì¸ì‹ ì¤‘..."):
                            try:
                                genai.configure(api_key=api_key)
                                model = genai.GenerativeModel('gemini-2.5-pro')

                                prompt = """
ì´ ì´ë¯¸ì§€ì—ì„œ:
1. ì°¨ëŸ‰ì„ íƒì§€í•˜ê³ 
2. ë²ˆí˜¸íŒ ìœ„ì¹˜ë¥¼ ì°¾ê³ 
3. ë²ˆí˜¸íŒì˜ ìˆ«ì/ë¬¸ìë¥¼ ì½ì–´ì£¼ì„¸ìš”.

ë²ˆí˜¸íŒì´ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´ ê·¸ ì´ìœ ë„ ì„¤ëª…í•´ì£¼ì„¸ìš”.
                                """

                                response = model.generate_content([prompt, image])

                                st.success("âœ… ì¸ì‹ ì™„ë£Œ!")
                                st.write(response.text)

                            except Exception as e:
                                st.error(f"API ì˜¤ë¥˜: {str(e)}")
                    else:
                        st.warning("âš ï¸ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ì¸ì‹ ì¤‘..."):
                        st.success("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
                        st.info("""
**ì¸ì‹ ê²°ê³¼:**

ì°¨ëŸ‰: ìŠ¹ìš©ì°¨ (ì‹ ë¢°ë„ 0.95)
ë²ˆí˜¸íŒ ìœ„ì¹˜: ì „ë©´ ì¤‘ì•™
ë²ˆí˜¸íŒ ë²ˆí˜¸: 12ê°€ 3456

ì¶”ê°€ ì •ë³´:
- ì°¨ëŸ‰ ìƒ‰ìƒ: í°ìƒ‰
- ì°¨ëŸ‰ íƒ€ì…: ì„¸ë‹¨
                        """)

    def hand_gesture_project(self):
        """ì†ë™ì‘ ì¸ì‹"""
        st.subheader("âœ‹ ì†ë™ì‘ ì¸ì‹")

        st.markdown("""
        ### í”„ë¡œì íŠ¸ ê°œìš”

        ì†ì„ íƒì§€í•˜ê³  ì†ê°€ë½ ê°œìˆ˜ë¥¼ ì„¸ê±°ë‚˜ ì œìŠ¤ì²˜ë¥¼ ì¸ì‹í•©ë‹ˆë‹¤.

        **ì‘ìš© ë¶„ì•¼:**
        - ê°€ìƒ ë§ˆìš°ìŠ¤
        - ìˆ˜í™” ë²ˆì—­
        - ê²Œì„ ì»¨íŠ¸ë¡¤
        - ìŠ¤ë§ˆíŠ¸í™ˆ ì œì–´
        """)

        use_api = st.checkbox("ì‹¤ì œ Gemini API ì‚¬ìš©", key="hand_api")

        uploaded_file = st.file_uploader(
            "ì†ë™ì‘ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="hand_upload"
        )

        if uploaded_file:
            image = Image.open(uploaded_file)
            st.image(image, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

            if st.button("ì†ë™ì‘ ì¸ì‹ ì‹¤í–‰", key="hand_detect"):
                if use_api:
                    api_key = os.getenv('GOOGLE_API_KEY')
                    if api_key and api_key != 'your_api_key_here':
                        with st.spinner("ì†ë™ì‘ ì¸ì‹ ì¤‘..."):
                            try:
                                genai.configure(api_key=api_key)
                                model = genai.GenerativeModel('gemini-2.5-pro')

                                prompt = """
ì´ ì´ë¯¸ì§€ì—ì„œ ì†ì„ ë¶„ì„í•˜ê³ :
1. ì† ê°œìˆ˜
2. í¼ì³ì§„ ì†ê°€ë½ ê°œìˆ˜
3. ì†ë™ì‘/ì œìŠ¤ì²˜ (ì˜ˆ: ê°€ìœ„, ë°”ìœ„, ë³´, ì—„ì§€ì²™, Vì‚¬ì¸ ë“±)
4. ì†ì˜ ìœ„ì¹˜

ë¥¼ ì•Œë ¤ì£¼ì„¸ìš”.
                                """

                                response = model.generate_content([prompt, image])

                                st.success("âœ… ì¸ì‹ ì™„ë£Œ!")
                                st.write(response.text)

                            except Exception as e:
                                st.error(f"API ì˜¤ë¥˜: {str(e)}")
                    else:
                        st.warning("âš ï¸ API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                else:
                    with st.spinner("ì‹œë®¬ë ˆì´ì…˜ ì¸ì‹ ì¤‘..."):
                        st.success("âœ… ì‹œë®¬ë ˆì´ì…˜ ì™„ë£Œ!")
                        st.info("""
**ì¸ì‹ ê²°ê³¼:**

ì† ê°œìˆ˜: 1ê°œ
í¼ì³ì§„ ì†ê°€ë½: 2ê°œ
ì œìŠ¤ì²˜: Vì‚¬ì¸ (í‰í™”)
ì† ìœ„ì¹˜: ì¤‘ì•™
ì‹ ë¢°ë„: 0.94
                        """)

        st.markdown("### MediaPipe Hand Tracking")
        st.code("""
import mediapipe as mp
import cv2

mp_hands = mp.solutions.hands
mp_drawing = mp.solutions.drawing_utils

hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=2,
    min_detection_confidence=0.5
)

# ì´ë¯¸ì§€ ì²˜ë¦¬
results = hands.process(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))

if results.multi_hand_landmarks:
    for hand_landmarks in results.multi_hand_landmarks:
        mp_drawing.draw_landmarks(
            image,
            hand_landmarks,
            mp_hands.HAND_CONNECTIONS
        )
        """, language="python")

    # Helper methods
    def calculate_iou(self, box1, box2):
        """IoU ê³„ì‚°"""
        x1 = max(box1[0], box2[0])
        y1 = max(box1[1], box2[1])
        x2 = min(box1[2], box2[2])
        y2 = min(box1[3], box2[3])

        intersection = max(0, x2 - x1) * max(0, y2 - y1)

        area1 = (box1[2] - box1[0]) * (box1[3] - box1[1])
        area2 = (box2[2] - box2[0]) * (box2[3] - box2[1])

        union = area1 + area2 - intersection

        return intersection / union if union > 0 else 0

    def apply_nms(self, detections, iou_threshold):
        """NMS ì ìš©"""
        detections = sorted(detections, key=lambda x: x['confidence'], reverse=True)

        keep = []
        while detections:
            best = detections.pop(0)
            keep.append(best)

            remaining = []
            for det in detections:
                iou = self.calculate_iou(best['bbox'], det['bbox'])
                if iou <= iou_threshold:
                    remaining.append(det)

            detections = remaining

        return keep