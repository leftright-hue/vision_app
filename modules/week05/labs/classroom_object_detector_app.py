#!/usr/bin/env python3
"""
Week 5 Lab: êµì‹¤ ë¬¼ê±´ íƒì§€ê¸° ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
Gradioë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ êµì‹¤ ë¬¼ê±´ íƒì§€ ì›¹ ì•±

ì´ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ”:
1. ì‹¤ì‹œê°„ ì´ë¯¸ì§€/ë¹„ë””ì˜¤ ê°ì²´ íƒì§€
2. ì‚¬ìš©ì ì¹œí™”ì  ì›¹ ì¸í„°í˜ì´ìŠ¤
3. íƒì§€ ê²°ê³¼ ë¶„ì„ ë° ì‹œê°í™”
4. ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
5. HuggingFace Space ë°°í¬ ì¤€ë¹„
"""

import gradio as gr
import cv2
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
import torch
import time
import json
from pathlib import Path
from collections import Counter, defaultdict
import io
import base64
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# YOLOv8 import
try:
    from ultralytics import YOLO
    print("âœ… Ultralytics YOLOv8 íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âŒ Ultralytics íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹ì–´: pip install ultralytics")

# ì „ì—­ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

class ClassroomObjectDetector:
    """
    êµì‹¤ ë¬¼ê±´ íƒì§€ê¸° í´ë˜ìŠ¤
    """
    
    def __init__(self, model_path=None):
        """
        íƒì§€ê¸° ì´ˆê¸°í™”
        
        Args:
            model_path: ì»¤ìŠ¤í…€ ëª¨ë¸ ê²½ë¡œ (Noneì´ë©´ ê¸°ë³¸ YOLO ëª¨ë¸ ì‚¬ìš©)
        """
        self.model_path = model_path
        self.model = None
        self.is_custom_model = model_path is not None
        
        # êµì‹¤ ë¬¼ê±´ í´ë˜ìŠ¤ (ì»¤ìŠ¤í…€ ëª¨ë¸ìš©)
        self.classroom_classes = {
            0: 'book',
            1: 'laptop', 
            2: 'chair',
            3: 'whiteboard',
            4: 'bag'
        }
        
        # COCO í´ë˜ìŠ¤ì—ì„œ êµì‹¤ ê´€ë ¨ í´ë˜ìŠ¤ë“¤
        self.coco_classroom_classes = {
            'book': 84,
            'laptop': 73,
            'chair': 62,
            'backpack': 27,
            'handbag': 31,
            'suitcase': 33,
            'bottle': 44,
            'cup': 47,
            'cell phone': 77,
            'clock': 85,
            'mouse': 74,
            'keyboard': 76,
            'remote': 75
        }
        
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ
        self.class_colors = {
            'book': (255, 0, 0),
            'laptop': (0, 255, 0),
            'chair': (0, 0, 255),
            'whiteboard': (255, 255, 0),
            'bag': (255, 0, 255),
            'backpack': (255, 0, 255),
            'handbag': (255, 128, 0),
            'suitcase': (128, 255, 0),
            'bottle': (0, 255, 255),
            'cup': (255, 192, 203),
            'cell phone': (128, 0, 128),
            'clock': (255, 165, 0),
            'mouse': (0, 128, 255),
            'keyboard': (128, 128, 128),
            'remote': (64, 224, 208)
        }
        
        # í†µê³„ ì €ì¥
        self.detection_history = []
        self.performance_stats = {
            'total_detections': 0,
            'total_images': 0,
            'avg_inference_time': 0,
            'class_counts': Counter()
        }
        
        self.load_model()
    
    def load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            if self.is_custom_model and self.model_path and Path(self.model_path).exists():
                print(f"ğŸ”„ ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë”©: {self.model_path}")
                self.model = YOLO(self.model_path)
                print("âœ… ì»¤ìŠ¤í…€ êµì‹¤ ë¬¼ê±´ íƒì§€ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            else:
                print("ğŸ”„ ê¸°ë³¸ YOLOv8 ëª¨ë¸ ë¡œë”©...")
                self.model = YOLO('yolov8n.pt')  # Nano ëª¨ë¸ (ë¹ ë¥¸ ì¶”ë¡ )
                print("âœ… ê¸°ë³¸ YOLOv8n ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
                self.is_custom_model = False
        
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            self.model = None
    
    def detect_objects(self, image, conf_threshold=0.25, iou_threshold=0.7):
        """
        ê°ì²´ íƒì§€ ìˆ˜í–‰
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: IoU ì„ê³„ê°’
        
        Returns:
            results: íƒì§€ ê²°ê³¼
            inference_time: ì¶”ë¡  ì‹œê°„ (ms)
        """
        if self.model is None:
            return None, 0
        
        start_time = time.time()
        
        try:
            results = self.model.predict(
                image,
                conf=conf_threshold,
                iou=iou_threshold,
                verbose=False
            )
            
            end_time = time.time()
            inference_time = (end_time - start_time) * 1000
            
            return results[0] if results else None, inference_time
            
        except Exception as e:
            print(f"âŒ íƒì§€ ì‹¤íŒ¨: {e}")
            return None, 0
    
    def filter_classroom_objects(self, results):
        """
        êµì‹¤ ê´€ë ¨ ê°ì²´ë§Œ í•„í„°ë§ (ê¸°ë³¸ YOLO ëª¨ë¸ ì‚¬ìš© ì‹œ)
        
        Args:
            results: YOLO ê²°ê³¼
        
        Returns:
            filtered_results: í•„í„°ë§ëœ ê²°ê³¼
        """
        if results is None or results.boxes is None:
            return results
        
        if self.is_custom_model:
            return results  # ì»¤ìŠ¤í…€ ëª¨ë¸ì€ ì´ë¯¸ êµì‹¤ ê°ì²´ë§Œ íƒì§€
        
        # COCO í´ë˜ìŠ¤ì—ì„œ êµì‹¤ ê´€ë ¨ ê°ì²´ë§Œ í•„í„°ë§
        boxes = results.boxes.xyxy.cpu().numpy()
        confidences = results.boxes.conf.cpu().numpy()
        class_ids = results.boxes.cls.cpu().numpy().astype(int)
        
        # COCO í´ë˜ìŠ¤ ì´ë¦„
        coco_names = results.names
        
        filtered_indices = []
        for i, class_id in enumerate(class_ids):
            class_name = coco_names[class_id]
            if class_name in self.coco_classroom_classes.values() or \
               any(classroom_name in class_name.lower() for classroom_name in self.coco_classroom_classes.keys()):
                filtered_indices.append(i)
        
        if filtered_indices:
            # í•„í„°ë§ëœ ê²°ê³¼ë¡œ ìƒˆë¡œìš´ ê²°ê³¼ ê°ì²´ ìƒì„±
            filtered_boxes = boxes[filtered_indices]
            filtered_confidences = confidences[filtered_indices]
            filtered_class_ids = class_ids[filtered_indices]
            
            # ê²°ê³¼ ì—…ë°ì´íŠ¸ (ê°„ë‹¨í•œ ë°©ì‹)
            results.boxes.xyxy = torch.tensor(filtered_boxes)
            results.boxes.conf = torch.tensor(filtered_confidences)
            results.boxes.cls = torch.tensor(filtered_class_ids)
        else:
            # íƒì§€ëœ êµì‹¤ ê°ì²´ê°€ ì—†ìŒ
            results.boxes = None
        
        return results
    
    def visualize_results(self, image, results, inference_time):
        """
        íƒì§€ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            results: íƒì§€ ê²°ê³¼
            inference_time: ì¶”ë¡  ì‹œê°„
        
        Returns:
            annotated_image: ì–´ë…¸í…Œì´ì…˜ëœ ì´ë¯¸ì§€
            detection_info: íƒì§€ ì •ë³´
        """
        if isinstance(image, str):
            image = Image.open(image)
        elif isinstance(image, np.ndarray):
            image = Image.fromarray(image)
        
        annotated_image = image.copy()
        draw = ImageDraw.Draw(annotated_image)
        
        detection_info = {
            'total_objects': 0,
            'classes': {},
            'inference_time': inference_time,
            'image_size': image.size
        }
        
        if results is None or results.boxes is None:
            return annotated_image, detection_info
        
        # íƒì§€ ê²°ê³¼ ì¶”ì¶œ
        boxes = results.boxes.xyxy.cpu().numpy()
        confidences = results.boxes.conf.cpu().numpy()
        class_ids = results.boxes.cls.cpu().numpy().astype(int)
        
        detection_info['total_objects'] = len(boxes)
        
        # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸
        class_counts = Counter()
        
        try:
            # í°íŠ¸ ë¡œë“œ ì‹œë„
            font = ImageFont.truetype("arial.ttf", 16)
        except:
            font = ImageFont.load_default()
        
        # ê° íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):
            x1, y1, x2, y2 = box.astype(int)
            
            # í´ë˜ìŠ¤ ì´ë¦„ ê²°ì •
            if self.is_custom_model:
                class_name = self.classroom_classes.get(class_id, f'class_{class_id}')
            else:
                class_name = results.names[class_id]
            
            class_counts[class_name] += 1
            
            # ìƒ‰ìƒ ì„ íƒ
            color = self.class_colors.get(class_name, (128, 128, 128))
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            draw.rectangle([x1, y1, x2, y2], outline=color, width=3)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            label = f"{class_name}: {conf:.2f}"
            
            # ë¼ë²¨ ë°°ê²½
            bbox = draw.textbbox((x1, y1-25), label, font=font)
            draw.rectangle(bbox, fill=color)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            draw.text((x1, y1-25), label, fill='white', font=font)
        
        detection_info['classes'] = dict(class_counts)
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self.update_statistics(detection_info)
        
        return annotated_image, detection_info
    
    def update_statistics(self, detection_info):
        """í†µê³„ ì •ë³´ ì—…ë°ì´íŠ¸"""
        self.performance_stats['total_images'] += 1
        self.performance_stats['total_detections'] += detection_info['total_objects']
        
        # í‰ê·  ì¶”ë¡  ì‹œê°„ ì—…ë°ì´íŠ¸
        current_avg = self.performance_stats['avg_inference_time']
        total_images = self.performance_stats['total_images']
        new_avg = (current_avg * (total_images - 1) + detection_info['inference_time']) / total_images
        self.performance_stats['avg_inference_time'] = new_avg
        
        # í´ë˜ìŠ¤ë³„ ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
        for class_name, count in detection_info['classes'].items():
            self.performance_stats['class_counts'][class_name] += count
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€ (ìµœê·¼ 100ê°œë§Œ ìœ ì§€)
        self.detection_history.append({
            'timestamp': datetime.now().isoformat(),
            'objects': detection_info['total_objects'],
            'inference_time': detection_info['inference_time'],
            'classes': detection_info['classes']
        })
        
        if len(self.detection_history) > 100:
            self.detection_history.pop(0)
    
    def get_statistics_summary(self):
        """í†µê³„ ìš”ì•½ ì •ë³´ ë°˜í™˜"""
        stats = self.performance_stats.copy()
        
        if stats['total_images'] > 0:
            stats['avg_objects_per_image'] = stats['total_detections'] / stats['total_images']
        else:
            stats['avg_objects_per_image'] = 0
        
        # ìµœê·¼ 10ê°œ ì´ë¯¸ì§€ì˜ ì„±ëŠ¥
        recent_history = self.detection_history[-10:] if len(self.detection_history) >= 10 else self.detection_history
        
        if recent_history:
            recent_times = [h['inference_time'] for h in recent_history]
            stats['recent_avg_time'] = sum(recent_times) / len(recent_times)
            stats['recent_fps'] = 1000 / stats['recent_avg_time'] if stats['recent_avg_time'] > 0 else 0
        else:
            stats['recent_avg_time'] = 0
            stats['recent_fps'] = 0
        
        return stats
    
    def create_statistics_plot(self):
        """í†µê³„ ì‹œê°í™” í”Œë¡¯ ìƒì„±"""
        if len(self.detection_history) < 2:
            # ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš° ë¹ˆ í”Œë¡¯ ë°˜í™˜
            fig, ax = plt.subplots(figsize=(10, 6))
            ax.text(0.5, 0.5, 'ì¶©ë¶„í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤\në” ë§ì€ ì´ë¯¸ì§€ë¥¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”', 
                   ha='center', va='center', fontsize=14)
            ax.set_xlim(0, 1)
            ax.set_ylim(0, 1)
            ax.axis('off')
            return fig
        
        fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 10))
        
        # 1. ì‹œê°„ë³„ ì¶”ë¡  ì‹œê°„
        times = [h['inference_time'] for h in self.detection_history]
        ax1.plot(times, 'b-', alpha=0.7, linewidth=2)
        ax1.set_title('ì¶”ë¡  ì‹œê°„ ë³€í™”')
        ax1.set_xlabel('ì´ë¯¸ì§€ ìˆœì„œ')
        ax1.set_ylabel('ì‹œê°„ (ms)')
        ax1.grid(True, alpha=0.3)
        
        # 2. ì‹œê°„ë³„ íƒì§€ ê°ì²´ ìˆ˜
        object_counts = [h['objects'] for h in self.detection_history]
        ax2.plot(object_counts, 'g-', alpha=0.7, linewidth=2, marker='o', markersize=4)
        ax2.set_title('íƒì§€ ê°ì²´ ìˆ˜ ë³€í™”')
        ax2.set_xlabel('ì´ë¯¸ì§€ ìˆœì„œ')
        ax2.set_ylabel('ê°ì²´ ìˆ˜')
        ax2.grid(True, alpha=0.3)
        
        # 3. í´ë˜ìŠ¤ë³„ ëˆ„ì  íƒì§€ ìˆ˜
        class_counts = self.performance_stats['class_counts']
        if class_counts:
            classes = list(class_counts.keys())
            counts = list(class_counts.values())
            
            bars = ax3.bar(classes, counts, alpha=0.7, 
                          color=[np.array(self.class_colors.get(cls, (128, 128, 128)))/255 for cls in classes])
            ax3.set_title('í´ë˜ìŠ¤ë³„ ëˆ„ì  íƒì§€ ìˆ˜')
            ax3.set_xlabel('í´ë˜ìŠ¤')
            ax3.set_ylabel('íƒì§€ ìˆ˜')
            ax3.tick_params(axis='x', rotation=45)
            
            # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
            for bar, count in zip(bars, counts):
                ax3.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                        str(count), ha='center', va='bottom')
        else:
            ax3.text(0.5, 0.5, 'íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤', ha='center', va='center')
            ax3.set_xlim(0, 1)
            ax3.set_ylim(0, 1)
        
        # 4. ì„±ëŠ¥ ìš”ì•½
        stats = self.get_statistics_summary()
        
        summary_text = f"""ì„±ëŠ¥ ìš”ì•½:
        
ì´ ì²˜ë¦¬ ì´ë¯¸ì§€: {stats['total_images']}ê°œ
ì´ íƒì§€ ê°ì²´: {stats['total_detections']}ê°œ
í‰ê·  ê°ì²´/ì´ë¯¸ì§€: {stats['avg_objects_per_image']:.1f}ê°œ

í‰ê·  ì¶”ë¡  ì‹œê°„: {stats['avg_inference_time']:.1f}ms
ìµœê·¼ í‰ê·  ì‹œê°„: {stats['recent_avg_time']:.1f}ms
ì˜ˆìƒ FPS: {stats['recent_fps']:.1f}

ë””ë°”ì´ìŠ¤: {DEVICE}
ëª¨ë¸ íƒ€ì…: {'ì»¤ìŠ¤í…€' if self.is_custom_model else 'COCO'}"""
        
        ax4.text(0.1, 0.9, summary_text, transform=ax4.transAxes, fontsize=11,
                verticalalignment='top', fontfamily='monospace')
        ax4.axis('off')
        
        plt.tight_layout()
        return fig

# ì „ì—­ íƒì§€ê¸° ì¸ìŠ¤í„´ìŠ¤
detector = ClassroomObjectDetector()

def detect_objects_interface(image, conf_threshold, iou_threshold, show_stats):
    """
    Gradio ì¸í„°í˜ì´ìŠ¤ìš© ê°ì²´ íƒì§€ í•¨ìˆ˜
    
    Args:
        image: ì…ë ¥ ì´ë¯¸ì§€
        conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
        iou_threshold: IoU ì„ê³„ê°’
        show_stats: í†µê³„ í‘œì‹œ ì—¬ë¶€
    
    Returns:
        annotated_image: ì–´ë…¸í…Œì´ì…˜ëœ ì´ë¯¸ì§€
        detection_summary: íƒì§€ ìš”ì•½
        stats_plot: í†µê³„ í”Œë¡¯ (ì„ íƒì‚¬í•­)
    """
    if image is None:
        return None, "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", None
    
    try:
        # ê°ì²´ íƒì§€
        results, inference_time = detector.detect_objects(image, conf_threshold, iou_threshold)
        
        # êµì‹¤ ê°ì²´ë§Œ í•„í„°ë§ (ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš© ì‹œ)
        results = detector.filter_classroom_objects(results)
        
        # ê²°ê³¼ ì‹œê°í™”
        annotated_image, detection_info = detector.visualize_results(image, results, inference_time)
        
        # íƒì§€ ìš”ì•½ ìƒì„±
        summary = f"""ğŸ” íƒì§€ ê²°ê³¼:
        
ğŸ“Š ê¸°ë³¸ ì •ë³´:
â€¢ íƒì§€ëœ ê°ì²´: {detection_info['total_objects']}ê°œ
â€¢ ì¶”ë¡  ì‹œê°„: {detection_info['inference_time']:.1f}ms
â€¢ ì´ë¯¸ì§€ í¬ê¸°: {detection_info['image_size'][0]}Ã—{detection_info['image_size'][1]}

ğŸ“‹ í´ë˜ìŠ¤ë³„ íƒì§€:"""
        
        if detection_info['classes']:
            for class_name, count in detection_info['classes'].items():
                summary += f"\nâ€¢ {class_name}: {count}ê°œ"
        else:
            summary += "\nâ€¢ íƒì§€ëœ êµì‹¤ ë¬¼ê±´ì´ ì—†ìŠµë‹ˆë‹¤"
        
        # ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
        stats = detector.get_statistics_summary()
        summary += f"""

ğŸ“ˆ ëˆ„ì  í†µê³„:
â€¢ ì´ ì²˜ë¦¬ ì´ë¯¸ì§€: {stats['total_images']}ê°œ
â€¢ í‰ê·  ì¶”ë¡  ì‹œê°„: {stats['avg_inference_time']:.1f}ms
â€¢ ì˜ˆìƒ FPS: {stats['recent_fps']:.1f}"""
        
        # í†µê³„ í”Œë¡¯ ìƒì„± (ìš”ì²­ ì‹œ)
        stats_plot = None
        if show_stats and len(detector.detection_history) > 1:
            stats_plot = detector.create_statistics_plot()
        
        return annotated_image, summary, stats_plot
        
    except Exception as e:
        error_msg = f"âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return None, error_msg, None

def reset_statistics():
    """í†µê³„ ì´ˆê¸°í™”"""
    global detector
    detector.detection_history = []
    detector.performance_stats = {
        'total_detections': 0,
        'total_images': 0,
        'avg_inference_time': 0,
        'class_counts': Counter()
    }
    return "âœ… í†µê³„ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤."

def load_custom_model(model_file):
    """ì»¤ìŠ¤í…€ ëª¨ë¸ ë¡œë“œ"""
    global detector
    
    if model_file is None:
        return "âŒ ëª¨ë¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”."
    
    try:
        # ì„ì‹œë¡œ íŒŒì¼ ì €ì¥
        temp_path = "temp_model.pt"
        with open(temp_path, "wb") as f:
            f.write(model_file)
        
        # ìƒˆë¡œìš´ íƒì§€ê¸° ìƒì„±
        detector = ClassroomObjectDetector(temp_path)
        
        if detector.model is not None:
            return "âœ… ì»¤ìŠ¤í…€ ëª¨ë¸ì´ ì„±ê³µì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤."
        else:
            return "âŒ ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            
    except Exception as e:
        return f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {str(e)}"

def create_sample_images():
    """ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±"""
    samples = []
    
    # ìƒ˜í”Œ 1: ê°„ë‹¨í•œ êµì‹¤ ì¥ë©´
    img1 = Image.new('RGB', (640, 480), color='lightgray')
    draw = ImageDraw.Draw(img1)
    
    # ì±…ìƒê³¼ ì˜ì
    draw.rectangle([100, 200, 200, 400], fill='brown', outline='black', width=2)
    draw.rectangle([250, 300, 350, 350], fill='blue', outline='black', width=2)
    draw.rectangle([400, 150, 500, 300], fill='gray', outline='black', width=2)
    
    samples.append(img1)
    
    # ìƒ˜í”Œ 2: ë³µì¡í•œ êµì‹¤ í™˜ê²½
    img2 = Image.new('RGB', (640, 480), color='white')
    draw = ImageDraw.Draw(img2)
    
    # ì—¬ëŸ¬ ê°ì²´ë“¤
    objects = [
        ([50, 100, 150, 200], 'red'),      # ì±…
        ([200, 150, 350, 250], 'green'),   # ë…¸íŠ¸ë¶
        ([400, 100, 550, 300], 'blue'),    # ì˜ì
        ([100, 350, 300, 400], 'orange'),  # ê°€ë°©
        ([350, 50, 600, 150], 'yellow')    # í™”ì´íŠ¸ë³´ë“œ
    ]
    
    for (x1, y1, x2, y2), color in objects:
        draw.rectangle([x1, y1, x2, y2], fill=color, outline='black', width=2)
    
    samples.append(img2)
    
    return samples

def create_gradio_interface():
    """Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    # ì»¤ìŠ¤í…€ CSS
    custom_css = """
    .gradio-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .main-header {
        text-align: center;
        background: linear-gradient(90deg, #4CAF50 0%, #45a049 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .detect-button {
        background: linear-gradient(45deg, #FF6B6B 30%, #4ECDC4 90%);
        border: none;
        border-radius: 25px;
        color: white;
        padding: 15px 30px;
        font-size: 16px;
        font-weight: bold;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .detect-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    """
    
    with gr.Blocks(title="ğŸ¯ êµì‹¤ ë¬¼ê±´ íƒì§€ê¸°", theme=gr.themes.Soft(), css=custom_css) as demo:
        
        # í—¤ë”
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸ¯ êµì‹¤ ë¬¼ê±´ íƒì§€ê¸°</h1>
            <p>YOLOv8ì„ í™œìš©í•œ ì‹¤ì‹œê°„ êµì‹¤ ë¬¼ê±´ íƒì§€ ì‹œìŠ¤í…œ</p>
            <p><strong>íƒì§€ ê°€ëŠ¥í•œ ë¬¼ê±´:</strong> ì±…, ë…¸íŠ¸ë¶, ì˜ì, í™”ì´íŠ¸ë³´ë“œ, ê°€ë°©</p>
        </div>
        """)
        
        with gr.Row():
            # ì…ë ¥ ì„¹ì…˜
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                
                image_input = gr.Image(
                    type="pil",
                    label="íƒì§€í•  ì´ë¯¸ì§€",
                    height=300
                )
                
                # ì„¤ì • ì˜µì…˜
                with gr.Accordion("âš™ï¸ íƒì§€ ì„¤ì •", open=False):
                    conf_threshold = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.25,
                        step=0.05,
                        label="ì‹ ë¢°ë„ ì„ê³„ê°’",
                        info="ë‚®ì„ìˆ˜ë¡ ë” ë§ì€ ê°ì²´ë¥¼ íƒì§€í•˜ì§€ë§Œ ì˜¤íƒì§€ ì¦ê°€"
                    )
                    
                    iou_threshold = gr.Slider(
                        minimum=0.1,
                        maximum=1.0,
                        value=0.7,
                        step=0.05,
                        label="IoU ì„ê³„ê°’ (NMS)",
                        info="ì¤‘ë³µ íƒì§€ ì œê±° ê°•ë„"
                    )
                    
                    show_stats = gr.Checkbox(
                        value=False,
                        label="í†µê³„ ì°¨íŠ¸ í‘œì‹œ",
                        info="ì„±ëŠ¥ í†µê³„ ì‹œê°í™”"
                    )
                
                # ë²„íŠ¼ë“¤
                with gr.Row():
                    detect_btn = gr.Button(
                        "ğŸ” ê°ì²´ íƒì§€",
                        variant="primary",
                        size="lg",
                        elem_classes=["detect-button"]
                    )
                    
                    reset_btn = gr.Button(
                        "ğŸ”„ í†µê³„ ì´ˆê¸°í™”",
                        variant="secondary"
                    )
                
                # ì»¤ìŠ¤í…€ ëª¨ë¸ ì—…ë¡œë“œ
                with gr.Accordion("ğŸ¤– ì»¤ìŠ¤í…€ ëª¨ë¸", open=False):
                    model_file = gr.File(
                        label="YOLOv8 ëª¨ë¸ íŒŒì¼ (.pt)",
                        file_types=[".pt"]
                    )
                    
                    load_model_btn = gr.Button("ëª¨ë¸ ë¡œë“œ")
                    model_status = gr.Textbox(
                        label="ëª¨ë¸ ìƒíƒœ",
                        value="ê¸°ë³¸ YOLOv8n ëª¨ë¸ ì‚¬ìš© ì¤‘",
                        interactive=False
                    )
                
                # ì‹œìŠ¤í…œ ì •ë³´
                gr.Markdown(f"""
                ### ğŸ’» ì‹œìŠ¤í…œ ì •ë³´
                - **ë””ë°”ì´ìŠ¤**: {DEVICE}
                - **ëª¨ë¸**: YOLOv8n (ê¸°ë³¸)
                - **ì§€ì› í˜•ì‹**: JPG, PNG, WebP
                """)
            
            # ê²°ê³¼ ì„¹ì…˜
            with gr.Column(scale=2):
                with gr.Tabs():
                    with gr.Tab("ğŸ–¼ï¸ íƒì§€ ê²°ê³¼"):
                        output_image = gr.Image(
                            label="íƒì§€ ê²°ê³¼",
                            height=400
                        )
                        
                        detection_summary = gr.Textbox(
                            label="íƒì§€ ìš”ì•½",
                            lines=10,
                            max_lines=15,
                            value="ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê³  'ê°ì²´ íƒì§€' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”."
                        )
                    
                    with gr.Tab("ğŸ“Š ì„±ëŠ¥ í†µê³„"):
                        stats_plot = gr.Plot(
                            label="ì„±ëŠ¥ í†µê³„ ì°¨íŠ¸"
                        )
                        
                        gr.Markdown("""
                        ### ğŸ“ˆ í†µê³„ ì„¤ëª…
                        - **ì¶”ë¡  ì‹œê°„**: ê° ì´ë¯¸ì§€ ì²˜ë¦¬ì— ê±¸ë¦° ì‹œê°„
                        - **íƒì§€ ê°ì²´ ìˆ˜**: ì´ë¯¸ì§€ë³„ íƒì§€ëœ ê°ì²´ ê°œìˆ˜
                        - **í´ë˜ìŠ¤ë³„ ëˆ„ì **: ì „ì²´ ì„¸ì…˜ì—ì„œ íƒì§€ëœ í´ë˜ìŠ¤ë³„ ê°œìˆ˜
                        - **ì„±ëŠ¥ ìš”ì•½**: ì „ì²´ì ì¸ ì„±ëŠ¥ ì§€í‘œ
                        """)
        
        # ì˜ˆì œ ì´ë¯¸ì§€
        sample_images = create_sample_images()
        gr.Examples(
            examples=[[img] for img in sample_images],
            inputs=[image_input],
            label="ğŸ“‹ ì˜ˆì œ ì´ë¯¸ì§€"
        )
        
        # ì‚¬ìš© ê°€ì´ë“œ
        with gr.Accordion("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ", open=False):
            gr.Markdown("""
            ### ğŸ”§ ì‚¬ìš© ë°©ë²•
            1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: êµì‹¤ ì‚¬ì§„ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ì˜ˆì œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
            2. **ì„¤ì • ì¡°ì •**: í•„ìš”ì— ë”°ë¼ ì‹ ë¢°ë„ ì„ê³„ê°’ì„ ì¡°ì •í•˜ì„¸ìš”
            3. **íƒì§€ ì‹¤í–‰**: 'ê°ì²´ íƒì§€' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”
            4. **ê²°ê³¼ í™•ì¸**: íƒì§€ëœ ê°ì²´ì™€ í†µê³„ë¥¼ í™•ì¸í•˜ì„¸ìš”
            
            ### ğŸ¯ íƒì§€ ê°€ëŠ¥í•œ ê°ì²´
            - **ì±… (Book)**: êµê³¼ì„œ, ë…¸íŠ¸, ì°¸ê³ ì„œ ë“±
            - **ë…¸íŠ¸ë¶ (Laptop)**: ë…¸íŠ¸ë¶ ì»´í“¨í„°
            - **ì˜ì (Chair)**: í•™ìƒìš© ì˜ì, êµì‚¬ìš© ì˜ì
            - **í™”ì´íŠ¸ë³´ë“œ (Whiteboard)**: ì¹ íŒ, í™”ì´íŠ¸ë³´ë“œ
            - **ê°€ë°© (Bag)**: ë°±íŒ©, í•¸ë“œë°±, ì„œë¥˜ê°€ë°©
            
            ### âš™ï¸ ì„¤ì • íŒ
            - **ë†’ì€ ì •í™•ë„**: ì‹ ë¢°ë„ ì„ê³„ê°’ì„ 0.5 ì´ìƒìœ¼ë¡œ ì„¤ì •
            - **ë” ë§ì€ íƒì§€**: ì‹ ë¢°ë„ ì„ê³„ê°’ì„ 0.2 ì´í•˜ë¡œ ì„¤ì •
            - **ì¤‘ë³µ ì œê±°**: IoU ì„ê³„ê°’ì„ 0.5-0.7 ì‚¬ì´ë¡œ ì„¤ì •
            
            ### ğŸš€ ì„±ëŠ¥ ìµœì í™”
            - GPU ì‚¬ìš© ì‹œ ë” ë¹ ë¥¸ ì²˜ë¦¬ ì†ë„
            - ì´ë¯¸ì§€ í¬ê¸°ê°€ í´ìˆ˜ë¡ ì²˜ë¦¬ ì‹œê°„ ì¦ê°€
            - ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥
            """)
        
        # ì´ë²¤íŠ¸ ì—°ê²°
        detect_btn.click(
            fn=detect_objects_interface,
            inputs=[image_input, conf_threshold, iou_threshold, show_stats],
            outputs=[output_image, detection_summary, stats_plot],
            show_progress=True
        )
        
        reset_btn.click(
            fn=reset_statistics,
            outputs=[model_status]
        )
        
        load_model_btn.click(
            fn=load_custom_model,
            inputs=[model_file],
            outputs=[model_status]
        )
    
    return demo

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ¯ êµì‹¤ ë¬¼ê±´ íƒì§€ê¸° ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘")
    print("=" * 60)
    
    # Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
    demo = create_gradio_interface()
    
    # ì•± ì‹¤í–‰
    print("ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹œì‘ ì¤‘...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,  # ê³µê°œ ë§í¬ ìƒì„±
        debug=False,
        show_error=True,
        favicon_path=None,
        app_kwargs={"docs_url": None, "redoc_url": None}
    )

if __name__ == "__main__":
    main()
