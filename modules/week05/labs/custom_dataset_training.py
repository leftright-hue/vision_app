#!/usr/bin/env python3
"""
Week 5 Lab: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„ ë° YOLOv8 í•™ìŠµ
êµì‹¤ ë¬¼ê±´ íƒì§€ë¥¼ ìœ„í•œ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ìƒì„± ë° ëª¨ë¸ í•™ìŠµ

ì´ ì‹¤ìŠµì—ì„œëŠ”:
1. êµì‹¤ ë¬¼ê±´ ë°ì´í„°ì…‹ ì‹œë®¬ë ˆì´ì…˜ ìƒì„±
2. YOLO í˜•ì‹ ë¼ë²¨ë§
3. ë°ì´í„° ì¦ê°• ë° ì „ì²˜ë¦¬
4. YOLOv8 ì»¤ìŠ¤í…€ í•™ìŠµ
5. ëª¨ë¸ í‰ê°€ ë° ìµœì í™”
"""

import os
import json
import yaml
import shutil
import random
from pathlib import Path
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.patches as patches
from PIL import Image, ImageDraw, ImageFont
import cv2
from sklearn.model_selection import train_test_split
import albumentations as A
from collections import Counter, defaultdict
import warnings
warnings.filterwarnings('ignore')

# YOLOv8 import
try:
    from ultralytics import YOLO
    print("âœ… Ultralytics YOLOv8 íŒ¨í‚¤ì§€ ë¡œë“œ ì™„ë£Œ")
except ImportError:
    print("âŒ Ultralytics íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ì„¤ì¹˜ ëª…ë ¹ì–´: pip install ultralytics")
    exit(1)

class ClassroomDatasetGenerator:
    """
    êµì‹¤ ë¬¼ê±´ íƒì§€ë¥¼ ìœ„í•œ ë°ì´í„°ì…‹ ìƒì„±ê¸°
    """
    
    def __init__(self, output_dir="classroom_dataset"):
        """
        ë°ì´í„°ì…‹ ìƒì„±ê¸° ì´ˆê¸°í™”
        
        Args:
            output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        """
        self.output_dir = Path(output_dir)
        self.classes = {
            0: 'book',
            1: 'laptop', 
            2: 'chair',
            3: 'whiteboard',
            4: 'bag'
        }
        
        # í´ë˜ìŠ¤ë³„ ìƒ‰ìƒ (ì‹œê°í™”ìš©)
        self.class_colors = {
            'book': (255, 0, 0),      # ë¹¨ê°•
            'laptop': (0, 255, 0),    # ì´ˆë¡
            'chair': (0, 0, 255),     # íŒŒë‘
            'whiteboard': (255, 255, 0), # ë…¸ë‘
            'bag': (255, 0, 255)      # ë§ˆì  íƒ€
        }
        
        # ë°ì´í„°ì…‹ êµ¬ì¡° ìƒì„±
        self.setup_directory_structure()
    
    def setup_directory_structure(self):
        """ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±"""
        directories = [
            self.output_dir / 'images' / 'train',
            self.output_dir / 'images' / 'val',
            self.output_dir / 'images' / 'test',
            self.output_dir / 'labels' / 'train',
            self.output_dir / 'labels' / 'val',
            self.output_dir / 'labels' / 'test'
        ]
        
        for directory in directories:
            directory.mkdir(parents=True, exist_ok=True)
        
        print(f"âœ… ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬ êµ¬ì¡° ìƒì„±: {self.output_dir}")
    
    def generate_synthetic_image(self, image_id, image_size=(640, 480)):
        """
        í•©ì„± êµì‹¤ ì´ë¯¸ì§€ ìƒì„±
        
        Args:
            image_id: ì´ë¯¸ì§€ ID
            image_size: ì´ë¯¸ì§€ í¬ê¸° (width, height)
        
        Returns:
            image: PIL Image
            annotations: ë°”ìš´ë”© ë°•ìŠ¤ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        width, height = image_size
        
        # ë°°ê²½ ìƒ‰ìƒ ëœë¤ ì„ íƒ
        background_colors = [
            (240, 240, 240),  # ë°ì€ íšŒìƒ‰
            (255, 255, 255),  # í°ìƒ‰
            (230, 230, 250),  # ì—°í•œ ë³´ë¼
            (245, 245, 220),  # ë² ì´ì§€
            (248, 248, 255)   # ê³ ìŠ¤íŠ¸ í™”ì´íŠ¸
        ]
        
        bg_color = random.choice(background_colors)
        image = Image.new('RGB', image_size, color=bg_color)
        draw = ImageDraw.Draw(image)
        
        annotations = []
        
        # ê°ì²´ ê°œìˆ˜ ëœë¤ ê²°ì • (1-8ê°œ)
        num_objects = random.randint(1, 8)
        
        for _ in range(num_objects):
            # í´ë˜ìŠ¤ ëœë¤ ì„ íƒ
            class_id = random.randint(0, 4)
            class_name = self.classes[class_id]
            
            # ê°ì²´ í¬ê¸°ì™€ ìœ„ì¹˜ ê²°ì •
            obj_width, obj_height, obj_x, obj_y = self.generate_object_bbox(
                class_name, width, height
            )
            
            # ê²¹ì¹¨ ê²€ì‚¬ (ê°„ë‹¨í•œ ë²„ì „)
            bbox = [obj_x, obj_y, obj_x + obj_width, obj_y + obj_height]
            if self.check_overlap(bbox, annotations):
                continue
            
            # ê°ì²´ ê·¸ë¦¬ê¸°
            self.draw_object(draw, class_name, obj_x, obj_y, obj_width, obj_height)
            
            # YOLO í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¤‘ì‹¬ì , ì •ê·œí™”ëœ ì¢Œí‘œ)
            center_x = (obj_x + obj_width / 2) / width
            center_y = (obj_y + obj_height / 2) / height
            norm_width = obj_width / width
            norm_height = obj_height / height
            
            annotations.append({
                'class_id': class_id,
                'class_name': class_name,
                'bbox': [center_x, center_y, norm_width, norm_height],
                'bbox_xyxy': bbox
            })
        
        return image, annotations
    
    def generate_object_bbox(self, class_name, img_width, img_height):
        """
        í´ë˜ìŠ¤ë³„ ì ì ˆí•œ ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸°ì™€ ìœ„ì¹˜ ìƒì„±
        
        Args:
            class_name: ê°ì²´ í´ë˜ìŠ¤ ì´ë¦„
            img_width: ì´ë¯¸ì§€ ë„ˆë¹„
            img_height: ì´ë¯¸ì§€ ë†’ì´
        
        Returns:
            width, height, x, y: ê°ì²´ì˜ í¬ê¸°ì™€ ìœ„ì¹˜
        """
        # í´ë˜ìŠ¤ë³„ í¬ê¸° ë²”ìœ„ ì •ì˜
        size_ranges = {
            'book': {'w': (40, 120), 'h': (60, 150)},
            'laptop': {'w': (100, 200), 'h': (80, 150)},
            'chair': {'w': (80, 150), 'h': (120, 200)},
            'whiteboard': {'w': (200, 400), 'h': (150, 250)},
            'bag': {'w': (60, 120), 'h': (80, 140)}
        }
        
        size_range = size_ranges[class_name]
        
        # í¬ê¸° ëœë¤ ê²°ì •
        obj_width = random.randint(*size_range['w'])
        obj_height = random.randint(*size_range['h'])
        
        # ì´ë¯¸ì§€ ê²½ê³„ ë‚´ ìœ„ì¹˜ ê²°ì •
        max_x = max(0, img_width - obj_width)
        max_y = max(0, img_height - obj_height)
        
        obj_x = random.randint(0, max_x) if max_x > 0 else 0
        obj_y = random.randint(0, max_y) if max_y > 0 else 0
        
        return obj_width, obj_height, obj_x, obj_y
    
    def check_overlap(self, new_bbox, existing_annotations, overlap_threshold=0.3):
        """
        ìƒˆë¡œìš´ ë°”ìš´ë”© ë°•ìŠ¤ê°€ ê¸°ì¡´ ë°•ìŠ¤ë“¤ê³¼ ê²¹ì¹˜ëŠ”ì§€ í™•ì¸
        
        Args:
            new_bbox: ìƒˆë¡œìš´ ë°”ìš´ë”© ë°•ìŠ¤ [x1, y1, x2, y2]
            existing_annotations: ê¸°ì¡´ ì–´ë…¸í…Œì´ì…˜ ë¦¬ìŠ¤íŠ¸
            overlap_threshold: ê²¹ì¹¨ ì„ê³„ê°’
        
        Returns:
            bool: ê²¹ì¹¨ ì—¬ë¶€
        """
        for ann in existing_annotations:
            existing_bbox = ann['bbox_xyxy']
            
            # IoU ê³„ì‚°
            x1 = max(new_bbox[0], existing_bbox[0])
            y1 = max(new_bbox[1], existing_bbox[1])
            x2 = min(new_bbox[2], existing_bbox[2])
            y2 = min(new_bbox[3], existing_bbox[3])
            
            if x2 <= x1 or y2 <= y1:
                continue  # ê²¹ì¹˜ì§€ ì•ŠìŒ
            
            intersection = (x2 - x1) * (y2 - y1)
            
            area1 = (new_bbox[2] - new_bbox[0]) * (new_bbox[3] - new_bbox[1])
            area2 = (existing_bbox[2] - existing_bbox[0]) * (existing_bbox[3] - existing_bbox[1])
            
            union = area1 + area2 - intersection
            iou = intersection / union if union > 0 else 0
            
            if iou > overlap_threshold:
                return True
        
        return False
    
    def draw_object(self, draw, class_name, x, y, width, height):
        """
        íŠ¹ì • í´ë˜ìŠ¤ì˜ ê°ì²´ë¥¼ ì´ë¯¸ì§€ì— ê·¸ë¦¬ê¸°
        
        Args:
            draw: ImageDraw ê°ì²´
            class_name: í´ë˜ìŠ¤ ì´ë¦„
            x, y: ì¢Œìƒë‹¨ ì¢Œí‘œ
            width, height: ê°ì²´ í¬ê¸°
        """
        color = self.class_colors[class_name]
        
        if class_name == 'book':
            # ì±…: ì‚¬ê°í˜• + ì„ ë“¤
            draw.rectangle([x, y, x + width, y + height], fill=color, outline='black', width=2)
            # í˜ì´ì§€ ì„ ë“¤
            for i in range(3):
                line_x = x + (i + 1) * width // 4
                draw.line([line_x, y, line_x, y + height], fill='white', width=1)
        
        elif class_name == 'laptop':
            # ë…¸íŠ¸ë¶: ë‘ ê°œì˜ ì‚¬ê°í˜• (í™”ë©´ + í‚¤ë³´ë“œ)
            screen_height = height * 0.6
            keyboard_height = height * 0.4
            
            # í™”ë©´
            draw.rectangle([x, y, x + width, y + screen_height], 
                          fill=color, outline='black', width=2)
            # í‚¤ë³´ë“œ
            draw.rectangle([x, y + screen_height, x + width, y + height], 
                          fill=(color[0]//2, color[1]//2, color[2]//2), outline='black', width=2)
        
        elif class_name == 'chair':
            # ì˜ì: ë“±ë°›ì´ + ì¢Œì„ + ë‹¤ë¦¬
            back_width = width * 0.8
            seat_height = height * 0.3
            
            # ë“±ë°›ì´
            draw.rectangle([x + width * 0.1, y, x + width * 0.9, y + height * 0.7], 
                          fill=color, outline='black', width=2)
            # ì¢Œì„
            draw.rectangle([x, y + height * 0.5, x + width, y + height * 0.8], 
                          fill=color, outline='black', width=2)
            # ë‹¤ë¦¬ë“¤
            leg_positions = [(x + 5, y + height * 0.8), (x + width - 15, y + height * 0.8)]
            for leg_x, leg_y in leg_positions:
                draw.rectangle([leg_x, leg_y, leg_x + 10, y + height], 
                              fill=(color[0]//2, color[1]//2, color[2]//2), outline='black')
        
        elif class_name == 'whiteboard':
            # í™”ì´íŠ¸ë³´ë“œ: í° ì‚¬ê°í˜• + í”„ë ˆì„
            draw.rectangle([x, y, x + width, y + height], fill='white', outline='black', width=3)
            # í”„ë ˆì„
            draw.rectangle([x + 5, y + 5, x + width - 5, y + height - 5], 
                          fill=None, outline=color, width=2)
            # ê°„ë‹¨í•œ ë‚´ìš© (ì„ ë“¤)
            for i in range(3):
                line_y = y + (i + 1) * height // 4
                draw.line([x + 20, line_y, x + width - 20, line_y], fill='blue', width=2)
        
        elif class_name == 'bag':
            # ê°€ë°©: íƒ€ì›í˜• + ì†ì¡ì´
            draw.ellipse([x, y + height * 0.2, x + width, y + height], 
                        fill=color, outline='black', width=2)
            # ì†ì¡ì´
            handle_y = y + height * 0.1
            draw.arc([x + width * 0.2, handle_y, x + width * 0.8, y + height * 0.4], 
                    start=0, end=180, fill='black', width=3)
    
    def save_yolo_annotation(self, annotations, label_path):
        """
        YOLO í˜•ì‹ìœ¼ë¡œ ì–´ë…¸í…Œì´ì…˜ ì €ì¥
        
        Args:
            annotations: ì–´ë…¸í…Œì´ì…˜ ë¦¬ìŠ¤íŠ¸
            label_path: ë¼ë²¨ íŒŒì¼ ê²½ë¡œ
        """
        with open(label_path, 'w') as f:
            for ann in annotations:
                class_id = ann['class_id']
                bbox = ann['bbox']
                # YOLO í˜•ì‹: class_id center_x center_y width height
                f.write(f"{class_id} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
    
    def generate_dataset(self, num_images=1000, train_ratio=0.7, val_ratio=0.2):
        """
        ì „ì²´ ë°ì´í„°ì…‹ ìƒì„±
        
        Args:
            num_images: ìƒì„±í•  ì´ë¯¸ì§€ ìˆ˜
            train_ratio: í›ˆë ¨ ë°ì´í„° ë¹„ìœ¨
            val_ratio: ê²€ì¦ ë°ì´í„° ë¹„ìœ¨
        """
        print(f"ğŸ”„ {num_images}ê°œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        
        # ë°ì´í„° ë¶„í•  ê³„ì‚°
        num_train = int(num_images * train_ratio)
        num_val = int(num_images * val_ratio)
        num_test = num_images - num_train - num_val
        
        print(f"   í›ˆë ¨: {num_train}ê°œ, ê²€ì¦: {num_val}ê°œ, í…ŒìŠ¤íŠ¸: {num_test}ê°œ")
        
        # í†µê³„ ìˆ˜ì§‘
        class_counts = Counter()
        total_objects = 0
        
        # ë°ì´í„° ìƒì„±
        splits = [
            ('train', num_train),
            ('val', num_val),
            ('test', num_test)
        ]
        
        image_id = 0
        
        for split_name, split_count in splits:
            print(f"\nğŸ“ {split_name} ë°ì´í„° ìƒì„± ì¤‘...")
            
            for i in range(split_count):
                # ì´ë¯¸ì§€ ìƒì„±
                image, annotations = self.generate_synthetic_image(image_id)
                
                # íŒŒì¼ ê²½ë¡œ
                image_filename = f"image_{image_id:06d}.jpg"
                label_filename = f"image_{image_id:06d}.txt"
                
                image_path = self.output_dir / 'images' / split_name / image_filename
                label_path = self.output_dir / 'labels' / split_name / label_filename
                
                # ì´ë¯¸ì§€ ì €ì¥
                image.save(image_path, quality=95)
                
                # ë¼ë²¨ ì €ì¥
                self.save_yolo_annotation(annotations, label_path)
                
                # í†µê³„ ì—…ë°ì´íŠ¸
                for ann in annotations:
                    class_counts[ann['class_name']] += 1
                    total_objects += 1
                
                image_id += 1
                
                if (i + 1) % 100 == 0:
                    print(f"   ì§„í–‰ë¥ : {i + 1}/{split_count}")
        
        # ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±
        self.create_dataset_config()
        
        # í†µê³„ ì¶œë ¥
        print(f"\nğŸ“Š ë°ì´í„°ì…‹ ìƒì„± ì™„ë£Œ!")
        print(f"   ì´ ì´ë¯¸ì§€: {num_images}ê°œ")
        print(f"   ì´ ê°ì²´: {total_objects}ê°œ")
        print(f"   í´ë˜ìŠ¤ë³„ ë¶„í¬:")
        for class_name, count in class_counts.items():
            print(f"     {class_name}: {count}ê°œ ({count/total_objects*100:.1f}%)")
        
        return class_counts
    
    def create_dataset_config(self):
        """YOLO ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±"""
        config = {
            'path': str(self.output_dir.absolute()),
            'train': 'images/train',
            'val': 'images/val',
            'test': 'images/test',
            'nc': len(self.classes),
            'names': list(self.classes.values())
        }
        
        config_path = self.output_dir / 'dataset.yaml'
        with open(config_path, 'w') as f:
            yaml.dump(config, f, default_flow_style=False)
        
        print(f"âœ… ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ìƒì„±: {config_path}")
    
    def visualize_samples(self, num_samples=6):
        """
        ìƒì„±ëœ ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™”
        
        Args:
            num_samples: ì‹œê°í™”í•  ìƒ˜í”Œ ìˆ˜
        """
        print(f"ğŸ¨ ë°ì´í„°ì…‹ ìƒ˜í”Œ {num_samples}ê°œ ì‹œê°í™”")
        
        # í›ˆë ¨ ë°ì´í„°ì—ì„œ ìƒ˜í”Œ ì„ íƒ
        train_images_dir = self.output_dir / 'images' / 'train'
        train_labels_dir = self.output_dir / 'labels' / 'train'
        
        image_files = list(train_images_dir.glob('*.jpg'))[:num_samples]
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        axes = axes.flatten()
        
        for i, image_path in enumerate(image_files):
            # ì´ë¯¸ì§€ ë¡œë“œ
            image = Image.open(image_path)
            
            # ë¼ë²¨ ë¡œë“œ
            label_path = train_labels_dir / (image_path.stem + '.txt')
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            fig_ax = axes[i]
            fig_ax.imshow(image)
            fig_ax.set_title(f'Sample {i+1}: {image_path.name}')
            fig_ax.axis('off')
            
            if label_path.exists():
                with open(label_path, 'r') as f:
                    lines = f.readlines()
                
                img_width, img_height = image.size
                
                for line in lines:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id, cx, cy, w, h = map(float, parts)
                        
                        # YOLO í˜•ì‹ì„ í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                        x = (cx - w/2) * img_width
                        y = (cy - h/2) * img_height
                        width = w * img_width
                        height = h * img_height
                        
                        # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
                        rect = patches.Rectangle(
                            (x, y), width, height,
                            linewidth=2, 
                            edgecolor=np.array(self.class_colors[self.classes[int(class_id)]])/255,
                            facecolor='none'
                        )
                        fig_ax.add_patch(rect)
                        
                        # í´ë˜ìŠ¤ ë¼ë²¨
                        fig_ax.text(x, y-5, self.classes[int(class_id)], 
                                  fontsize=10, color='red', fontweight='bold')
        
        plt.tight_layout()
        plt.show()

class DataAugmentation:
    """
    ë°ì´í„° ì¦ê°• í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """ë°ì´í„° ì¦ê°• íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”"""
        self.transform = A.Compose([
            # ê¸°í•˜í•™ì  ë³€í™˜
            A.HorizontalFlip(p=0.5),
            A.VerticalFlip(p=0.1),
            A.RandomRotate90(p=0.3),
            A.ShiftScaleRotate(
                shift_limit=0.1,
                scale_limit=0.2,
                rotate_limit=15,
                p=0.5
            ),
            
            # ìƒ‰ìƒ ë³€í™˜
            A.RandomBrightnessContrast(
                brightness_limit=0.2,
                contrast_limit=0.2,
                p=0.5
            ),
            A.HueSaturationValue(
                hue_shift_limit=20,
                sat_shift_limit=30,
                val_shift_limit=20,
                p=0.5
            ),
            A.RGBShift(
                r_shift_limit=15,
                g_shift_limit=15,
                b_shift_limit=15,
                p=0.3
            ),
            
            # ë…¸ì´ì¦ˆ ë° ë¸”ëŸ¬
            A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),
            A.GaussianBlur(blur_limit=(3, 7), p=0.2),
            A.MotionBlur(blur_limit=7, p=0.2),
            
            # ë‚ ì”¨ íš¨ê³¼
            A.RandomRain(p=0.1),
            A.RandomShadow(p=0.2),
            A.RandomSunFlare(p=0.1),
            
            # ì»·ì•„ì›ƒ
            A.CoarseDropout(
                max_holes=8,
                max_height=32,
                max_width=32,
                p=0.3
            ),
            
        ], bbox_params=A.BboxParams(
            format='yolo',
            label_fields=['class_labels']
        ))
    
    def augment_dataset(self, dataset_dir, output_dir, multiplier=2):
        """
        ë°ì´í„°ì…‹ì— ì¦ê°• ì ìš©
        
        Args:
            dataset_dir: ì›ë³¸ ë°ì´í„°ì…‹ ë””ë ‰í† ë¦¬
            output_dir: ì¦ê°•ëœ ë°ì´í„°ì…‹ ì¶œë ¥ ë””ë ‰í† ë¦¬
            multiplier: ì¦ê°• ë°°ìˆ˜
        """
        dataset_dir = Path(dataset_dir)
        output_dir = Path(output_dir)
        
        print(f"ğŸ”„ ë°ì´í„° ì¦ê°• ì‹œì‘ (ë°°ìˆ˜: {multiplier})")
        
        # ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
        for split in ['train', 'val', 'test']:
            (output_dir / 'images' / split).mkdir(parents=True, exist_ok=True)
            (output_dir / 'labels' / split).mkdir(parents=True, exist_ok=True)
        
        for split in ['train', 'val', 'test']:
            print(f"\nğŸ“ {split} ë°ì´í„° ì¦ê°• ì¤‘...")
            
            images_dir = dataset_dir / 'images' / split
            labels_dir = dataset_dir / 'labels' / split
            
            output_images_dir = output_dir / 'images' / split
            output_labels_dir = output_dir / 'labels' / split
            
            image_files = list(images_dir.glob('*.jpg'))
            
            for i, image_path in enumerate(image_files):
                # ì›ë³¸ ë³µì‚¬
                shutil.copy2(image_path, output_images_dir)
                
                label_path = labels_dir / (image_path.stem + '.txt')
                if label_path.exists():
                    shutil.copy2(label_path, output_labels_dir)
                
                # ì¦ê°• ë²„ì „ ìƒì„±
                if split == 'train':  # í›ˆë ¨ ë°ì´í„°ë§Œ ì¦ê°•
                    for aug_idx in range(multiplier - 1):
                        self.create_augmented_sample(
                            image_path, label_path,
                            output_images_dir, output_labels_dir,
                            aug_idx + 1
                        )
                
                if (i + 1) % 100 == 0:
                    print(f"   ì§„í–‰ë¥ : {i + 1}/{len(image_files)}")
        
        # ì„¤ì • íŒŒì¼ ë³µì‚¬
        shutil.copy2(dataset_dir / 'dataset.yaml', output_dir / 'dataset.yaml')
        
        print("âœ… ë°ì´í„° ì¦ê°• ì™„ë£Œ!")
    
    def create_augmented_sample(self, image_path, label_path, 
                              output_images_dir, output_labels_dir, aug_idx):
        """
        ë‹¨ì¼ ìƒ˜í”Œì— ëŒ€í•œ ì¦ê°• ìˆ˜í–‰
        
        Args:
            image_path: ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
            label_path: ì›ë³¸ ë¼ë²¨ ê²½ë¡œ
            output_images_dir: ì¶œë ¥ ì´ë¯¸ì§€ ë””ë ‰í† ë¦¬
            output_labels_dir: ì¶œë ¥ ë¼ë²¨ ë””ë ‰í† ë¦¬
            aug_idx: ì¦ê°• ì¸ë±ìŠ¤
        """
        # ì´ë¯¸ì§€ ë¡œë“œ
        image = cv2.imread(str(image_path))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # ë¼ë²¨ ë¡œë“œ
        bboxes = []
        class_labels = []
        
        if label_path.exists():
            with open(label_path, 'r') as f:
                for line in f:
                    parts = line.strip().split()
                    if len(parts) == 5:
                        class_id, cx, cy, w, h = map(float, parts)
                        bboxes.append([cx, cy, w, h])
                        class_labels.append(int(class_id))
        
        try:
            # ì¦ê°• ì ìš©
            augmented = self.transform(
                image=image,
                bboxes=bboxes,
                class_labels=class_labels
            )
            
            # ì¦ê°•ëœ ì´ë¯¸ì§€ ì €ì¥
            aug_image_name = f"{image_path.stem}_aug{aug_idx}.jpg"
            aug_image_path = output_images_dir / aug_image_name
            
            aug_image = cv2.cvtColor(augmented['image'], cv2.COLOR_RGB2BGR)
            cv2.imwrite(str(aug_image_path), aug_image)
            
            # ì¦ê°•ëœ ë¼ë²¨ ì €ì¥
            aug_label_name = f"{image_path.stem}_aug{aug_idx}.txt"
            aug_label_path = output_labels_dir / aug_label_name
            
            with open(aug_label_path, 'w') as f:
                for bbox, class_label in zip(augmented['bboxes'], augmented['class_labels']):
                    f.write(f"{class_label} {bbox[0]:.6f} {bbox[1]:.6f} {bbox[2]:.6f} {bbox[3]:.6f}\n")
        
        except Exception as e:
            print(f"   âš ï¸ ì¦ê°• ì‹¤íŒ¨: {image_path.name} - {e}")

class YOLOv8Trainer:
    """
    YOLOv8 ì»¤ìŠ¤í…€ í•™ìŠµ í´ë˜ìŠ¤
    """
    
    def __init__(self, dataset_config_path):
        """
        í•™ìŠµê¸° ì´ˆê¸°í™”
        
        Args:
            dataset_config_path: ë°ì´í„°ì…‹ ì„¤ì • íŒŒì¼ ê²½ë¡œ
        """
        self.dataset_config_path = dataset_config_path
        self.model = None
        self.training_results = None
    
    def train_model(self, model_size='n', epochs=100, batch_size=16, 
                   learning_rate=0.01, patience=20, project_name='classroom_detector'):
        """
        ëª¨ë¸ í•™ìŠµ
        
        Args:
            model_size: ëª¨ë¸ í¬ê¸° ('n', 's', 'm', 'l', 'x')
            epochs: ì—í¬í¬ ìˆ˜
            batch_size: ë°°ì¹˜ í¬ê¸°
            learning_rate: í•™ìŠµë¥ 
            patience: ì¡°ê¸° ì¢…ë£Œ patience
            project_name: í”„ë¡œì íŠ¸ ì´ë¦„
        
        Returns:
            model: í•™ìŠµëœ ëª¨ë¸
            results: í•™ìŠµ ê²°ê³¼
        """
        print(f"ğŸš€ YOLOv8{model_size.upper()} ëª¨ë¸ í•™ìŠµ ì‹œì‘")
        print(f"   ì—í¬í¬: {epochs}, ë°°ì¹˜ í¬ê¸°: {batch_size}, í•™ìŠµë¥ : {learning_rate}")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        model_name = f'yolov8{model_size}.pt'
        self.model = YOLO(model_name)
        
        # í•™ìŠµ ì„¤ì •
        training_args = {
            'data': self.dataset_config_path,
            'epochs': epochs,
            'batch': batch_size,
            'lr0': learning_rate,
            'patience': patience,
            'project': project_name,
            'name': f'yolov8{model_size}_classroom',
            'save_period': 10,
            'plots': True,
            'val': True,
            'device': 'cuda' if torch.cuda.is_available() else 'cpu',
            'workers': 4,
            'mosaic': 1.0,
            'mixup': 0.1,
            'copy_paste': 0.1,
            'degrees': 10.0,
            'translate': 0.1,
            'scale': 0.5,
            'shear': 2.0,
            'perspective': 0.0,
            'flipud': 0.0,
            'fliplr': 0.5,
            'hsv_h': 0.015,
            'hsv_s': 0.7,
            'hsv_v': 0.4,
        }
        
        try:
            # í•™ìŠµ ì‹¤í–‰
            self.training_results = self.model.train(**training_args)
            
            print("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
            best_model_path = Path(project_name) / f'yolov8{model_size}_classroom' / 'weights' / 'best.pt'
            if best_model_path.exists():
                self.model = YOLO(str(best_model_path))
                print(f"ğŸ“ ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ: {best_model_path}")
            
            return self.model, self.training_results
            
        except Exception as e:
            print(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None, None
    
    def evaluate_model(self, test_data_path=None):
        """
        ëª¨ë¸ í‰ê°€
        
        Args:
            test_data_path: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œ (ì„ íƒì‚¬í•­)
        
        Returns:
            evaluation_results: í‰ê°€ ê²°ê³¼
        """
        if self.model is None:
            print("âŒ í•™ìŠµëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        print("ğŸ“Š ëª¨ë¸ í‰ê°€ ì¤‘...")
        
        try:
            # ê²€ì¦ ë°ì´í„°ë¡œ í‰ê°€
            if test_data_path:
                results = self.model.val(data=test_data_path, split='test')
            else:
                results = self.model.val(data=self.dataset_config_path, split='val')
            
            # í‰ê°€ ê²°ê³¼ ì •ë¦¬
            evaluation_results = {
                'mAP50': results.box.map50,
                'mAP50-95': results.box.map,
                'precision': results.box.mp,
                'recall': results.box.mr,
                'f1_score': 2 * (results.box.mp * results.box.mr) / (results.box.mp + results.box.mr) if (results.box.mp + results.box.mr) > 0 else 0
            }
            
            # í´ë˜ìŠ¤ë³„ ì„±ëŠ¥
            class_names = ['book', 'laptop', 'chair', 'whiteboard', 'bag']
            evaluation_results['per_class'] = {}
            
            for i, class_name in enumerate(class_names):
                if i < len(results.box.ap50):
                    evaluation_results['per_class'][class_name] = {
                        'AP50': results.box.ap50[i],
                        'AP50-95': results.box.ap[i] if i < len(results.box.ap) else 0,
                        'precision': results.box.p[i] if i < len(results.box.p) else 0,
                        'recall': results.box.r[i] if i < len(results.box.r) else 0
                    }
            
            print("âœ… ëª¨ë¸ í‰ê°€ ì™„ë£Œ!")
            self.print_evaluation_results(evaluation_results)
            
            return evaluation_results
            
        except Exception as e:
            print(f"âŒ í‰ê°€ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None
    
    def print_evaluation_results(self, results):
        """í‰ê°€ ê²°ê³¼ ì¶œë ¥"""
        print("\nğŸ“ˆ í‰ê°€ ê²°ê³¼:")
        print(f"   mAP@0.5: {results['mAP50']:.3f}")
        print(f"   mAP@0.5:0.95: {results['mAP50-95']:.3f}")
        print(f"   Precision: {results['precision']:.3f}")
        print(f"   Recall: {results['recall']:.3f}")
        print(f"   F1-Score: {results['f1_score']:.3f}")
        
        print("\nğŸ“‹ í´ë˜ìŠ¤ë³„ ì„±ëŠ¥:")
        for class_name, metrics in results['per_class'].items():
            print(f"   {class_name}:")
            print(f"     AP@0.5: {metrics['AP50']:.3f}")
            print(f"     Precision: {metrics['precision']:.3f}")
            print(f"     Recall: {metrics['recall']:.3f}")

def main():
    """ë©”ì¸ ì‹¤ìŠµ í•¨ìˆ˜"""
    print("ğŸ¯ Week 5: ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ ì¤€ë¹„ ë° YOLOv8 í•™ìŠµ")
    print("=" * 60)
    
    # 1. ë°ì´í„°ì…‹ ìƒì„±
    print("\n1ï¸âƒ£ êµì‹¤ ë¬¼ê±´ ë°ì´í„°ì…‹ ìƒì„±")
    
    dataset_generator = ClassroomDatasetGenerator("classroom_dataset")
    class_counts = dataset_generator.generate_dataset(
        num_images=500,  # ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì ì€ ìˆ˜
        train_ratio=0.7,
        val_ratio=0.2
    )
    
    # 2. ë°ì´í„°ì…‹ ì‹œê°í™”
    print("\n2ï¸âƒ£ ë°ì´í„°ì…‹ ìƒ˜í”Œ ì‹œê°í™”")
    dataset_generator.visualize_samples(num_samples=6)
    
    # 3. ë°ì´í„° ì¦ê°• (ì„ íƒì‚¬í•­)
    print("\n3ï¸âƒ£ ë°ì´í„° ì¦ê°•")
    augmentation = DataAugmentation()
    
    # ì¦ê°•ëœ ë°ì´í„°ì…‹ ìƒì„± (ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìŒ)
    create_augmented = input("ë°ì´í„° ì¦ê°•ì„ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y'
    
    if create_augmented:
        augmentation.augment_dataset(
            "classroom_dataset",
            "classroom_dataset_augmented",
            multiplier=2
        )
        dataset_path = "classroom_dataset_augmented/dataset.yaml"
    else:
        dataset_path = "classroom_dataset/dataset.yaml"
    
    # 4. ëª¨ë¸ í•™ìŠµ
    print("\n4ï¸âƒ£ YOLOv8 ëª¨ë¸ í•™ìŠµ")
    
    train_model = input("ëª¨ë¸ í•™ìŠµì„ ìˆ˜í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y'
    
    if train_model:
        trainer = YOLOv8Trainer(dataset_path)
        
        model, results = trainer.train_model(
            model_size='n',  # Nano ëª¨ë¸ (ë¹ ë¥¸ í•™ìŠµ)
            epochs=50,       # ì ì€ ì—í¬í¬ (í…ŒìŠ¤íŠ¸ìš©)
            batch_size=8,    # ì‘ì€ ë°°ì¹˜ í¬ê¸°
            learning_rate=0.01,
            patience=10
        )
        
        if model is not None:
            # 5. ëª¨ë¸ í‰ê°€
            print("\n5ï¸âƒ£ ëª¨ë¸ í‰ê°€")
            evaluation_results = trainer.evaluate_model()
            
            # 6. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ì¶”ë¡ 
            print("\n6ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì¶”ë¡ ")
            test_image_path = "classroom_dataset/images/test"
            test_images = list(Path(test_image_path).glob("*.jpg"))[:3]
            
            for test_img in test_images:
                print(f"\nğŸ” {test_img.name} ì¶”ë¡  ì¤‘...")
                results = model.predict(str(test_img), conf=0.25, save=True)
                
                if results and results[0].boxes is not None:
                    num_detections = len(results[0].boxes)
                    print(f"   íƒì§€ëœ ê°ì²´: {num_detections}ê°œ")
    
    print("\nğŸ‰ ì»¤ìŠ¤í…€ ë°ì´í„°ì…‹ í•™ìŠµ ì‹¤ìŠµ ì™„ë£Œ!")
    print("\nğŸ“š ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
    print("   - ì‹¤ì œ êµì‹¤ ì‚¬ì§„ìœ¼ë¡œ ë°ì´í„°ì…‹ êµ¬ì„±")
    print("   - ë” ë§ì€ í´ë˜ìŠ¤ ì¶”ê°€")
    print("   - í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹")
    print("   - ëª¨ë¸ í¬ê¸°ë³„ ì„±ëŠ¥ ë¹„êµ")
    print("   - ì‹¤ì‹œê°„ ì›¹ìº  íƒì§€ êµ¬í˜„")

if __name__ == "__main__":
    main()
