#!/usr/bin/env python3
"""
Week 5 Lab: YOLOv8 ê¸°ì´ˆ ì‹¤ìŠµ
YOLOv8ì„ ì‚¬ìš©í•œ ê°ì²´ íƒì§€ ê¸°ë³¸ êµ¬í˜„ ë° ë¶„ì„

ì´ ì‹¤ìŠµì—ì„œëŠ”:
1. YOLOv8 ëª¨ë¸ ë¡œë“œ ë° ê¸°ë³¸ ì‚¬ìš©ë²•
2. ì´ë¯¸ì§€/ë¹„ë””ì˜¤ì—ì„œ ê°ì²´ íƒì§€
3. ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„
4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí‚¹
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image, ImageDraw, ImageFont
import torch
import time
from pathlib import Path
import json
from collections import defaultdict, Counter
import warnings
warnings.filterwarnings('ignore')

# YOLOv8 ì„¤ì¹˜ í™•ì¸ ë° import
try:
    from ultralytics import YOLO
    print("âœ… Ultralytics YOLOv8 íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
except ImportError:
    print("âŒ Ultralytics íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("ë‹¤ìŒ ëª…ë ¹ì–´ë¡œ ì„¤ì¹˜í•˜ì„¸ìš”: pip install ultralytics")
    exit(1)

# ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ì‚¬ìš© ì¤‘ì¸ ë””ë°”ì´ìŠ¤: {DEVICE}")

class YOLOv8Analyzer:
    """
    YOLOv8 ëª¨ë¸ ë¶„ì„ ë° ì‹œê°í™” í´ë˜ìŠ¤
    """
    
    def __init__(self, model_size='n'):
        """
        YOLOv8 ë¶„ì„ê¸° ì´ˆê¸°í™”
        
        Args:
            model_size: ëª¨ë¸ í¬ê¸° ('n', 's', 'm', 'l', 'x')
        """
        self.model_size = model_size
        self.model = None
        self.model_info = {
            'n': {'params': '3.2M', 'size': '6MB', 'description': 'Nano - ê°€ì¥ ë¹ ë¦„'},
            's': {'params': '11.2M', 'size': '22MB', 'description': 'Small - ì†ë„ì™€ ì •í™•ë„ ê· í˜•'},
            'm': {'params': '25.9M', 'size': '50MB', 'description': 'Medium - ë†’ì€ ì •í™•ë„'},
            'l': {'params': '43.7M', 'size': '87MB', 'description': 'Large - ë§¤ìš° ë†’ì€ ì •í™•ë„'},
            'x': {'params': '68.2M', 'size': '136MB', 'description': 'Extra Large - ìµœê³  ì •í™•ë„'}
        }
        
        # COCO í´ë˜ìŠ¤ ì´ë¦„
        self.coco_classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench',
            'bird', 'cat', 'dog', 'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra',
            'giraffe', 'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',
            'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat', 'baseball glove',
            'skateboard', 'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup',
            'fork', 'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',
            'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',
            'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop', 'mouse',
            'remote', 'keyboard', 'cell phone', 'microwave', 'oven', 'toaster', 'sink',
            'refrigerator', 'book', 'clock', 'vase', 'scissors', 'teddy bear', 'hair drier',
            'toothbrush'
        ]
        
        self.load_model()
    
    def load_model(self):
        """YOLOv8 ëª¨ë¸ ë¡œë“œ"""
        try:
            model_name = f'yolov8{self.model_size}.pt'
            print(f"ğŸ”„ {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
            
            self.model = YOLO(model_name)
            
            info = self.model_info[self.model_size]
            print(f"âœ… YOLOv8{self.model_size.upper()} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
            print(f"   - íŒŒë¼ë¯¸í„°: {info['params']}")
            print(f"   - ëª¨ë¸ í¬ê¸°: {info['size']}")
            print(f"   - ì„¤ëª…: {info['description']}")
            
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("ğŸ’¡ ì¸í„°ë„· ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ë‹¤ë¥¸ ëª¨ë¸ í¬ê¸°ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”.")
    
    def detect_objects(self, image_source, conf_threshold=0.25, iou_threshold=0.7):
        """
        ê°ì²´ íƒì§€ ìˆ˜í–‰
        
        Args:
            image_source: ì´ë¯¸ì§€ ê²½ë¡œ, PIL Image, ë˜ëŠ” numpy array
            conf_threshold: ì‹ ë¢°ë„ ì„ê³„ê°’
            iou_threshold: IoU ì„ê³„ê°’ (NMSìš©)
        
        Returns:
            results: YOLO ê²°ê³¼ ê°ì²´
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        try:
            results = self.model.predict(
                image_source,
                conf=conf_threshold,
                iou=iou_threshold,
                verbose=False
            )
            
            return results[0] if results else None
            
        except Exception as e:
            print(f"âŒ ê°ì²´ íƒì§€ ì‹¤íŒ¨: {e}")
            return None
    
    def visualize_results(self, image, results, save_path=None):
        """
        íƒì§€ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            image: ì›ë³¸ ì´ë¯¸ì§€
            results: YOLO ê²°ê³¼
            save_path: ì €ì¥ ê²½ë¡œ (ì„ íƒì‚¬í•­)
        """
        if results is None or results.boxes is None:
            print("âš ï¸ íƒì§€ëœ ê°ì²´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return image
        
        # ì´ë¯¸ì§€ ë³µì‚¬
        if isinstance(image, str):
            image = cv2.imread(image)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        elif isinstance(image, Image.Image):
            image = np.array(image)
        
        annotated_image = image.copy()
        
        # íƒì§€ ê²°ê³¼ ì¶”ì¶œ
        boxes = results.boxes.xyxy.cpu().numpy()
        confidences = results.boxes.conf.cpu().numpy()
        class_ids = results.boxes.cls.cpu().numpy().astype(int)
        
        # ìƒ‰ìƒ íŒ”ë ˆíŠ¸
        colors = [
            (255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (255, 0, 255),
            (0, 255, 255), (128, 0, 0), (0, 128, 0), (0, 0, 128), (128, 128, 0),
            (128, 0, 128), (0, 128, 128), (192, 192, 192), (255, 165, 0), (255, 20, 147)
        ]
        
        # ê° íƒì§€ ê²°ê³¼ ê·¸ë¦¬ê¸°
        for i, (box, conf, class_id) in enumerate(zip(boxes, confidences, class_ids)):
            x1, y1, x2, y2 = box.astype(int)
            
            # ë°”ìš´ë”© ë°•ìŠ¤ ê·¸ë¦¬ê¸°
            color = colors[class_id % len(colors)]
            cv2.rectangle(annotated_image, (x1, y1), (x2, y2), color, 2)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸
            class_name = self.coco_classes[class_id]
            label = f"{class_name}: {conf:.2f}"
            
            # ë¼ë²¨ ë°°ê²½ ê·¸ë¦¬ê¸°
            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
            cv2.rectangle(annotated_image, (x1, y1 - label_size[1] - 10), 
                         (x1 + label_size[0], y1), color, -1)
            
            # ë¼ë²¨ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            cv2.putText(annotated_image, label, (x1, y1 - 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # ê²°ê³¼ í‘œì‹œ
        plt.figure(figsize=(15, 10))
        
        plt.subplot(1, 2, 1)
        plt.imshow(image)
        plt.title('ì›ë³¸ ì´ë¯¸ì§€')
        plt.axis('off')
        
        plt.subplot(1, 2, 2)
        plt.imshow(annotated_image)
        plt.title(f'íƒì§€ ê²°ê³¼ ({len(boxes)}ê°œ ê°ì²´)')
        plt.axis('off')
        
        plt.tight_layout()
        
        if save_path:
            plt.savefig(save_path, dpi=150, bbox_inches='tight')
            print(f"ğŸ’¾ ê²°ê³¼ê°€ {save_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        plt.show()
        
        return annotated_image
    
    def analyze_detection_results(self, results):
        """
        íƒì§€ ê²°ê³¼ ìƒì„¸ ë¶„ì„
        
        Args:
            results: YOLO ê²°ê³¼
        
        Returns:
            analysis: ë¶„ì„ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        if results is None or results.boxes is None:
            return {"total_objects": 0, "classes": {}, "confidence_stats": {}}
        
        # ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ
        boxes = results.boxes.xyxy.cpu().numpy()
        confidences = results.boxes.conf.cpu().numpy()
        class_ids = results.boxes.cls.cpu().numpy().astype(int)
        
        # í´ë˜ìŠ¤ë³„ í†µê³„
        class_counts = Counter(class_ids)
        class_stats = {}
        
        for class_id, count in class_counts.items():
            class_name = self.coco_classes[class_id]
            class_confidences = confidences[class_ids == class_id]
            
            class_stats[class_name] = {
                'count': count,
                'avg_confidence': float(np.mean(class_confidences)),
                'max_confidence': float(np.max(class_confidences)),
                'min_confidence': float(np.min(class_confidences))
            }
        
        # ì‹ ë¢°ë„ í†µê³„
        confidence_stats = {
            'mean': float(np.mean(confidences)),
            'std': float(np.std(confidences)),
            'min': float(np.min(confidences)),
            'max': float(np.max(confidences)),
            'median': float(np.median(confidences))
        }
        
        # ë°”ìš´ë”© ë°•ìŠ¤ í¬ê¸° ë¶„ì„
        box_areas = []
        for box in boxes:
            x1, y1, x2, y2 = box
            area = (x2 - x1) * (y2 - y1)
            box_areas.append(area)
        
        box_stats = {
            'mean_area': float(np.mean(box_areas)) if box_areas else 0,
            'std_area': float(np.std(box_areas)) if box_areas else 0,
            'min_area': float(np.min(box_areas)) if box_areas else 0,
            'max_area': float(np.max(box_areas)) if box_areas else 0
        }
        
        analysis = {
            'total_objects': len(boxes),
            'unique_classes': len(class_counts),
            'classes': class_stats,
            'confidence_stats': confidence_stats,
            'box_stats': box_stats
        }
        
        return analysis
    
    def benchmark_performance(self, test_images, num_runs=5):
        """
        ëª¨ë¸ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
        
        Args:
            test_images: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸
            num_runs: ê° ì´ë¯¸ì§€ë‹¹ ì‹¤í–‰ íšŸìˆ˜
        
        Returns:
            benchmark_results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
        """
        if self.model is None:
            print("âŒ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return None
        
        print(f"ğŸ”„ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘ ({len(test_images)}ê°œ ì´ë¯¸ì§€, {num_runs}íšŒ ë°˜ë³µ)")
        
        all_times = []
        all_detections = []
        
        for i, image_path in enumerate(test_images):
            print(f"   ì´ë¯¸ì§€ {i+1}/{len(test_images)} ì²˜ë¦¬ ì¤‘...")
            
            image_times = []
            
            # Warm-up
            _ = self.model.predict(image_path, verbose=False)
            
            # ì‹¤ì œ ì¸¡ì •
            for run in range(num_runs):
                start_time = time.time()
                
                results = self.model.predict(image_path, verbose=False)
                
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                
                end_time = time.time()
                
                inference_time = (end_time - start_time) * 1000  # ms
                image_times.append(inference_time)
                
                # ì²« ë²ˆì§¸ ì‹¤í–‰ì—ì„œë§Œ íƒì§€ ê²°ê³¼ ì €ì¥
                if run == 0:
                    num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
                    all_detections.append(num_detections)
            
            all_times.extend(image_times)
        
        # í†µê³„ ê³„ì‚°
        benchmark_results = {
            'model_size': self.model_size,
            'device': str(DEVICE),
            'num_images': len(test_images),
            'num_runs_per_image': num_runs,
            'inference_times': {
                'mean': np.mean(all_times),
                'std': np.std(all_times),
                'min': np.min(all_times),
                'max': np.max(all_times),
                'median': np.median(all_times)
            },
            'fps': 1000 / np.mean(all_times),
            'total_detections': sum(all_detections),
            'avg_detections_per_image': np.mean(all_detections)
        }
        
        return benchmark_results
    
    def compare_model_sizes(self, test_image):
        """
        ë‹¤ì–‘í•œ YOLOv8 ëª¨ë¸ í¬ê¸° ë¹„êµ
        
        Args:
            test_image: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ê²½ë¡œ
        
        Returns:
            comparison_results: ë¹„êµ ê²°ê³¼
        """
        model_sizes = ['n', 's', 'm', 'l']  # 'x'ëŠ” ì‹œê°„ì´ ì˜¤ë˜ ê±¸ë ¤ì„œ ì œì™¸
        comparison_results = {}
        
        print("ğŸ”„ ë‹¤ì–‘í•œ YOLOv8 ëª¨ë¸ í¬ê¸° ë¹„êµ ì¤‘...")
        
        for size in model_sizes:
            print(f"   YOLOv8{size.upper()} í…ŒìŠ¤íŠ¸ ì¤‘...")
            
            try:
                # ì„ì‹œ ëª¨ë¸ ìƒì„±
                temp_model = YOLO(f'yolov8{size}.pt')
                
                # ì„±ëŠ¥ ì¸¡ì •
                times = []
                for _ in range(5):  # 5íšŒ ë°˜ë³µ
                    start_time = time.time()
                    results = temp_model.predict(test_image, verbose=False)
                    end_time = time.time()
                    times.append((end_time - start_time) * 1000)
                
                # íƒì§€ ê²°ê³¼
                num_detections = len(results[0].boxes) if results[0].boxes is not None else 0
                
                comparison_results[size] = {
                    'avg_time': np.mean(times),
                    'std_time': np.std(times),
                    'fps': 1000 / np.mean(times),
                    'num_detections': num_detections,
                    'model_info': self.model_info[size]
                }
                
            except Exception as e:
                print(f"   âŒ YOLOv8{size.upper()} í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
                comparison_results[size] = None
        
        return comparison_results
    
    def visualize_benchmark_results(self, benchmark_results, comparison_results=None):
        """
        ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì‹œê°í™”
        
        Args:
            benchmark_results: ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼
            comparison_results: ëª¨ë¸ í¬ê¸° ë¹„êµ ê²°ê³¼ (ì„ íƒì‚¬í•­)
        """
        if comparison_results:
            # ëª¨ë¸ í¬ê¸° ë¹„êµ ì‹œê°í™”
            fig, axes = plt.subplots(2, 2, figsize=(15, 12))
            
            # ìœ íš¨í•œ ê²°ê³¼ë§Œ í•„í„°ë§
            valid_results = {k: v for k, v in comparison_results.items() if v is not None}
            
            if valid_results:
                models = list(valid_results.keys())
                avg_times = [valid_results[m]['avg_time'] for m in models]
                fps_values = [valid_results[m]['fps'] for m in models]
                detections = [valid_results[m]['num_detections'] for m in models]
                
                # ì¶”ë¡  ì‹œê°„ ë¹„êµ
                bars1 = axes[0, 0].bar(models, avg_times, alpha=0.7, color='skyblue')
                axes[0, 0].set_title('ëª¨ë¸ë³„ í‰ê·  ì¶”ë¡  ì‹œê°„')
                axes[0, 0].set_ylabel('ì‹œê°„ (ms)')
                axes[0, 0].set_xlabel('ëª¨ë¸ í¬ê¸°')
                
                for bar, time_val in zip(bars1, avg_times):
                    axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                                   f'{time_val:.1f}ms', ha='center', va='bottom')
                
                # FPS ë¹„êµ
                bars2 = axes[0, 1].bar(models, fps_values, alpha=0.7, color='lightcoral')
                axes[0, 1].set_title('ëª¨ë¸ë³„ FPS')
                axes[0, 1].set_ylabel('FPS')
                axes[0, 1].set_xlabel('ëª¨ë¸ í¬ê¸°')
                
                for bar, fps_val in zip(bars2, fps_values):
                    axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                                   f'{fps_val:.1f}', ha='center', va='bottom')
                
                # íƒì§€ ê°œìˆ˜ ë¹„êµ
                bars3 = axes[1, 0].bar(models, detections, alpha=0.7, color='lightgreen')
                axes[1, 0].set_title('ëª¨ë¸ë³„ íƒì§€ ê°ì²´ ìˆ˜')
                axes[1, 0].set_ylabel('ê°ì²´ ìˆ˜')
                axes[1, 0].set_xlabel('ëª¨ë¸ í¬ê¸°')
                
                for bar, det_val in zip(bars3, detections):
                    axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                                   f'{det_val}', ha='center', va='bottom')
                
                # ì„±ëŠ¥ ëŒ€ë¹„ íš¨ìœ¨ì„± (FPS/Parameters)
                param_counts = []
                for model in models:
                    param_str = valid_results[model]['model_info']['params']
                    param_count = float(param_str.replace('M', ''))
                    param_counts.append(param_count)
                
                efficiency = [fps / params for fps, params in zip(fps_values, param_counts)]
                
                bars4 = axes[1, 1].bar(models, efficiency, alpha=0.7, color='gold')
                axes[1, 1].set_title('íš¨ìœ¨ì„± (FPS/íŒŒë¼ë¯¸í„° ìˆ˜)')
                axes[1, 1].set_ylabel('FPS per Million Parameters')
                axes[1, 1].set_xlabel('ëª¨ë¸ í¬ê¸°')
                
                for bar, eff_val in zip(bars4, efficiency):
                    axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                                   f'{eff_val:.2f}', ha='center', va='bottom')
            
            plt.tight_layout()
            plt.show()
        
        # ë‹¨ì¼ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“Š ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ìš”ì•½")
        print("=" * 50)
        print(f"ëª¨ë¸: YOLOv8{benchmark_results['model_size'].upper()}")
        print(f"ë””ë°”ì´ìŠ¤: {benchmark_results['device']}")
        print(f"í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€: {benchmark_results['num_images']}ê°œ")
        print(f"ë°˜ë³µ íšŸìˆ˜: {benchmark_results['num_runs_per_image']}íšŒ")
        print(f"í‰ê·  ì¶”ë¡  ì‹œê°„: {benchmark_results['inference_times']['mean']:.2f}ms")
        print(f"í‘œì¤€ í¸ì°¨: {benchmark_results['inference_times']['std']:.2f}ms")
        print(f"ìµœì†Œ ì‹œê°„: {benchmark_results['inference_times']['min']:.2f}ms")
        print(f"ìµœëŒ€ ì‹œê°„: {benchmark_results['inference_times']['max']:.2f}ms")
        print(f"í‰ê·  FPS: {benchmark_results['fps']:.1f}")
        print(f"ì´ íƒì§€ ê°ì²´: {benchmark_results['total_detections']}ê°œ")
        print(f"ì´ë¯¸ì§€ë‹¹ í‰ê·  ê°ì²´: {benchmark_results['avg_detections_per_image']:.1f}ê°œ")

def create_test_images():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
    test_images = []
    
    # 1. ê°„ë‹¨í•œ ê¸°í•˜í•™ì  ë„í˜• ì´ë¯¸ì§€
    img1 = Image.new('RGB', (640, 480), color='white')
    draw = ImageDraw.Draw(img1)
    
    # ì—¬ëŸ¬ ë„í˜• ê·¸ë¦¬ê¸° (ì˜ì, ì±… ë“±ì„ ì—°ìƒì‹œí‚¤ëŠ” í˜•íƒœ)
    draw.rectangle([100, 200, 200, 400], fill='brown', outline='black', width=3)  # ì˜ì ë“±ë°›ì´
    draw.rectangle([100, 350, 250, 380], fill='brown', outline='black', width=3)  # ì˜ì ì¢Œì„
    draw.rectangle([300, 250, 400, 300], fill='blue', outline='black', width=2)   # ì±…
    draw.rectangle([450, 200, 550, 350], fill='gray', outline='black', width=2)   # ë…¸íŠ¸ë¶
    
    test_images.append(('geometric_shapes.jpg', img1))
    
    # 2. ë³µì¡í•œ ì‹¤ë‚´ ì¥ë©´ ì‹œë®¬ë ˆì´ì…˜
    img2 = Image.new('RGB', (640, 480), color='lightgray')
    draw = ImageDraw.Draw(img2)
    
    # êµì‹¤ í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜
    draw.rectangle([50, 100, 150, 300], fill='brown', outline='black', width=2)   # ì±…ìƒ
    draw.rectangle([200, 150, 300, 250], fill='red', outline='black', width=2)    # ì±…
    draw.rectangle([350, 120, 450, 280], fill='black', outline='gray', width=2)   # ì¹ íŒ
    draw.ellipse([500, 200, 600, 300], fill='green', outline='black', width=2)    # ê°€ë°©
    
    test_images.append(('classroom_scene.jpg', img2))
    
    # 3. ë‹¤ì–‘í•œ ê°ì²´ê°€ ìˆëŠ” ë³µí•© ì¥ë©´
    img3 = Image.new('RGB', (640, 480), color='skyblue')
    draw = ImageDraw.Draw(img3)
    
    # ì—¬ëŸ¬ ê°ì²´ ë°°ì¹˜
    objects = [
        ([100, 100, 180, 200], 'orange'),   # ì‚¬ëŒ í˜•íƒœ
        ([250, 150, 350, 250], 'red'),      # ìë™ì°¨ í˜•íƒœ
        ([400, 200, 500, 300], 'blue'),     # ì˜ì í˜•íƒœ
        ([150, 300, 250, 350], 'green'),    # ì±… í˜•íƒœ
        ([350, 350, 450, 400], 'purple'),   # ê°€ë°© í˜•íƒœ
    ]
    
    for bbox, color in objects:
        draw.rectangle(bbox, fill=color, outline='black', width=2)
    
    test_images.append(('mixed_objects.jpg', img3))
    
    return test_images

def demonstrate_yolo_features():
    """YOLOv8 ì£¼ìš” ê¸°ëŠ¥ ì‹œì—°"""
    print("ğŸš€ YOLOv8 ê¸°ëŠ¥ ì‹œì—° ì‹œì‘")
    print("=" * 50)
    
    # 1. YOLOv8 ë¶„ì„ê¸° ìƒì„±
    print("\n1ï¸âƒ£ YOLOv8 ëª¨ë¸ ì´ˆê¸°í™”")
    analyzer = YOLOv8Analyzer(model_size='n')  # Nano ë²„ì „ ì‚¬ìš© (ë¹ ë¥¸ í…ŒìŠ¤íŠ¸)
    
    # 2. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    print("\n2ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±")
    test_images = create_test_images()
    
    # ì´ë¯¸ì§€ ì €ì¥ ë° í‘œì‹œ
    saved_paths = []
    for name, img in test_images:
        img.save(name)
        saved_paths.append(name)
        print(f"   ğŸ’¾ {name} ì €ì¥ ì™„ë£Œ")
    
    # ìƒì„±ëœ ì´ë¯¸ì§€ í‘œì‹œ
    fig, axes = plt.subplots(1, len(test_images), figsize=(15, 5))
    for i, (name, img) in enumerate(test_images):
        axes[i].imshow(img)
        axes[i].set_title(name.replace('.jpg', ''))
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()
    
    # 3. ê°ì²´ íƒì§€ ìˆ˜í–‰
    print("\n3ï¸âƒ£ ê°ì²´ íƒì§€ ìˆ˜í–‰")
    
    for i, (name, img) in enumerate(test_images):
        print(f"\nğŸ“¸ {name} ë¶„ì„ ì¤‘...")
        
        # íƒì§€ ìˆ˜í–‰
        results = analyzer.detect_objects(name, conf_threshold=0.1)  # ë‚®ì€ ì„ê³„ê°’ìœ¼ë¡œ ë” ë§ì€ íƒì§€
        
        # ê²°ê³¼ ë¶„ì„
        analysis = analyzer.analyze_detection_results(results)
        
        print(f"   íƒì§€ëœ ê°ì²´: {analysis['total_objects']}ê°œ")
        print(f"   ê³ ìœ  í´ë˜ìŠ¤: {analysis['unique_classes']}ê°œ")
        
        if analysis['classes']:
            print("   í´ë˜ìŠ¤ë³„ íƒì§€ ê²°ê³¼:")
            for class_name, stats in analysis['classes'].items():
                print(f"     - {class_name}: {stats['count']}ê°œ (í‰ê·  ì‹ ë¢°ë„: {stats['avg_confidence']:.2f})")
        
        # ì‹œê°í™”
        annotated_img = analyzer.visualize_results(img, results, save_path=f"result_{name}")
    
    # 4. ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬
    print("\n4ï¸âƒ£ ì„±ëŠ¥ ë²¤ì¹˜ë§ˆí¬")
    benchmark_results = analyzer.benchmark_performance(saved_paths, num_runs=3)
    
    # 5. ëª¨ë¸ í¬ê¸° ë¹„êµ
    print("\n5ï¸âƒ£ ëª¨ë¸ í¬ê¸° ë¹„êµ")
    comparison_results = analyzer.compare_model_sizes(saved_paths[0])
    
    # 6. ê²°ê³¼ ì‹œê°í™”
    print("\n6ï¸âƒ£ ê²°ê³¼ ì‹œê°í™”")
    analyzer.visualize_benchmark_results(benchmark_results, comparison_results)
    
    # 7. ì •ë¦¬
    print("\nğŸ§¹ ì„ì‹œ íŒŒì¼ ì •ë¦¬")
    for path in saved_paths:
        try:
            Path(path).unlink()
            print(f"   ğŸ—‘ï¸ {path} ì‚­ì œ")
        except:
            pass
    
    print("\nğŸ‰ YOLOv8 ê¸°ëŠ¥ ì‹œì—° ì™„ë£Œ!")
    
    return analyzer, benchmark_results, comparison_results

def advanced_detection_demo():
    """ê³ ê¸‰ íƒì§€ ê¸°ëŠ¥ ë°ëª¨"""
    print("\nğŸ”¬ ê³ ê¸‰ YOLOv8 ê¸°ëŠ¥ ë°ëª¨")
    print("=" * 50)
    
    analyzer = YOLOv8Analyzer('s')  # Small ëª¨ë¸ ì‚¬ìš©
    
    # 1. ë‹¤ì–‘í•œ ì„ê³„ê°’ í…ŒìŠ¤íŠ¸
    print("\n1ï¸âƒ£ ì‹ ë¢°ë„ ì„ê³„ê°’ ì˜í–¥ ë¶„ì„")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    test_img = Image.new('RGB', (640, 480), color='white')
    draw = ImageDraw.Draw(test_img)
    
    # ë³µì¡í•œ ì¥ë©´ ìƒì„±
    for i in range(10):
        x = np.random.randint(50, 550)
        y = np.random.randint(50, 400)
        w = np.random.randint(30, 100)
        h = np.random.randint(30, 100)
        color = tuple(np.random.randint(0, 256, 3))
        draw.rectangle([x, y, x+w, y+h], fill=color, outline='black')
    
    test_img.save('complex_scene.jpg')
    
    # ë‹¤ì–‘í•œ ì„ê³„ê°’ìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    thresholds = [0.1, 0.25, 0.5, 0.7, 0.9]
    threshold_results = {}
    
    for threshold in thresholds:
        results = analyzer.detect_objects('complex_scene.jpg', conf_threshold=threshold)
        analysis = analyzer.analyze_detection_results(results)
        threshold_results[threshold] = analysis['total_objects']
        print(f"   ì„ê³„ê°’ {threshold}: {analysis['total_objects']}ê°œ ê°ì²´ íƒì§€")
    
    # ì„ê³„ê°’ ì˜í–¥ ì‹œê°í™”
    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, [threshold_results[t] for t in thresholds], 'bo-', linewidth=2, markersize=8)
    plt.xlabel('ì‹ ë¢°ë„ ì„ê³„ê°’')
    plt.ylabel('íƒì§€ëœ ê°ì²´ ìˆ˜')
    plt.title('ì‹ ë¢°ë„ ì„ê³„ê°’ì´ íƒì§€ ê²°ê³¼ì— ë¯¸ì¹˜ëŠ” ì˜í–¥')
    plt.grid(True, alpha=0.3)
    plt.show()
    
    # 2. ì‹¤ì‹œê°„ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    print("\n2ï¸âƒ£ ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥ ì‹œë®¬ë ˆì´ì…˜")
    
    # ì—°ì† ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜
    processing_times = []
    
    for i in range(20):  # 20í”„ë ˆì„ ì‹œë®¬ë ˆì´ì…˜
        # ëœë¤ ì´ë¯¸ì§€ ìƒì„±
        random_img = Image.new('RGB', (640, 480), 
                              color=tuple(np.random.randint(100, 256, 3)))
        draw = ImageDraw.Draw(random_img)
        
        # ëœë¤ ê°ì²´ ì¶”ê°€
        for _ in range(np.random.randint(1, 5)):
            x = np.random.randint(0, 500)
            y = np.random.randint(0, 400)
            w = np.random.randint(50, 150)
            h = np.random.randint(50, 150)
            color = tuple(np.random.randint(0, 256, 3))
            draw.rectangle([x, y, x+w, y+h], fill=color)
        
        # ì²˜ë¦¬ ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        results = analyzer.detect_objects(random_img)
        end_time = time.time()
        
        processing_time = (end_time - start_time) * 1000
        processing_times.append(processing_time)
        
        if i % 5 == 0:
            print(f"   í”„ë ˆì„ {i+1}: {processing_time:.1f}ms")
    
    # ì‹¤ì‹œê°„ ì„±ëŠ¥ ë¶„ì„
    avg_time = np.mean(processing_times)
    fps = 1000 / avg_time
    
    print(f"\nğŸ“Š ì‹¤ì‹œê°„ ì²˜ë¦¬ ì„±ëŠ¥:")
    print(f"   í‰ê·  ì²˜ë¦¬ ì‹œê°„: {avg_time:.1f}ms")
    print(f"   ì˜ˆìƒ FPS: {fps:.1f}")
    print(f"   ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥: {'âœ…' if fps >= 30 else 'âŒ'}")
    
    # ì²˜ë¦¬ ì‹œê°„ ë¶„í¬ ì‹œê°í™”
    plt.figure(figsize=(12, 5))
    
    plt.subplot(1, 2, 1)
    plt.plot(processing_times, 'b-', alpha=0.7)
    plt.axhline(y=avg_time, color='r', linestyle='--', label=f'í‰ê· : {avg_time:.1f}ms')
    plt.xlabel('í”„ë ˆì„ ë²ˆí˜¸')
    plt.ylabel('ì²˜ë¦¬ ì‹œê°„ (ms)')
    plt.title('í”„ë ˆì„ë³„ ì²˜ë¦¬ ì‹œê°„')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.subplot(1, 2, 2)
    plt.hist(processing_times, bins=10, alpha=0.7, color='skyblue', edgecolor='black')
    plt.axvline(x=avg_time, color='r', linestyle='--', label=f'í‰ê· : {avg_time:.1f}ms')
    plt.xlabel('ì²˜ë¦¬ ì‹œê°„ (ms)')
    plt.ylabel('ë¹ˆë„')
    plt.title('ì²˜ë¦¬ ì‹œê°„ ë¶„í¬')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()
    
    # ì •ë¦¬
    try:
        Path('complex_scene.jpg').unlink()
    except:
        pass
    
    print("\nğŸ‰ ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨ ì™„ë£Œ!")

def main():
    """ë©”ì¸ ì‹¤ìŠµ í•¨ìˆ˜"""
    print("ğŸ¯ Week 5: YOLOv8 ê¸°ì´ˆ ì‹¤ìŠµ")
    print("=" * 60)
    
    try:
        # 1. ê¸°ë³¸ ê¸°ëŠ¥ ì‹œì—°
        analyzer, benchmark_results, comparison_results = demonstrate_yolo_features()
        
        # 2. ê³ ê¸‰ ê¸°ëŠ¥ ë°ëª¨
        advanced_detection_demo()
        
        print("\nğŸ“š ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
        print("   - ì‹¤ì œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ìœ¼ë¡œ í…ŒìŠ¤íŠ¸")
        print("   - ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ê°ì²´ íƒì§€")
        print("   - ì›¹ìº ì„ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ íƒì§€")
        print("   - ì»¤ìŠ¤í…€ í´ë˜ìŠ¤ë¡œ ëª¨ë¸ íŒŒì¸íŠœë‹")
        print("   - ë‹¤ë¥¸ YOLO ë²„ì „ê³¼ ì„±ëŠ¥ ë¹„êµ")
        
    except Exception as e:
        print(f"âŒ ì‹¤ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("ğŸ’¡ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ìƒíƒœë¥¼ í™•ì¸í•˜ê³  ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.")

if __name__ == "__main__":
    main()
