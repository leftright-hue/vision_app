"""
í–‰ë™ì¸ì‹ í—¬í¼ í´ë˜ìŠ¤
3-tier fallback ì „ëµ: HuggingFace Transformers â†’ OpenCV â†’ Simulation
"""

import numpy as np
from PIL import Image
import streamlit as st
from typing import Optional, List, Dict, Tuple, Any, Union
import warnings
import sys
import os

# BaseImageProcessor import
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(__file__))))
from core.base_processor import BaseImageProcessor


class VideoHelper(BaseImageProcessor):
    """
    ë¹„ë””ì˜¤ í–‰ë™ì¸ì‹ í—¬í¼ í´ë˜ìŠ¤
    - 1ìˆœìœ„: HuggingFace Transformers (transformers íŒ¨í‚¤ì§€ + VideoMAE/TimeSformer ëª¨ë¸)
    - 2ìˆœìœ„: OpenCV only (ë¹„ë””ì˜¤ ì²˜ë¦¬, Optical Flowë§Œ ê°€ëŠ¥, ML ëª¨ë¸ ì—†ìŒ)
    - 3ìˆœìœ„: Simulation mode (ê¸°ë³¸ ë¹„ë””ì˜¤ ì²˜ë¦¬ ì‹œë®¬ë ˆì´ì…˜)
    """

    def __init__(self):
        """
        VideoHelper ì´ˆê¸°í™”
        - 3-tier fallbackìœ¼ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“œ ê°ì§€
        - ë””ë°”ì´ìŠ¤ ê°ì§€ (CPU/GPU)
        """
        super().__init__()
        self.mode = None  # 'transformers', 'opencv', 'simulation'
        self.device = None  # 'cuda', 'cpu', None
        self.model = None
        self.processor = None
        self.pipeline = None

        self._initialize()

    def _initialize(self):
        """
        3-tier fallbackìœ¼ë¡œ ì´ˆê¸°í™”
        """
        # Tier 1: Try HuggingFace Transformers
        if self._try_transformers():
            self.mode = 'transformers'
            st.success("âœ… í–‰ë™ì¸ì‹ ì¤€ë¹„ ì™„ë£Œ (HuggingFace Transformers)")
            return

        # Tier 2: Try OpenCV only
        if self._try_opencv():
            self.mode = 'opencv'
            st.info("â„¹ï¸ OpenCV ëª¨ë“œ í™œì„±í™” (ë¹„ë””ì˜¤ ì²˜ë¦¬ ê°€ëŠ¥, ML ëª¨ë¸ ë¯¸ì‚¬ìš©)\n\n"
                   "í–‰ë™ ë¶„ë¥˜ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´:\n"
                   "```bash\n"
                   "pip install transformers torch\n"
                   "```")
            return

        # Tier 3: Fallback to simulation
        self.mode = 'simulation'
        st.warning("âš ï¸ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ (ì‹¤ì œ ë¹„ë””ì˜¤ ì²˜ë¦¬ ë¯¸ì‚¬ìš©)\n\n"
                  "ì‹¤ì œ ê¸°ëŠ¥ì„ ì‚¬ìš©í•˜ë ¤ë©´:\n"
                  "```bash\n"
                  "pip install opencv-python transformers torch\n"
                  "```")

    def _try_transformers(self) -> bool:
        """
        HuggingFace Transformersë¡œ ë¡œë“œ ì‹œë„
        VideoMAE, TimeSformer, X-CLIP ë“± ë¹„ë””ì˜¤ ëª¨ë¸ ì§€ì›
        """
        try:
            import transformers
            import torch

            # ë””ë°”ì´ìŠ¤ ê°ì§€
            self.device = "cuda" if torch.cuda.is_available() else "cpu"
            if self.device == "cpu":
                st.info("â„¹ï¸ GPUë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ì–´ CPUë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤. (ë¹„ë””ì˜¤ ì²˜ë¦¬ëŠ” ëŠë¦´ ìˆ˜ ìˆìŒ)")

            # í•„ìš”í•œ ëª¨ë“ˆì´ ìˆëŠ”ì§€ë§Œ í™•ì¸ (ì‹¤ì œ ëª¨ë¸ì€ ë‚˜ì¤‘ì— ë¡œë“œ)
            return True

        except ImportError:
            return False
        except Exception as e:
            st.error(f"Transformers ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            return False

    def _try_opencv(self) -> bool:
        """
        OpenCV ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        ë¹„ë””ì˜¤ ì²˜ë¦¬ì™€ Optical FlowëŠ” ê°€ëŠ¥í•˜ì§€ë§Œ ML ëª¨ë¸ì€ ì—†ìŒ
        """
        try:
            import cv2
            return True
        except ImportError:
            return False
        except Exception as e:
            return False

    def _detect_device(self) -> Optional[str]:
        """
        CUDA ë””ë°”ì´ìŠ¤ ê°ì§€
        Returns:
            'cuda', 'cpu', or None
        """
        try:
            import torch
            return "cuda" if torch.cuda.is_available() else "cpu"
        except ImportError:
            return None

    def get_mode(self) -> str:
        """
        í˜„ì¬ ë™ì‘ ëª¨ë“œ ë°˜í™˜
        Returns:
            'transformers', 'opencv', 'simulation'
        """
        return self.mode

    def get_device(self) -> Optional[str]:
        """
        í˜„ì¬ ë””ë°”ì´ìŠ¤ ë°˜í™˜
        Returns:
            'cuda', 'cpu', or None
        """
        return self.device

    def is_available(self, feature: str) -> bool:
        """
        íŠ¹ì • ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸

        Args:
            feature: 'video_processing', 'optical_flow', 'action_classification'

        Returns:
            bool: ê¸°ëŠ¥ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        """
        if feature == 'video_processing':
            return self.mode in ['transformers', 'opencv']
        elif feature == 'optical_flow':
            return self.mode in ['transformers', 'opencv']
        elif feature == 'action_classification':
            return self.mode == 'transformers'
        else:
            return False

    def extract_frames(
        self,
        video_path: str,
        sample_rate: int = 30,
        max_frames: int = 100,
        target_size: Tuple[int, int] = (224, 224)
    ) -> List[np.ndarray]:
        """
        ë¹„ë””ì˜¤ì—ì„œ í”„ë ˆì„ ì¶”ì¶œ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì )

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            sample_rate: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ì˜ˆ: 30ì´ë©´ 30í”„ë ˆì„ë‹¹ 1ê°œ ì¶”ì¶œ)
            max_frames: ìµœëŒ€ í”„ë ˆì„ ìˆ˜ (ë©”ëª¨ë¦¬ ì œí•œ)
            target_size: ì¶œë ¥ ì´ë¯¸ì§€ í¬ê¸° (width, height)

        Returns:
            List[np.ndarray]: í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸, ê° í”„ë ˆì„ shape (H, W, 3) RGB
        """
        # Simulation mode: ëœë¤ í”„ë ˆì„ ìƒì„±
        if self.mode == 'simulation':
            st.info("â„¹ï¸ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ: ëœë¤ í”„ë ˆì„ ìƒì„±")
            frames = []
            for _ in range(min(10, max_frames)):
                frame = np.random.randint(0, 255, (target_size[1], target_size[0], 3), dtype=np.uint8)
                frames.append(frame)
            return frames

        # OpenCV or Transformers mode
        try:
            import cv2

            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

            # ë¹„ë””ì˜¤ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))

            # ì‹¤ì œ ìƒ˜í”Œë§ ë ˆì´íŠ¸ ê³„ì‚° (max_frames ì œí•œ ê³ ë ¤)
            actual_sample_rate = max(sample_rate, total_frames // max_frames) if total_frames > max_frames else sample_rate

            st.info(f"ğŸ“¹ ë¹„ë””ì˜¤ ì •ë³´: {total_frames}í”„ë ˆì„, {fps}fps\n"
                   f"ìƒ˜í”Œë§: ë§¤ {actual_sample_rate}í”„ë ˆì„ë‹¹ 1ê°œ ì¶”ì¶œ")

            frames = []
            frame_idx = 0

            # í”„ë ˆì„ ì¶”ì¶œ
            while len(frames) < max_frames:
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_idx)
                ret, frame = cap.read()

                if not ret:
                    break

                # BGR â†’ RGB ë³€í™˜
                frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

                # ë¦¬ì‚¬ì´ì¦ˆ
                frame_resized = cv2.resize(frame_rgb, target_size, interpolation=cv2.INTER_LINEAR)

                frames.append(frame_resized)
                frame_idx += actual_sample_rate

            cap.release()

            st.success(f"âœ… {len(frames)}ê°œ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ")
            return frames

        except ImportError:
            st.error("âŒ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return []
        except Exception as e:
            st.error(f"âŒ í”„ë ˆì„ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return []

    def compute_optical_flow(
        self,
        frame1: np.ndarray,
        frame2: np.ndarray
    ) -> np.ndarray:
        """
        ë‘ í”„ë ˆì„ ê°„ Optical Flow ê³„ì‚° (Farneback ì•Œê³ ë¦¬ì¦˜)

        Args:
            frame1: ì²« ë²ˆì§¸ í”„ë ˆì„ (H, W, 3) RGB
            frame2: ë‘ ë²ˆì§¸ í”„ë ˆì„ (H, W, 3) RGB

        Returns:
            np.ndarray: Optical flow (H, W, 2) - [dx, dy] ëª¨ì…˜ ë²¡í„°
        """
        # Simulation mode: ëœë¤ flow ìƒì„±
        if self.mode == 'simulation':
            h, w = frame1.shape[:2]
            flow = np.random.randn(h, w, 2).astype(np.float32) * 2
            return flow

        # OpenCV or Transformers mode
        try:
            import cv2

            # RGB â†’ Grayscale
            gray1 = cv2.cvtColor(frame1, cv2.COLOR_RGB2GRAY)
            gray2 = cv2.cvtColor(frame2, cv2.COLOR_RGB2GRAY)

            # Farneback Optical Flow ê³„ì‚°
            flow = cv2.calcOpticalFlowFarneback(
                gray1, gray2,
                None,
                pyr_scale=0.5,    # í”¼ë¼ë¯¸ë“œ ìŠ¤ì¼€ì¼
                levels=3,          # í”¼ë¼ë¯¸ë“œ ë ˆë²¨
                winsize=15,        # ìœˆë„ìš° í¬ê¸°
                iterations=3,      # ë°˜ë³µ íšŸìˆ˜
                poly_n=5,          # ë‹¤í•­ì‹ í™•ì¥
                poly_sigma=1.2,    # ê°€ìš°ì‹œì•ˆ ì‹œê·¸ë§ˆ
                flags=0
            )

            return flow

        except ImportError:
            st.error("âŒ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return np.zeros((frame1.shape[0], frame1.shape[1], 2), dtype=np.float32)
        except Exception as e:
            st.error(f"âŒ Optical Flow ê³„ì‚° ì‹¤íŒ¨: {e}")
            return np.zeros((frame1.shape[0], frame1.shape[1], 2), dtype=np.float32)

    def visualize_flow(
        self,
        flow: np.ndarray
    ) -> np.ndarray:
        """
        Optical Flowë¥¼ HSV ìƒ‰ìƒ ê³µê°„ìœ¼ë¡œ ì‹œê°í™”

        Args:
            flow: Optical flow (H, W, 2) - [dx, dy] ëª¨ì…˜ ë²¡í„°

        Returns:
            np.ndarray: RGB ì´ë¯¸ì§€ (H, W, 3)
        """
        try:
            import cv2

            h, w = flow.shape[:2]

            # HSV ì´ë¯¸ì§€ ìƒì„±
            hsv = np.zeros((h, w, 3), dtype=np.uint8)
            hsv[..., 1] = 255  # Saturationì„ ìµœëŒ€ë¡œ

            # Magnitude (í¬ê¸°)ì™€ Angle (ê°ë„) ê³„ì‚°
            magnitude, angle = cv2.cartToPolar(flow[..., 0], flow[..., 1])

            # Hue: ë°©í–¥ (0-180 ë²”ìœ„)
            hsv[..., 0] = angle * 180 / np.pi / 2

            # Value: í¬ê¸° (ì •ê·œí™”)
            hsv[..., 2] = cv2.normalize(magnitude, None, 0, 255, cv2.NORM_MINMAX)

            # HSV â†’ RGB ë³€í™˜
            rgb = cv2.cvtColor(hsv, cv2.COLOR_HSV2RGB)

            return rgb

        except ImportError:
            st.error("âŒ OpenCVê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)
        except Exception as e:
            st.error(f"âŒ Flow ì‹œê°í™” ì‹¤íŒ¨: {e}")
            return np.zeros((flow.shape[0], flow.shape[1], 3), dtype=np.uint8)


@st.cache_resource
def get_video_helper() -> VideoHelper:
    """
    ìºì‹œëœ VideoHelper ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì‹±ê¸€í†¤ íŒ¨í„´)

    Returns:
        VideoHelper: ìºì‹œëœ í—¬í¼ ì¸ìŠ¤í„´ìŠ¤
    """
    return VideoHelper()
