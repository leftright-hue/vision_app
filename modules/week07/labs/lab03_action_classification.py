"""
Lab 03: í–‰ë™ ë¶„ë¥˜ (Action Classification)

ì´ ì‹¤ìŠµì—ì„œëŠ” ì‚¬ì „í›ˆë ¨ëœ HuggingFace ëª¨ë¸ì„ ì‚¬ìš©í•œ í–‰ë™ ë¶„ë¥˜ë¥¼ ë°°ì›ë‹ˆë‹¤:
- VideoMAE ëª¨ë¸ë¡œ í–‰ë™ ì¸ì‹
- TimeSformer ëª¨ë¸ í™œìš©
- X-CLIP ëª¨ë¸ ì‚¬ìš©
- ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸”

ì‚¬ìš©ë²•:
    python lab03_action_classification.py --input sample.mp4 --model videomae
    python lab03_action_classification.py --input sample.mp4 --ensemble
"""

import argparse
import tempfile
from pathlib import Path
from typing import List, Tuple, Optional, Dict
import numpy as np

try:
    from transformers import (
        AutoImageProcessor,
        AutoModelForVideoClassification,
        VideoMAEImageProcessor,
        VideoMAEForVideoClassification,
        TimesformerForVideoClassification
    )
    import torch
    HAS_TRANSFORMERS = True
except ImportError:
    HAS_TRANSFORMERS = False

try:
    import cv2
    HAS_OPENCV = True
except ImportError:
    HAS_OPENCV = False


# ëª¨ë¸ ë ˆì§€ìŠ¤íŠ¸ë¦¬
MODEL_REGISTRY = {
    'videomae': 'MCG-NJU/videomae-base-finetuned-kinetics',
    'timesformer': 'facebook/timesformer-base-finetuned-k400',
    'xclip': 'microsoft/xclip-base-patch32',
}


class ActionClassifier:
    """
    HuggingFace ì‚¬ì „í›ˆë ¨ ëª¨ë¸ì„ ì‚¬ìš©í•œ í–‰ë™ ë¶„ë¥˜ê¸°
    """

    def __init__(self, model_name: str = 'videomae'):
        """
        Args:
            model_name: 'videomae', 'timesformer', 'xclip' ì¤‘ ì„ íƒ
        """
        if not HAS_TRANSFORMERS:
            raise ImportError("transformers íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install transformers torch")

        if not HAS_OPENCV:
            raise ImportError("opencv-python íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install opencv-python")

        self.model_name = model_name
        self.model_id = MODEL_REGISTRY.get(model_name)

        if not self.model_id:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” ëª¨ë¸: {model_name}")

        # ë””ë°”ì´ìŠ¤ ì„¤ì •
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        print(f"ë””ë°”ì´ìŠ¤: {self.device}")

        # ëª¨ë¸ ë¡œë“œ
        print(f"ëª¨ë¸ ë¡œë”© ì¤‘: {self.model_id}")
        self.processor = AutoImageProcessor.from_pretrained(self.model_id)
        self.model = AutoModelForVideoClassification.from_pretrained(self.model_id)
        self.model.to(self.device)
        self.model.eval()

        print(f"âœ… {model_name} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    def extract_frames(
        self,
        video_path: str,
        num_frames: int = 16,
        target_size: Tuple[int, int] = (224, 224)
    ) -> List[np.ndarray]:
        """
        ë¹„ë””ì˜¤ì—ì„œ ê· ë“±í•˜ê²Œ í”„ë ˆì„ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            num_frames: ì¶”ì¶œí•  í”„ë ˆì„ ìˆ˜
            target_size: íƒ€ê²Ÿ í¬ê¸° (width, height)

        Returns:
            í”„ë ˆì„ ë¦¬ìŠ¤íŠ¸ (RGB)
        """
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))

        # ê· ë“±í•˜ê²Œ í”„ë ˆì„ ì¸ë±ìŠ¤ ì„ íƒ
        frame_indices = np.linspace(0, total_frames - 1, num_frames, dtype=int)

        frames = []

        for idx in frame_indices:
            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)
            ret, frame = cap.read()

            if not ret:
                continue

            # BGR -> RGB ë³€í™˜
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)

            # í¬ê¸° ì¡°ì •
            frame_resized = cv2.resize(frame_rgb, target_size)

            frames.append(frame_resized)

        cap.release()

        if len(frames) < num_frames:
            # ë¶€ì¡±í•œ ê²½ìš° ë§ˆì§€ë§‰ í”„ë ˆì„ ë³µì œ
            while len(frames) < num_frames:
                frames.append(frames[-1])

        return frames

    def classify(
        self,
        video_path: str,
        top_k: int = 5
    ) -> List[Tuple[str, float]]:
        """
        ë¹„ë””ì˜¤ì˜ í–‰ë™ì„ ë¶„ë¥˜í•©ë‹ˆë‹¤.

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            top_k: ë°˜í™˜í•  ìƒìœ„ ì˜ˆì¸¡ ìˆ˜

        Returns:
            (label, score) ë¦¬ìŠ¤íŠ¸
        """
        # í”„ë ˆì„ ì¶”ì¶œ
        print(f"í”„ë ˆì„ ì¶”ì¶œ ì¤‘...")
        frames = self.extract_frames(video_path, num_frames=16)

        # ì „ì²˜ë¦¬
        print(f"ì „ì²˜ë¦¬ ì¤‘...")
        inputs = self.processor(frames, return_tensors="pt")
        inputs = {k: v.to(self.device) for k, v in inputs.items()}

        # ì¶”ë¡ 
        print(f"ì¶”ë¡  ì¤‘...")
        with torch.no_grad():
            outputs = self.model(**inputs)
            logits = outputs.logits

        # Softmax
        probs = torch.nn.functional.softmax(logits, dim=-1)
        probs = probs.cpu().numpy()[0]

        # Top-K ì„ íƒ
        top_indices = np.argsort(probs)[::-1][:top_k]

        results = []
        for idx in top_indices:
            label = self.model.config.id2label[idx]
            score = float(probs[idx])
            results.append((label, score))

        return results


class EnsembleClassifier:
    """
    ë‹¤ì¤‘ ëª¨ë¸ ì•™ìƒë¸” ë¶„ë¥˜ê¸°
    """

    def __init__(self, model_names: List[str] = None):
        """
        Args:
            model_names: ì•™ìƒë¸”í•  ëª¨ë¸ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ëª¨ë“  ëª¨ë¸)
        """
        if model_names is None:
            model_names = ['videomae', 'timesformer']

        self.classifiers = {}

        for name in model_names:
            try:
                print(f"\n{name} ëª¨ë¸ ë¡œë”©...")
                self.classifiers[name] = ActionClassifier(name)
            except Exception as e:
                print(f"âš ï¸ {name} ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        if not self.classifiers:
            raise ValueError("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤")

        print(f"\nâœ… ì•™ìƒë¸” ì¤€ë¹„ ì™„ë£Œ ({len(self.classifiers)}ê°œ ëª¨ë¸)")

    def classify(
        self,
        video_path: str,
        top_k: int = 5,
        voting: str = 'soft'
    ) -> List[Tuple[str, float]]:
        """
        ì•™ìƒë¸” ë¶„ë¥˜ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            video_path: ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ
            top_k: ë°˜í™˜í•  ìƒìœ„ ì˜ˆì¸¡ ìˆ˜
            voting: 'soft' (í™•ë¥  í‰ê· ) ë˜ëŠ” 'hard' (ë‹¤ìˆ˜ê²°)

        Returns:
            (label, score) ë¦¬ìŠ¤íŠ¸
        """
        all_predictions = {}

        # ê° ëª¨ë¸ì—ì„œ ì˜ˆì¸¡
        for name, classifier in self.classifiers.items():
            print(f"\n{name} ëª¨ë¸ ì˜ˆì¸¡ ì¤‘...")
            preds = classifier.classify(video_path, top_k=20)  # ë” ë§ì€ í›„ë³´ ìˆ˜ì§‘

            for label, score in preds:
                if label not in all_predictions:
                    all_predictions[label] = []
                all_predictions[label].append(score)

        # ì•™ìƒë¸”
        ensemble_results = []

        if voting == 'soft':
            # í™•ë¥  í‰ê· 
            for label, scores in all_predictions.items():
                avg_score = np.mean(scores)
                ensemble_results.append((label, avg_score))

        elif voting == 'hard':
            # ë‹¤ìˆ˜ê²° (ë“±ì¥ íšŸìˆ˜)
            for label, scores in all_predictions.items():
                vote_count = len(scores)
                ensemble_results.append((label, vote_count / len(self.classifiers)))

        # ì •ë ¬
        ensemble_results.sort(key=lambda x: x[1], reverse=True)

        return ensemble_results[:top_k]


def main():
    parser = argparse.ArgumentParser(description="Lab 03: í–‰ë™ ë¶„ë¥˜")
    parser.add_argument("--input", type=str, required=True,
                       help="ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ ê²½ë¡œ")
    parser.add_argument("--model", type=str, default='videomae',
                       choices=['videomae', 'timesformer', 'xclip'],
                       help="ì‚¬ìš©í•  ëª¨ë¸")
    parser.add_argument("--ensemble", action="store_true",
                       help="ì•™ìƒë¸” ëª¨ë“œ ì‚¬ìš©")
    parser.add_argument("--top-k", type=int, default=5,
                       help="ìƒìœ„ Kê°œ ì˜ˆì¸¡ ì¶œë ¥")

    args = parser.parse_args()

    print(f"ğŸ“¹ ë¹„ë””ì˜¤ íŒŒì¼: {args.input}")

    try:
        if args.ensemble:
            # ì•™ìƒë¸” ëª¨ë“œ
            print("\nğŸ­ ì•™ìƒë¸” ëª¨ë“œ")
            classifier = EnsembleClassifier()
            results = classifier.classify(args.input, top_k=args.top_k)

        else:
            # ë‹¨ì¼ ëª¨ë¸ ëª¨ë“œ
            print(f"\nğŸ¤– ëª¨ë¸: {args.model}")
            classifier = ActionClassifier(args.model)
            results = classifier.classify(args.input, top_k=args.top_k)

        # ê²°ê³¼ ì¶œë ¥
        print(f"\n{'='*60}")
        print(f"Top-{args.top_k} ì˜ˆì¸¡ ê²°ê³¼:")
        print(f"{'='*60}")

        for i, (label, score) in enumerate(results, 1):
            bar = 'â–ˆ' * int(score * 50)
            print(f"{i}. {label:30s} {score:.4f} {bar}")

        print(f"{'='*60}")

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
