"""
Lab 06: MediaPipeì™€ Google Video Intelligence API ë°ëª¨
ì‹¤ì‹œê°„ í–‰ë™ ì¸ì‹ ì‹¤ìŠµ
"""

import cv2
import numpy as np
import time
import os
from typing import List, Dict, Any, Tuple
import json

print("=" * 60)
print("Week 7 - Lab 06: MediaPipe & Google Video Intelligence Demo")
print("=" * 60)

# ============================================
# Part 1: MediaPipe ì‹¤ì‹œê°„ í–‰ë™ ì¸ì‹
# ============================================

def demo_mediapipe():
    """MediaPipeë¥¼ ì´ìš©í•œ ì‹¤ì‹œê°„ í¬ì¦ˆ ê°ì§€ ë° ìš´ë™ ì¹´ìš´íŒ…"""
    print("\nğŸ“¹ MediaPipe ë°ëª¨ ì‹œì‘...")

    try:
        import mediapipe as mp

        mp_pose = mp.solutions.pose
        mp_drawing = mp.solutions.drawing_utils

        print("âœ… MediaPipe ë¡œë“œ ì„±ê³µ!")

        # í¬ì¦ˆ ê°ì§€ê¸° ì´ˆê¸°í™”
        pose = mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        # ì›¹ìº  ì—´ê¸° (ë˜ëŠ” ë¹„ë””ì˜¤ íŒŒì¼)
        cap = cv2.VideoCapture(0)  # 0 = ê¸°ë³¸ ì›¹ìº 

        if not cap.isOpened():
            print("âŒ ì›¹ìº ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¹„ë””ì˜¤ íŒŒì¼ë¡œ ëŒ€ì²´...")
            # ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„±
            create_sample_video("sample_exercise.mp4")
            cap = cv2.VideoCapture("sample_exercise.mp4")

        # ìš´ë™ ì¹´ìš´í„° ë³€ìˆ˜
        counter = 0
        stage = None

        print("\nğŸƒ ìš´ë™ ì¹´ìš´íŒ… ì‹œì‘!")
        print("ESC í‚¤ë¥¼ ëˆ„ë¥´ë©´ ì¢…ë£Œë©ë‹ˆë‹¤.\n")

        while cap.isOpened():
            ret, frame = cap.read()
            if not ret:
                break

            # RGB ë³€í™˜
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False

            # í¬ì¦ˆ ê°ì§€
            results = pose.process(image)

            # BGR ë³€í™˜ (OpenCV í‘œì‹œìš©)
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if results.pose_landmarks:
                mp_drawing.draw_landmarks(
                    image,
                    results.pose_landmarks,
                    mp_pose.POSE_CONNECTIONS,
                    mp_drawing.DrawingSpec(color=(245,117,66), thickness=2, circle_radius=2),
                    mp_drawing.DrawingSpec(color=(245,66,230), thickness=2, circle_radius=2)
                )

                # ê°„ë‹¨í•œ ìŠ¤ì¿¼íŠ¸ ì¹´ìš´í„° (ë¬´ë¦ ê°ë„ ê¸°ë°˜)
                landmarks = results.pose_landmarks.landmark

                # ì™¼ìª½ ë¬´ë¦ ê°ë„ ê³„ì‚°
                hip = [landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].x,
                       landmarks[mp_pose.PoseLandmark.LEFT_HIP.value].y]
                knee = [landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].x,
                        landmarks[mp_pose.PoseLandmark.LEFT_KNEE.value].y]
                ankle = [landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].x,
                         landmarks[mp_pose.PoseLandmark.LEFT_ANKLE.value].y]

                angle = calculate_angle(hip, knee, ankle)

                # ìŠ¤ì¿¼íŠ¸ ì¹´ìš´íŒ… ë¡œì§
                if angle > 160:
                    stage = "up"
                if angle < 90 and stage == 'up':
                    stage = "down"
                    counter += 1
                    print(f"âœ… ìŠ¤ì¿¼íŠ¸ ì¹´ìš´íŠ¸: {counter}")

            # ì •ë³´ í‘œì‹œ
            cv2.rectangle(image, (0,0), (250,100), (245,117,16), -1)

            # ì¹´ìš´í„° í‘œì‹œ
            cv2.putText(image, 'REPS', (15,12),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)
            cv2.putText(image, str(counter),
                       (10,60),
                       cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 2, cv2.LINE_AA)

            # ìŠ¤í…Œì´ì§€ í‘œì‹œ
            cv2.putText(image, 'STAGE', (125,12),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)
            cv2.putText(image, stage if stage else "Ready",
                       (100,60),
                       cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)

            # ì´ë¯¸ì§€ í‘œì‹œ
            cv2.imshow('MediaPipe Pose Detection', image)

            if cv2.waitKey(10) & 0xFF == 27:  # ESC
                break

        cap.release()
        cv2.destroyAllWindows()

        print(f"\nğŸ“Š ìµœì¢… ê²°ê³¼: {counter}íšŒ ìš´ë™ ì™„ë£Œ!")

    except ImportError:
        print("âŒ MediaPipeê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ì„¤ì¹˜: pip install mediapipe opencv-python")


def calculate_angle(a, b, c):
    """ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ ê³„ì‚°"""
    import math

    a = np.array(a)
    b = np.array(b)
    c = np.array(c)

    radians = np.arctan2(c[1]-b[1], c[0]-b[0]) - np.arctan2(a[1]-b[1], a[0]-b[0])
    angle = np.abs(radians*180.0/np.pi)

    if angle > 180.0:
        angle = 360-angle

    return angle


# ============================================
# Part 2: Google Video Intelligence API ë°ëª¨
# ============================================

def demo_google_video_intelligence():
    """Google Video Intelligence APIë¥¼ ì´ìš©í•œ ë¹„ë””ì˜¤ ë¶„ì„"""
    print("\nâ˜ï¸ Google Video Intelligence API ë°ëª¨...")

    try:
        from google.cloud import videointelligence
        print("âœ… Google Cloud SDK ë¡œë“œ ì„±ê³µ!")

        # API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        video_client = videointelligence.VideoIntelligenceServiceClient()

        # ë¶„ì„í•  ë¹„ë””ì˜¤ (GCS URI ë˜ëŠ” ë¡œì»¬ íŒŒì¼)
        # ì˜ˆì‹œ: "gs://cloud-samples-data/video/gbikes_dinosaur.mp4"
        video_uri = input("GCS URI ì…ë ¥ (ë˜ëŠ” Enterë¡œ ìƒ˜í”Œ ì‚¬ìš©): ").strip()

        if not video_uri:
            video_uri = "gs://cloud-samples-data/video/gbikes_dinosaur.mp4"
            print(f"ìƒ˜í”Œ ë¹„ë””ì˜¤ ì‚¬ìš©: {video_uri}")

        # ë¶„ì„ ê¸°ëŠ¥ ì„ íƒ
        features = [
            videointelligence.Feature.LABEL_DETECTION,
            videointelligence.Feature.SHOT_CHANGE_DETECTION,
        ]

        print("\nğŸ”„ ë¹„ë””ì˜¤ ë¶„ì„ ì¤‘... (1-2ë¶„ ì†Œìš”)")

        # API í˜¸ì¶œ
        operation = video_client.annotate_video(
            request={"features": features, "input_uri": video_uri}
        )

        # ê²°ê³¼ ëŒ€ê¸°
        result = operation.result(timeout=180)
        print("âœ… ë¶„ì„ ì™„ë£Œ!\n")

        # ê²°ê³¼ íŒŒì‹±
        segment = result.annotation_results[0]

        # ë ˆì´ë¸” í‘œì‹œ
        print("ğŸ·ï¸ ê°ì§€ëœ ë ˆì´ë¸”:")
        for label_annotation in segment.segment_label_annotations[:10]:
            print(f"  - {label_annotation.entity.description}")

            for category in label_annotation.category_entities:
                print(f"    ì¹´í…Œê³ ë¦¬: {category.description}")

            for segment in label_annotation.segments[:1]:
                confidence = segment.confidence
                print(f"    ì‹ ë¢°ë„: {confidence:.2%}")

        # ì¥ë©´ ì „í™˜
        print(f"\nğŸ¬ ê°ì§€ëœ ì¥ë©´: {len(segment.shot_annotations)}ê°œ")

    except ImportError:
        print("âŒ Google Cloud SDKê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        print("ì„¤ì¹˜: pip install google-cloud-videointelligence")
        print("\nì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ í‘œì‹œ...")
        simulate_google_results()

    except Exception as e:
        print(f"âŒ API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")
        print("\nğŸ’¡ íŒ:")
        print("1. GOOGLE_APPLICATION_CREDENTIALS í™˜ê²½ë³€ìˆ˜ í™•ì¸")
        print("2. API í™œì„±í™” ì—¬ë¶€ í™•ì¸")
        print("3. ì„œë¹„ìŠ¤ ê³„ì • ê¶Œí•œ í™•ì¸")


def simulate_google_results():
    """Google API ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼"""
    print("\nğŸ“‹ ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼:")

    labels = [
        ("person", 0.95),
        ("bicycle", 0.89),
        ("outdoor", 0.87),
        ("vehicle", 0.82),
        ("road", 0.78),
        ("cycling", 0.92),
        ("sports", 0.75)
    ]

    print("\nğŸ·ï¸ ê°ì§€ëœ ë ˆì´ë¸”:")
    for label, confidence in labels:
        print(f"  - {label} (ì‹ ë¢°ë„: {confidence:.1%})")

    print("\nğŸ¬ ê°ì§€ëœ ì¥ë©´: 8ê°œ")
    print("  - ì¥ë©´ 1: 0.0s - 3.5s")
    print("  - ì¥ë©´ 2: 3.5s - 7.2s")
    print("  - ì¥ë©´ 3: 7.2s - 12.1s")
    print("  - ...")


# ============================================
# Part 3: ë¹„êµ ë° í†µí•©
# ============================================

def compare_approaches():
    """MediaPipe vs Google Video Intelligence ë¹„êµ"""
    print("\n" + "=" * 60)
    print("ğŸ“Š MediaPipe vs Google Video Intelligence ë¹„êµ")
    print("=" * 60)

    comparison = """
    | íŠ¹ì„± | MediaPipe | Google Video Intelligence |
    |------|-----------|--------------------------|
    | ì‹¤ì‹œê°„ ì²˜ë¦¬ | âœ… ê°€ëŠ¥ (30+ FPS) | âŒ ë°°ì¹˜ ì²˜ë¦¬ |
    | ì˜¤í”„ë¼ì¸ | âœ… ê°€ëŠ¥ | âŒ ì¸í„°ë„· í•„ìš” |
    | ë¹„ìš© | ë¬´ë£Œ | ìœ ë£Œ (ì›” 1000ë¶„ ë¬´ë£Œ) |
    | ì •í™•ë„ | ì¤‘ìƒ | ìƒ |
    | ì»¤ìŠ¤í„°ë§ˆì´ì§• | âœ… ê°€ëŠ¥ | âŒ ì œí•œì  |
    | í–‰ë™ ì¢…ë¥˜ | ì œí•œì  | 400+ ì‚¬ì „ì •ì˜ |
    | ì„¤ì¹˜ ë‚œì´ë„ | ì‰¬ì›€ | ì¤‘ê°„ (API ì„¤ì •) |
    | ìš©ë„ | ì‹¤ì‹œê°„ ì•± | ëŒ€ìš©ëŸ‰ ë¶„ì„ |
    """
    print(comparison)

    print("\nğŸ’¡ ì‚¬ìš© ê¶Œì¥ì‚¬í•­:")
    print("- ì‹¤ì‹œê°„ í”¼íŠ¸ë‹ˆìŠ¤ ì•± â†’ MediaPipe")
    print("- CCTV ì˜ìƒ ë¶„ì„ â†’ Google Video Intelligence")
    print("- í”„ë¡œí† íƒ€ì… â†’ MediaPipe")
    print("- í”„ë¡œë•ì…˜ (ëŒ€ê·œëª¨) â†’ Google Video Intelligence")


def create_sample_video(filename="sample.mp4"):
    """ê°„ë‹¨í•œ ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„±"""
    print(f"ğŸ“¹ ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„± ì¤‘: {filename}")

    # ë¹„ë””ì˜¤ ë¼ì´í„° ì„¤ì •
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')
    out = cv2.VideoWriter(filename, fourcc, 20.0, (640, 480))

    # ê°„ë‹¨í•œ ì• ë‹ˆë©”ì´ì…˜ (ì›€ì§ì´ëŠ” ì›)
    for i in range(100):
        frame = np.ones((480, 640, 3), dtype=np.uint8) * 255

        # ì›€ì§ì´ëŠ” ì›
        x = int(320 + 100 * np.sin(i * 0.1))
        y = int(240 + 100 * np.cos(i * 0.1))
        cv2.circle(frame, (x, y), 30, (0, 0, 255), -1)

        # í…ìŠ¤íŠ¸
        cv2.putText(frame, f"Frame {i}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0), 2)

        out.write(frame)

    out.release()
    print(f"âœ… ìƒ˜í”Œ ë¹„ë””ì˜¤ ìƒì„± ì™„ë£Œ: {filename}")


# ============================================
# ë©”ì¸ ì‹¤í–‰
# ============================================

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    while True:
        print("\n" + "=" * 60)
        print("ğŸ¬ Week 7 - í–‰ë™ ì¸ì‹ ë°ëª¨")
        print("=" * 60)
        print("\nì˜µì…˜ì„ ì„ íƒí•˜ì„¸ìš”:")
        print("1. MediaPipe ì‹¤ì‹œê°„ í¬ì¦ˆ ê°ì§€")
        print("2. Google Video Intelligence API ë¶„ì„")
        print("3. ë‘ ë°©ì‹ ë¹„êµ")
        print("4. ì¢…ë£Œ")

        choice = input("\nì„ íƒ (1-4): ").strip()

        if choice == '1':
            demo_mediapipe()
        elif choice == '2':
            demo_google_video_intelligence()
        elif choice == '3':
            compare_approaches()
        elif choice == '4':
            print("\nğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break
        else:
            print("âŒ ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")


if __name__ == "__main__":
    main()