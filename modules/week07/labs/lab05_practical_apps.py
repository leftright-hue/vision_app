"""
Lab 05: ì‹¤ì „ ì‘ìš© (Practical Applications)

ì´ ì‹¤ìŠµì—ì„œëŠ” í–‰ë™ ì¸ì‹ì˜ ì‹¤ì „ ì‘ìš© ì‚¬ë¡€ë¥¼ êµ¬í˜„í•©ë‹ˆë‹¤:
- ìš´ë™ ì¹´ìš´í„° (í‘¸ì‹œì—…, ìŠ¤ì¿¼íŠ¸, ì í•‘ì­)
- ì œìŠ¤ì²˜ ì¸ì‹
- ì´ìƒ í–‰ë™ ê°ì§€
- ìŠ¤í¬ì¸  ë™ì‘ ë¶„ì„

ì‚¬ìš©ë²•:
    python lab05_practical_apps.py --app exercise --exercise pushup
    python lab05_practical_apps.py --app gesture
    python lab05_practical_apps.py --app anomaly --input video.mp4
"""

import argparse
import time
from collections import deque
from typing import List, Tuple, Optional, Deque, Dict
import numpy as np

try:
    import mediapipe as mp
    HAS_MEDIAPIPE = True
except ImportError:
    HAS_MEDIAPIPE = False

try:
    import cv2
    HAS_OPENCV = True
except ImportError:
    HAS_OPENCV = False


class ExerciseCounter:
    """
    MediaPipe Poseë¥¼ ì‚¬ìš©í•œ ìš´ë™ ì¹´ìš´í„°
    """

    def __init__(self, exercise_type: str = 'pushup'):
        """
        Args:
            exercise_type: 'pushup', 'squat', 'jumping_jack'
        """
        if not HAS_MEDIAPIPE:
            raise ImportError("mediapipe íŒ¨í‚¤ì§€ í•„ìš”: pip install mediapipe")

        if not HAS_OPENCV:
            raise ImportError("opencv-python íŒ¨í‚¤ì§€ í•„ìš”: pip install opencv-python")

        self.exercise_type = exercise_type

        # MediaPipe Pose ì´ˆê¸°í™”
        self.mp_pose = mp.solutions.pose
        self.mp_drawing = mp.solutions.drawing_utils
        self.pose = self.mp_pose.Pose(
            min_detection_confidence=0.5,
            min_tracking_confidence=0.5
        )

        # ì¹´ìš´í„° ìƒíƒœ
        self.count = 0
        self.state = "up"  # "up" or "down"
        self.angle_history: Deque[float] = deque(maxlen=30)

        print(f"âœ… {exercise_type} ì¹´ìš´í„° ì¤€ë¹„ ì™„ë£Œ")

    def calculate_angle(
        self,
        point1: Tuple[float, float],
        point2: Tuple[float, float],
        point3: Tuple[float, float]
    ) -> float:
        """
        ì„¸ ì  ì‚¬ì´ì˜ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤ (point2ê°€ ê¼­ì§€ì )
        """
        a = np.array(point1)
        b = np.array(point2)
        c = np.array(point3)

        radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - \
                  np.arctan2(a[1] - b[1], a[0] - b[0])
        angle = np.abs(radians * 180.0 / np.pi)

        if angle > 180.0:
            angle = 360.0 - angle

        return angle

    def get_key_angle(self, landmarks) -> Optional[float]:
        """
        ìš´ë™ ì¢…ë¥˜ì— ë”°ë¼ í•µì‹¬ ê´€ì ˆ ê°ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        try:
            if self.exercise_type == 'pushup':
                # íŒ”ê¿ˆì¹˜ ê°ë„ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©)
                shoulder = [landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                           landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                elbow = [landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                        landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                wrist = [landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                        landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].y]

                return self.calculate_angle(shoulder, elbow, wrist)

            elif self.exercise_type == 'squat':
                # ë¬´ë¦ ê°ë„ (ì—‰ë©ì´-ë¬´ë¦-ë°œëª©)
                hip = [landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value].x,
                      landmarks[self.mp_pose.PoseLandmark.LEFT_HIP.value].y]
                knee = [landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value].x,
                       landmarks[self.mp_pose.PoseLandmark.LEFT_KNEE.value].y]
                ankle = [landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value].x,
                        landmarks[self.mp_pose.PoseLandmark.LEFT_ANKLE.value].y]

                return self.calculate_angle(hip, knee, ankle)

            elif self.exercise_type == 'jumping_jack':
                # íŒ” ê°ë„ (ì–´ê¹¨-íŒ”ê¿ˆì¹˜-ì†ëª©)
                shoulder = [landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                           landmarks[self.mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
                elbow = [landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                        landmarks[self.mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
                wrist = [landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                        landmarks[self.mp_pose.PoseLandmark.LEFT_WRIST.value].y]

                return self.calculate_angle(shoulder, elbow, wrist)

        except Exception as e:
            return None

        return None

    def update(self, angle: float) -> bool:
        """
        ê°ë„ë¥¼ ì—…ë°ì´íŠ¸í•˜ê³  ì¹´ìš´íŠ¸ê°€ ì¦ê°€í–ˆëŠ”ì§€ ë°˜í™˜í•©ë‹ˆë‹¤.

        Args:
            angle: ê´€ì ˆ ê°ë„

        Returns:
            ì¹´ìš´íŠ¸ ì¦ê°€ ì—¬ë¶€
        """
        self.angle_history.append(angle)

        count_increased = False

        # ìš´ë™ë³„ ì„ê³„ê°’
        if self.exercise_type in ['pushup', 'squat']:
            # ë‚´ë ¤ê°”ë‹¤ ì˜¬ë¼ì˜¤ê¸°
            if angle < 100 and self.state == "up":
                self.state = "down"
            elif angle > 140 and self.state == "down":
                self.state = "up"
                self.count += 1
                count_increased = True

        elif self.exercise_type == 'jumping_jack':
            # íŒ” ì˜¬ë ¸ë‹¤ ë‚´ë¦¬ê¸°
            if angle > 140 and self.state == "down":
                self.state = "up"
            elif angle < 100 and self.state == "up":
                self.state = "down"
                self.count += 1
                count_increased = True

        return count_increased

    def run(self, source: int = 0):
        """
        ìš´ë™ ì¹´ìš´í„° ì‹¤í–‰

        Args:
            source: ë¹„ë””ì˜¤ ì†ŒìŠ¤ (0 = ì›¹ìº , ë˜ëŠ” íŒŒì¼ ê²½ë¡œ)
        """
        cap = cv2.VideoCapture(source)

        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source}")

        print(f"\n{self.exercise_type.upper()} ì¹´ìš´í„° ì‹œì‘!")
        print("ì¢…ë£Œ: 'q' í‚¤\n")

        while cap.isOpened():
            ret, frame = cap.read()

            if not ret:
                break

            # BGR -> RGB
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False

            # Pose ê²€ì¶œ
            results = self.pose.process(image)

            # BGRë¡œ ë‹¤ì‹œ ë³€í™˜
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # Pose ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if results.pose_landmarks:
                self.mp_drawing.draw_landmarks(
                    image,
                    results.pose_landmarks,
                    self.mp_pose.POSE_CONNECTIONS,
                    self.mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),
                    self.mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)
                )

                # ê°ë„ ê³„ì‚°
                angle = self.get_key_angle(results.pose_landmarks.landmark)

                if angle is not None:
                    # ì¹´ìš´íŠ¸ ì—…ë°ì´íŠ¸
                    count_increased = self.update(angle)

                    if count_increased:
                        # ì¹´ìš´íŠ¸ ì¦ê°€ íš¨ê³¼
                        cv2.circle(image, (100, 100), 50, (0, 255, 0), -1)

                    # ê°ë„ í‘œì‹œ
                    cv2.putText(
                        image,
                        f"Angle: {int(angle)}",
                        (10, 100),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        (255, 255, 255),
                        2
                    )

                    # ìƒíƒœ í‘œì‹œ
                    cv2.putText(
                        image,
                        f"State: {self.state.upper()}",
                        (10, 140),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1,
                        (255, 255, 0),
                        2
                    )

            # ì¹´ìš´íŠ¸ í‘œì‹œ
            cv2.putText(
                image,
                f"Count: {self.count}",
                (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX,
                2,
                (0, 255, 0),
                3
            )

            cv2.imshow(f'{self.exercise_type.upper()} Counter', image)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()

        print(f"\nâœ… ì´ {self.count}íšŒ ì™„ë£Œ!")


class GestureRecognizer:
    """
    MediaPipe Handsë¥¼ ì‚¬ìš©í•œ ì œìŠ¤ì²˜ ì¸ì‹
    """

    def __init__(self):
        if not HAS_MEDIAPIPE:
            raise ImportError("mediapipe íŒ¨í‚¤ì§€ í•„ìš”: pip install mediapipe")

        # MediaPipe Hands ì´ˆê¸°í™”
        self.mp_hands = mp.solutions.hands
        self.mp_drawing = mp.solutions.drawing_utils
        self.hands = self.mp_hands.Hands(
            min_detection_confidence=0.7,
            min_tracking_confidence=0.5
        )

        print("âœ… ì œìŠ¤ì²˜ ì¸ì‹ê¸° ì¤€ë¹„ ì™„ë£Œ")

    def count_fingers(self, landmarks) -> int:
        """
        í¼ì³ì§„ ì†ê°€ë½ ê°œìˆ˜ë¥¼ ì„¸ìŠµë‹ˆë‹¤.
        """
        # ì†ê°€ë½ ëê³¼ ê´€ì ˆ ì¸ë±ìŠ¤
        finger_tips = [
            self.mp_hands.HandLandmark.THUMB_TIP,
            self.mp_hands.HandLandmark.INDEX_FINGER_TIP,
            self.mp_hands.HandLandmark.MIDDLE_FINGER_TIP,
            self.mp_hands.HandLandmark.RING_FINGER_TIP,
            self.mp_hands.HandLandmark.PINKY_TIP
        ]

        finger_joints = [
            self.mp_hands.HandLandmark.THUMB_IP,
            self.mp_hands.HandLandmark.INDEX_FINGER_PIP,
            self.mp_hands.HandLandmark.MIDDLE_FINGER_PIP,
            self.mp_hands.HandLandmark.RING_FINGER_PIP,
            self.mp_hands.HandLandmark.PINKY_PIP
        ]

        count = 0

        # ê° ì†ê°€ë½ ì²´í¬
        for tip, joint in zip(finger_tips, finger_joints):
            tip_y = landmarks[tip.value].y
            joint_y = landmarks[joint.value].y

            # ì†ê°€ë½ ëì´ ê´€ì ˆë³´ë‹¤ ìœ„ì— ìˆìœ¼ë©´ í¼ì³ì§„ ê²ƒ
            if tip_y < joint_y:
                count += 1

        return count

    def recognize_gesture(self, finger_count: int) -> str:
        """
        ì†ê°€ë½ ê°œìˆ˜ë¡œ ì œìŠ¤ì²˜ ì¸ì‹
        """
        gestures = {
            0: "Fist âœŠ",
            1: "One â˜ï¸",
            2: "Peace âœŒï¸",
            3: "Three ğŸ‘Œ",
            4: "Four ğŸ¤š",
            5: "Five âœ‹"
        }

        return gestures.get(finger_count, "Unknown")

    def run(self, source: int = 0):
        """
        ì œìŠ¤ì²˜ ì¸ì‹ ì‹¤í–‰
        """
        cap = cv2.VideoCapture(source)

        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ ì†ŒìŠ¤ë¥¼ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source}")

        print("\nì œìŠ¤ì²˜ ì¸ì‹ ì‹œì‘!")
        print("ì¢…ë£Œ: 'q' í‚¤\n")

        while cap.isOpened():
            ret, frame = cap.read()

            if not ret:
                break

            # BGR -> RGB
            image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            image.flags.writeable = False

            # Hands ê²€ì¶œ
            results = self.hands.process(image)

            # BGRë¡œ ë‹¤ì‹œ ë³€í™˜
            image.flags.writeable = True
            image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)

            # Hands ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸°
            if results.multi_hand_landmarks:
                for hand_landmarks in results.multi_hand_landmarks:
                    self.mp_drawing.draw_landmarks(
                        image,
                        hand_landmarks,
                        self.mp_hands.HAND_CONNECTIONS
                    )

                    # ì†ê°€ë½ ê°œìˆ˜ ì„¸ê¸°
                    finger_count = self.count_fingers(hand_landmarks.landmark)

                    # ì œìŠ¤ì²˜ ì¸ì‹
                    gesture = self.recognize_gesture(finger_count)

                    # ê²°ê³¼ í‘œì‹œ
                    cv2.putText(
                        image,
                        f"Fingers: {finger_count}",
                        (10, 50),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1.5,
                        (0, 255, 0),
                        3
                    )

                    cv2.putText(
                        image,
                        f"Gesture: {gesture}",
                        (10, 100),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1.5,
                        (255, 0, 0),
                        3
                    )

            cv2.imshow('Gesture Recognition', image)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

        cap.release()
        cv2.destroyAllWindows()


class AnomalyDetector:
    """
    ê°„ë‹¨í•œ ì´ìƒ í–‰ë™ ê°ì§€ê¸° (ëª¨ì…˜ í¬ê¸° ê¸°ë°˜)
    """

    def __init__(self, threshold: float = 50.0):
        """
        Args:
            threshold: ì´ìƒ í–‰ë™ íŒì • ì„ê³„ê°’
        """
        if not HAS_OPENCV:
            raise ImportError("opencv-python íŒ¨í‚¤ì§€ í•„ìš”: pip install opencv-python")

        self.threshold = threshold
        self.motion_history: Deque[float] = deque(maxlen=60)

        print(f"âœ… ì´ìƒ ê°ì§€ê¸° ì¤€ë¹„ ì™„ë£Œ (ì„ê³„ê°’: {threshold})")

    def detect(self, video_path: str):
        """
        ë¹„ë””ì˜¤ì—ì„œ ì´ìƒ í–‰ë™ì„ ê°ì§€í•©ë‹ˆë‹¤.
        """
        cap = cv2.VideoCapture(video_path)

        if not cap.isOpened():
            raise ValueError(f"ë¹„ë””ì˜¤ íŒŒì¼ì„ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}")

        ret, prev_frame = cap.read()

        if not ret:
            raise ValueError("ì²« ë²ˆì§¸ í”„ë ˆì„ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")

        prev_gray = cv2.cvtColor(prev_frame, cv2.COLOR_BGR2GRAY)

        frame_idx = 0
        anomaly_frames = []

        print("\nì´ìƒ í–‰ë™ ê°ì§€ ì¤‘...")

        while True:
            ret, frame = cap.read()

            if not ret:
                break

            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)

            # Optical Flow ê³„ì‚°
            flow = cv2.calcOpticalFlowFarneback(
                prev_gray,
                gray,
                None,
                0.5, 3, 15, 3, 5, 1.2, 0
            )

            # ëª¨ì…˜ í¬ê¸°
            mag, _ = cv2.cartToPolar(flow[..., 0], flow[..., 1])
            mean_mag = np.mean(mag)

            self.motion_history.append(mean_mag)

            # ì´ìƒ ê°ì§€ (í‰ê· ë³´ë‹¤ í¬ê²Œ ë²—ì–´ë‚¨)
            if len(self.motion_history) > 30:
                avg = np.mean(self.motion_history)
                std = np.std(self.motion_history)

                if mean_mag > avg + 2 * std or mean_mag > self.threshold:
                    anomaly_frames.append(frame_idx)
                    cv2.putText(
                        frame,
                        "ANOMALY DETECTED!",
                        (50, 50),
                        cv2.FONT_HERSHEY_SIMPLEX,
                        1.5,
                        (0, 0, 255),
                        3
                    )

            # ëª¨ì…˜ ê·¸ë˜í”„ í‘œì‹œ
            cv2.putText(
                frame,
                f"Motion: {mean_mag:.2f}",
                (10, 30),
                cv2.FONT_HERSHEY_SIMPLEX,
                0.7,
                (255, 255, 255),
                2
            )

            cv2.imshow('Anomaly Detection', frame)

            if cv2.waitKey(1) & 0xFF == ord('q'):
                break

            prev_gray = gray
            frame_idx += 1

            if frame_idx % 30 == 0:
                print(f"  {frame_idx} í”„ë ˆì„ ì²˜ë¦¬ë¨...")

        cap.release()
        cv2.destroyAllWindows()

        print(f"\nâœ… ë¶„ì„ ì™„ë£Œ")
        print(f"ì´ {len(anomaly_frames)}ê°œ ì´ìƒ í”„ë ˆì„ ê°ì§€: {anomaly_frames[:10]}...")


def main():
    parser = argparse.ArgumentParser(description="Lab 05: ì‹¤ì „ ì‘ìš©")
    parser.add_argument("--app", type=str, required=True,
                       choices=['exercise', 'gesture', 'anomaly'],
                       help="ì‹¤í–‰í•  ì•±")
    parser.add_argument("--exercise", type=str, default='pushup',
                       choices=['pushup', 'squat', 'jumping_jack'],
                       help="ìš´ë™ ì¢…ë¥˜ (exercise ì•±ìš©)")
    parser.add_argument("--input", type=str, help="ì…ë ¥ ë¹„ë””ì˜¤ íŒŒì¼ (anomaly ì•±ìš©)")
    parser.add_argument("--threshold", type=float, default=50.0,
                       help="ì´ìƒ ê°ì§€ ì„ê³„ê°’ (anomaly ì•±ìš©)")

    args = parser.parse_args()

    try:
        if args.app == 'exercise':
            counter = ExerciseCounter(exercise_type=args.exercise)
            counter.run(source=0)

        elif args.app == 'gesture':
            recognizer = GestureRecognizer()
            recognizer.run(source=0)

        elif args.app == 'anomaly':
            if not args.input:
                print("âŒ --input íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                return

            detector = AnomalyDetector(threshold=args.threshold)
            detector.detect(args.input)

    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()
