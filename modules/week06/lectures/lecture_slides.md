# Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ SAM

## ğŸ“‹ ê°•ì˜ ê°œìš”

**í•™ìŠµ ëª©í‘œ**:
- ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ì¢…ë¥˜ì™€ ì°¨ì´ì  ì´í•´
- U-Net ì•„í‚¤í…ì²˜ì˜ í•µì‹¬ êµ¬ì¡° í•™ìŠµ
- Segment Anything Model (SAM) ì›ë¦¬ì™€ í™œìš©ë²• ìŠµë“
- ì‹¤ì „ ì‘ìš©: ë°°ê²½ ì œê±°, ìë™ ë¼ë²¨ë§ êµ¬í˜„

**ê°•ì˜ ì‹œê°„**: 180ë¶„ (ì´ë¡  90ë¶„ + ì‹¤ìŠµ 90ë¶„)

---

## Part 1: ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ì´ˆ (30ë¶„)

### 1.1 ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ë€?

**ì •ì˜**: ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì„ íŠ¹ì • í´ë˜ìŠ¤ë‚˜ ê°ì²´ì— í• ë‹¹í•˜ëŠ” ì‘ì—…

**Computer Vision íƒœìŠ¤í¬ ë¹„êµ**:
| íƒœìŠ¤í¬ | ì…ë ¥ | ì¶œë ¥ | ì •ë°€ë„ |
|--------|------|------|--------|
| Classification | ì´ë¯¸ì§€ | í´ë˜ìŠ¤ ë ˆì´ë¸” | ì´ë¯¸ì§€ ì „ì²´ |
| Object Detection | ì´ë¯¸ì§€ | BBox + í´ë˜ìŠ¤ | ë°•ìŠ¤ ë‹¨ìœ„ |
| Segmentation | ì´ë¯¸ì§€ | í”½ì…€ë³„ ë§ˆìŠ¤í¬ | í”½ì…€ ë‹¨ìœ„ |

### 1.2 ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ì¢…ë¥˜

#### Semantic Segmentation
- **ëª©í‘œ**: ê°™ì€ í´ë˜ìŠ¤ì˜ ëª¨ë“  í”½ì…€ì— ê°™ì€ ë ˆì´ë¸”
- **íŠ¹ì§•**: ê°œë³„ ì¸ìŠ¤í„´ìŠ¤ êµ¬ë¶„ ì—†ìŒ
- **ì˜ˆì‹œ**:
  - "road" í´ë˜ìŠ¤ â†’ ëª¨ë“  ë„ë¡œ í”½ì…€
  - "sky" í´ë˜ìŠ¤ â†’ ëª¨ë“  í•˜ëŠ˜ í”½ì…€
- **ì‘ìš©**: ììœ¨ì£¼í–‰ (ì°¨ì„ , ë„ë¡œ, ë³´í–‰ì êµ¬ì—­)

#### Instance Segmentation
- **ëª©í‘œ**: ê°™ì€ í´ë˜ìŠ¤ë¼ë„ ê°œë³„ ê°ì²´ êµ¬ë¶„
- **íŠ¹ì§•**: ê° ì¸ìŠ¤í„´ìŠ¤ë§ˆë‹¤ ë³„ë„ ë§ˆìŠ¤í¬
- **ì˜ˆì‹œ**:
  - person_1, person_2, person_3
  - car_1, car_2, car_3
- **ì‘ìš©**: ê°ì²´ ì¶”ì , ë¡œë´‡ ë¹„ì „

#### Panoptic Segmentation
- **ëª©í‘œ**: Semantic + Instance ê²°í•©
- **êµ¬ë¶„**:
  - **Stuff**: ë°°ê²½ ìš”ì†Œ (í•˜ëŠ˜, ë„ë¡œ) â†’ Semantic
  - **Thing**: ê°œë³„ ê°ì²´ (ì‚¬ëŒ, ì°¨) â†’ Instance
- **ì‘ìš©**: ì™„ì „í•œ ì¥ë©´ ì´í•´

### 1.3 ì„¸ê·¸ë©˜í…Œì´ì…˜ì˜ ë‚œì´ë„

**Challenge 1: ê²½ê³„ ì •í™•ë„**
- í”½ì…€ ë‹¨ìœ„ ì •ë°€ ì˜ˆì¸¡ í•„ìš”
- ê°ì²´ ê²½ê³„ê°€ ë¶ˆë¶„ëª…í•œ ê²½ìš° (ë¨¸ë¦¬ì¹´ë½, ë‚˜ë­‡ì ë“±)

**Challenge 2: ë‹¤ì–‘í•œ ìŠ¤ì¼€ì¼**
- í° ê°ì²´ì™€ ì‘ì€ ê°ì²´ ë™ì‹œ ì²˜ë¦¬
- Multi-scale feature í•„ìš”

**Challenge 3: Occlusion**
- ê°€ë ¤ì§„ ê°ì²´ ì²˜ë¦¬
- ê²¹ì¹˜ëŠ” ê°ì²´ ê²½ê³„ êµ¬ë¶„

---

## Part 2: U-Net ì•„í‚¤í…ì²˜ (30ë¶„)

### 2.1 U-Net ì—­ì‚¬

**ë°°ê²½**:
- 2015ë…„ Ronneberger et al. ë°œí‘œ
- ì˜ë£Œ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•´ ê°œë°œ
- ì ì€ ë°ì´í„°ë¡œ ë†’ì€ ì„±ëŠ¥

**í˜ì‹ ì„±**:
- Skip connectionsë¡œ ì„¸ë¶€ ì •ë³´ ë³´ì¡´
- Encoder-Decoder êµ¬ì¡°
- Data augmentation í™œìš©

### 2.2 U-Net êµ¬ì¡°

```
ì…ë ¥ ì´ë¯¸ì§€ (572x572x3)
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Contracting Path (Encoder)        â”‚
â”‚                                     â”‚
â”‚   Conv 3x3 + ReLU (2ë²ˆ)            â”‚
â”‚   â†“ Max Pool 2x2                    â”‚
â”‚   64 â†’ 128 â†’ 256 â†’ 512 â†’ 1024      â”‚
â”‚   (ê³µê°„ í•´ìƒë„ ê°ì†Œ, ì±„ë„ ì¦ê°€)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Bottleneck (1024 channels)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Expansive Path (Decoder)          â”‚
â”‚                                     â”‚
â”‚   Up-Conv 2x2                       â”‚
â”‚   + Skip Connection                 â”‚
â”‚   + Conv 3x3 + ReLU (2ë²ˆ)          â”‚
â”‚   1024 â†’ 512 â†’ 256 â†’ 128 â†’ 64      â”‚
â”‚   (ê³µê°„ í•´ìƒë„ ë³µì›, ì±„ë„ ê°ì†Œ)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â†“
ì¶œë ¥ ë§ˆìŠ¤í¬ (388x388x2)
```

### 2.3 í•µì‹¬ êµ¬ì„± ìš”ì†Œ

#### Skip Connections â­
```
Encoder Level 1 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Concat â†’ Decoder Level 4
Encoder Level 2 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Concat â†’ Decoder Level 3
Encoder Level 3 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Concat â†’ Decoder Level 2
Encoder Level 4 â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ Concat â†’ Decoder Level 1
```

**ì—­í• **:
1. **ì„¸ë¶€ ì •ë³´ ë³´ì¡´**: ê³ í•´ìƒë„ íŠ¹ì§•ì„ ì§ì ‘ ì „ë‹¬
2. **Gradient Flow**: í•™ìŠµ ì•ˆì •ì„± í–¥ìƒ
3. **ìœ„ì¹˜ ì •ë³´**: ì •í™•í•œ í”½ì…€ ìœ„ì¹˜ ë³µì›

#### Contracting Path (Encoder)
```python
# Pseudo code
for level in [1, 2, 3, 4]:
    x = Conv3x3_ReLU(x)  # íŠ¹ì§• ì¶”ì¶œ
    x = Conv3x3_ReLU(x)
    skip_connections[level] = x  # ì €ì¥
    x = MaxPool2x2(x)  # ë‹¤ìš´ìƒ˜í”Œë§
```

#### Expansive Path (Decoder)
```python
# Pseudo code
for level in [4, 3, 2, 1]:
    x = UpConv2x2(x)  # ì—…ìƒ˜í”Œë§
    x = Concat(x, skip_connections[level])  # Skip connection
    x = Conv3x3_ReLU(x)
    x = Conv3x3_ReLU(x)
```

### 2.4 U-Net ë³€í˜•

- **U-Net++**: Nested skip pathways
- **Attention U-Net**: Attention gates ì¶”ê°€
- **3D U-Net**: 3D ì˜ë£Œ ì˜ìƒìš©
- **ResUNet**: Residual connections

---

## Part 3: Segment Anything Model (SAM) (30ë¶„)

### 3.1 SAM ì†Œê°œ

**ê°œë°œ**: Meta AI (2023ë…„ 4ì›”)

**í˜ì‹ ì„±**:
- **Zero-shot Transfer**: í•™ìŠµë˜ì§€ ì•Šì€ ê°ì²´ë„ ë¶„í• 
- **Promptable**: Point, Box, Maskë¡œ ì œì–´
- **ëŒ€ê·œëª¨ ë°ì´í„°**: SA-1B (11M ì´ë¯¸ì§€, 1.1B ë§ˆìŠ¤í¬)
- **ë²”ìš©ì„±**: ë‹¤ì–‘í•œ ë„ë©”ì¸ì— ì ìš© ê°€ëŠ¥

**ê¸°ì¡´ ëª¨ë¸ê³¼ì˜ ì°¨ì´**:
| íŠ¹ì§• | ê¸°ì¡´ ëª¨ë¸ | SAM |
|------|----------|-----|
| í•™ìŠµ ë°ì´í„° | íŠ¹ì • ë„ë©”ì¸ | ë²”ìš© (11M ì´ë¯¸ì§€) |
| ë¶„í•  ëŒ€ìƒ | ê³ ì •ëœ í´ë˜ìŠ¤ | ì„ì˜ì˜ ê°ì²´ |
| í”„ë¡¬í”„íŠ¸ | ë¶ˆê°€ëŠ¥ | Point, Box, Mask |
| Zero-shot | Fine-tuning í•„ìš” | ì¦‰ì‹œ ê°€ëŠ¥ |

### 3.2 SAM ì•„í‚¤í…ì²˜

#### ì „ì²´ êµ¬ì¡°
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Image Encoder (ViT-H/L/B)              â”‚
â”‚  - Vision Transformer                   â”‚
â”‚  - 1024x1024 â†’ 64x64x256 embedding     â”‚
â”‚  - Heavy, í•œ ë²ˆë§Œ ì‹¤í–‰                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Prompt Encoder                         â”‚
â”‚  - Point: Positional encoding           â”‚
â”‚  - Box: Corner embeddings               â”‚
â”‚  - Mask: Conv downsampling              â”‚
â”‚  - Lightweight                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Mask Decoder                           â”‚
â”‚  - Transformer decoder (2 layers)       â”‚
â”‚  - 3ê°œ ë§ˆìŠ¤í¬ ì¶œë ¥ (ambiguity)            â”‚
â”‚  - IoU confidence score                 â”‚
â”‚  - Lightweight, ì‹¤ì‹œê°„ ê°€ëŠ¥               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### Image Encoder: Vision Transformer
- **ViT-B**: ~375MB, 12 layers
- **ViT-L**: ~1.2GB, 24 layers
- **ViT-H**: ~2.4GB, 32 layers

**íŠ¹ì§•**:
- MAE (Masked Autoencoder) pre-training
- Global receptive field
- ê³ í•´ìƒë„ íŠ¹ì§• ì¶”ì¶œ

#### Prompt Encoder
```python
# Point Prompt
point_embedding = positional_encoding(x, y) + fg/bg_token

# Box Prompt
box_embedding = corner_embeddings(x1, y1, x2, y2)

# Mask Prompt
mask_embedding = conv_layers(sparse_mask)
```

#### Mask Decoder
- Transformer ê¸°ë°˜ ë””ì½”ë” (ê²½ëŸ‰)
- 3ê°œ í›„ë³´ ë§ˆìŠ¤í¬ ì¶œë ¥
  - **ì´ìœ **: Ambiguity ì²˜ë¦¬ (ë‹¤ì–‘í•œ í•´ì„ ê°€ëŠ¥)
  - ì˜ˆ: "ì»µ" í´ë¦­ â†’ ì»µë§Œ? ì»µ+ì†ì¡ì´? ì „ì²´ í…Œì´ë¸”?
- IoU prediction headë¡œ í’ˆì§ˆ í‰ê°€

### 3.3 SAMì˜ í•™ìŠµ ì „ëµ

#### Data Engine (3ë‹¨ê³„)
1. **Assisted-manual stage**:
   - ì „ë¬¸ annotatorê°€ SAM ë„ì›€ìœ¼ë¡œ ë¼ë²¨ë§
   - 4.3M ë§ˆìŠ¤í¬ ìˆ˜ì§‘

2. **Semi-automatic stage**:
   - SAMì´ ìë™ ì œì•ˆ â†’ ì‚¬ëŒì´ ê²€ì¦
   - 10.2M ë§ˆìŠ¤í¬ ì¶”ê°€

3. **Fully automatic stage**:
   - SAMì´ ì™„ì „ ìë™ìœ¼ë¡œ ìƒì„±
   - 1.1B ë§ˆìŠ¤í¬ (ìµœì¢… ë°ì´í„°ì…‹)

#### Loss Function
```
Total Loss = Focal Loss + Dice Loss + IoU Loss

- Focal Loss: í´ë˜ìŠ¤ ë¶ˆê· í˜• í•´ê²°
- Dice Loss: ì„¸ê·¸ë©˜í…Œì´ì…˜ í’ˆì§ˆ
- IoU Loss: IoU ì˜ˆì¸¡ ì •í™•ë„
```

### 3.4 SAM í™œìš© ë°©ë²•

#### Point Prompt
```python
# Foreground point (x, y, label=1)
sam.segment_with_points(
    image,
    points=[(300, 200)],
    labels=[1]
)

# Multi-point (fg + bg)
sam.segment_with_points(
    image,
    points=[(300, 200), (100, 100)],
    labels=[1, 0]  # 1=fg, 0=bg
)
```

#### Box Prompt
```python
# Bounding box (x1, y1, x2, y2)
sam.segment_with_box(
    image,
    box=(100, 100, 400, 400)
)
```

#### Automatic Mask Generation
```python
# Grid sampling â†’ multiple masks
masks = sam.generate_auto_masks(
    image,
    points_per_side=32,  # ê·¸ë¦¬ë“œ ë°€ë„
    pred_iou_thresh=0.88,  # í’ˆì§ˆ í•„í„°
    stability_score_thresh=0.95
)
```

---

## Part 4: ì‹¤ìŠµ ê°€ì´ë“œ (90ë¶„)

### ì‹¤ìŠµ 1: SAM ê¸°ì´ˆ ì‚¬ìš© (20ë¶„)

**ëª©í‘œ**: Point/Box í”„ë¡¬í”„íŠ¸ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜

**ì‹¤ìŠµ ë‚´ìš©**:
1. ìƒ˜í”Œ ì´ë¯¸ì§€ ë¡œë“œ
2. Point promptë¡œ ê°ì²´ ë¶„í• 
3. Background pointë¡œ ì •ë°€í™”
4. Box promptë¡œ ì˜ì—­ ì§€ì •

**í•™ìŠµ í¬ì¸íŠ¸**:
- Foreground vs Background label
- ì—¬ëŸ¬ í¬ì¸íŠ¸ì˜ íš¨ê³¼
- ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ì˜ ì¥ë‹¨ì 

### ì‹¤ìŠµ 2: Interactive Annotation (25ë¶„)

**ëª©í‘œ**: ë°˜ë³µì ìœ¼ë¡œ í¬ì¸íŠ¸ ì¶”ê°€í•˜ë©° ë§ˆìŠ¤í¬ ê°œì„ 

**ì›Œí¬í”Œë¡œìš°**:
1. ì´ˆê¸° í¬ì¸íŠ¸ë¡œ ëŒ€ëµ ë¶„í• 
2. ëˆ„ë½ ì˜ì—­ì— fg point ì¶”ê°€
3. ê³¼ë„ í¬í•¨ ì˜ì—­ì— bg point ì¶”ê°€
4. ë§Œì¡±í•  ë•Œê¹Œì§€ ë°˜ë³µ

**í•™ìŠµ í¬ì¸íŠ¸**:
- Interactive segmentation í”„ë¡œì„¸ìŠ¤
- íš¨ìœ¨ì ì¸ annotation ì „ëµ
- ì‹¤ë¬´ ë°ì´í„° ë¼ë²¨ë§ ì‹œë®¬ë ˆì´ì…˜

### ì‹¤ìŠµ 3: Auto Mask Generation (20ë¶„)

**ëª©í‘œ**: í”„ë¡¬í”„íŠ¸ ì—†ì´ ì „ì²´ ì´ë¯¸ì§€ ìë™ ë¶„í• 

**ì‹¤ìŠµ ë‚´ìš©**:
1. ìë™ ë§ˆìŠ¤í¬ ìƒì„±
2. íŒŒë¼ë¯¸í„° ì¡°ì • (points_per_side)
3. í’ˆì§ˆ í•„í„°ë§ (IoU, stability)
4. ê²°ê³¼ ì‹œê°í™” ë° ë¶„ì„

**í•™ìŠµ í¬ì¸íŠ¸**:
- Grid sampling ì›ë¦¬
- NMS (Non-Maximum Suppression)
- í’ˆì§ˆ ë©”íŠ¸ë¦­ì˜ ì˜ë¯¸

### ì‹¤ìŠµ 4: ë°°ê²½ ì œê±° ì•± (15ë¶„)

**ëª©í‘œ**: ì¦ëª…ì‚¬ì§„ ìë™ í¸ì§‘ê¸° êµ¬í˜„

**ê¸°ëŠ¥**:
1. ì¸ë¬¼ ì‚¬ì§„ ì—…ë¡œë“œ
2. SAMìœ¼ë¡œ ì¸ë¬¼ ë¶„í• 
3. ë°°ê²½ ìƒ‰ìƒ ë³€ê²½
4. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ

**ì‘ìš©**: ì¦ëª…ì‚¬ì§„, ìƒí’ˆ ì´ë¯¸ì§€, í”„ë¡œí•„ ì‚¬ì§„

### ì‹¤ìŠµ 5: ìë™ ë¼ë²¨ë§ ë„êµ¬ (10ë¶„)

**ëª©í‘œ**: ê°ì²´ íƒì§€ í•™ìŠµ ë°ì´í„° ìƒì„± ìë™í™”

**ì›Œí¬í”Œë¡œìš°**:
1. ì´ë¯¸ì§€ì—ì„œ ìë™ ë§ˆìŠ¤í¬ ìƒì„±
2. ê° ë§ˆìŠ¤í¬ì— í´ë˜ìŠ¤ ë ˆì´ë¸” í• ë‹¹
3. BBox ì¶”ì¶œ
4. COCO/YOLO í¬ë§· ë³€í™˜

**ì‹¤ë¬´ ê°€ì¹˜**: ë°ì´í„° ë¼ë²¨ë§ ì‹œê°„ 90% ê°ì†Œ

---

## Part 5: ì‹¬í™” ì£¼ì œ

### 5.1 SAMì˜ í•œê³„

**í˜„ì¬ í•œê³„**:
1. **í´ë˜ìŠ¤ ì¸ì‹ ë¶ˆê°€**: SAMì€ "ë¬´ì—‡ì„ ë¶„í• í• ì§€"ë§Œ ê²°ì •, "ë¬´ì—‡ì¸ì§€"ëŠ” ëª¨ë¦„
2. **ì˜ìƒ ì²˜ë¦¬**: ë™ì˜ìƒì€ í”„ë ˆì„ë³„ ì²˜ë¦¬ í•„ìš” (ì¼ê´€ì„± ë¶€ì¡±)
3. **Fine details**: ë¨¸ë¦¬ì¹´ë½, íˆ¬ëª… ê°ì²´ ë“± ì–´ë ¤ì›€
4. **ê³„ì‚° ë¹„ìš©**: ViT-HëŠ” ê³ ì‚¬ì–‘ GPU í•„ìš”

**í•´ê²° ë°©ì•ˆ**:
- **Grounded-SAM**: CLIP + SAM (í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸)
- **Track-Anything**: ì˜ìƒ ì¶”ì  + SAM
- **HQ-SAM**: ê³ í’ˆì§ˆ ë§ˆìŠ¤í¬ ìƒì„±

### 5.2 SAM ë³€í˜• ëª¨ë¸ë“¤

#### Grounded-SAM
```
Text: "a red car" â†’ CLIP â†’ Object Detection â†’ SAM
```
- ìì—°ì–´ë¡œ ê°ì²´ ì§€ì • ê°€ëŠ¥
- Zero-shot object detection

#### Mobile-SAM
- ViT ëŒ€ì‹  ê²½ëŸ‰ encoder
- ëª¨ë°”ì¼ ê¸°ê¸°ì—ì„œ ì‹¤ì‹œê°„ ë™ì‘
- ì„±ëŠ¥ ì•½ê°„ í•˜ë½, ì†ë„ 10ë°° í–¥ìƒ

#### HQ-SAM
- High-quality mask ìƒì„±
- ë¯¸ì„¸í•œ ê²½ê³„ ê°œì„ 
- ì¶”ê°€ í•™ìŠµ í•„ìš”

### 5.3 ì‹¤ì „ ë°°í¬ ê³ ë ¤ì‚¬í•­

**ì„±ëŠ¥ ìµœì í™”**:
```python
# 1. ì´ë¯¸ì§€ í¬ê¸° ì œí•œ
image = resize_if_needed(image, max_size=1024)

# 2. ëª¨ë¸ ìºì‹±
@st.cache_resource
def load_sam():
    return SAMHelper()

# 3. Batch processing
masks = sam.batch_predict(images)  # ì—¬ëŸ¬ ì´ë¯¸ì§€ ë™ì‹œ ì²˜ë¦¬
```

**ë©”ëª¨ë¦¬ ê´€ë¦¬**:
- ViT-B ì‚¬ìš© (375MB)
- ì´ë¯¸ì§€ ì „ì²˜ë¦¬ë¡œ í¬ê¸° ì œí•œ
- GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ CPU fallback

**ì‚¬ìš©ì ê²½í—˜**:
- Progress barë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ
- ì¤‘ê°„ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
- ì˜¤ë¥˜ ë°œìƒ ì‹œ ëª…í™•í•œ ë©”ì‹œì§€

---

## ìš”ì•½ ë° ë‹¤ìŒ ì£¼ ì˜ˆê³ 

### ì´ë²ˆ ì£¼ í•µì‹¬ ë‚´ìš©
âœ… Semantic, Instance, Panoptic Segmentation êµ¬ë¶„
âœ… U-Netì˜ Skip Connections ì´í•´
âœ… SAMì˜ Promptable Segmentation í™œìš©
âœ… ì‹¤ì „ ì‘ìš©: ë°°ê²½ ì œê±°, ìë™ ë¼ë²¨ë§

### ë‹¤ìŒ ì£¼ (Week 7): Action Recognition
- ì˜ìƒ ë°ì´í„° ì²˜ë¦¬
- 3D CNN vs 2D CNN + LSTM
- Temporal modeling
- ì‹¤ì‹œê°„ í–‰ë™ ì¸ì‹

---

## ì¶”ê°€ í•™ìŠµ ìë£Œ

### ë…¼ë¬¸
- U-Net: [https://arxiv.org/abs/1505.04597](https://arxiv.org/abs/1505.04597)
- SAM: [https://arxiv.org/abs/2304.02643](https://arxiv.org/abs/2304.02643)

### ë°ëª¨
- SAM Demo: [https://segment-anything.com/](https://segment-anything.com/)
- Grounded-SAM: [https://github.com/IDEA-Research/Grounded-Segment-Anything](https://github.com/IDEA-Research/Grounded-Segment-Anything)

### ì½”ë“œ
- Official SAM: [https://github.com/facebookresearch/segment-anything](https://github.com/facebookresearch/segment-anything)
- HuggingFace: [https://huggingface.co/docs/transformers/model_doc/sam](https://huggingface.co/docs/transformers/model_doc/sam)

---

**ê°•ì˜ ì¢…ë£Œ | Week 6 ì™„ë£Œ ğŸ‰**
