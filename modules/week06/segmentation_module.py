"""
Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ SAM (Segment Anything Model)
"""

import streamlit as st
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional, Dict, Any
import io

from core.base_processor import BaseImageProcessor
from .sam_helpers import get_sam_helper


class SegmentationModule(BaseImageProcessor):
    """Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ"""

    def __init__(self):
        super().__init__()
        self.name = "Week 6: Segmentation & SAM"

    def render(self):
        """ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜"""
        st.title("ğŸ¨ Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ SAM")

        st.markdown("""
        ## í•™ìŠµ ëª©í‘œ
        - **ì´ë¡ **: U-Net, Instance/Panoptic Segmentation, SAM ì›ë¦¬ ì´í•´
        - **ì‹¤ìŠµ**: SAMì„ í™œìš©í•œ interactive segmentation êµ¬í˜„
        - **ì‘ìš©**: ë°°ê²½ ì œê±°, ìë™ ë¼ë²¨ë§ ë„êµ¬ ì œì‘
        """)

        # í™˜ê²½ ì²´í¬
        self._check_environment()

        # 5ê°œ íƒ­ êµ¬ì„±
        tabs = st.tabs([
            "ğŸ“š ê°œë… ì†Œê°œ",
            "ğŸ¯ SAM ê¸°ì´ˆ",
            "ğŸ–±ï¸ Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜",
            "ğŸ¤– Auto Mask ìƒì„±",
            "ğŸ’¼ ì‹¤ì „ ì‘ìš©"
        ])

        with tabs[0]:
            self.render_theory()

        with tabs[1]:
            self.render_sam_basics()

        with tabs[2]:
            self.render_interactive()

        with tabs[3]:
            self.render_auto_mask()

        with tabs[4]:
            self.render_practical()

    def _check_environment(self):
        """í™˜ê²½ ì²´í¬ ë° ì„¤ì •"""
        with st.expander("ğŸ”§ í™˜ê²½ ì„¤ì • í™•ì¸", expanded=False):
            st.markdown("""
            ### í•„ìš”í•œ íŒ¨í‚¤ì§€
            - `transformers`: SAM ëª¨ë¸ ë¡œë”© (HuggingFace)
            - `torch`: PyTorch ë°±ì—”ë“œ
            - `Pillow`, `numpy`, `matplotlib`: ì´ë¯¸ì§€ ì²˜ë¦¬

            ### 3-Tier Fallback ì „ëµ
            1. **HuggingFace Transformers** (ê¶Œì¥): `pip install transformers torch`
            2. **Official segment-anything**: `pip install segment-anything`
            3. **Simulation Mode**: íŒ¨í‚¤ì§€ ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ ì‚¬ìš©
            """)

            issues = []

            # Check transformers
            try:
                import transformers
                st.success(f"âœ… transformers {transformers.__version__}")
            except ImportError:
                issues.append("transformers")
                st.warning("âš ï¸ transformers ë¯¸ì„¤ì¹˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)")

            # Check torch
            try:
                import torch
                device = "GPU" if torch.cuda.is_available() else "CPU"
                st.success(f"âœ… torch {torch.__version__} ({device})")
            except ImportError:
                issues.append("torch")
                st.warning("âš ï¸ torch ë¯¸ì„¤ì¹˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)")

            if issues:
                st.info(f"""
                ### ğŸ”§ ì„¤ì¹˜ ë°©ë²•
                ```bash
                pip install transformers torch
                ```

                ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œë„ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
                """)

    # ==================== Tab 1: ê°œë… ì†Œê°œ ====================

    def render_theory(self):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ë¡  ì„¤ëª…"""
        st.header("ğŸ“š ì„¸ê·¸ë©˜í…Œì´ì…˜ ê°œë… ì†Œê°œ")

        st.markdown("""
        ## 1. ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ë€?

        **ì„¸ê·¸ë©˜í…Œì´ì…˜(Segmentation)**ì€ ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì„ íŠ¹ì • í´ë˜ìŠ¤ë‚˜ ê°ì²´ì— í• ë‹¹í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

        ### 1.1 Classification vs Detection vs Segmentation

        | íƒœìŠ¤í¬ | ëª©í‘œ | ì¶œë ¥ |
        |--------|------|------|
        | **Classification** | ì´ë¯¸ì§€ ì „ì²´ ë¶„ë¥˜ | "ê³ ì–‘ì´" |
        | **Object Detection** | ê°ì²´ ìœ„ì¹˜ íƒì§€ | ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ |
        | **Segmentation** | í”½ì…€ ë‹¨ìœ„ ë¶„ë¥˜ | í”½ì…€ë³„ ë§ˆìŠ¤í¬ |

        """)

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì… ë¹„êµ ì´ë¯¸ì§€
        import os
        seg_img_path = os.path.join(os.path.dirname(__file__), "assets", "3.png")
        if os.path.exists(seg_img_path):
            st.image(seg_img_path,
                    caption="ë¶„ë¥˜ vs ê°ì²´ íƒì§€ vs ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¹„êµ",
                    use_container_width=True)

        st.markdown("""

        ---

        ## 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¢…ë¥˜

        ### 2.1 Semantic Segmentation
        - **ì •ì˜**: ê°™ì€ í´ë˜ìŠ¤ì˜ ëª¨ë“  í”½ì…€ì„ ê°™ì€ ë ˆì´ë¸”ë¡œ ì§€ì •
        - **íŠ¹ì§•**: ê°œë³„ ê°ì²´ êµ¬ë¶„ ì•ˆ í•¨ (ëª¨ë“  ì‚¬ëŒ â†’ "person")
        - **ì˜ˆ**: ë„ë¡œ, í•˜ëŠ˜, ê±´ë¬¼ ë“± ì˜ì—­ ë¶„í• 

        ### 2.2 Instance Segmentation
        - **ì •ì˜**: ê°™ì€ í´ë˜ìŠ¤ë¼ë„ ê°œë³„ ê°ì²´ë¥¼ êµ¬ë¶„
        - **íŠ¹ì§•**: ê° ê°ì²´ë§ˆë‹¤ ë‹¤ë¥¸ ë§ˆìŠ¤í¬
        - **ì˜ˆ**: person1, person2, person3 êµ¬ë¶„

        ### 2.3 Panoptic Segmentation
        - **ì •ì˜**: Semantic + Instance ê²°í•©
        - **íŠ¹ì§•**: ë°°ê²½(stuff)ì€ semantic, ê°ì²´(thing)ëŠ” instance
        - **ì˜ˆ**: ë„ë¡œ(semantic) + ìë™ì°¨ë“¤(instance)
        """)

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¢…ë¥˜ ë¹„êµ ì´ë¯¸ì§€
        import os
        seg_img_path = os.path.join(os.path.dirname(__file__), "assets", "segmentation.png")
        if os.path.exists(seg_img_path):
            st.image(seg_img_path,
                    caption="Semantic vs Instance vs Panoptic Segmentation ë¹„êµ",
                    use_container_width=True)

        st.markdown("""

        ---

        ## 3. U-Net ì•„í‚¤í…ì²˜

        U-Netì€ ì˜ë£Œ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•´ ê°œë°œëœ ëŒ€í‘œì ì¸ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.
        """)

        # U-Net êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨
        import os
        unet_img_path = os.path.join(os.path.dirname(__file__), "assets", "unet_architecture.png")
        if os.path.exists(unet_img_path):
            st.image(unet_img_path,
                    caption="U-Net Architecture (Ronneberger et al., 2015)",
                    use_container_width=True)
        else:
            st.image("https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png",
                    caption="U-Net Architecture (Ronneberger et al., 2015)",
                    use_container_width=True)

        st.markdown("""
        ### U-Net í•µì‹¬ êµ¬ì¡°

        U-Netì€ **"U"ì í˜•íƒœ**ì˜ ì•„í‚¤í…ì²˜ë¥¼ ê°€ì§€ê³  ìˆì–´ ì´ì™€ ê°™ì´ ëª…ëª…ë˜ì—ˆìŠµë‹ˆë‹¤. ì¸ì½”ë”-ë””ì½”ë” êµ¬ì¡°ì˜ ëŒ€ì¹­ì  í˜•íƒœë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤.

        ---

        #### ğŸ”½ 1ë‹¨ê³„: Contracting Path (ì¶•ì†Œ ê²½ë¡œ) - "ì •ë³´ ì••ì¶•"

        **ë¹„ìœ **: ë§ì›ê²½ìœ¼ë¡œ ì‚¬ì§„ì„ ì°ë“¯ì´, í° ê·¸ë¦¼ì„ ì ì  ì‘ê²Œ ì••ì¶•í•©ë‹ˆë‹¤.

        - **ë™ì‘ ì›ë¦¬**: ì´ë¯¸ì§€ë¥¼ ì ì§„ì ìœ¼ë¡œ ë‹¤ìš´ìƒ˜í”Œë§í•˜ë©´ì„œ ê³ ìˆ˜ì¤€ íŠ¹ì§•ì„ ì¶”ì¶œ
        - **ëª©ì **: ê°ì²´ì™€ ë°°ê²½ì„ êµ¬ë¶„í•˜ëŠ” ì˜ë¯¸ë¡ ì  ì •ë³´ë¥¼ í•™ìŠµí•˜ê¸° ìœ„í•¨
        - **ì˜ˆì‹œ**: 512Ã—512 â†’ 256Ã—256 â†’ 128Ã—128 â†’ 64Ã—64ë¡œ ì¶•ì†Œ

        ğŸ’¡ *ê³µê°„ì  í•´ìƒë„ëŠ” ê°ì†Œí•˜ì§€ë§Œ ì¶”ìƒí™” ìˆ˜ì¤€ì€ ì¦ê°€í•©ë‹ˆë‹¤*

        ---

        #### ğŸ¯ 2ë‹¨ê³„: Bottleneck (ë³‘ëª©) - "í•µì‹¬ ì´í•´"

        **ë¹„ìœ **: ì •ë³´ë¥¼ ìµœëŒ€í•œ ì••ì¶•í•˜ì—¬ í•µì‹¬ë§Œ ì¶”ì¶œí•˜ëŠ” ê³¼ì •ì…ë‹ˆë‹¤.

        - **ë™ì‘ ì›ë¦¬**: ì´ë¯¸ì§€ì˜ í•µì‹¬ ì •ë³´ë§Œì„ í¬í•¨í•˜ëŠ” ìµœì†Œ í‘œí˜„ì„ ìƒì„±
        - **ëª©ì **: ì „ì²´ ì´ë¯¸ì§€ì˜ ë§¥ë½ì  ì •ë³´ë¥¼ í†µí•©ì ìœ¼ë¡œ ì´í•´í•˜ê¸° ìœ„í•¨

        ğŸ’¡ *ìµœì†Œ í•´ìƒë„ì´ì§€ë§Œ ìµœëŒ€ ì˜ë¯¸ ì •ë³´ë¥¼ í¬í•¨í•©ë‹ˆë‹¤*

        ---

        #### ğŸ”¼ 3ë‹¨ê³„: Expansive Path (í™•ì¥ ê²½ë¡œ) - "ë””í…Œì¼ ë³µì›"

        **ë¹„ìœ **: ì••ì¶• íŒŒì¼ì„ ë‹¤ì‹œ í’€ë“¯ì´, ì‘ì€ ì´ë¯¸ì§€ë¥¼ ì›ë˜ í¬ê¸°ë¡œ í‚¤ì›ë‹ˆë‹¤.

        - **ë™ì‘ ì›ë¦¬**: ì••ì¶•ëœ íŠ¹ì§• ë§µì„ ì ì§„ì ìœ¼ë¡œ ì—…ìƒ˜í”Œë§í•˜ì—¬ ì›ë˜ í•´ìƒë„ë¡œ ë³µì›
        - **ëª©ì **: ê° í”½ì…€ ë‹¨ìœ„ì˜ ì •í™•í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ë§ˆìŠ¤í¬ë¥¼ ìƒì„±í•˜ê¸° ìœ„í•¨
        - **ì˜ˆì‹œ**: 64Ã—64 â†’ 128Ã—128 â†’ 256Ã—256 â†’ 512Ã—512ë¡œ í™•ëŒ€

        ğŸ’¡ *í•´ìƒë„ë¥¼ ë³µì›í•˜ë©´ì„œ í”½ì…€ ë‹¨ìœ„ì˜ ì„¸ë°€í•œ ë¶„ë¥˜ ì •ë³´ë¥¼ ì¬êµ¬ì„±í•©ë‹ˆë‹¤*

        ---

        #### â­ 4ë‹¨ê³„: Skip Connections (ì§€ë¦„ê¸¸ ì—°ê²°) - "ë””í…Œì¼ ë³´ì¡´"

        **ë¹„ìœ **: ì •ë³´ ì†ì‹¤ì„ ë°©ì§€í•˜ê¸° ìœ„í•œ ì§ì ‘ì ì¸ ì—°ê²° í†µë¡œì…ë‹ˆë‹¤.

        - **ë™ì‘ ì›ë¦¬**: ì¸ì½”ë”ì˜ ê³ í•´ìƒë„ íŠ¹ì§•ì„ ë””ì½”ë”ì˜ í•´ë‹¹ ë ˆë²¨ì— ì§ì ‘ ì—°ê²°
        - **ëª©ì **: ë‹¤ìš´ìƒ˜í”Œë§ ê³¼ì •ì—ì„œ ì†ì‹¤ëœ ì„¸ë¶€ ì •ë³´ë¥¼ ë³µì›í•˜ê¸° ìœ„í•¨
        - **íš¨ê³¼**: ê²½ê³„ì„ ì´ ë” ì„ ëª…í•˜ê³  ì •í™•í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ìƒì„±

        ğŸ’¡ *ì´ëŠ” U-Netì˜ í•µì‹¬ ì„¤ê³„ë¡œ, ê³µê°„ì  ì„¸ë¶€ ì •ë³´ì˜ ë³´ì¡´ì„ ê°€ëŠ¥í•˜ê²Œ í•©ë‹ˆë‹¤*

        ---

        ### ğŸ“ U-Netì˜ ì¥ì 

        1. **ì„¸ë¶€ ì •ë³´ ë³´ì¡´**: Skip Connectionì„ í†µí•œ ì •ë°€í•œ ê²½ê³„ ë¶„í•  ì„±ëŠ¥
        2. **ë°ì´í„° íš¨ìœ¨ì„±**: ì œí•œëœ í›ˆë ¨ ë°ì´í„°ì—ì„œë„ íš¨ê³¼ì ì¸ í•™ìŠµ ê°€ëŠ¥
        3. **ê³„ì‚° íš¨ìœ¨ì„±**: ìµœì í™”ëœ êµ¬ì¡°ë¥¼ í†µí•œ ë¹ ë¥¸ ì¶”ë¡  ì†ë„
        4. **ë²”ìš©ì„±**: ì˜ë£Œ ì˜ìƒ, ìœ„ì„± ì´ë¯¸ì§€, ììœ¨ì£¼í–‰ ë“± ë‹¤ì–‘í•œ ë„ë©”ì¸ ì ìš©

        ---

        ## 4. Segment Anything Model (SAM)

        **SAM(Segment Anything Model)**ì€ Meta AIê°€ 2023ë…„ ë°œí‘œí•œ "ë¬´ì—‡ì´ë“  ë¶„í• í•˜ëŠ”" AIì…ë‹ˆë‹¤.

        ---

        ### ğŸ¯ SAMì´ ë­ê°€ íŠ¹ë³„í•œê°€ìš”?

        **ë¹„ìœ **: SAMì€ **"ë§ŒëŠ¥ ê°€ìœ„"** ê°™ì•„ìš”!

        ê¸°ì¡´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ì´ íŠ¹ì • ë„ë©”ì¸ì— íŠ¹í™”ë˜ì–´ ìˆëŠ” ë°˜ë©´, SAMì€ ë‹¤ì–‘í•œ ê°ì²´ì— ëŒ€í•´ ë²”ìš©ì ì¸ ë¶„í•  ì„±ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤.

        ---

        #### âœ¨ SAMì˜ 3ê°€ì§€ ìŠˆí¼íŒŒì›Œ

        **1. ğŸŒŸ Zero-Shot ëŠ¥ë ¥ - "ì²˜ìŒ ë´ë„ ì•Œì•„ìš”!"**

        **ë¹„ìœ **: ì™¸êµ­ì¸ì´ ì²˜ìŒ ë³¸ ê³¼ì¼ë„ "ì´ê²Œ ê³¼ì¼ì´êµ¬ë‚˜"ë¼ê³  ì•„ëŠ” ê²ƒì²˜ëŸ¼

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** í•œ ë²ˆë„ ë³¸ ì  ì—†ëŠ” ë¬¼ê±´ë„ ì •í™•í•˜ê²Œ ë¶„í• 
        - **ì˜ˆì‹œ**:
          - ê³ ì–‘ì´ë§Œ í•™ìŠµí–ˆëŠ”ë° ê°•ì•„ì§€ë„ ë¶„í•  ê°€ëŠ¥
          - ìë™ì°¨ ë°ì´í„°ë¡œ í•™ìŠµí–ˆìœ¼ë‚˜ ìì „ê±° ë¶„í• ë„ ê°€ëŠ¥
        - **ì™œ ëŒ€ë‹¨í•œê°€ìš”?** ê¸°ì¡´ ëª¨ë¸ì€ í•™ìŠµí•œ ê²ƒë§Œ ë¶„í•  ê°€ëŠ¥í–ˆì–´ìš”

        ğŸ’¡ *1,100ë§Œ ê°œ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ìœ¼ë¡œ í›ˆë ¨ë˜ì–´ ê´‘ë²”ìœ„í•œ ê°ì²´ ì¸ì‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤*

        ---

        **2. ğŸ–±ï¸ Prompt ê¸°ë°˜ - "ì›í•˜ëŠ” ëŒ€ë¡œ ì¡°ì‘ ê°€ëŠ¥!"**

        **ë¹„ìœ **: ë¦¬ëª¨ì»¨ìœ¼ë¡œ TV ì±„ë„ì„ ë°”ê¾¸ë“¯ì´, í´ë¦­ê³¼ ë°•ìŠ¤ë¡œ AIë¥¼ ì¡°ì¢…

        3ê°€ì§€ ì¡°ì‘ ë°©ë²•:
        - **Point (í´ë¦­)**: íŠ¹ì • ì¢Œí‘œì˜ ê°ì²´ ë¶„í•  ìš”ì²­ ğŸ‘†
        - **Box (ë°•ìŠ¤)**: ì§€ì •ëœ ì˜ì—­ ë‚´ ê°ì²´ ë¶„í•  ìš”ì²­ â¬œ
        - **Mask (ë§ˆìŠ¤í¬)**: "ì´ê±° ë” ì •í™•í•˜ê²Œ ë‹¤ë“¬ì–´ì¤˜!" âœ‚ï¸

        ğŸ’¡ *ë§ˆì¹˜ í¬í† ìƒµì˜ ë§ˆìˆ  ì§€íŒ¡ì´ ë„êµ¬ì²˜ëŸ¼ ì‰¬ì›Œìš”!*

        ---

        **3. âš¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ - "ë¹ ë¥´ê³  ì •í™•í•´ìš”!"**

        **íŠ¹ì§•**: ì´ˆê³ ì† ì²˜ë¦¬ ì„±ëŠ¥

        - **ì†ë„**: í´ë¦­í•˜ë©´ ì¦‰ì‹œ ê²°ê³¼ (< 1ì´ˆ)
        - **ëŒ€í™”í˜•**: ê²°ê³¼ë¥¼ ë³´ë©´ì„œ ê³„ì† ìˆ˜ì • ê°€ëŠ¥
        - **ì‹¤ìš©ì„±**: ì‹¤ì œ ì‘ì—…ì— ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥

        ğŸ’¡ *ëŠë¦° ê¸°ì¡´ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë°”ë¡œë°”ë¡œ ë°˜ì‘í•´ìš”!*

        ---

        ### ğŸ”§ SAMì˜ ê¸°ìˆ ì  ì›ë¦¬

        SAMì€ **Transformer ê¸°ë°˜ ì•„í‚¤í…ì²˜**ë¡œ êµ¬ì„±ë˜ë©°, 3ê°œì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ê°€ ìƒí˜¸ì‘ìš©í•©ë‹ˆë‹¤.

        ---

        #### 1ë‹¨ê³„: ì´ë¯¸ì§€ ì¸ì½”ë” (Image Encoder) ğŸ”

        **ì•„í‚¤í…ì²˜**: Vision Transformer (ViT) ê¸°ë°˜ì˜ ê³„ì¸µì  ì¸ì½”ë”

        **ë™ì‘ ì›ë¦¬**:
        - **íŒ¨ì¹˜ ì„ë² ë”©**: ì´ë¯¸ì§€ë¥¼ 16Ã—16 íŒ¨ì¹˜ë¡œ ë¶„í• í•˜ì—¬ í† í°í™”
        - **ìœ„ì¹˜ ì¸ì½”ë”©**: ê° íŒ¨ì¹˜ì˜ ê³µê°„ì  ìœ„ì¹˜ ì •ë³´ë¥¼ ì„ë² ë”©ì— ì¶”ê°€
        - **Self-Attention**: íŒ¨ì¹˜ ê°„ ì „ì—­ì  ê´€ê³„ë¥¼ í•™ìŠµí•˜ì—¬ ì»¨í…ìŠ¤íŠ¸ íŒŒì•…
        - **ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ íŠ¹ì§•**: ë‹¤ì–‘í•œ í•´ìƒë„ì—ì„œ íŠ¹ì§• ë§µ ìƒì„± (1/4, 1/8, 1/16, 1/32)

        **í•µì‹¬ ê¸°ìˆ **:
        ```
        Input Image (1024Ã—1024) 
        â†’ Patch Embedding (64Ã—64Ã—768)
        â†’ Multi-Head Attention Layers
        â†’ Hierarchical Feature Maps
        ```

        ---

        #### 2ë‹¨ê³„: í”„ë¡¬í”„íŠ¸ ì¸ì½”ë” (Prompt Encoder) ğŸ¯

        **ì•„í‚¤í…ì²˜**: ë‹¤ì¤‘ ëª¨ë‹¬ ì…ë ¥ ì²˜ë¦¬ë¥¼ ìœ„í•œ íŠ¹í™”ëœ ì¸ì½”ë”

        **Point í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬**:
        - **ìœ„ì¹˜ ì„ë² ë”©**: 2D ì¢Œí‘œë¥¼ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
        - **íƒ€ì… ì„ë² ë”©**: Positive/Negative í´ë¦­ì„ êµ¬ë¶„í•˜ëŠ” í•™ìŠµëœ ì„ë² ë”©
        - **ê²°í•©**: `point_embedding = positional_embedding + type_embedding`

        **Box í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬**:
        - **ëª¨ì„œë¦¬ ì¸ì½”ë”©**: 4ê°œ ëª¨ì„œë¦¬ ì¢Œí‘œë¥¼ ê°ê° ì„ë² ë”©
        - **í˜•íƒœ ì •ë³´**: ë°•ìŠ¤ì˜ ê°€ë¡œ/ì„¸ë¡œ ë¹„ìœ¨ ë° í¬ê¸° ì •ë³´ í¬í•¨

        **Mask í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬**:
        - **CNN ê¸°ë°˜**: 2D ë§ˆìŠ¤í¬ë¥¼ í•©ì„±ê³±ìœ¼ë¡œ ì¸ì½”ë”©
        - **ë‹¤ìš´ìƒ˜í”Œë§**: ì´ë¯¸ì§€ í•´ìƒë„ì™€ ë§ì¶¤

        ---

        #### 3ë‹¨ê³„: ë§ˆìŠ¤í¬ ë””ì½”ë” (Mask Decoder) âœ‚ï¸

        **ì•„í‚¤í…ì²˜**: Transformer ë””ì½”ë” + CNN ì—…ìƒ˜í”Œë§

        **Cross-Attention ë©”ì»¤ë‹ˆì¦˜**:
        - **Query**: í”„ë¡¬í”„íŠ¸ ì„ë² ë”© (ì‚¬ìš©ì ì˜ë„)
        - **Key/Value**: ì´ë¯¸ì§€ íŠ¹ì§• ë§µ (ì‹œê°ì  ì •ë³´)
        - **ì¶œë ¥**: í”„ë¡¬í”„íŠ¸ì— ë§ëŠ” ê´€ë ¨ ì´ë¯¸ì§€ ì˜ì—­ ì‹ë³„

        **ë‹¤ì¤‘ ìŠ¤ì¼€ì¼ ìœµí•©**:
        ```
        Low-level features (ì„¸ë¶€ ê²½ê³„) + High-level features (ì˜ë¯¸ ì •ë³´)
        â†’ Skip connectionsë¡œ ê²°í•©
        â†’ ì •ë°€í•œ ë§ˆìŠ¤í¬ ìƒì„±
        ```

        **Ambiguity-Aware ì¶œë ¥**:
        - **3ê°œ ë§ˆìŠ¤í¬ í›„ë³´**: ì„œë¡œ ë‹¤ë¥¸ ì„¸ë¶„í™” ìˆ˜ì¤€
          - **ì„¸ë°€**: íŠ¹ì • ë¶€ë¶„ë§Œ (ì˜ˆ: ìë™ì°¨ ë°”í€´)
          - **ì¤‘ê°„**: ë‹¨ì¼ ê°ì²´ (ì˜ˆ: ìë™ì°¨ ì „ì²´)  
          - **ê´‘ë²”ìœ„**: ê´€ë ¨ ì˜ì—­ ì „ì²´ (ì˜ˆ: ìë™ì°¨ + ê·¸ë¦¼ì)
        - **IoU ì ìˆ˜**: ê° ë§ˆìŠ¤í¬ì˜ í’ˆì§ˆ ì˜ˆì¸¡ê°’ ì œê³µ

        **ì—…ìƒ˜í”Œë§ ê³¼ì •**:
        ```
        64Ã—64 feature map 
        â†’ Bilinear interpolation (Ã—4)
        â†’ 256Ã—256 mask
        â†’ Final upsampling (Ã—4)
        â†’ 1024Ã—1024 final mask
        ```

        ğŸ’¡ *ëª¨í˜¸í•œ ìƒí™©ì— ëŒ€ì‘í•˜ëŠ” ë‹¤ì¤‘ í•´ì„ ëŠ¥ë ¥ì´ SAMì˜ í•µì‹¬ í˜ì‹ ì…ë‹ˆë‹¤*

        ---

        ### âš™ï¸ SAMì˜ í•™ìŠµ ì „ëµ

        **ë°ì´í„° ì—”ì§„ (Data Engine)**:
        1. **Manual Stage**: ì „ë¬¸ê°€ê°€ 120K ì´ë¯¸ì§€ì— ìˆ˜ë™ ë¼ë²¨ë§
        2. **Semi-automatic**: SAM ë³´ì¡°ë¡œ 180ë§Œ ë§ˆìŠ¤í¬ ìƒì„±  
        3. **Fully automatic**: SAMë§Œìœ¼ë¡œ 1100ë§Œ ë§ˆìŠ¤í¬ ìë™ ìƒì„±

        **ì†ì‹¤ í•¨ìˆ˜ (Loss Function)**:
        ```
        Total Loss = Focal Loss (ë¶„ë¥˜) + Dice Loss (ë§ˆìŠ¤í¬) + IoU Loss (í’ˆì§ˆ)
        ```

        **Zero-shot ì¼ë°˜í™”ì˜ ë¹„ë°€**:
        - **ëŒ€ê·œëª¨ ë°ì´í„°**: 1100ë§Œ ê³ í’ˆì§ˆ ë§ˆìŠ¤í¬
        - **ë‹¤ì–‘ì„±**: ë‹¤ì–‘í•œ ë„ë©”ì¸, ê°ì²´, ìŠ¤íƒ€ì¼
        - **í”„ë¡¬í”„íŠ¸ í•™ìŠµ**: ë‹¤ì–‘í•œ ì‚¬ìš©ì ì…ë ¥ íŒ¨í„´ í•™ìŠµ

        ---

        ### ğŸ“Š ê¸°ìˆ ì  ë¹„êµ: ê¸°ì¡´ ëª¨ë¸ vs SAM

        | êµ¬ë¶„ | ê¸°ì¡´ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë¸ | SAM |
        |------|---------------------|-----|
        | **ì•„í‚¤í…ì²˜** | CNN ê¸°ë°˜ (FCN, U-Net, DeepLab) | Vision Transformer + Cross-Attention |
        | **í•™ìŠµ ë°©ì‹** | ê³ ì •ëœ í´ë˜ìŠ¤ ë ˆì´ë¸” í•™ìŠµ | í”„ë¡¬í”„íŠ¸ ê¸°ë°˜ í•™ìŠµ |
        | **ì¼ë°˜í™”** | íŠ¹ì • ë„ë©”ì¸/í´ë˜ìŠ¤ì— í•œì • | Zero-shot ë²”ìš© ë¶„í•  â­ |
        | **ì…ë ¥ ë°©ì‹** | ì´ë¯¸ì§€ë§Œ ì²˜ë¦¬ | ì´ë¯¸ì§€ + ë‹¤ì¤‘ í”„ë¡¬í”„íŠ¸ â­ |
        | **ì¶œë ¥** | ë‹¨ì¼ ë§ˆìŠ¤í¬ | ë‹¤ì¤‘ í›„ë³´ ë§ˆìŠ¤í¬ + ì‹ ë¢°ë„ â­ |
        | **ë°ì´í„°** | ìˆ˜ì²œ~ìˆ˜ë§Œ ë¼ë²¨ë§ ì´ë¯¸ì§€ | 1100ë§Œ ìë™ ìƒì„± ë§ˆìŠ¤í¬ |
        | **ì¶”ë¡  ì†ë„** | ë„ë©”ì¸ë³„ ìµœì í™” í•„ìš” | ì‹¤ì‹œê°„ ì²˜ë¦¬ (50ms) â­ |

        ---

        ### ğŸ”¬ SAM vs U-Net ì›ë¦¬ ë¹„êµ

        | ì¸¡ë©´ | U-Net | SAM |
        |------|-------|-----|
        | **ì¸ì½”ë”** | CNN ê¸°ë°˜ ë‹¤ìš´ìƒ˜í”Œë§ | Vision Transformer |
        | **íŠ¹ì§• í•™ìŠµ** | ì§€ì—­ì  Convolution | ì „ì—­ì  Self-Attention |
        | **ë””ì½”ë”** | ëŒ€ì¹­ì  ì—…ìƒ˜í”Œë§ | Cross-Attention + ì—…ìƒ˜í”Œë§ |
        | **Skip Connection** | ë™ì¼ ë ˆë²¨ íŠ¹ì§• ê²°í•© | í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ íŠ¹ì§• ìœµí•© |
        | **í•™ìŠµ ëª©í‘œ** | í”½ì…€ë³„ í´ë˜ìŠ¤ ë¶„ë¥˜ | í”„ë¡¬í”„íŠ¸ ì¡°ê±´ë¶€ ë¶„í•  |
        | **ëª¨í˜¸ì„± ì²˜ë¦¬** | ë‹¨ì¼ í•´ì„ | ë‹¤ì¤‘ í•´ì„ + ë¶ˆí™•ì‹¤ì„± ì¶”ì • |

        ---

        ### ğŸ’¼ ì‹¤ì œ ì‘ìš© ë¶„ì•¼

        #### 1. ğŸ“¸ **ì´ë¯¸ì§€ í¸ì§‘**
        - **ì‘ìš©**: ì •ë°€í•œ ë°°ê²½ ë¶„ë¦¬ ë° êµì²´
        - **í™œìš©ì²˜**: ì‚¬ì§„ ìŠ¤íŠœë””ì˜¤, ë””ì§€í„¸ ì½˜í…ì¸  ì œì‘

        #### 2. ğŸ·ï¸ **ë°ì´í„° ì–´ë…¸í…Œì´ì…˜**
        - **ì‘ìš©**: ëŒ€ëŸ‰ ì´ë¯¸ì§€ ë°ì´í„°ì…‹ì˜ ìë™ ë¼ë²¨ë§
        - **í™œìš©ì²˜**: ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ê°œë°œ, ì»´í“¨í„° ë¹„ì „ ì—°êµ¬

        #### 3. ğŸ©º **ì˜ë£Œ ì˜ìƒ ë¶„ì„**
        - **ì˜ˆì‹œ**: X-ray, MRIì—ì„œ ë³‘ë³€ ë¶€ìœ„ ìë™ ê°ì§€
        - **ì‚¬ìš©ì**: ì˜ì‚¬, ë³‘ì›

        #### 4. ğŸ¬ **ì˜ìƒ í¸ì§‘**
        - **ì˜ˆì‹œ**: ìœ íŠœë¸Œ ì˜ìƒì—ì„œ ë°°ê²½ë§Œ êµì²´, íŠ¹ì • ë¬¼ê±´ ì œê±°
        - **ì‚¬ìš©ì**: í¬ë¦¬ì—ì´í„°, ì˜ìƒ í¸ì§‘ì

        #### 5. ğŸš— **ììœ¨ì£¼í–‰ ì°¨ëŸ‰**
        - **ì˜ˆì‹œ**: ë„ë¡œ, ì°¨ëŸ‰, ë³´í–‰ì ì‹¤ì‹œê°„ êµ¬ë¶„
        - **ì‚¬ìš©ì**: ìë™ì°¨ íšŒì‚¬, ììœ¨ì£¼í–‰ ê°œë°œì‚¬

        #### 6. ğŸ›ï¸ **ì‡¼í•‘ëª° ìƒí’ˆ ì‚¬ì§„**
        - **ì˜ˆì‹œ**: ì˜·, ì‹ ë°œ ë“± ìƒí’ˆë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
        - **ì‚¬ìš©ì**: ì´ì»¤ë¨¸ìŠ¤, ì˜¨ë¼ì¸ ì‡¼í•‘ëª°

        ---

        ### ğŸ‰ ì •ë¦¬í•˜ë©´?

        ### ğŸ’¡ í•µì‹¬ ì›ë¦¬ ìš”ì•½

        **U-Net**: 
        ```
        CNN ì¸ì½”ë”-ë””ì½”ë” + Skip Connections
        â†’ ì˜ë£Œ ì´ë¯¸ì§€ ë“± íŠ¹ì • ë„ë©”ì¸ì—ì„œ ì •ë°€í•œ ë¶„í• 
        ```

        **SAM**: 
        ```
        Vision Transformer + Cross-Attention + í”„ë¡¬í”„íŠ¸ í•™ìŠµ
        â†’ ë²”ìš© ë„ë©”ì¸ì—ì„œ ëŒ€í™”í˜• ì‹¤ì‹œê°„ ë¶„í• 
        ```

        **ê²°ë¡ **: U-Netì€ **íŠ¹ì • íƒœìŠ¤í¬ì˜ ì •í™•ì„±**, SAMì€ **ë²”ìš©ì„±ê³¼ ìœ ì—°ì„±**ì— íŠ¹í™”

        ë” ì´ìƒ ë³µì¡í•œ ì„¤ì • ì—†ì´, í´ë¦­ ëª‡ ë²ˆìœ¼ë¡œ ì›í•˜ëŠ” ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ë¶„í• í•  ìˆ˜ ìˆì–´ìš”! ğŸ¯

        ---

        ## ì°¸ê³  ìë£Œ
        - [U-Net ë…¼ë¬¸](https://arxiv.org/abs/1505.04597)
        - [SAM ë…¼ë¬¸](https://arxiv.org/abs/2304.02643)
        - [SAM Demo](https://segment-anything.com/)
        """)

    # ==================== Tab 2: SAM ê¸°ì´ˆ ====================

    def render_sam_basics(self):
        """SAM ê¸°ë³¸ ì‚¬ìš©ë²•"""
        st.header("ğŸ¯ SAM ê¸°ì´ˆ ì‚¬ìš©ë²•")

        st.markdown("""
        ì´ íƒ­ì—ì„œëŠ” SAMì˜ 3ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë°©ì‹ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
        1. **Point Prompt**: í´ë¦­ìœ¼ë¡œ ê°ì²´ ì§€ì •
        2. **Box Prompt**: ë°•ìŠ¤ë¡œ ì˜ì—­ ì§€ì •
        3. **Mask Prompt**: ê¸°ì¡´ ë§ˆìŠ¤í¬ ê°œì„ 
        """)

        # ëª¨ë¸ ì„ íƒ
        col1, col2 = st.columns([1, 2])
        with col1:
            model_type = st.selectbox(
                "SAM ëª¨ë¸ ì„ íƒ",
                ["vit_b", "vit_l", "vit_h"],
                index=0,
                help="vit_b: ë¹ ë¦„(375MB), vit_l: ê· í˜•(1.2GB), vit_h: ê³ í’ˆì§ˆ(2.4GB)"
            )

        with col2:
            st.info(f"""
            **ì„ íƒëœ ëª¨ë¸**: {model_type}
            - vit_b: ~375MB, ë¹ ë¥¸ ì¶”ë¡ 
            - vit_l: ~1.2GB, ê· í˜•ì¡íŒ ì„±ëŠ¥
            - vit_h: ~2.4GB, ìµœê³  í’ˆì§ˆ
            """)

        # SAM í—¬í¼ ë¡œë“œ
        sam = get_sam_helper(model_type)

        st.markdown(f"**í˜„ì¬ ëª¨ë“œ**: `{sam.mode}` ({sam.device if sam.device else 'simulation'})")

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded = st.file_uploader(
            "ì´ë¯¸ì§€ ì„ íƒ",
            type=['png', 'jpg', 'jpeg'],
            key="sam_basics_upload"
        )

        if uploaded:
            image = Image.open(uploaded).convert("RGB")
            st.image(image, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

            # í”„ë¡¬í”„íŠ¸ ë°©ì‹ ì„ íƒ
            prompt_type = st.radio(
                "í”„ë¡¬í”„íŠ¸ ë°©ì‹",
                ["Point Prompt", "Box Prompt"],
                horizontal=True
            )

            if prompt_type == "Point Prompt":
                self._demo_point_prompt(image, sam)
            else:
                self._demo_box_prompt(image, sam)

    def _demo_point_prompt(self, image: Image.Image, sam):
        """í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ë°ëª¨"""
        st.subheader("ğŸ–±ï¸ Point Prompt")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ë¶„í• í•˜ê³  ì‹¶ì€ ê°ì²´ ìœ„ì— í¬ì¸íŠ¸ ì§€ì •
        2. Label: 1=foreground (í¬í•¨), 0=background (ì œì™¸)
        3. ì—¬ëŸ¬ í¬ì¸íŠ¸ë¡œ ì •í™•ë„ í–¥ìƒ
        """)

        # í¬ì¸íŠ¸ ì…ë ¥
        num_points = st.number_input("í¬ì¸íŠ¸ ê°œìˆ˜", 1, 10, 1)

        points = []
        labels = []

        cols = st.columns(3)
        for i in range(num_points):
            with cols[i % 3]:
                st.markdown(f"**Point {i+1}**")
                x = st.number_input(f"X{i+1}", 0, image.width, image.width//2, key=f"x{i}")
                y = st.number_input(f"Y{i+1}", 0, image.height, image.height//2, key=f"y{i}")
                label = st.selectbox(f"Label{i+1}", [1, 0], key=f"label{i}",
                                    help="1=foreground, 0=background")
                points.append((x, y))
                labels.append(label)

        if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰", key="point_segment"):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
                mask = sam.segment_with_points(image, points, labels)

                # ì‹œê°í™”
                self._visualize_segmentation(image, mask, points, labels)

    def _demo_box_prompt(self, image: Image.Image, sam):
        """ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ ë°ëª¨"""
        st.subheader("ğŸ“¦ Box Prompt")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ê°ì²´ë¥¼ í¬í•¨í•˜ëŠ” ë°•ìŠ¤ ì¢Œí‘œ ì…ë ¥ (x1, y1, x2, y2)
        2. ë°•ìŠ¤ ë‚´ë¶€ì˜ ì£¼ìš” ê°ì²´ë¥¼ ìë™ìœ¼ë¡œ ë¶„í• 
        """)

        col1, col2 = st.columns(2)
        with col1:
            x1 = st.number_input("X1 (ì¢Œìƒë‹¨)", 0, image.width, 0)
            y1 = st.number_input("Y1 (ì¢Œìƒë‹¨)", 0, image.height, 0)

        with col2:
            x2 = st.number_input("X2 (ìš°í•˜ë‹¨)", 0, image.width, image.width)
            y2 = st.number_input("Y2 (ìš°í•˜ë‹¨)", 0, image.height, image.height)

        box = (x1, y1, x2, y2)

        if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰", key="box_segment"):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
                mask = sam.segment_with_box(image, box)

                # ì‹œê°í™”
                self._visualize_segmentation(image, mask, box=box)

    def _visualize_segmentation(
        self,
        image: Image.Image,
        mask: np.ndarray,
        points: Optional[List[Tuple[int, int]]] = None,
        labels: Optional[List[int]] = None,
        box: Optional[Tuple[int, int, int, int]] = None
    ):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™”"""

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # 1. ì›ë³¸ + í”„ë¡¬í”„íŠ¸
        axes[0].imshow(image)
        if points:
            for (x, y), label in zip(points, labels):
                color = 'green' if label == 1 else 'red'
                axes[0].plot(x, y, marker='o', markersize=10, color=color)
        if box:
            from matplotlib.patches import Rectangle
            x1, y1, x2, y2 = box
            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                           edgecolor='red', facecolor='none')
            axes[0].add_patch(rect)
        axes[0].set_title("ì›ë³¸ + í”„ë¡¬í”„íŠ¸")
        axes[0].axis('off')

        # 2. ë§ˆìŠ¤í¬
        axes[1].imshow(mask, cmap='gray')
        axes[1].set_title("ìƒì„±ëœ ë§ˆìŠ¤í¬")
        axes[1].axis('off')

        # 3. ì˜¤ë²„ë ˆì´
        axes[2].imshow(image)
        axes[2].imshow(mask, alpha=0.5, cmap='jet')
        axes[2].set_title("ì˜¤ë²„ë ˆì´")
        axes[2].axis('off')

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # í†µê³„
        total_pixels = mask.size
        selected_pixels = mask.sum()
        percentage = (selected_pixels / total_pixels) * 100

        st.success(f"""
        **ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ**
        - ì„ íƒëœ í”½ì…€: {selected_pixels:,} / {total_pixels:,}
        - ë¹„ìœ¨: {percentage:.2f}%
        """)

    # ==================== Tab 3: Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜ ====================

    def render_interactive(self):
        """Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤ìŠµ"""
        st.header("ğŸ–±ï¸ Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜")

        st.markdown("""
        ## Interactive Annotation

        ì‹¤ì „ì—ì„œëŠ” ë°˜ë³µì ìœ¼ë¡œ í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•˜ë©° ë§ˆìŠ¤í¬ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

        ### ì›Œí¬í”Œë¡œìš°
        1. ì´ˆê¸° í¬ì¸íŠ¸ë¡œ ëŒ€ëµì ì¸ ë§ˆìŠ¤í¬ ìƒì„±
        2. ëˆ„ë½ëœ ì˜ì—­ì— foreground point ì¶”ê°€
        3. ì˜ëª» í¬í•¨ëœ ì˜ì—­ì— background point ì¶”ê°€
        4. ë§Œì¡±í•  ë•Œê¹Œì§€ ë°˜ë³µ
        """)

        model_type = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["vit_b", "vit_l", "vit_h"],
            key="interactive_model"
        )
        sam = get_sam_helper(model_type)

        uploaded = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="interactive_upload"
        )

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì„¸ì…˜ ìƒíƒœë¡œ í¬ì¸íŠ¸ ê´€ë¦¬
            if 'interactive_points' not in st.session_state:
                st.session_state.interactive_points = []
                st.session_state.interactive_labels = []

            col1, col2 = st.columns([2, 1])

            with col1:
                st.image(image, caption="ì‘ì—… ì´ë¯¸ì§€", use_container_width=True)

            with col2:
                st.markdown("### í¬ì¸íŠ¸ ì¶”ê°€")

                x = st.number_input("X ì¢Œí‘œ", 0, image.width, image.width//2, key="int_x")
                y = st.number_input("Y ì¢Œí‘œ", 0, image.height, image.height//2, key="int_y")
                label = st.radio("íƒ€ì…", [1, 0], format_func=lambda x: "Foreground" if x == 1 else "Background", key="int_label")

                if st.button("â• í¬ì¸íŠ¸ ì¶”ê°€"):
                    st.session_state.interactive_points.append((x, y))
                    st.session_state.interactive_labels.append(label)
                    st.success(f"í¬ì¸íŠ¸ ì¶”ê°€ë¨ (ì´ {len(st.session_state.interactive_points)}ê°œ)")

                if st.button("ğŸ—‘ï¸ ëª¨ë‘ ì§€ìš°ê¸°"):
                    st.session_state.interactive_points = []
                    st.session_state.interactive_labels = []
                    st.rerun()

                st.markdown(f"**í˜„ì¬ í¬ì¸íŠ¸**: {len(st.session_state.interactive_points)}ê°œ")

            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
            if st.session_state.interactive_points:
                if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—…ë°ì´íŠ¸", type="primary"):
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        mask = sam.segment_with_points(
                            image,
                            st.session_state.interactive_points,
                            st.session_state.interactive_labels
                        )

                        self._visualize_segmentation(
                            image,
                            mask,
                            st.session_state.interactive_points,
                            st.session_state.interactive_labels
                        )

                        # ë‹¤ìš´ë¡œë“œ
                        self._offer_mask_download(mask, "interactive_mask.png")

    def _offer_mask_download(self, mask: np.ndarray, filename: str):
        """ë§ˆìŠ¤í¬ ë‹¤ìš´ë¡œë“œ ì œê³µ"""
        mask_img = Image.fromarray((mask * 255).astype(np.uint8))

        buf = io.BytesIO()
        mask_img.save(buf, format='PNG')
        buf.seek(0)

        st.download_button(
            label="ğŸ’¾ ë§ˆìŠ¤í¬ ë‹¤ìš´ë¡œë“œ",
            data=buf,
            file_name=filename,
            mime="image/png"
        )

    # ==================== Tab 4: Auto Mask ìƒì„± ====================

    def render_auto_mask(self):
        """ìë™ ë§ˆìŠ¤í¬ ìƒì„±"""
        st.header("ğŸ¤– Auto Mask ìƒì„±")

        st.markdown("""
        ## Automatic Mask Generation

        í”„ë¡¬í”„íŠ¸ ì—†ì´ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ìë™ìœ¼ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜í•©ë‹ˆë‹¤.

        ### ë™ì‘ ì›ë¦¬
        1. ì´ë¯¸ì§€ì— ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìƒ˜í”Œë§
        2. ê° í¬ì¸íŠ¸ì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
        3. ì¤‘ë³µ ë§ˆìŠ¤í¬ ì œê±° (NMS)
        4. í’ˆì§ˆ í•„í„°ë§ (IoU, stability score)

        ### í™œìš© ì‚¬ë¡€
        - ë°ì´í„°ì…‹ ìë™ ë¼ë²¨ë§
        - ê°ì²´ ê°œìˆ˜ ì¹´ìš´íŒ…
        - ì „ì²´ ì¥ë©´ ë¶„ì„
        """)

        # âš ï¸ ë©”ëª¨ë¦¬ ê²½ê³ 
        st.warning("""
        âš ï¸ **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì£¼ì˜**

        ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì€ **ë§¤ìš° ë§ì€ ë©”ëª¨ë¦¬(8~12GB)**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

        **ê¶Œì¥ ì„¤ì •**:
        - ì´ë¯¸ì§€ í¬ê¸°: 512px ì´í•˜ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        - Points per side: 8~16 (ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„)
        - ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë¸Œë¼ìš°ì €ê°€ ë©ˆì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)

        model_type = st.selectbox("ëª¨ë¸", ["vit_b", "vit_l", "vit_h"], key="auto_model")
        sam = get_sam_helper(model_type)

        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="auto_upload")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì´ë¯¸ì§€ í¬ê¸° ì²´í¬
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì›ë³¸ í¬ê¸°", f"{image.width}Ã—{image.height}")
            with col2:
                resize_enabled = st.checkbox("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ê¶Œì¥)", value=True)

            if resize_enabled:
                max_size = st.slider("ìµœëŒ€ í¬ê¸°", 256, 1024, 512, step=128,
                                    help="ì´ë¯¸ì§€ë¥¼ ì´ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë©”ëª¨ë¦¬ ì ˆì•½)")

                # ë¦¬ì‚¬ì´ì¦ˆ
                if max(image.width, image.height) > max_size:
                    ratio = max_size / max(image.width, image.height)
                    new_size = (int(image.width * ratio), int(image.height * ratio))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    st.info(f"âœ… ë¦¬ì‚¬ì´ì¦ˆë¨: {new_size[0]}Ã—{new_size[1]}")

            st.image(image, caption="ì²˜ë¦¬í•  ì´ë¯¸ì§€", use_container_width=True)

            # íŒŒë¼ë¯¸í„° ì„¤ì •
            with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
                points_per_side = st.slider("Points per side", 8, 64, 16,
                                           help="ê·¸ë¦¬ë“œ ë°€ë„ (ë†’ì„ìˆ˜ë¡ ì •ë°€í•˜ì§€ë§Œ ë§¤ìš° ëŠë¦¬ê³  ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)")
                pred_iou_thresh = st.slider("IoU threshold", 0.5, 1.0, 0.88,
                                            help="ë§ˆìŠ¤í¬ í’ˆì§ˆ ì„ê³„ê°’")
                stability_score_thresh = st.slider("Stability threshold", 0.5, 1.0, 0.95,
                                                  help="ë§ˆìŠ¤í¬ ì•ˆì •ì„± ì„ê³„ê°’")

            if st.button("ğŸ¤– ìë™ ë§ˆìŠ¤í¬ ìƒì„±", type="primary"):
                try:
                    with st.spinner("ìë™ ë§ˆìŠ¤í¬ ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                        masks = sam.generate_auto_masks(
                            image,
                            points_per_side=points_per_side,
                            pred_iou_thresh=pred_iou_thresh,
                            stability_score_thresh=stability_score_thresh
                        )

                        st.success(f"âœ… {len(masks)}ê°œ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")

                        # ì‹œê°í™”
                        self._visualize_auto_masks(image, masks)

                except RuntimeError as e:
                    if "not enough memory" in str(e):
                        st.error("""
                        âŒ **ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬**

                        ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì— í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.

                        **í•´ê²° ë°©ë²•**:
                        1. âœ… ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í™œì„±í™” (512px ì´í•˜ ê¶Œì¥)
                        2. Points per sideë¥¼ 8~12ë¡œ ë‚®ì¶”ê¸°
                        3. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
                        4. ë” ì‘ì€ ì´ë¯¸ì§€ ì‚¬ìš©

                        ë˜ëŠ” **Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜** íƒ­ì„ ì‚¬ìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤ (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ).
                        """)
                    else:
                        st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

    def _visualize_auto_masks(self, image: Image.Image, masks: List[Dict[str, Any]]):
        """ìë™ ë§ˆìŠ¤í¬ ì‹œê°í™”"""

        if not masks:
            st.warning("ìƒì„±ëœ ë§ˆìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # í†µê³„
        total_area = sum(m['area'] for m in masks)
        avg_area = total_area / len(masks)

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ë§ˆìŠ¤í¬ ìˆ˜", len(masks))
        col2.metric("í‰ê·  ì˜ì—­", f"{avg_area:.0f}px")
        col3.metric("ì´ ì»¤ë²„ë¦¬ì§€", f"{(total_area / (image.width * image.height) * 100):.1f}%")

        # ì»¬ëŸ¬ë§µìœ¼ë¡œ ëª¨ë“  ë§ˆìŠ¤í¬ í‘œì‹œ
        fig, axes = plt.subplots(1, 2, figsize=(12, 6))

        axes[0].imshow(image)
        axes[0].set_title("ì›ë³¸ ì´ë¯¸ì§€")
        axes[0].axis('off')

        # ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì„±
        combined_mask = np.zeros((*masks[0]['segmentation'].shape, 3), dtype=np.uint8)
        for i, mask_data in enumerate(masks[:50]):  # ìƒìœ„ 50ê°œë§Œ
            mask = mask_data['segmentation']
            color = np.random.randint(0, 255, 3)
            combined_mask[mask] = color

        axes[1].imshow(image)
        axes[1].imshow(combined_mask, alpha=0.5)
        axes[1].set_title(f"ìë™ ë§ˆìŠ¤í¬ ({len(masks)}ê°œ)")
        axes[1].axis('off')

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # ê°œë³„ ë§ˆìŠ¤í¬ ë³´ê¸°
        if st.checkbox("ê°œë³„ ë§ˆìŠ¤í¬ ë³´ê¸°"):
            mask_idx = st.slider("ë§ˆìŠ¤í¬ ì„ íƒ", 0, len(masks)-1, 0)
            selected_mask = masks[mask_idx]

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.imshow(image)
            ax.imshow(selected_mask['segmentation'], alpha=0.6, cmap='jet')
            ax.set_title(f"Mask {mask_idx} (Area: {selected_mask['area']}px)")
            ax.axis('off')
            st.pyplot(fig)
            plt.close()

            # bbox ì •ë³´
            x1, y1, x2, y2 = selected_mask['bbox']
            st.info(f"BBox: ({x1}, {y1}) â†’ ({x2}, {y2})")

    # ==================== Tab 5: ì‹¤ì „ ì‘ìš© ====================

    def render_practical(self):
        """ì‹¤ì „ ì‘ìš© ì˜ˆì œ"""
        st.header("ğŸ’¼ ì‹¤ì „ ì‘ìš©")

        st.markdown("""
        ## SAM í™œìš© ì‚¬ë¡€

        ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ìˆ ì˜ ì‹¤ì „ ì‘ìš© ì˜ˆì œë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.
        """)

        app_type = st.selectbox(
            "ì‘ìš© ì˜ˆì œ ì„ íƒ",
            [
                "ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„)",
                "ìë™ ë¼ë²¨ë§ ë„êµ¬",
                "ê°ì²´ ì¹´ìš´íŒ…"
            ]
        )

        if app_type == "ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„)":
            self._app_background_removal()
        elif app_type == "ìë™ ë¼ë²¨ë§ ë„êµ¬":
            self._app_auto_labeling()
        else:
            self._app_object_counting()

    def _app_background_removal(self):
        """ë°°ê²½ ì œê±° ì•±"""
        st.subheader("ğŸ“¸ ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„ í¸ì§‘ê¸°)")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ì¸ë¬¼ ì‚¬ì§„ ì—…ë¡œë“œ
        2. ì¸ë¬¼ ìœ„ì— í¬ì¸íŠ¸ ì§€ì •
        3. ë°°ê²½ ì œê±° ë° ìƒˆ ë°°ê²½ ì„ íƒ
        """)

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì¸ë¬¼ ì‚¬ì§„", type=['png', 'jpg', 'jpeg'], key="bg_remove")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="ì›ë³¸", use_container_width=True)

            with col2:
                # í¬ì¸íŠ¸ ì…ë ¥
                x = st.number_input("X (ì¸ë¬¼)", 0, image.width, image.width//2)
                y = st.number_input("Y (ì¸ë¬¼)", 0, image.height, image.height//2)

                # ìƒˆ ë°°ê²½ ìƒ‰ìƒ
                bg_color = st.color_picker("ìƒˆ ë°°ê²½ ìƒ‰ìƒ", "#FFFFFF")

            if st.button("ğŸ¨ ë°°ê²½ ì œê±°", type="primary"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    try:
                        # ì„¸ê·¸ë©˜í…Œì´ì…˜
                        mask = sam.segment_with_points(image, [(x, y)], [1])
                        
                        # ë§ˆìŠ¤í¬ ìœ íš¨ì„± ê²€ì‚¬
                        if mask is None:
                            st.error("ì„¸ê·¸ë©˜í…Œì´ì…˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì ì„ ì„ íƒí•´ë³´ì„¸ìš”.")
                            return
                        
                        # ë§ˆìŠ¤í¬ í˜•íƒœ ê²€ì¦
                        if len(mask.shape) != 2:
                            st.error(f"ë§ˆìŠ¤í¬ í˜•íƒœê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {mask.shape}")
                            return
                        
                        st.success(f"ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ: {mask.shape}")

                        # ë°°ê²½ êµì²´
                        result_image = self._replace_background(image, mask, bg_color)
                        
                    except Exception as e:
                        st.error(f"ì„¸ê·¸ë©˜í…Œì´ì…˜ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                        import traceback
                        st.text(traceback.format_exc())
                        return

                    st.image(result_image, caption="ê²°ê³¼", use_container_width=True)

                    # ë‹¤ìš´ë¡œë“œ
                    buf = io.BytesIO()
                    result_image.save(buf, format='PNG')
                    buf.seek(0)

                    st.download_button(
                        "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                        data=buf,
                        file_name="background_removed.png",
                        mime="image/png"
                    )

    def _replace_background(
        self,
        image: Image.Image,
        mask: np.ndarray,
        bg_color: str
    ) -> Image.Image:
        """ë°°ê²½ êµì²´"""
        # RGB ë³€í™˜
        r = int(bg_color[1:3], 16)
        g = int(bg_color[3:5], 16)
        b = int(bg_color[5:7], 16)

        # ìƒˆ ë°°ê²½ ìƒì„±
        bg = Image.new("RGB", image.size, (r, g, b))

        # ë§ˆìŠ¤í¬ë¥¼ PIL ì´ë¯¸ì§€ë¡œ ë³€í™˜í•˜ë©´ì„œ í¬ê¸° í™•ì¸
        mask_img = Image.fromarray((mask * 255).astype(np.uint8))
        
        # ë§ˆìŠ¤í¬ì™€ ì´ë¯¸ì§€ í¬ê¸°ê°€ ë‹¤ë¥¸ ê²½ìš° ë§ˆìŠ¤í¬ë¥¼ ì´ë¯¸ì§€ í¬ê¸°ì— ë§ê²Œ ì¡°ì •
        if mask_img.size != image.size:
            mask_img = mask_img.resize(image.size, Image.Resampling.NEAREST)
        
        # ë§ˆìŠ¤í¬ê°€ L ëª¨ë“œ(ê·¸ë ˆì´ìŠ¤ì¼€ì¼)ì¸ì§€ í™•ì¸í•˜ê³ , í•„ìš”ì‹œ ë³€í™˜
        if mask_img.mode != 'L':
            mask_img = mask_img.convert('L')

        # í•©ì„±
        try:
            result = Image.composite(image, bg, mask_img)
        except ValueError as e:
            # í¬ê¸° ë¶ˆì¼ì¹˜ ë¬¸ì œê°€ ì—¬ì „íˆ ìˆëŠ” ê²½ìš°, ëŒ€ì²´ ë°©ë²• ì‚¬ìš©
            st.error(f"ì´ë¯¸ì§€ í•©ì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            # numpyë¥¼ ì‚¬ìš©í•œ ëŒ€ì²´ ë°©ë²•
            image_np = np.array(image)
            bg_np = np.array(bg)
            mask_np = np.array(mask_img) / 255.0
            
            # ë§ˆìŠ¤í¬ë¥¼ 3ì°¨ì›ìœ¼ë¡œ í™•ì¥
            if len(mask_np.shape) == 2:
                mask_np = np.stack([mask_np] * 3, axis=-1)
            
            # ë°°ê²½ êµì²´
            result_np = image_np * mask_np + bg_np * (1 - mask_np)
            result = Image.fromarray(result_np.astype(np.uint8))
        
        return result

    def _app_auto_labeling(self):
        """ìë™ ë¼ë²¨ë§ ë„êµ¬"""
        st.subheader("ğŸ·ï¸ ìë™ ë¼ë²¨ë§ ë„êµ¬")

        st.markdown("""
        **ëª©ì **: ê°ì²´ íƒì§€ í•™ìŠµ ë°ì´í„° ìƒì„± ìë™í™”

        **ì›Œí¬í”Œë¡œìš°**:
        1. ì´ë¯¸ì§€ ì—…ë¡œë“œ
        2. ìë™ ë§ˆìŠ¤í¬ ìƒì„±
        3. ê° ë§ˆìŠ¤í¬ì— í´ë˜ìŠ¤ ë ˆì´ë¸” í• ë‹¹
        4. COCO/YOLO í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
        """)

        st.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. ì‘ì€ ì´ë¯¸ì§€ ì‚¬ìš© ë˜ëŠ” ë¦¬ì‚¬ì´ì§•ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="label_img")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            resize = st.checkbox("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ", value=True, key="label_resize")
            if resize:
                max_size = st.slider("ìµœëŒ€ í¬ê¸°", 256, 1024, 512, step=128, key="label_max")
                if max(image.width, image.height) > max_size:
                    ratio = max_size / max(image.width, image.height)
                    new_size = (int(image.width * ratio), int(image.height * ratio))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    st.info(f"âœ… ë¦¬ì‚¬ì´ì¦ˆ: {new_size[0]}Ã—{new_size[1]}")

            st.image(image, use_container_width=True)

            if st.button("ğŸ¤– ìë™ ë§ˆìŠ¤í¬ ìƒì„±"):
                try:
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        masks = sam.generate_auto_masks(image, points_per_side=16)
                        st.session_state.labeling_masks = masks
                        st.success(f"âœ… {len(masks)}ê°œ í›„ë³´ ìƒì„±")
                except RuntimeError as e:
                    if "not enough memory" in str(e):
                        st.error("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±! ì´ë¯¸ì§€ í¬ê¸°ë¥¼ ì¶•ì†Œí•˜ì—¬ ë‹¤ì‹œ ì‹œë„í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.")
                    else:
                        st.error(f"ì—ëŸ¬: {e}")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

            if 'labeling_masks' in st.session_state:
                masks = st.session_state.labeling_masks

                st.markdown("### ë ˆì´ë¸” í• ë‹¹")

                # í´ë˜ìŠ¤ ì •ì˜
                class_names = st.text_input("í´ë˜ìŠ¤ (ì‰¼í‘œ êµ¬ë¶„)", "person,car,dog,cat")
                classes = [c.strip() for c in class_names.split(",")]

                # ë§ˆìŠ¤í¬ë³„ ë ˆì´ë¸”
                for i, mask_data in enumerate(masks[:10]):  # ìƒìœ„ 10ê°œ
                    col1, col2, col3 = st.columns([2, 1, 1])

                    with col1:
                        # ë¯¸ë¦¬ë³´ê¸°
                        fig, ax = plt.subplots(figsize=(4, 3))
                        ax.imshow(image)
                        ax.imshow(mask_data['segmentation'], alpha=0.5)
                        ax.set_title(f"Mask {i}")
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close()

                    with col2:
                        label = st.selectbox(f"Class", ["(skip)"] + classes, key=f"class_{i}")

                    with col3:
                        st.metric("Area", f"{mask_data['area']}px")

                st.info("ğŸ’¡ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì—¬ê¸°ì„œ JSON/XML íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° êµ¬í˜„")

    def _app_object_counting(self):
        """ê°ì²´ ì¹´ìš´íŒ…"""
        st.subheader("ğŸ”¢ ê°ì²´ ì¹´ìš´íŒ…")

        st.markdown("""
        **ì‘ìš© ë¶„ì•¼**:
        - êµ°ì¤‘ ê³„ìˆ˜ (crowd counting)
        - ì„¸í¬ ì¹´ìš´íŒ… (medical imaging)
        - ì¬ê³  ê´€ë¦¬ (inventory counting)
        """)

        st.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="count_img")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            resize = st.checkbox("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ", value=True, key="count_resize")
            if resize:
                max_size = st.slider("ìµœëŒ€ í¬ê¸°", 256, 1024, 512, step=128, key="count_max")
                if max(image.width, image.height) > max_size:
                    ratio = max_size / max(image.width, image.height)
                    new_size = (int(image.width * ratio), int(image.height * ratio))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    st.info(f"âœ… ë¦¬ì‚¬ì´ì¦ˆ: {new_size[0]}Ã—{new_size[1]}")

            st.image(image, use_container_width=True)

            # í•„í„°ë§ íŒŒë¼ë¯¸í„°
            min_area = st.slider("ìµœì†Œ ê°ì²´ í¬ê¸° (pxÂ²)", 100, 5000, 500)
            max_area = st.slider("ìµœëŒ€ ê°ì²´ í¬ê¸° (pxÂ²)", 1000, 50000, 10000)

            if st.button("ğŸ”¢ ê°ì²´ ì¹´ìš´íŒ…", type="primary"):
                try:
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        masks = sam.generate_auto_masks(image, points_per_side=16)

                        # í•„í„°ë§
                        filtered = [
                            m for m in masks
                            if min_area <= m['area'] <= max_area
                        ]

                        st.success(f"âœ… ê²€ì¶œëœ ê°ì²´: **{len(filtered)}ê°œ**")

                        # ì‹œê°í™”
                        fig, ax = plt.subplots(figsize=(10, 8))
                        ax.imshow(image)

                        for i, mask_data in enumerate(filtered):
                            mask = mask_data['segmentation']
                            color = np.random.rand(3)

                            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
                            colored_mask = np.zeros((*mask.shape, 3))
                            colored_mask[mask] = color
                            ax.imshow(colored_mask, alpha=0.4)

                            # ë²ˆí˜¸ í‘œì‹œ
                            x1, y1, x2, y2 = mask_data['bbox']
                            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                            ax.text(cx, cy, str(i+1), color='white',
                                   fontsize=12, weight='bold',
                                   ha='center', va='center',
                                   bbox=dict(boxstyle='circle', facecolor='red', alpha=0.8))

                        ax.set_title(f"ì´ {len(filtered)}ê°œ ê°ì²´ ê²€ì¶œ")
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close()

                        # í†µê³„
                        if filtered:
                            areas = [m['area'] for m in filtered]
                            st.markdown(f"""
                            ### í†µê³„
                            - í‰ê·  í¬ê¸°: {np.mean(areas):.0f}pxÂ²
                            - ìµœì†Œ í¬ê¸°: {np.min(areas)}pxÂ²
                            - ìµœëŒ€ í¬ê¸°: {np.max(areas)}pxÂ²
                            """)

                except RuntimeError as e:
                    if "not enough memory" in str(e):
                        st.error("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±! ì´ë¯¸ì§€ í¬ê¸° ì¶•ì†Œ ë˜ëŠ” Interactive íƒ­ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.")
                    else:
                        st.error(f"ì—ëŸ¬: {e}")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
