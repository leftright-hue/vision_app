"""
Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ SAM (Segment Anything Model)
"""

import streamlit as st
import numpy as np
from PIL import Image, ImageDraw
import matplotlib.pyplot as plt
from typing import List, Tuple, Optional, Dict, Any
import io

from core.base_processor import BaseImageProcessor
from .sam_helpers import get_sam_helper


class SegmentationModule(BaseImageProcessor):
    """Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ ëª¨ë“ˆ"""

    def __init__(self):
        super().__init__()
        self.name = "Week 6: Segmentation & SAM"

    def render(self):
        """ë©”ì¸ ë Œë”ë§ í•¨ìˆ˜"""
        st.title("ğŸ¨ Week 6: ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ê³¼ SAM")

        st.markdown("""
        ## í•™ìŠµ ëª©í‘œ
        - **ì´ë¡ **: U-Net, Instance/Panoptic Segmentation, SAM ì›ë¦¬ ì´í•´
        - **ì‹¤ìŠµ**: SAMì„ í™œìš©í•œ interactive segmentation êµ¬í˜„
        - **ì‘ìš©**: ë°°ê²½ ì œê±°, ìë™ ë¼ë²¨ë§ ë„êµ¬ ì œì‘
        """)

        # í™˜ê²½ ì²´í¬
        self._check_environment()

        # 5ê°œ íƒ­ êµ¬ì„±
        tabs = st.tabs([
            "ğŸ“š ê°œë… ì†Œê°œ",
            "ğŸ¯ SAM ê¸°ì´ˆ",
            "ğŸ–±ï¸ Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜",
            "ğŸ¤– Auto Mask ìƒì„±",
            "ğŸ’¼ ì‹¤ì „ ì‘ìš©"
        ])

        with tabs[0]:
            self.render_theory()

        with tabs[1]:
            self.render_sam_basics()

        with tabs[2]:
            self.render_interactive()

        with tabs[3]:
            self.render_auto_mask()

        with tabs[4]:
            self.render_practical()

    def _check_environment(self):
        """í™˜ê²½ ì²´í¬ ë° ì„¤ì •"""
        with st.expander("ğŸ”§ í™˜ê²½ ì„¤ì • í™•ì¸", expanded=False):
            st.markdown("""
            ### í•„ìš”í•œ íŒ¨í‚¤ì§€
            - `transformers`: SAM ëª¨ë¸ ë¡œë”© (HuggingFace)
            - `torch`: PyTorch ë°±ì—”ë“œ
            - `Pillow`, `numpy`, `matplotlib`: ì´ë¯¸ì§€ ì²˜ë¦¬

            ### 3-Tier Fallback ì „ëµ
            1. **HuggingFace Transformers** (ê¶Œì¥): `pip install transformers torch`
            2. **Official segment-anything**: `pip install segment-anything`
            3. **Simulation Mode**: íŒ¨í‚¤ì§€ ì—†ì´ ê¸°ë³¸ ê¸°ëŠ¥ ì‚¬ìš©
            """)

            issues = []

            # Check transformers
            try:
                import transformers
                st.success(f"âœ… transformers {transformers.__version__}")
            except ImportError:
                issues.append("transformers")
                st.warning("âš ï¸ transformers ë¯¸ì„¤ì¹˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)")

            # Check torch
            try:
                import torch
                device = "GPU" if torch.cuda.is_available() else "CPU"
                st.success(f"âœ… torch {torch.__version__} ({device})")
            except ImportError:
                issues.append("torch")
                st.warning("âš ï¸ torch ë¯¸ì„¤ì¹˜ (ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ)")

            if issues:
                st.info(f"""
                ### ğŸ”§ ì„¤ì¹˜ ë°©ë²•
                ```bash
                pip install transformers torch
                ```

                ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œì—ì„œë„ ê¸°ë³¸ ê¸°ëŠ¥ì€ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤.
                """)

    # ==================== Tab 1: ê°œë… ì†Œê°œ ====================

    def render_theory(self):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ì´ë¡  ì„¤ëª…"""
        st.header("ğŸ“š ì„¸ê·¸ë©˜í…Œì´ì…˜ ê°œë… ì†Œê°œ")

        st.markdown("""
        ## 1. ì„¸ê·¸ë©˜í…Œì´ì…˜ì´ë€?

        **ì„¸ê·¸ë©˜í…Œì´ì…˜(Segmentation)**ì€ ì´ë¯¸ì§€ì˜ ê° í”½ì…€ì„ íŠ¹ì • í´ë˜ìŠ¤ë‚˜ ê°ì²´ì— í• ë‹¹í•˜ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.

        ### 1.1 Classification vs Detection vs Segmentation

        | íƒœìŠ¤í¬ | ëª©í‘œ | ì¶œë ¥ |
        |--------|------|------|
        | **Classification** | ì´ë¯¸ì§€ ì „ì²´ ë¶„ë¥˜ | "ê³ ì–‘ì´" |
        | **Object Detection** | ê°ì²´ ìœ„ì¹˜ íƒì§€ | ë°”ìš´ë”© ë°•ìŠ¤ + í´ë˜ìŠ¤ |
        | **Segmentation** | í”½ì…€ ë‹¨ìœ„ ë¶„ë¥˜ | í”½ì…€ë³„ ë§ˆìŠ¤í¬ |

        """)

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ íƒ€ì… ë¹„êµ ì´ë¯¸ì§€
        import os
        seg_img_path = os.path.join(os.path.dirname(__file__), "assets", "3.png")
        if os.path.exists(seg_img_path):
            st.image(seg_img_path,
                    caption="ë¶„ë¥˜ vs ê°ì²´ íƒì§€ vs ì„¸ê·¸ë©˜í…Œì´ì…˜ ë¹„êµ",
                    use_container_width=True)

        st.markdown("""

        ---

        ## 2. ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¢…ë¥˜

        ### 2.1 Semantic Segmentation
        - **ì •ì˜**: ê°™ì€ í´ë˜ìŠ¤ì˜ ëª¨ë“  í”½ì…€ì„ ê°™ì€ ë ˆì´ë¸”ë¡œ ì§€ì •
        - **íŠ¹ì§•**: ê°œë³„ ê°ì²´ êµ¬ë¶„ ì•ˆ í•¨ (ëª¨ë“  ì‚¬ëŒ â†’ "person")
        - **ì˜ˆ**: ë„ë¡œ, í•˜ëŠ˜, ê±´ë¬¼ ë“± ì˜ì—­ ë¶„í• 

        ### 2.2 Instance Segmentation
        - **ì •ì˜**: ê°™ì€ í´ë˜ìŠ¤ë¼ë„ ê°œë³„ ê°ì²´ë¥¼ êµ¬ë¶„
        - **íŠ¹ì§•**: ê° ê°ì²´ë§ˆë‹¤ ë‹¤ë¥¸ ë§ˆìŠ¤í¬
        - **ì˜ˆ**: person1, person2, person3 êµ¬ë¶„

        ### 2.3 Panoptic Segmentation
        - **ì •ì˜**: Semantic + Instance ê²°í•©
        - **íŠ¹ì§•**: ë°°ê²½(stuff)ì€ semantic, ê°ì²´(thing)ëŠ” instance
        - **ì˜ˆ**: ë„ë¡œ(semantic) + ìë™ì°¨ë“¤(instance)
        """)

        # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì¢…ë¥˜ ë¹„êµ ì´ë¯¸ì§€
        import os
        seg_img_path = os.path.join(os.path.dirname(__file__), "assets", "segmentation.png")
        if os.path.exists(seg_img_path):
            st.image(seg_img_path,
                    caption="Semantic vs Instance vs Panoptic Segmentation ë¹„êµ",
                    use_container_width=True)

        st.markdown("""

        ---

        ## 3. U-Net ì•„í‚¤í…ì²˜

        U-Netì€ ì˜ë£Œ ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜ì„ ìœ„í•´ ê°œë°œëœ ëŒ€í‘œì ì¸ ì•„í‚¤í…ì²˜ì…ë‹ˆë‹¤.
        """)

        # U-Net êµ¬ì¡° ë‹¤ì´ì–´ê·¸ë¨
        import os
        unet_img_path = os.path.join(os.path.dirname(__file__), "assets", "unet_architecture.png")
        if os.path.exists(unet_img_path):
            st.image(unet_img_path,
                    caption="U-Net Architecture (Ronneberger et al., 2015)",
                    use_container_width=True)
        else:
            st.image("https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png",
                    caption="U-Net Architecture (Ronneberger et al., 2015)",
                    use_container_width=True)

        st.markdown("""
        ### U-Net í•µì‹¬ êµ¬ì¡° (ì‰¬ìš´ ì„¤ëª…)

        U-Netì€ **"U"ì ëª¨ì–‘**ì²˜ëŸ¼ ìƒê²¨ì„œ U-Netì´ë¼ê³  ë¶€ë¦…ë‹ˆë‹¤. ë§ˆì¹˜ ê³„ê³¡ì„ ë‚´ë ¤ê°”ë‹¤ê°€ ë‹¤ì‹œ ì˜¬ë¼ì˜¤ëŠ” ëª¨ì–‘ì´ì—ìš”.

        ---

        #### ğŸ”½ 1ë‹¨ê³„: Contracting Path (ì¶•ì†Œ ê²½ë¡œ) - "ì •ë³´ ì••ì¶•"

        **ë¹„ìœ **: ë§ì›ê²½ìœ¼ë¡œ ì‚¬ì§„ì„ ì°ë“¯ì´, í° ê·¸ë¦¼ì„ ì ì  ì‘ê²Œ ì••ì¶•í•©ë‹ˆë‹¤.

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** ì´ë¯¸ì§€ë¥¼ ì ì  ì‘ê²Œ ë§Œë“¤ë©´ì„œ ì¤‘ìš”í•œ íŠ¹ì§•ë§Œ ì¶”ì¶œ
        - **ì™œ í•„ìš”í•œê°€ìš”?** "ì´ê±´ ê³ ì–‘ì´ì•¼", "ì´ê±´ ë°°ê²½ì´ì•¼" ê°™ì€ í° ì˜ë¯¸ë¥¼ ì´í•´í•˜ê¸° ìœ„í•´
        - **ì˜ˆì‹œ**: 512Ã—512 â†’ 256Ã—256 â†’ 128Ã—128 â†’ 64Ã—64ë¡œ ì¶•ì†Œ

        ğŸ’¡ *ì´ë¯¸ì§€ëŠ” ì‘ì•„ì§€ì§€ë§Œ, ì´í•´í•˜ëŠ” ì •ë³´ëŠ” ë” ë§ì•„ì§‘ë‹ˆë‹¤!*

        ---

        #### ğŸ¯ 2ë‹¨ê³„: Bottleneck (ë³‘ëª©) - "í•µì‹¬ ì´í•´"

        **ë¹„ìœ **: ê¸´ ê¸€ì„ í•œ ì¤„ë¡œ ìš”ì•½í•˜ëŠ” ê²ƒì²˜ëŸ¼, ê°€ì¥ ì••ì¶•ëœ ìƒíƒœì…ë‹ˆë‹¤.

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** ì´ë¯¸ì§€ì˜ í•µì‹¬ ì •ë³´ë§Œ ë‹´ì€ ê°€ì¥ ì‘ì€ í‘œí˜„
        - **ì™œ í•„ìš”í•œê°€ìš”?** "ì´ ì´ë¯¸ì§€ì—ëŠ” ê³ ì–‘ì´ 2ë§ˆë¦¬ì™€ ì†ŒíŒŒê°€ ìˆì–´"ì²˜ëŸ¼ ì „ì²´ ìƒí™©ì„ íŒŒì•…

        ğŸ’¡ *ê°€ì¥ ì‘ì§€ë§Œ, ê°€ì¥ ë§ì€ ì˜ë¯¸ë¥¼ ë‹´ê³  ìˆì–´ìš”!*

        ---

        #### ğŸ”¼ 3ë‹¨ê³„: Expansive Path (í™•ì¥ ê²½ë¡œ) - "ë””í…Œì¼ ë³µì›"

        **ë¹„ìœ **: ì••ì¶• íŒŒì¼ì„ ë‹¤ì‹œ í’€ë“¯ì´, ì‘ì€ ì´ë¯¸ì§€ë¥¼ ì›ë˜ í¬ê¸°ë¡œ í‚¤ì›ë‹ˆë‹¤.

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** ì••ì¶•ëœ ì •ë³´ë¥¼ ë‹¤ì‹œ ì›ë˜ í¬ê¸°ë¡œ í™•ëŒ€
        - **ì™œ í•„ìš”í•œê°€ìš”?** "ê° í”½ì…€ì´ ê³ ì–‘ì´ì¸ì§€ ì†ŒíŒŒì¸ì§€" êµ¬ë¶„í•˜ê¸° ìœ„í•´
        - **ì˜ˆì‹œ**: 64Ã—64 â†’ 128Ã—128 â†’ 256Ã—256 â†’ 512Ã—512ë¡œ í™•ëŒ€

        ğŸ’¡ *ì´ë¯¸ì§€ë¥¼ í‚¤ìš°ë©´ì„œ "ì´ í”½ì…€ì€ ê³ ì–‘ì´ ê·€", "ì € í”½ì…€ì€ ì†ŒíŒŒ" ê°™ì€ ì„¸ë°€í•œ ì •ë³´ë¥¼ ë³µì›í•´ìš”!*

        ---

        #### â­ 4ë‹¨ê³„: Skip Connections (ì§€ë¦„ê¸¸ ì—°ê²°) - "ë””í…Œì¼ ë³´ì¡´"

        **ë¹„ìœ **: ì‚°ì„ ë‚´ë ¤ê°”ë‹¤ ì˜¬ë¼ì˜¬ ë•Œ, ë‚´ë ¤ê°€ë©´ì„œ ë³¸ í‘œì§€íŒì„ ê¸°ì–µí•˜ëŠ” ê²ƒê³¼ ê°™ì•„ìš”.

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** ì••ì¶• ë‹¨ê³„(â†“)ì˜ ì„¸ë°€í•œ ì •ë³´ë¥¼ ë³µì› ë‹¨ê³„(â†‘)ì— ì§ì ‘ ì „ë‹¬
        - **ì™œ í•„ìš”í•œê°€ìš”?** ì••ì¶•í•˜ë©´ì„œ ìƒì–´ë²„ë¦° "ê³ ì–‘ì´ ìˆ˜ì—¼", "í„¸ ì§ˆê°" ê°™ì€ ë””í…Œì¼ì„ ë˜ì‚´ë¦¬ê¸° ìœ„í•´
        - **íš¨ê³¼**: ê²½ê³„ì„ ì´ ë” ì„ ëª…í•˜ê³  ì •í™•í•œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ê°€ëŠ¥

        ğŸ’¡ *ì´ê²Œ U-Netì˜ í•µì‹¬ ë¹„ë²•ì…ë‹ˆë‹¤! ë‚´ë ¤ê°ˆ ë•Œ ë³¸ ì •ë³´ë¥¼ ì˜¬ë¼ì˜¬ ë•Œ ë‹¤ì‹œ ì‚¬ìš©í•´ìš”!*

        ---

        ### ğŸ“ ì™œ U-Netì´ ì¢‹ì€ê°€ìš”?

        1. **ë””í…Œì¼ ë³´ì¡´**: Skip Connection ë•ë¶„ì— ì„¸ë°€í•œ ê²½ê³„ì„ ê¹Œì§€ ì •í™•í•˜ê²Œ ë¶„í• 
        2. **ì ì€ ë°ì´í„°ë¡œ í•™ìŠµ**: ì˜ë£Œ ì´ë¯¸ì§€ì²˜ëŸ¼ ë°ì´í„°ê°€ ì ì–´ë„ ì˜ ì‘ë™
        3. **ë¹ ë¥¸ ì²˜ë¦¬**: íš¨ìœ¨ì ì¸ êµ¬ì¡°ë¡œ ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
        4. **ë‹¤ì–‘í•œ ì‘ìš©**: ì˜ë£Œ, ìœ„ì„± ì´ë¯¸ì§€, ììœ¨ì£¼í–‰ ë“± í­ë„“ê²Œ ì‚¬ìš©

        ---

        ## 4. Segment Anything Model (SAM) - ì‰¬ìš´ ì„¤ëª…

        **SAM(Segment Anything Model)**ì€ Meta AIê°€ 2023ë…„ ë°œí‘œí•œ "ë¬´ì—‡ì´ë“  ë¶„í• í•˜ëŠ”" AIì…ë‹ˆë‹¤.

        ---

        ### ğŸ¯ SAMì´ ë­ê°€ íŠ¹ë³„í•œê°€ìš”?

        **ë¹„ìœ **: SAMì€ **"ë§ŒëŠ¥ ê°€ìœ„"** ê°™ì•„ìš”!

        ì¼ë°˜ ê°€ìœ„ëŠ” ì¢…ì´ë§Œ ìë¥´ê±°ë‚˜ ì²œë§Œ ìë¥´ëŠ” ë“± íŠ¹í™”ë˜ì–´ ìˆì§€ë§Œ, SAMì€ ì²˜ìŒ ë³´ëŠ” ë¬¼ê±´ì´ë¼ë„ ì²™ì²™ ì˜ë¼ë‚¼ ìˆ˜ ìˆì–´ìš”.

        ---

        #### âœ¨ SAMì˜ 3ê°€ì§€ ìŠˆí¼íŒŒì›Œ

        **1. ğŸŒŸ Zero-Shot ëŠ¥ë ¥ - "ì²˜ìŒ ë´ë„ ì•Œì•„ìš”!"**

        **ë¹„ìœ **: ì™¸êµ­ì¸ì´ ì²˜ìŒ ë³¸ ê³¼ì¼ë„ "ì´ê²Œ ê³¼ì¼ì´êµ¬ë‚˜"ë¼ê³  ì•„ëŠ” ê²ƒì²˜ëŸ¼

        - **ë¬´ì—‡ì„ í•˜ë‚˜ìš”?** í•œ ë²ˆë„ ë³¸ ì  ì—†ëŠ” ë¬¼ê±´ë„ ì •í™•í•˜ê²Œ ë¶„í• 
        - **ì˜ˆì‹œ**:
          - ê³ ì–‘ì´ë§Œ í•™ìŠµí–ˆëŠ”ë° ê°•ì•„ì§€ë„ ë¶„í•  ê°€ëŠ¥
          - ìë™ì°¨ë§Œ í•™ìŠµí–ˆëŠ”ë° ìì „ê±°ë„ ë¶„í•  ê°€ëŠ¥
        - **ì™œ ëŒ€ë‹¨í•œê°€ìš”?** ê¸°ì¡´ ëª¨ë¸ì€ í•™ìŠµí•œ ê²ƒë§Œ ë¶„í•  ê°€ëŠ¥í–ˆì–´ìš”

        ğŸ’¡ *1,100ë§Œ ê°œ ì´ë¯¸ì§€ë¡œ í•™ìŠµí•´ì„œ ê±°ì˜ ëª¨ë“  ê²ƒì„ ì•Œì•„ìš”!*

        ---

        **2. ğŸ–±ï¸ Prompt ê¸°ë°˜ - "ì›í•˜ëŠ” ëŒ€ë¡œ ì¡°ì‘ ê°€ëŠ¥!"**

        **ë¹„ìœ **: ë¦¬ëª¨ì»¨ìœ¼ë¡œ TV ì±„ë„ì„ ë°”ê¾¸ë“¯ì´, í´ë¦­ê³¼ ë°•ìŠ¤ë¡œ AIë¥¼ ì¡°ì¢…

        3ê°€ì§€ ì¡°ì‘ ë°©ë²•:
        - **Point (í´ë¦­)**: "ì—¬ê¸° ìˆëŠ” ê²ƒ ì˜ë¼ì¤˜!" ğŸ‘†
        - **Box (ë°•ìŠ¤)**: "ì´ ì˜ì—­ ì•ˆì— ìˆëŠ” ê±° ì˜ë¼ì¤˜!" â¬œ
        - **Mask (ë§ˆìŠ¤í¬)**: "ì´ê±° ë” ì •í™•í•˜ê²Œ ë‹¤ë“¬ì–´ì¤˜!" âœ‚ï¸

        ğŸ’¡ *ë§ˆì¹˜ í¬í† ìƒµì˜ ë§ˆìˆ  ì§€íŒ¡ì´ ë„êµ¬ì²˜ëŸ¼ ì‰¬ì›Œìš”!*

        ---

        **3. âš¡ ì‹¤ì‹œê°„ ì²˜ë¦¬ - "ë¹ ë¥´ê³  ì •í™•í•´ìš”!"**

        **ë¹„ìœ **: ë²ˆê°œì²˜ëŸ¼ ë¹ ë¥¸ ë°˜ì‘ ì†ë„

        - **ì†ë„**: í´ë¦­í•˜ë©´ ì¦‰ì‹œ ê²°ê³¼ (< 1ì´ˆ)
        - **ëŒ€í™”í˜•**: ê²°ê³¼ë¥¼ ë³´ë©´ì„œ ê³„ì† ìˆ˜ì • ê°€ëŠ¥
        - **ì‹¤ìš©ì„±**: ì‹¤ì œ ì‘ì—…ì— ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥

        ğŸ’¡ *ëŠë¦° ê¸°ì¡´ ëª¨ë¸ê³¼ ë‹¬ë¦¬ ë°”ë¡œë°”ë¡œ ë°˜ì‘í•´ìš”!*

        ---

        ### ğŸ”§ SAMì€ ì–´ë–»ê²Œ ë™ì‘í•˜ë‚˜ìš”?

        **3ë‹¨ê³„ ì‘ë™ ë°©ì‹** (ì‰½ê²Œ ì„¤ëª…)

        #### 1ë‹¨ê³„: ì´ë¯¸ì§€ ì´í•´í•˜ê¸° (Image Encoder) ğŸ”

        **ë¹„ìœ **: ì‚¬ì§„ì„ ê¼¼ê¼¼íˆ ê´€ì°°í•˜ëŠ” íƒì •

        - ì´ë¯¸ì§€ì˜ ëª¨ë“  ë¶€ë¶„ì„ ë¶„ì„
        - "ì—¬ê¸°ëŠ” ê³ ì–‘ì´", "ì €ê¸°ëŠ” ì†ŒíŒŒ", "ë°°ê²½ì€ ë²½" ê°™ì€ ì •ë³´ íŒŒì•…
        - Vision Transformer ì‚¬ìš© (ëˆˆìœ¼ë¡œ ë³´ë“¯ ì´ë¯¸ì§€ ìŠ¤ìº”)

        ---

        #### 2ë‹¨ê³„: ëª…ë ¹ ì´í•´í•˜ê¸° (Prompt Encoder) ğŸ¯

        **ë¹„ìœ **: ì‚¬ìš©ìì˜ ë§ì„ ì•Œì•„ë“£ëŠ” í†µì—­ì‚¬

        - í´ë¦­(Point): "ì´ ìœ„ì¹˜ì— ìˆëŠ” ë¬¼ê±´"
        - ë°•ìŠ¤(Box): "ì´ ì˜ì—­ ì•ˆì˜ ë¬¼ê±´"
        - ë§ˆìŠ¤í¬(Mask): "ì´ë¯¸ ì„ íƒëœ ê²ƒì„ ê°œì„ "

        ---

        #### 3ë‹¨ê³„: ê²°ê³¼ ë§Œë“¤ê¸° (Mask Decoder) âœ‚ï¸

        **ë¹„ìœ **: ê°€ìœ„ë¡œ ì •í™•í•˜ê²Œ ì˜¤ë ¤ë‚´ê¸°

        - 1ë‹¨ê³„(ì´ë¯¸ì§€ ì •ë³´) + 2ë‹¨ê³„(ëª…ë ¹) ê²°í•©
        - ì •í™•í•œ ê²½ê³„ì„  ì°¾ê¸°
        - **íŠ¹ë³„ ê¸°ëŠ¥**: 3ê°œ í›„ë³´ ì œì‹œ (ë‹¤ì–‘í•œ í•´ì„ ê°€ëŠ¥)

        ğŸ’¡ *"ê³ ì–‘ì´ë§Œ ìë¥¼ê¹Œìš”? ê³ ì–‘ì´+ì†ŒíŒŒ? ì „ì²´?"ì²˜ëŸ¼ ì—¬ëŸ¬ ì„ íƒì§€ë¥¼ ì¤˜ìš”!*

        ---

        ### ğŸ“ ì™œ SAMì´ í˜ëª…ì ì¸ê°€ìš”?

        | êµ¬ë¶„ | ê¸°ì¡´ ëª¨ë¸ | SAM |
        |------|----------|-----|
        | **í•™ìŠµ** | "ê³ ì–‘ì´", "ê°œ" ë“± ì •í•´ì§„ ê²ƒë§Œ | ì²˜ìŒ ë³´ëŠ” ê²ƒë„ ë¶„í•  â­ |
        | **ì‚¬ìš©ë²•** | ìë™ìœ¼ë¡œë§Œ ì‘ë™ | í´ë¦­/ë°•ìŠ¤ë¡œ ì¡°ì‘ ê°€ëŠ¥ â­ |
        | **ì†ë„** | ëŠë¦¼ (ëª‡ ì´ˆ~ëª‡ ë¶„) | ë¹ ë¦„ (< 1ì´ˆ) â­ |
        | **ì •í™•ë„** | íŠ¹ì • ë°ì´í„°ì—ë§Œ ì •í™• | ê±°ì˜ ëª¨ë“  ê²ƒì— ì •í™• â­ |

        ---

        ### ğŸ’¼ ì‹¤ìƒí™œì—ì„œ ì–´ë””ì— ì“°ë‚˜ìš”?

        #### 1. ğŸ“¸ **ì¦ëª…ì‚¬ì§„ ë°°ê²½ ì œê±°**
        - **ì˜ˆì‹œ**: í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ë°°ê²½ì„ í°ìƒ‰/íŒŒë€ìƒ‰ìœ¼ë¡œ ë³€ê²½
        - **ì‚¬ìš©ì**: ì‚¬ì§„ê´€, ì˜¨ë¼ì¸ ì¦ëª…ì‚¬ì§„ ì„œë¹„ìŠ¤

        #### 2. ğŸ·ï¸ **AI í•™ìŠµ ë°ì´í„° ë§Œë“¤ê¸°**
        - **ì˜ˆì‹œ**: ìˆ˜ì²œ ì¥ ì´ë¯¸ì§€ì—ì„œ ìë™ìœ¼ë¡œ ìë™ì°¨, ì‚¬ëŒ ë¶„í• 
        - **ì‚¬ìš©ì**: AI ê°œë°œì, ë°ì´í„° ë¼ë²¨ëŸ¬

        #### 3. ğŸ©º **ì˜ë£Œ ì˜ìƒ ë¶„ì„**
        - **ì˜ˆì‹œ**: X-ray, MRIì—ì„œ ë³‘ë³€ ë¶€ìœ„ ìë™ ê°ì§€
        - **ì‚¬ìš©ì**: ì˜ì‚¬, ë³‘ì›

        #### 4. ğŸ¬ **ì˜ìƒ í¸ì§‘**
        - **ì˜ˆì‹œ**: ìœ íŠœë¸Œ ì˜ìƒì—ì„œ ë°°ê²½ë§Œ êµì²´, íŠ¹ì • ë¬¼ê±´ ì œê±°
        - **ì‚¬ìš©ì**: í¬ë¦¬ì—ì´í„°, ì˜ìƒ í¸ì§‘ì

        #### 5. ğŸš— **ììœ¨ì£¼í–‰ ì°¨ëŸ‰**
        - **ì˜ˆì‹œ**: ë„ë¡œ, ì°¨ëŸ‰, ë³´í–‰ì ì‹¤ì‹œê°„ êµ¬ë¶„
        - **ì‚¬ìš©ì**: ìë™ì°¨ íšŒì‚¬, ììœ¨ì£¼í–‰ ê°œë°œì‚¬

        #### 6. ğŸ›ï¸ **ì‡¼í•‘ëª° ìƒí’ˆ ì‚¬ì§„**
        - **ì˜ˆì‹œ**: ì˜·, ì‹ ë°œ ë“± ìƒí’ˆë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
        - **ì‚¬ìš©ì**: ì´ì»¤ë¨¸ìŠ¤, ì˜¨ë¼ì¸ ì‡¼í•‘ëª°

        ---

        ### ğŸ‰ ì •ë¦¬í•˜ë©´?

        **SAM = ì²˜ìŒ ë³´ëŠ” ê²ƒë„ ì²™ì²™ + í´ë¦­ìœ¼ë¡œ ì¡°ì‘ + ë²ˆê°œì²˜ëŸ¼ ë¹ ë¥¸ = ë§ŒëŠ¥ ì„¸ê·¸ë©˜í…Œì´ì…˜ AI**

        ë” ì´ìƒ ë³µì¡í•œ ì„¤ì • ì—†ì´, í´ë¦­ ëª‡ ë²ˆìœ¼ë¡œ ì›í•˜ëŠ” ê°ì²´ë¥¼ ì •í™•í•˜ê²Œ ë¶„í• í•  ìˆ˜ ìˆì–´ìš”! ğŸ¯

        ---

        ## ì°¸ê³  ìë£Œ
        - [U-Net ë…¼ë¬¸](https://arxiv.org/abs/1505.04597)
        - [SAM ë…¼ë¬¸](https://arxiv.org/abs/2304.02643)
        - [SAM Demo](https://segment-anything.com/)
        """)

    # ==================== Tab 2: SAM ê¸°ì´ˆ ====================

    def render_sam_basics(self):
        """SAM ê¸°ë³¸ ì‚¬ìš©ë²•"""
        st.header("ğŸ¯ SAM ê¸°ì´ˆ ì‚¬ìš©ë²•")

        st.markdown("""
        ì´ íƒ­ì—ì„œëŠ” SAMì˜ 3ê°€ì§€ í”„ë¡¬í”„íŠ¸ ë°©ì‹ì„ ì‹¤ìŠµí•©ë‹ˆë‹¤:
        1. **Point Prompt**: í´ë¦­ìœ¼ë¡œ ê°ì²´ ì§€ì •
        2. **Box Prompt**: ë°•ìŠ¤ë¡œ ì˜ì—­ ì§€ì •
        3. **Mask Prompt**: ê¸°ì¡´ ë§ˆìŠ¤í¬ ê°œì„ 
        """)

        # ëª¨ë¸ ì„ íƒ
        col1, col2 = st.columns([1, 2])
        with col1:
            model_type = st.selectbox(
                "SAM ëª¨ë¸ ì„ íƒ",
                ["vit_b", "vit_l", "vit_h"],
                index=0,
                help="vit_b: ë¹ ë¦„(375MB), vit_l: ê· í˜•(1.2GB), vit_h: ê³ í’ˆì§ˆ(2.4GB)"
            )

        with col2:
            st.info(f"""
            **ì„ íƒëœ ëª¨ë¸**: {model_type}
            - vit_b: ~375MB, ë¹ ë¥¸ ì¶”ë¡ 
            - vit_l: ~1.2GB, ê· í˜•ì¡íŒ ì„±ëŠ¥
            - vit_h: ~2.4GB, ìµœê³  í’ˆì§ˆ
            """)

        # SAM í—¬í¼ ë¡œë“œ
        sam = get_sam_helper(model_type)

        st.markdown(f"**í˜„ì¬ ëª¨ë“œ**: `{sam.mode}` ({sam.device if sam.device else 'simulation'})")

        # ì´ë¯¸ì§€ ì—…ë¡œë“œ
        uploaded = st.file_uploader(
            "ì´ë¯¸ì§€ ì„ íƒ",
            type=['png', 'jpg', 'jpeg'],
            key="sam_basics_upload"
        )

        if uploaded:
            image = Image.open(uploaded).convert("RGB")
            st.image(image, caption="ì›ë³¸ ì´ë¯¸ì§€", use_container_width=True)

            # í”„ë¡¬í”„íŠ¸ ë°©ì‹ ì„ íƒ
            prompt_type = st.radio(
                "í”„ë¡¬í”„íŠ¸ ë°©ì‹",
                ["Point Prompt", "Box Prompt"],
                horizontal=True
            )

            if prompt_type == "Point Prompt":
                self._demo_point_prompt(image, sam)
            else:
                self._demo_box_prompt(image, sam)

    def _demo_point_prompt(self, image: Image.Image, sam):
        """í¬ì¸íŠ¸ í”„ë¡¬í”„íŠ¸ ë°ëª¨"""
        st.subheader("ğŸ–±ï¸ Point Prompt")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ë¶„í• í•˜ê³  ì‹¶ì€ ê°ì²´ ìœ„ì— í¬ì¸íŠ¸ ì§€ì •
        2. Label: 1=foreground (í¬í•¨), 0=background (ì œì™¸)
        3. ì—¬ëŸ¬ í¬ì¸íŠ¸ë¡œ ì •í™•ë„ í–¥ìƒ
        """)

        # í¬ì¸íŠ¸ ì…ë ¥
        num_points = st.number_input("í¬ì¸íŠ¸ ê°œìˆ˜", 1, 10, 1)

        points = []
        labels = []

        cols = st.columns(3)
        for i in range(num_points):
            with cols[i % 3]:
                st.markdown(f"**Point {i+1}**")
                x = st.number_input(f"X{i+1}", 0, image.width, image.width//2, key=f"x{i}")
                y = st.number_input(f"Y{i+1}", 0, image.height, image.height//2, key=f"y{i}")
                label = st.selectbox(f"Label{i+1}", [1, 0], key=f"label{i}",
                                    help="1=foreground, 0=background")
                points.append((x, y))
                labels.append(label)

        if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰", key="point_segment"):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
                mask = sam.segment_with_points(image, points, labels)

                # ì‹œê°í™”
                self._visualize_segmentation(image, mask, points, labels)

    def _demo_box_prompt(self, image: Image.Image, sam):
        """ë°•ìŠ¤ í”„ë¡¬í”„íŠ¸ ë°ëª¨"""
        st.subheader("ğŸ“¦ Box Prompt")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ê°ì²´ë¥¼ í¬í•¨í•˜ëŠ” ë°•ìŠ¤ ì¢Œí‘œ ì…ë ¥ (x1, y1, x2, y2)
        2. ë°•ìŠ¤ ë‚´ë¶€ì˜ ì£¼ìš” ê°ì²´ë¥¼ ìë™ìœ¼ë¡œ ë¶„í• 
        """)

        col1, col2 = st.columns(2)
        with col1:
            x1 = st.number_input("X1 (ì¢Œìƒë‹¨)", 0, image.width, 0)
            y1 = st.number_input("Y1 (ì¢Œìƒë‹¨)", 0, image.height, 0)

        with col2:
            x2 = st.number_input("X2 (ìš°í•˜ë‹¨)", 0, image.width, image.width)
            y2 = st.number_input("Y2 (ìš°í•˜ë‹¨)", 0, image.height, image.height)

        box = (x1, y1, x2, y2)

        if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰", key="box_segment"):
            with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                # ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
                mask = sam.segment_with_box(image, box)

                # ì‹œê°í™”
                self._visualize_segmentation(image, mask, box=box)

    def _visualize_segmentation(
        self,
        image: Image.Image,
        mask: np.ndarray,
        points: Optional[List[Tuple[int, int]]] = None,
        labels: Optional[List[int]] = None,
        box: Optional[Tuple[int, int, int, int]] = None
    ):
        """ì„¸ê·¸ë©˜í…Œì´ì…˜ ê²°ê³¼ ì‹œê°í™”"""

        fig, axes = plt.subplots(1, 3, figsize=(15, 5))

        # 1. ì›ë³¸ + í”„ë¡¬í”„íŠ¸
        axes[0].imshow(image)
        if points:
            for (x, y), label in zip(points, labels):
                color = 'green' if label == 1 else 'red'
                axes[0].plot(x, y, marker='o', markersize=10, color=color)
        if box:
            from matplotlib.patches import Rectangle
            x1, y1, x2, y2 = box
            rect = Rectangle((x1, y1), x2-x1, y2-y1, linewidth=2,
                           edgecolor='red', facecolor='none')
            axes[0].add_patch(rect)
        axes[0].set_title("ì›ë³¸ + í”„ë¡¬í”„íŠ¸")
        axes[0].axis('off')

        # 2. ë§ˆìŠ¤í¬
        axes[1].imshow(mask, cmap='gray')
        axes[1].set_title("ìƒì„±ëœ ë§ˆìŠ¤í¬")
        axes[1].axis('off')

        # 3. ì˜¤ë²„ë ˆì´
        axes[2].imshow(image)
        axes[2].imshow(mask, alpha=0.5, cmap='jet')
        axes[2].set_title("ì˜¤ë²„ë ˆì´")
        axes[2].axis('off')

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # í†µê³„
        total_pixels = mask.size
        selected_pixels = mask.sum()
        percentage = (selected_pixels / total_pixels) * 100

        st.success(f"""
        **ì„¸ê·¸ë©˜í…Œì´ì…˜ ì™„ë£Œ**
        - ì„ íƒëœ í”½ì…€: {selected_pixels:,} / {total_pixels:,}
        - ë¹„ìœ¨: {percentage:.2f}%
        """)

    # ==================== Tab 3: Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜ ====================

    def render_interactive(self):
        """Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤ìŠµ"""
        st.header("ğŸ–±ï¸ Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜")

        st.markdown("""
        ## Interactive Annotation

        ì‹¤ì „ì—ì„œëŠ” ë°˜ë³µì ìœ¼ë¡œ í¬ì¸íŠ¸ë¥¼ ì¶”ê°€í•˜ë©° ë§ˆìŠ¤í¬ë¥¼ ê°œì„ í•©ë‹ˆë‹¤.

        ### ì›Œí¬í”Œë¡œìš°
        1. ì´ˆê¸° í¬ì¸íŠ¸ë¡œ ëŒ€ëµì ì¸ ë§ˆìŠ¤í¬ ìƒì„±
        2. ëˆ„ë½ëœ ì˜ì—­ì— foreground point ì¶”ê°€
        3. ì˜ëª» í¬í•¨ëœ ì˜ì—­ì— background point ì¶”ê°€
        4. ë§Œì¡±í•  ë•Œê¹Œì§€ ë°˜ë³µ
        """)

        model_type = st.selectbox(
            "ëª¨ë¸ ì„ íƒ",
            ["vit_b", "vit_l", "vit_h"],
            key="interactive_model"
        )
        sam = get_sam_helper(model_type)

        uploaded = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="interactive_upload"
        )

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì„¸ì…˜ ìƒíƒœë¡œ í¬ì¸íŠ¸ ê´€ë¦¬
            if 'interactive_points' not in st.session_state:
                st.session_state.interactive_points = []
                st.session_state.interactive_labels = []

            col1, col2 = st.columns([2, 1])

            with col1:
                st.image(image, caption="ì‘ì—… ì´ë¯¸ì§€", use_container_width=True)

            with col2:
                st.markdown("### í¬ì¸íŠ¸ ì¶”ê°€")

                x = st.number_input("X ì¢Œí‘œ", 0, image.width, image.width//2, key="int_x")
                y = st.number_input("Y ì¢Œí‘œ", 0, image.height, image.height//2, key="int_y")
                label = st.radio("íƒ€ì…", [1, 0], format_func=lambda x: "Foreground" if x == 1 else "Background", key="int_label")

                if st.button("â• í¬ì¸íŠ¸ ì¶”ê°€"):
                    st.session_state.interactive_points.append((x, y))
                    st.session_state.interactive_labels.append(label)
                    st.success(f"í¬ì¸íŠ¸ ì¶”ê°€ë¨ (ì´ {len(st.session_state.interactive_points)}ê°œ)")

                if st.button("ğŸ—‘ï¸ ëª¨ë‘ ì§€ìš°ê¸°"):
                    st.session_state.interactive_points = []
                    st.session_state.interactive_labels = []
                    st.rerun()

                st.markdown(f"**í˜„ì¬ í¬ì¸íŠ¸**: {len(st.session_state.interactive_points)}ê°œ")

            # ì„¸ê·¸ë©˜í…Œì´ì…˜ ì‹¤í–‰
            if st.session_state.interactive_points:
                if st.button("ğŸ¨ ì„¸ê·¸ë©˜í…Œì´ì…˜ ì—…ë°ì´íŠ¸", type="primary"):
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        mask = sam.segment_with_points(
                            image,
                            st.session_state.interactive_points,
                            st.session_state.interactive_labels
                        )

                        self._visualize_segmentation(
                            image,
                            mask,
                            st.session_state.interactive_points,
                            st.session_state.interactive_labels
                        )

                        # ë‹¤ìš´ë¡œë“œ
                        self._offer_mask_download(mask, "interactive_mask.png")

    def _offer_mask_download(self, mask: np.ndarray, filename: str):
        """ë§ˆìŠ¤í¬ ë‹¤ìš´ë¡œë“œ ì œê³µ"""
        mask_img = Image.fromarray((mask * 255).astype(np.uint8))

        buf = io.BytesIO()
        mask_img.save(buf, format='PNG')
        buf.seek(0)

        st.download_button(
            label="ğŸ’¾ ë§ˆìŠ¤í¬ ë‹¤ìš´ë¡œë“œ",
            data=buf,
            file_name=filename,
            mime="image/png"
        )

    # ==================== Tab 4: Auto Mask ìƒì„± ====================

    def render_auto_mask(self):
        """ìë™ ë§ˆìŠ¤í¬ ìƒì„±"""
        st.header("ğŸ¤– Auto Mask ìƒì„±")

        st.markdown("""
        ## Automatic Mask Generation

        í”„ë¡¬í”„íŠ¸ ì—†ì´ ì´ë¯¸ì§€ ì „ì²´ë¥¼ ìë™ìœ¼ë¡œ ì„¸ê·¸ë©˜í…Œì´ì…˜í•©ë‹ˆë‹¤.

        ### ë™ì‘ ì›ë¦¬
        1. ì´ë¯¸ì§€ì— ê·¸ë¦¬ë“œ í¬ì¸íŠ¸ ìƒ˜í”Œë§
        2. ê° í¬ì¸íŠ¸ì—ì„œ ì„¸ê·¸ë©˜í…Œì´ì…˜ ìˆ˜í–‰
        3. ì¤‘ë³µ ë§ˆìŠ¤í¬ ì œê±° (NMS)
        4. í’ˆì§ˆ í•„í„°ë§ (IoU, stability score)

        ### í™œìš© ì‚¬ë¡€
        - ë°ì´í„°ì…‹ ìë™ ë¼ë²¨ë§
        - ê°ì²´ ê°œìˆ˜ ì¹´ìš´íŒ…
        - ì „ì²´ ì¥ë©´ ë¶„ì„
        """)

        # âš ï¸ ë©”ëª¨ë¦¬ ê²½ê³ 
        st.warning("""
        âš ï¸ **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì£¼ì˜**

        ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì€ **ë§¤ìš° ë§ì€ ë©”ëª¨ë¦¬(8~12GB)**ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.

        **ê¶Œì¥ ì„¤ì •**:
        - ì´ë¯¸ì§€ í¬ê¸°: 512px ì´í•˜ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
        - Points per side: 8~16 (ë‚®ì„ìˆ˜ë¡ ë¹ ë¦„)
        - ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ë¸Œë¼ìš°ì €ê°€ ë©ˆì¶œ ìˆ˜ ìˆìŠµë‹ˆë‹¤
        """)

        model_type = st.selectbox("ëª¨ë¸", ["vit_b", "vit_l", "vit_h"], key="auto_model")
        sam = get_sam_helper(model_type)

        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="auto_upload")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì´ë¯¸ì§€ í¬ê¸° ì²´í¬
            col1, col2 = st.columns(2)
            with col1:
                st.metric("ì›ë³¸ í¬ê¸°", f"{image.width}Ã—{image.height}")
            with col2:
                resize_enabled = st.checkbox("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ê¶Œì¥)", value=True)

            if resize_enabled:
                max_size = st.slider("ìµœëŒ€ í¬ê¸°", 256, 1024, 512, step=128,
                                    help="ì´ë¯¸ì§€ë¥¼ ì´ í¬ê¸°ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (ë©”ëª¨ë¦¬ ì ˆì•½)")

                # ë¦¬ì‚¬ì´ì¦ˆ
                if max(image.width, image.height) > max_size:
                    ratio = max_size / max(image.width, image.height)
                    new_size = (int(image.width * ratio), int(image.height * ratio))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    st.info(f"âœ… ë¦¬ì‚¬ì´ì¦ˆë¨: {new_size[0]}Ã—{new_size[1]}")

            st.image(image, caption="ì²˜ë¦¬í•  ì´ë¯¸ì§€", use_container_width=True)

            # íŒŒë¼ë¯¸í„° ì„¤ì •
            with st.expander("âš™ï¸ ê³ ê¸‰ ì„¤ì •"):
                points_per_side = st.slider("Points per side", 8, 64, 16,
                                           help="ê·¸ë¦¬ë“œ ë°€ë„ (ë†’ì„ìˆ˜ë¡ ì •ë°€í•˜ì§€ë§Œ ë§¤ìš° ëŠë¦¬ê³  ë©”ëª¨ë¦¬ ë§ì´ ì‚¬ìš©)")
                pred_iou_thresh = st.slider("IoU threshold", 0.5, 1.0, 0.88,
                                            help="ë§ˆìŠ¤í¬ í’ˆì§ˆ ì„ê³„ê°’")
                stability_score_thresh = st.slider("Stability threshold", 0.5, 1.0, 0.95,
                                                  help="ë§ˆìŠ¤í¬ ì•ˆì •ì„± ì„ê³„ê°’")

            if st.button("ğŸ¤– ìë™ ë§ˆìŠ¤í¬ ìƒì„±", type="primary"):
                try:
                    with st.spinner("ìë™ ë§ˆìŠ¤í¬ ìƒì„± ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                        masks = sam.generate_auto_masks(
                            image,
                            points_per_side=points_per_side,
                            pred_iou_thresh=pred_iou_thresh,
                            stability_score_thresh=stability_score_thresh
                        )

                        st.success(f"âœ… {len(masks)}ê°œ ë§ˆìŠ¤í¬ ìƒì„± ì™„ë£Œ")

                        # ì‹œê°í™”
                        self._visualize_auto_masks(image, masks)

                except RuntimeError as e:
                    if "not enough memory" in str(e):
                        st.error("""
                        âŒ **ë©”ëª¨ë¦¬ ë¶€ì¡± ì—ëŸ¬**

                        ìë™ ë§ˆìŠ¤í¬ ìƒì„±ì— í•„ìš”í•œ ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.

                        **í•´ê²° ë°©ë²•**:
                        1. âœ… ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ í™œì„±í™” (512px ì´í•˜ ê¶Œì¥)
                        2. Points per sideë¥¼ 8~12ë¡œ ë‚®ì¶”ê¸°
                        3. ë‹¤ë¥¸ í”„ë¡œê·¸ë¨ ì¢…ë£Œ
                        4. ë” ì‘ì€ ì´ë¯¸ì§€ ì‚¬ìš©

                        ë˜ëŠ” **Interactive ì„¸ê·¸ë©˜í…Œì´ì…˜** íƒ­ì„ ì‚¬ìš©í•˜ì„¸ìš” (ë©”ëª¨ë¦¬ íš¨ìœ¨ì ).
                        """)
                    else:
                        st.error(f"ì—ëŸ¬ ë°œìƒ: {e}")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")

    def _visualize_auto_masks(self, image: Image.Image, masks: List[Dict[str, Any]]):
        """ìë™ ë§ˆìŠ¤í¬ ì‹œê°í™”"""

        if not masks:
            st.warning("ìƒì„±ëœ ë§ˆìŠ¤í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        # í†µê³„
        total_area = sum(m['area'] for m in masks)
        avg_area = total_area / len(masks)

        col1, col2, col3 = st.columns(3)
        col1.metric("ì´ ë§ˆìŠ¤í¬ ìˆ˜", len(masks))
        col2.metric("í‰ê·  ì˜ì—­", f"{avg_area:.0f}px")
        col3.metric("ì´ ì»¤ë²„ë¦¬ì§€", f"{(total_area / (image.width * image.height) * 100):.1f}%")

        # ì»¬ëŸ¬ë§µìœ¼ë¡œ ëª¨ë“  ë§ˆìŠ¤í¬ í‘œì‹œ
        fig, axes = plt.subplots(1, 2, figsize=(12, 6))

        axes[0].imshow(image)
        axes[0].set_title("ì›ë³¸ ì´ë¯¸ì§€")
        axes[0].axis('off')

        # ëª¨ë“  ë§ˆìŠ¤í¬ í•©ì„±
        combined_mask = np.zeros((*masks[0]['segmentation'].shape, 3), dtype=np.uint8)
        for i, mask_data in enumerate(masks[:50]):  # ìƒìœ„ 50ê°œë§Œ
            mask = mask_data['segmentation']
            color = np.random.randint(0, 255, 3)
            combined_mask[mask] = color

        axes[1].imshow(image)
        axes[1].imshow(combined_mask, alpha=0.5)
        axes[1].set_title(f"ìë™ ë§ˆìŠ¤í¬ ({len(masks)}ê°œ)")
        axes[1].axis('off')

        plt.tight_layout()
        st.pyplot(fig)
        plt.close()

        # ê°œë³„ ë§ˆìŠ¤í¬ ë³´ê¸°
        if st.checkbox("ê°œë³„ ë§ˆìŠ¤í¬ ë³´ê¸°"):
            mask_idx = st.slider("ë§ˆìŠ¤í¬ ì„ íƒ", 0, len(masks)-1, 0)
            selected_mask = masks[mask_idx]

            fig, ax = plt.subplots(figsize=(8, 6))
            ax.imshow(image)
            ax.imshow(selected_mask['segmentation'], alpha=0.6, cmap='jet')
            ax.set_title(f"Mask {mask_idx} (Area: {selected_mask['area']}px)")
            ax.axis('off')
            st.pyplot(fig)
            plt.close()

            # bbox ì •ë³´
            x1, y1, x2, y2 = selected_mask['bbox']
            st.info(f"BBox: ({x1}, {y1}) â†’ ({x2}, {y2})")

    # ==================== Tab 5: ì‹¤ì „ ì‘ìš© ====================

    def render_practical(self):
        """ì‹¤ì „ ì‘ìš© ì˜ˆì œ"""
        st.header("ğŸ’¼ ì‹¤ì „ ì‘ìš©")

        st.markdown("""
        ## SAM í™œìš© ì‚¬ë¡€

        ì„¸ê·¸ë©˜í…Œì´ì…˜ ê¸°ìˆ ì˜ ì‹¤ì „ ì‘ìš© ì˜ˆì œë¥¼ ì‹¤ìŠµí•©ë‹ˆë‹¤.
        """)

        app_type = st.selectbox(
            "ì‘ìš© ì˜ˆì œ ì„ íƒ",
            [
                "ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„)",
                "ìë™ ë¼ë²¨ë§ ë„êµ¬",
                "ê°ì²´ ì¹´ìš´íŒ…"
            ]
        )

        if app_type == "ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„)":
            self._app_background_removal()
        elif app_type == "ìë™ ë¼ë²¨ë§ ë„êµ¬":
            self._app_auto_labeling()
        else:
            self._app_object_counting()

    def _app_background_removal(self):
        """ë°°ê²½ ì œê±° ì•±"""
        st.subheader("ğŸ“¸ ë°°ê²½ ì œê±° (ì¦ëª…ì‚¬ì§„ í¸ì§‘ê¸°)")

        st.markdown("""
        **ì‚¬ìš©ë²•**:
        1. ì¸ë¬¼ ì‚¬ì§„ ì—…ë¡œë“œ
        2. ì¸ë¬¼ ìœ„ì— í¬ì¸íŠ¸ ì§€ì •
        3. ë°°ê²½ ì œê±° ë° ìƒˆ ë°°ê²½ ì„ íƒ
        """)

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì¸ë¬¼ ì‚¬ì§„", type=['png', 'jpg', 'jpeg'], key="bg_remove")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="ì›ë³¸", use_container_width=True)

            with col2:
                # í¬ì¸íŠ¸ ì…ë ¥
                x = st.number_input("X (ì¸ë¬¼)", 0, image.width, image.width//2)
                y = st.number_input("Y (ì¸ë¬¼)", 0, image.height, image.height//2)

                # ìƒˆ ë°°ê²½ ìƒ‰ìƒ
                bg_color = st.color_picker("ìƒˆ ë°°ê²½ ìƒ‰ìƒ", "#FFFFFF")

            if st.button("ğŸ¨ ë°°ê²½ ì œê±°", type="primary"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    # ì„¸ê·¸ë©˜í…Œì´ì…˜
                    mask = sam.segment_with_points(image, [(x, y)], [1])

                    # ë°°ê²½ êµì²´
                    result_image = self._replace_background(image, mask, bg_color)

                    st.image(result_image, caption="ê²°ê³¼", use_container_width=True)

                    # ë‹¤ìš´ë¡œë“œ
                    buf = io.BytesIO()
                    result_image.save(buf, format='PNG')
                    buf.seek(0)

                    st.download_button(
                        "ğŸ’¾ ë‹¤ìš´ë¡œë“œ",
                        data=buf,
                        file_name="background_removed.png",
                        mime="image/png"
                    )

    def _replace_background(
        self,
        image: Image.Image,
        mask: np.ndarray,
        bg_color: str
    ) -> Image.Image:
        """ë°°ê²½ êµì²´"""
        # RGB ë³€í™˜
        r = int(bg_color[1:3], 16)
        g = int(bg_color[3:5], 16)
        b = int(bg_color[5:7], 16)

        # ìƒˆ ë°°ê²½ ìƒì„±
        bg = Image.new("RGB", image.size, (r, g, b))

        # ë§ˆìŠ¤í¬ë¥¼ PIL ì´ë¯¸ì§€ë¡œ
        mask_img = Image.fromarray((mask * 255).astype(np.uint8))

        # í•©ì„±
        result = Image.composite(image, bg, mask_img)
        return result

    def _app_auto_labeling(self):
        """ìë™ ë¼ë²¨ë§ ë„êµ¬"""
        st.subheader("ğŸ·ï¸ ìë™ ë¼ë²¨ë§ ë„êµ¬")

        st.markdown("""
        **ëª©ì **: ê°ì²´ íƒì§€ í•™ìŠµ ë°ì´í„° ìƒì„± ìë™í™”

        **ì›Œí¬í”Œë¡œìš°**:
        1. ì´ë¯¸ì§€ ì—…ë¡œë“œ
        2. ìë™ ë§ˆìŠ¤í¬ ìƒì„±
        3. ê° ë§ˆìŠ¤í¬ì— í´ë˜ìŠ¤ ë ˆì´ë¸” í• ë‹¹
        4. COCO/YOLO í¬ë§·ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸°
        """)

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="label_img")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")
            st.image(image, use_container_width=True)

            if st.button("ğŸ¤– ìë™ ë§ˆìŠ¤í¬ ìƒì„±"):
                with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                    masks = sam.generate_auto_masks(image, points_per_side=16)
                    st.session_state.labeling_masks = masks
                    st.success(f"âœ… {len(masks)}ê°œ í›„ë³´ ìƒì„±")

            if 'labeling_masks' in st.session_state:
                masks = st.session_state.labeling_masks

                st.markdown("### ë ˆì´ë¸” í• ë‹¹")

                # í´ë˜ìŠ¤ ì •ì˜
                class_names = st.text_input("í´ë˜ìŠ¤ (ì‰¼í‘œ êµ¬ë¶„)", "person,car,dog,cat")
                classes = [c.strip() for c in class_names.split(",")]

                # ë§ˆìŠ¤í¬ë³„ ë ˆì´ë¸”
                for i, mask_data in enumerate(masks[:10]):  # ìƒìœ„ 10ê°œ
                    col1, col2, col3 = st.columns([2, 1, 1])

                    with col1:
                        # ë¯¸ë¦¬ë³´ê¸°
                        fig, ax = plt.subplots(figsize=(4, 3))
                        ax.imshow(image)
                        ax.imshow(mask_data['segmentation'], alpha=0.5)
                        ax.set_title(f"Mask {i}")
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close()

                    with col2:
                        label = st.selectbox(f"Class", ["(skip)"] + classes, key=f"class_{i}")

                    with col3:
                        st.metric("Area", f"{mask_data['area']}px")

                st.info("ğŸ’¡ ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„œëŠ” ì—¬ê¸°ì„œ JSON/XML íŒŒì¼ë¡œ ë‚´ë³´ë‚´ê¸° êµ¬í˜„")

    def _app_object_counting(self):
        """ê°ì²´ ì¹´ìš´íŒ…"""
        st.subheader("ğŸ”¢ ê°ì²´ ì¹´ìš´íŒ…")

        st.markdown("""
        **ì‘ìš© ë¶„ì•¼**:
        - êµ°ì¤‘ ê³„ìˆ˜ (crowd counting)
        - ì„¸í¬ ì¹´ìš´íŒ… (medical imaging)
        - ì¬ê³  ê´€ë¦¬ (inventory counting)
        """)

        st.warning("âš ï¸ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.")

        sam = get_sam_helper("vit_b")
        uploaded = st.file_uploader("ì´ë¯¸ì§€", type=['png', 'jpg', 'jpeg'], key="count_img")

        if uploaded:
            image = Image.open(uploaded).convert("RGB")

            # ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ
            resize = st.checkbox("ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ", value=True, key="count_resize")
            if resize:
                max_size = st.slider("ìµœëŒ€ í¬ê¸°", 256, 1024, 512, step=128, key="count_max")
                if max(image.width, image.height) > max_size:
                    ratio = max_size / max(image.width, image.height)
                    new_size = (int(image.width * ratio), int(image.height * ratio))
                    image = image.resize(new_size, Image.Resampling.LANCZOS)
                    st.info(f"âœ… ë¦¬ì‚¬ì´ì¦ˆ: {new_size[0]}Ã—{new_size[1]}")

            st.image(image, use_container_width=True)

            # í•„í„°ë§ íŒŒë¼ë¯¸í„°
            min_area = st.slider("ìµœì†Œ ê°ì²´ í¬ê¸° (pxÂ²)", 100, 5000, 500)
            max_area = st.slider("ìµœëŒ€ ê°ì²´ í¬ê¸° (pxÂ²)", 1000, 50000, 10000)

            if st.button("ğŸ”¢ ê°ì²´ ì¹´ìš´íŒ…", type="primary"):
                try:
                    with st.spinner("ì²˜ë¦¬ ì¤‘..."):
                        masks = sam.generate_auto_masks(image, points_per_side=16)

                        # í•„í„°ë§
                        filtered = [
                            m for m in masks
                            if min_area <= m['area'] <= max_area
                        ]

                        st.success(f"âœ… ê²€ì¶œëœ ê°ì²´: **{len(filtered)}ê°œ**")

                        # ì‹œê°í™”
                        fig, ax = plt.subplots(figsize=(10, 8))
                        ax.imshow(image)

                        for i, mask_data in enumerate(filtered):
                            mask = mask_data['segmentation']
                            color = np.random.rand(3)

                            # ë§ˆìŠ¤í¬ ì˜¤ë²„ë ˆì´
                            colored_mask = np.zeros((*mask.shape, 3))
                            colored_mask[mask] = color
                            ax.imshow(colored_mask, alpha=0.4)

                            # ë²ˆí˜¸ í‘œì‹œ
                            x1, y1, x2, y2 = mask_data['bbox']
                            cx, cy = (x1 + x2) // 2, (y1 + y2) // 2
                            ax.text(cx, cy, str(i+1), color='white',
                                   fontsize=12, weight='bold',
                                   ha='center', va='center',
                                   bbox=dict(boxstyle='circle', facecolor='red', alpha=0.8))

                        ax.set_title(f"ì´ {len(filtered)}ê°œ ê°ì²´ ê²€ì¶œ")
                        ax.axis('off')
                        st.pyplot(fig)
                        plt.close()

                        # í†µê³„
                        if filtered:
                            areas = [m['area'] for m in filtered]
                            st.markdown(f"""
                            ### í†µê³„
                            - í‰ê·  í¬ê¸°: {np.mean(areas):.0f}pxÂ²
                            - ìµœì†Œ í¬ê¸°: {np.min(areas)}pxÂ²
                            - ìµœëŒ€ í¬ê¸°: {np.max(areas)}pxÂ²
                            """)

                except RuntimeError as e:
                    if "not enough memory" in str(e):
                        st.error("âŒ ë©”ëª¨ë¦¬ ë¶€ì¡±! ì´ë¯¸ì§€ë¥¼ ë” ì‘ê²Œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê±°ë‚˜ Interactive íƒ­ì„ ì‚¬ìš©í•˜ì„¸ìš”.")
                    else:
                        st.error(f"ì—ëŸ¬: {e}")
                except Exception as e:
                    st.error(f"ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
