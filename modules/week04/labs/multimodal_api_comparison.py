#!/usr/bin/env python3
"""
Week 4 Lab: ë©€í‹°ëª¨ë‹¬ API ë¹„êµ ë° ìµœì  ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ
Gemini vs GPT-4V vs Llama Vision ì„±ëŠ¥ ë¹„êµ ë° ì‹¤ì œ í…ŒìŠ¤íŠ¸

ì´ ì‹¤ìŠµì—ì„œëŠ”:
1. ì£¼ìš” ë©€í‹°ëª¨ë‹¬ API ì„±ëŠ¥ ë¹„êµ
2. ì‹¤ì œ API í˜¸ì¶œ ë° ì‘ë‹µ ë¶„ì„
3. íƒœìŠ¤í¬ë³„ ìµœì  ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ
4. ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„
"""

import asyncio
import aiohttp
import time
import json
import base64
import io
import os
from typing import Dict, List, Optional
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
from PIL import Image, ImageDraw, ImageFont
import requests
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

class MultimodalAPITester:
    """
    ë©€í‹°ëª¨ë‹¬ API í…ŒìŠ¤íŠ¸ ë° ë¹„êµ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """API í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.api_configs = {
            "gemini": {
                "name": "Google Gemini Vision",
                "endpoint": "https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent",
                "api_key_env": "GEMINI_API_KEY",
                "free_tier": "ë§¤ìš° ê´€ëŒ€í•¨",
                "rate_limit": "60 RPM",
                "max_image_size": "20MB",
                "supported_formats": ["JPEG", "PNG", "WebP", "HEIC", "HEIF"]
            },
            "gpt4v": {
                "name": "OpenAI GPT-4V",
                "endpoint": "https://api.openai.com/v1/chat/completions",
                "api_key_env": "OPENAI_API_KEY", 
                "free_tier": "ì œí•œì ",
                "rate_limit": "100 RPM",
                "max_image_size": "20MB",
                "supported_formats": ["JPEG", "PNG", "GIF", "WebP"]
            },
            "llama_vision": {
                "name": "Together AI Llama Vision",
                "endpoint": "https://api.together.xyz/inference",
                "api_key_env": "TOGETHER_API_KEY",
                "free_tier": "3ê°œì›” ë¬´ë£Œ",
                "rate_limit": "50 RPM",
                "max_image_size": "10MB",
                "supported_formats": ["JPEG", "PNG"]
            },
            "claude_vision": {
                "name": "Anthropic Claude Vision",
                "endpoint": "https://api.anthropic.com/v1/messages",
                "api_key_env": "ANTHROPIC_API_KEY",
                "free_tier": "ì œí•œì ",
                "rate_limit": "50 RPM",
                "max_image_size": "5MB",
                "supported_formats": ["JPEG", "PNG", "GIF", "WebP"]
            }
        }
        
        self.test_results = []
        self.load_api_keys()
    
    def load_api_keys(self):
        """í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ë¡œë“œ"""
        self.api_keys = {}
        
        for api_id, config in self.api_configs.items():
            key = os.getenv(config["api_key_env"])
            if key:
                self.api_keys[api_id] = key
                print(f"âœ… {config['name']} API í‚¤ ë¡œë“œë¨")
            else:
                print(f"âš ï¸ {config['name']} API í‚¤ ì—†ìŒ (í™˜ê²½ë³€ìˆ˜: {config['api_key_env']})")
    
    def encode_image_base64(self, image_path_or_pil):
        """ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©"""
        if isinstance(image_path_or_pil, str):
            with open(image_path_or_pil, "rb") as image_file:
                return base64.b64encode(image_file.read()).decode('utf-8')
        elif isinstance(image_path_or_pil, Image.Image):
            buffer = io.BytesIO()
            image_path_or_pil.save(buffer, format='JPEG')
            return base64.b64encode(buffer.getvalue()).decode('utf-8')
        else:
            raise ValueError("ì´ë¯¸ì§€ëŠ” íŒŒì¼ ê²½ë¡œ ë˜ëŠ” PIL Image ê°ì²´ì—¬ì•¼ í•©ë‹ˆë‹¤.")
    
    async def call_gemini_api(self, image, prompt):
        """Gemini API í˜¸ì¶œ"""
        if "gemini" not in self.api_keys:
            return {"error": "API í‚¤ ì—†ìŒ", "response_time": 0}
        
        try:
            image_base64 = self.encode_image_base64(image)
            
            payload = {
                "contents": [{
                    "parts": [
                        {"text": prompt},
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": image_base64
                            }
                        }
                    ]
                }]
            }
            
            headers = {
                "Content-Type": "application/json"
            }
            
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                url = f"{self.api_configs['gemini']['endpoint']}?key={self.api_keys['gemini']}"
                async with session.post(url, json=payload, headers=headers) as response:
                    end_time = time.time()
                    response_time = (end_time - start_time) * 1000
                    
                    if response.status == 200:
                        result = await response.json()
                        text_response = result.get("candidates", [{}])[0].get("content", {}).get("parts", [{}])[0].get("text", "")
                        return {
                            "response": text_response,
                            "response_time": response_time,
                            "success": True,
                            "tokens_used": len(text_response.split())
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": response_time,
                            "success": False
                        }
        
        except Exception as e:
            return {"error": str(e), "response_time": 0, "success": False}
    
    async def call_gpt4v_api(self, image, prompt):
        """GPT-4V API í˜¸ì¶œ"""
        if "gpt4v" not in self.api_keys:
            return {"error": "API í‚¤ ì—†ìŒ", "response_time": 0}
        
        try:
            image_base64 = self.encode_image_base64(image)
            
            payload = {
                "model": "gpt-4-vision-preview",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 300
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_keys['gpt4v']}"
            }
            
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                async with session.post(self.api_configs['gpt4v']['endpoint'], 
                                      json=payload, headers=headers) as response:
                    end_time = time.time()
                    response_time = (end_time - start_time) * 1000
                    
                    if response.status == 200:
                        result = await response.json()
                        text_response = result["choices"][0]["message"]["content"]
                        return {
                            "response": text_response,
                            "response_time": response_time,
                            "success": True,
                            "tokens_used": result.get("usage", {}).get("total_tokens", 0)
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": response_time,
                            "success": False
                        }
        
        except Exception as e:
            return {"error": str(e), "response_time": 0, "success": False}
    
    async def call_llama_vision_api(self, image, prompt):
        """Llama Vision API í˜¸ì¶œ"""
        if "llama_vision" not in self.api_keys:
            return {"error": "API í‚¤ ì—†ìŒ", "response_time": 0}
        
        try:
            image_base64 = self.encode_image_base64(image)
            
            payload = {
                "model": "meta-llama/Llama-3.2-11B-Vision-Instruct-Turbo",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 300
            }
            
            headers = {
                "Content-Type": "application/json",
                "Authorization": f"Bearer {self.api_keys['llama_vision']}"
            }
            
            start_time = time.time()
            
            async with aiohttp.ClientSession() as session:
                async with session.post(self.api_configs['llama_vision']['endpoint'], 
                                      json=payload, headers=headers) as response:
                    end_time = time.time()
                    response_time = (end_time - start_time) * 1000
                    
                    if response.status == 200:
                        result = await response.json()
                        text_response = result["choices"][0]["message"]["content"]
                        return {
                            "response": text_response,
                            "response_time": response_time,
                            "success": True,
                            "tokens_used": len(text_response.split())
                        }
                    else:
                        error_text = await response.text()
                        return {
                            "error": f"HTTP {response.status}: {error_text}",
                            "response_time": response_time,
                            "success": False
                        }
        
        except Exception as e:
            return {"error": str(e), "response_time": 0, "success": False}
    
    async def test_single_api(self, api_name, image, prompt):
        """ë‹¨ì¼ API í…ŒìŠ¤íŠ¸"""
        print(f"ğŸ”„ {self.api_configs[api_name]['name']} í…ŒìŠ¤íŠ¸ ì¤‘...")
        
        if api_name == "gemini":
            result = await self.call_gemini_api(image, prompt)
        elif api_name == "gpt4v":
            result = await self.call_gpt4v_api(image, prompt)
        elif api_name == "llama_vision":
            result = await self.call_llama_vision_api(image, prompt)
        else:
            result = {"error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” API", "response_time": 0, "success": False}
        
        result["api"] = api_name
        result["api_name"] = self.api_configs[api_name]["name"]
        result["timestamp"] = datetime.now().isoformat()
        
        if result.get("success", False):
            print(f"âœ… {self.api_configs[api_name]['name']}: {result['response_time']:.0f}ms")
        else:
            print(f"âŒ {self.api_configs[api_name]['name']}: {result.get('error', 'Unknown error')}")
        
        return result
    
    async def run_comprehensive_test(self, test_images, prompts):
        """ì¢…í•© API í…ŒìŠ¤íŠ¸"""
        print("ğŸš€ ë©€í‹°ëª¨ë‹¬ API ì¢…í•© í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("=" * 60)
        
        all_results = []
        
        for i, (image, image_name) in enumerate(test_images):
            print(f"\nğŸ“¸ ì´ë¯¸ì§€ {i+1}/{len(test_images)}: {image_name}")
            print("-" * 40)
            
            for j, prompt in enumerate(prompts):
                print(f"\nğŸ’¬ í”„ë¡¬í”„íŠ¸ {j+1}: {prompt[:50]}...")
                
                # ëª¨ë“  APIì— ëŒ€í•´ ë³‘ë ¬ í…ŒìŠ¤íŠ¸
                tasks = []
                for api_name in self.api_keys.keys():
                    task = self.test_single_api(api_name, image, prompt)
                    tasks.append(task)
                
                if tasks:
                    results = await asyncio.gather(*tasks, return_exceptions=True)
                    
                    for result in results:
                        if isinstance(result, dict):
                            result["image_name"] = image_name
                            result["prompt"] = prompt
                            all_results.append(result)
                
                # API í˜¸ì¶œ ê°„ê²© (Rate Limit ê³ ë ¤)
                await asyncio.sleep(1)
        
        self.test_results = all_results
        return all_results
    
    def analyze_results(self):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„"""
        if not self.test_results:
            print("âŒ ë¶„ì„í•  ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¶„ì„")
        print("=" * 60)
        
        # ì„±ê³µí•œ ê²°ê³¼ë§Œ í•„í„°ë§
        successful_results = [r for r in self.test_results if r.get("success", False)]
        
        if not successful_results:
            print("âŒ ì„±ê³µí•œ API í˜¸ì¶œì´ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # DataFrame ìƒì„±
        df = pd.DataFrame(successful_results)
        
        # APIë³„ í†µê³„
        api_stats = df.groupby('api_name').agg({
            'response_time': ['mean', 'std', 'min', 'max'],
            'tokens_used': ['mean', 'sum'],
            'success': 'count'
        }).round(2)
        
        print("\nğŸ“ˆ APIë³„ ì„±ëŠ¥ í†µê³„")
        print(api_stats)
        
        # ì‹œê°í™”
        self.visualize_results(df)
        
        return api_stats
    
    def visualize_results(self, df):
        """ê²°ê³¼ ì‹œê°í™”"""
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ì‘ë‹µ ì‹œê°„ ë¹„êµ
        sns.boxplot(data=df, x='api_name', y='response_time', ax=axes[0, 0])
        axes[0, 0].set_title('APIë³„ ì‘ë‹µ ì‹œê°„ ë¶„í¬')
        axes[0, 0].set_ylabel('ì‘ë‹µ ì‹œê°„ (ms)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        # 2. í‰ê·  ì‘ë‹µ ì‹œê°„
        avg_times = df.groupby('api_name')['response_time'].mean()
        bars = axes[0, 1].bar(avg_times.index, avg_times.values, alpha=0.7)
        axes[0, 1].set_title('í‰ê·  ì‘ë‹µ ì‹œê°„')
        axes[0, 1].set_ylabel('ì‘ë‹µ ì‹œê°„ (ms)')
        axes[0, 1].tick_params(axis='x', rotation=45)
        
        for bar, val in zip(bars, avg_times.values):
            axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,
                           f'{val:.0f}ms', ha='center', va='bottom')
        
        # 3. í† í° ì‚¬ìš©ëŸ‰
        if 'tokens_used' in df.columns:
            avg_tokens = df.groupby('api_name')['tokens_used'].mean()
            bars = axes[0, 2].bar(avg_tokens.index, avg_tokens.values, alpha=0.7, color='lightcoral')
            axes[0, 2].set_title('í‰ê·  í† í° ì‚¬ìš©ëŸ‰')
            axes[0, 2].set_ylabel('í† í° ìˆ˜')
            axes[0, 2].tick_params(axis='x', rotation=45)
        
        # 4. ì„±ê³µë¥ 
        success_rate = df.groupby('api_name').size()
        total_attempts = len(df['api_name'].unique()) * len(df) // len(df['api_name'].unique())
        success_rates = (success_rate / total_attempts * 100) if total_attempts > 0 else success_rate
        
        bars = axes[1, 0].bar(success_rates.index, success_rates.values, alpha=0.7, color='lightgreen')
        axes[1, 0].set_title('ì„±ê³µë¥ ')
        axes[1, 0].set_ylabel('ì„±ê³µë¥  (%)')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        # 5. ì‘ë‹µ ê¸¸ì´ ë¶„í¬
        df['response_length'] = df['response'].str.len()
        sns.boxplot(data=df, x='api_name', y='response_length', ax=axes[1, 1])
        axes[1, 1].set_title('ì‘ë‹µ ê¸¸ì´ ë¶„í¬')
        axes[1, 1].set_ylabel('ë¬¸ì ìˆ˜')
        axes[1, 1].tick_params(axis='x', rotation=45)
        
        # 6. ì¢…í•© ì ìˆ˜ (ì‘ë‹µì‹œê°„ ì—­ìˆ˜ + ì‘ë‹µí’ˆì§ˆ ê°€ì¤‘ì¹˜)
        # ê°„ë‹¨í•œ ì ìˆ˜ ê³„ì‚°: (1000/ì‘ë‹µì‹œê°„) + (ì‘ë‹µê¸¸ì´/100)
        df['composite_score'] = (1000 / df['response_time']) + (df['response_length'] / 100)
        avg_scores = df.groupby('api_name')['composite_score'].mean()
        
        bars = axes[1, 2].bar(avg_scores.index, avg_scores.values, alpha=0.7, color='gold')
        axes[1, 2].set_title('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜')
        axes[1, 2].set_ylabel('ì ìˆ˜')
        axes[1, 2].tick_params(axis='x', rotation=45)
        
        plt.tight_layout()
        plt.show()
    
    def generate_selection_guide(self):
        """ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ ìƒì„±"""
        print("\nğŸ¯ ë©€í‹°ëª¨ë‹¬ API ì„ íƒ ê°€ì´ë“œ")
        print("=" * 60)
        
        guide = {
            "ë¹„ìš© ìµœìš°ì„ ": {
                "ì¶”ì²œ": "Google Gemini Vision",
                "ì´ìœ ": "ì™„ì „ ë¬´ë£Œ, ê´€ëŒ€í•œ í• ë‹¹ëŸ‰",
                "ì í•©í•œ ìš©ë„": "í”„ë¡œí† íƒ€ì…, ê°œì¸ í”„ë¡œì íŠ¸, êµìœ¡ìš©"
            },
            "ì •í™•ë„ ìµœìš°ì„ ": {
                "ì¶”ì²œ": "GPT-4V ë˜ëŠ” Gemini Vision",
                "ì´ìœ ": "ë†’ì€ ì´í•´ë ¥ê³¼ ì •í™•í•œ ë¶„ì„",
                "ì í•©í•œ ìš©ë„": "ìƒì—…ìš© ì„œë¹„ìŠ¤, ì¤‘ìš”í•œ ë¶„ì„ ì‘ì—…"
            },
            "ì†ë„ ìµœìš°ì„ ": {
                "ì¶”ì²œ": "Gemini Vision",
                "ì´ìœ ": "ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„",
                "ì í•©í•œ ìš©ë„": "ì‹¤ì‹œê°„ ì• í”Œë¦¬ì¼€ì´ì…˜, ëŒ€í™”í˜• ì„œë¹„ìŠ¤"
            },
            "ì»¤ìŠ¤í„°ë§ˆì´ì§•": {
                "ì¶”ì²œ": "Llama Vision",
                "ì´ìœ ": "ì˜¤í”ˆì†ŒìŠ¤, ë¡œì»¬ ì‹¤í–‰ ê°€ëŠ¥",
                "ì í•©í•œ ìš©ë„": "íŠ¹ìˆ˜ ë„ë©”ì¸, í”„ë¼ì´ë²„ì‹œ ì¤‘ìš” ì„œë¹„ìŠ¤"
            },
            "ì•ˆì „ì„±/ìœ¤ë¦¬": {
                "ì¶”ì²œ": "Claude Vision",
                "ì´ìœ ": "ê°•í™”ëœ ì•ˆì „ì„± í•„í„°",
                "ì í•©í•œ ìš©ë„": "êµìœ¡, ì˜ë£Œ, ë²•ë¥  ë¶„ì•¼"
            }
        }
        
        for category, info in guide.items():
            print(f"\nğŸ”¹ {category}")
            print(f"   ì¶”ì²œ: {info['ì¶”ì²œ']}")
            print(f"   ì´ìœ : {info['ì´ìœ ']}")
            print(f"   ì í•©í•œ ìš©ë„: {info['ì í•©í•œ ìš©ë„']}")
        
        # íƒœìŠ¤í¬ë³„ ì¶”ì²œ
        print(f"\nğŸ“‹ íƒœìŠ¤í¬ë³„ ì¶”ì²œ")
        print("-" * 30)
        
        task_recommendations = {
            "ì´ë¯¸ì§€ ìº¡ì…˜ ìƒì„±": "Gemini Vision (ë¬´ë£Œ, ê³ í’ˆì§ˆ)",
            "OCR/í…ìŠ¤íŠ¸ ì¶”ì¶œ": "GPT-4V (ì •í™•ë„ ë†’ìŒ)",
            "ê°ì²´ ì¸ì‹": "Gemini Vision (ë¹ ë¥´ê³  ì •í™•)",
            "ì˜ë£Œ ì´ë¯¸ì§€ ë¶„ì„": "Claude Vision (ì•ˆì „ì„±)",
            "ì°½ì‘/ìŠ¤í† ë¦¬í…”ë§": "GPT-4V (ì°½ì˜ì„±)",
            "ì‹¤ì‹œê°„ ë¶„ì„": "Gemini Vision (ì†ë„)",
            "ë°°ì¹˜ ì²˜ë¦¬": "Llama Vision (ë¹„ìš© íš¨ìœ¨)",
            "í”„ë¼ì´ë²„ì‹œ ì¤‘ìš”": "Llama Vision (ë¡œì»¬ ì‹¤í–‰)"
        }
        
        for task, recommendation in task_recommendations.items():
            print(f"â€¢ {task}: {recommendation}")

def create_test_images():
    """í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ ìƒì„±"""
    test_images = []
    
    # 1. í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ì´ë¯¸ì§€ (OCR í…ŒìŠ¤íŠ¸ìš©)
    img1 = Image.new('RGB', (400, 200), color='white')
    draw = ImageDraw.Draw(img1)
    try:
        font = ImageFont.truetype("arial.ttf", 24)
    except:
        font = ImageFont.load_default()
    
    draw.text((50, 50), "Hello World!", fill='black', font=font)
    draw.text((50, 100), "API Test 2024", fill='blue', font=font)
    test_images.append((img1, "í…ìŠ¤íŠ¸_ì´ë¯¸ì§€"))
    
    # 2. ê¸°í•˜í•™ì  ë„í˜• (ê°ì²´ ì¸ì‹ í…ŒìŠ¤íŠ¸ìš©)
    img2 = Image.new('RGB', (400, 400), color='lightgray')
    draw = ImageDraw.Draw(img2)
    draw.ellipse([50, 50, 150, 150], fill='red')
    draw.rectangle([200, 50, 350, 200], fill='blue')
    draw.polygon([(100, 250), (200, 200), (300, 300)], fill='green')
    test_images.append((img2, "ê¸°í•˜í•™ì _ë„í˜•"))
    
    # 3. ë³µì¡í•œ ì¥ë©´ (ì¢…í•© ë¶„ì„ í…ŒìŠ¤íŠ¸ìš©)
    img3 = Image.new('RGB', (400, 400), color='skyblue')
    draw = ImageDraw.Draw(img3)
    
    # ì§‘ ê·¸ë¦¬ê¸°
    draw.rectangle([150, 200, 250, 300], fill='brown')  # ì§‘ ëª¸ì²´
    draw.polygon([(130, 200), (200, 150), (270, 200)], fill='red')  # ì§€ë¶•
    draw.rectangle([170, 240, 190, 300], fill='yellow')  # ë¬¸
    draw.rectangle([210, 220, 230, 250], fill='lightblue')  # ì°½ë¬¸
    
    # ë‚˜ë¬´ ê·¸ë¦¬ê¸°
    draw.rectangle([80, 250, 100, 350], fill='brown')  # ë‚˜ë¬´ ì¤„ê¸°
    draw.ellipse([60, 200, 120, 260], fill='green')  # ë‚˜ë¬´ ì
    
    # íƒœì–‘ ê·¸ë¦¬ê¸°
    draw.ellipse([320, 50, 370, 100], fill='yellow')
    
    test_images.append((img3, "ë³µí•©_ì¥ë©´"))
    
    return test_images

def simulate_api_responses():
    """API ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ (ì‹¤ì œ API í‚¤ê°€ ì—†ì„ ë•Œ)"""
    print("ğŸ­ API ì‘ë‹µ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œ")
    print("=" * 50)
    
    # ì‹œë®¬ë ˆì´ì…˜ ë°ì´í„°
    simulation_data = {
        "Google Gemini Vision": {
            "response_times": np.random.normal(1200, 200, 10),
            "accuracy_score": 0.95,
            "sample_responses": [
                "ì´ ì´ë¯¸ì§€ëŠ” 'Hello World!'ì™€ 'API Test 2024'ë¼ëŠ” í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ í°ìƒ‰ ë°°ê²½ì˜ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.",
                "ë¹¨ê°„ìƒ‰ ì›, íŒŒë€ìƒ‰ ì‚¬ê°í˜•, ë…¹ìƒ‰ ì‚¼ê°í˜•ì´ ìˆëŠ” ê¸°í•˜í•™ì  ë„í˜•ë“¤ì˜ ì´ë¯¸ì§€ì…ë‹ˆë‹¤.",
                "ì§‘, ë‚˜ë¬´, íƒœì–‘ì´ ìˆëŠ” ê°„ë‹¨í•œ í’ê²½í™”ì…ë‹ˆë‹¤. íŒŒë€ í•˜ëŠ˜ ë°°ê²½ì— ë¹¨ê°„ ì§€ë¶•ì˜ ì§‘ê³¼ ë…¹ìƒ‰ ë‚˜ë¬´ê°€ ë³´ì…ë‹ˆë‹¤."
            ]
        },
        "OpenAI GPT-4V": {
            "response_times": np.random.normal(2100, 300, 10),
            "accuracy_score": 0.92,
            "sample_responses": [
                "The image contains text reading 'Hello World!' and 'API Test 2024' on a white background. The text appears to be in a standard font.",
                "This image shows geometric shapes: a red circle in the upper left, a blue rectangle in the upper right, and a green triangle at the bottom.",
                "A simple drawing depicting a house with a red roof, a tree, and a sun. The scene has a childlike, cartoon-style appearance with basic shapes and bright colors."
            ]
        },
        "Together AI Llama Vision": {
            "response_times": np.random.normal(1800, 250, 10),
            "accuracy_score": 0.88,
            "sample_responses": [
                "I can see text in this image that says 'Hello World!' and 'API Test 2024' written on what appears to be a white background.",
                "The image contains several geometric shapes including a red circular shape, a blue rectangular shape, and a green triangular shape arranged on a gray background.",
                "This appears to be a simple illustration of a house scene with a brown house that has a red roof, a green tree, and a yellow sun in a blue sky."
            ]
        }
    }
    
    # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼ ì‹œê°í™”
    fig, axes = plt.subplots(2, 2, figsize=(15, 12))
    
    # ì‘ë‹µ ì‹œê°„ ë¹„êµ
    apis = list(simulation_data.keys())
    avg_times = [np.mean(data['response_times']) for data in simulation_data.values()]
    std_times = [np.std(data['response_times']) for data in simulation_data.values()]
    
    bars1 = axes[0, 0].bar(apis, avg_times, yerr=std_times, capsize=5, alpha=0.7)
    axes[0, 0].set_title('í‰ê·  ì‘ë‹µ ì‹œê°„ (ì‹œë®¬ë ˆì´ì…˜)')
    axes[0, 0].set_ylabel('ì‹œê°„ (ms)')
    axes[0, 0].tick_params(axis='x', rotation=45)
    
    for bar, time_val in zip(bars1, avg_times):
        axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 50,
                       f'{time_val:.0f}ms', ha='center', va='bottom')
    
    # ì •í™•ë„ ì ìˆ˜
    accuracy_scores = [data['accuracy_score'] for data in simulation_data.values()]
    bars2 = axes[0, 1].bar(apis, accuracy_scores, alpha=0.7, color='lightcoral')
    axes[0, 1].set_title('ì •í™•ë„ ì ìˆ˜ (ì‹œë®¬ë ˆì´ì…˜)')
    axes[0, 1].set_ylabel('ì •í™•ë„')
    axes[0, 1].set_ylim(0.8, 1.0)
    axes[0, 1].tick_params(axis='x', rotation=45)
    
    for bar, acc_val in zip(bars2, accuracy_scores):
        axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                       f'{acc_val:.2f}', ha='center', va='bottom')
    
    # ì‘ë‹µ ê¸¸ì´ ë¶„í¬
    response_lengths = []
    api_labels = []
    for api, data in simulation_data.items():
        for response in data['sample_responses']:
            response_lengths.append(len(response))
            api_labels.append(api)
    
    df_sim = pd.DataFrame({'API': api_labels, 'Response_Length': response_lengths})
    sns.boxplot(data=df_sim, x='API', y='Response_Length', ax=axes[1, 0])
    axes[1, 0].set_title('ì‘ë‹µ ê¸¸ì´ ë¶„í¬')
    axes[1, 0].set_ylabel('ë¬¸ì ìˆ˜')
    axes[1, 0].tick_params(axis='x', rotation=45)
    
    # ì¢…í•© ì„±ëŠ¥ ì ìˆ˜
    composite_scores = []
    for api, data in simulation_data.items():
        time_score = 1000 / np.mean(data['response_times'])  # ì†ë„ ì ìˆ˜
        acc_score = data['accuracy_score'] * 10  # ì •í™•ë„ ì ìˆ˜
        composite = time_score + acc_score
        composite_scores.append(composite)
    
    bars4 = axes[1, 1].bar(apis, composite_scores, alpha=0.7, color='gold')
    axes[1, 1].set_title('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜')
    axes[1, 1].set_ylabel('ì ìˆ˜')
    axes[1, 1].tick_params(axis='x', rotation=45)
    
    for bar, score_val in zip(bars4, composite_scores):
        axes[1, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                       f'{score_val:.1f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.show()
    
    # ìƒ˜í”Œ ì‘ë‹µ ì¶œë ¥
    print("\nğŸ“ ìƒ˜í”Œ ì‘ë‹µ ë¹„êµ")
    print("=" * 60)
    
    test_prompts = [
        "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” í…ìŠ¤íŠ¸ë¥¼ ì½ì–´ì£¼ì„¸ìš”.",
        "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë„í˜•ë“¤ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì´ ì´ë¯¸ì§€ì˜ ì¥ë©´ì„ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”."
    ]
    
    for i, prompt in enumerate(test_prompts):
        print(f"\nğŸ”¸ í”„ë¡¬í”„íŠ¸: {prompt}")
        print("-" * 40)
        
        for api, data in simulation_data.items():
            print(f"\n{api}:")
            print(f"ì‘ë‹µ: {data['sample_responses'][i]}")
            print(f"ì˜ˆìƒ ì‘ë‹µì‹œê°„: {np.mean(data['response_times']):.0f}ms")

async def main():
    """ë©”ì¸ ì‹¤ìŠµ í•¨ìˆ˜"""
    print("ğŸ¤– Week 4: ë©€í‹°ëª¨ë‹¬ API ë¹„êµ ì‹¤ìŠµ")
    print("=" * 60)
    
    # 1. í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    print("\n1ï¸âƒ£ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±")
    test_images = create_test_images()
    print(f"âœ… {len(test_images)}ê°œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ")
    
    # í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ í‘œì‹œ
    fig, axes = plt.subplots(1, len(test_images), figsize=(15, 5))
    for i, (img, name) in enumerate(test_images):
        axes[i].imshow(img)
        axes[i].set_title(name)
        axes[i].axis('off')
    plt.tight_layout()
    plt.show()
    
    # 2. API í…ŒìŠ¤í„° ì´ˆê¸°í™”
    print("\n2ï¸âƒ£ API í…ŒìŠ¤í„° ì´ˆê¸°í™”")
    tester = MultimodalAPITester()
    
    # 3. í…ŒìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ ì •ì˜
    test_prompts = [
        "ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
        "ì´ ì´ë¯¸ì§€ì—ì„œ ë³¼ ìˆ˜ ìˆëŠ” ê°ì²´ë“¤ì„ ë‚˜ì—´í•´ì£¼ì„¸ìš”.",
        "ì´ ì´ë¯¸ì§€ì˜ ì£¼ìš” íŠ¹ì§•ì€ ë¬´ì—‡ì¸ê°€ìš”?"
    ]
    
    # 4. API í‚¤ í™•ì¸ ë° í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    if tester.api_keys:
        print("\n3ï¸âƒ£ ì‹¤ì œ API í…ŒìŠ¤íŠ¸ ì‹¤í–‰")
        try:
            results = await tester.run_comprehensive_test(test_images, test_prompts)
            
            # ê²°ê³¼ ë¶„ì„
            print("\n4ï¸âƒ£ ê²°ê³¼ ë¶„ì„")
            stats = tester.analyze_results()
            
        except Exception as e:
            print(f"âŒ API í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            print("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
            simulate_api_responses()
    else:
        print("\nâš ï¸ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        print("ğŸ­ ì‹œë®¬ë ˆì´ì…˜ ëª¨ë“œë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
        simulate_api_responses()
    
    # 5. ì„ íƒ ê°€ì´ë“œ ìƒì„±
    print("\n5ï¸âƒ£ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ")
    tester.generate_selection_guide()
    
    print("\nğŸ‰ ë©€í‹°ëª¨ë‹¬ API ë¹„êµ ì‹¤ìŠµ ì™„ë£Œ!")
    print("\nğŸ“š ì¶”ê°€ ì‹¤í—˜ ì•„ì´ë””ì–´:")
    print("   - ì‹¤ì œ API í‚¤ë¡œ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")
    print("   - ë‹¤ì–‘í•œ ì´ë¯¸ì§€ íƒ€ì…ìœ¼ë¡œ ì •í™•ë„ ë¹„êµ")
    print("   - ë¹„ìš© íš¨ìœ¨ì„± ë¶„ì„")
    print("   - ì‘ë‹µ í’ˆì§ˆ í‰ê°€ ì‹œìŠ¤í…œ êµ¬ì¶•")

if __name__ == "__main__":
    # ë¹„ë™ê¸° í•¨ìˆ˜ ì‹¤í–‰
    asyncio.run(main())
