#!/usr/bin/env python3
"""
Week 4 Lab: Vision Model í†µí•© ë²¤ì¹˜ë§ˆí¬ ì•±
Gradioë¥¼ ì‚¬ìš©í•œ ì‹¤ì‹œê°„ Vision ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜

ì´ ì•±ì—ì„œëŠ”:
1. ë‹¤ì–‘í•œ Vision ëª¨ë¸ ì‹¤ì‹œê°„ ë¹„êµ
2. ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì‹œê°í™”
3. ì‚¬ìš©ì ì¹œí™”ì  ì¸í„°í˜ì´ìŠ¤
4. HuggingFace Space ë°°í¬ ì¤€ë¹„
"""

import gradio as gr
import torch
import torch.nn.functional as F
import torchvision.transforms as transforms
import torchvision.models as models
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import time
import io
import base64
from PIL import Image
import warnings
warnings.filterwarnings('ignore')

# ì „ì—­ ì„¤ì •
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì•± ì‹œì‘ - ë””ë°”ì´ìŠ¤: {DEVICE}")

class ModelBenchmark:
    """
    Vision ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ í´ë˜ìŠ¤
    """
    
    def __init__(self):
        """ë²¤ì¹˜ë§ˆí¬ ì´ˆê¸°í™”"""
        self.models = {}
        self.model_info = {
            "resnet50": {
                "name": "ResNet-50",
                "type": "CNN",
                "params": "25.6M",
                "description": "ê¹Šì€ ì”ì°¨ ë„¤íŠ¸ì›Œí¬, ì´ë¯¸ì§€ ë¶„ë¥˜ì˜ ê¸°ì¤€ì "
            },
            "efficientnet_b4": {
                "name": "EfficientNet-B4", 
                "type": "CNN",
                "params": "19.3M",
                "description": "íš¨ìœ¨ì ì¸ CNN ì•„í‚¤í…ì²˜, ëª¨ë°”ì¼ ìµœì í™”"
            },
            "vit_base": {
                "name": "ViT-Base/16",
                "type": "Transformer",
                "params": "86.6M", 
                "description": "Vision Transformer, íŒ¨ì¹˜ ê¸°ë°˜ ì–´í…ì…˜"
            },
            "dinov2": {
                "name": "DINOv2-Base",
                "type": "Self-Supervised",
                "params": "86.6M",
                "description": "ìê¸°ì§€ë„í•™ìŠµ Vision Transformer"
            }
        }
        self.load_models()
    
    def load_models(self):
        """ëª¨ë¸ ë¡œë“œ"""
        print("ğŸ”„ ëª¨ë¸ ë¡œë”© ì¤‘...")
        
        try:
            # ResNet-50
            self.models["resnet50"] = models.resnet50(pretrained=True).to(DEVICE).eval()
            print("âœ… ResNet-50 ë¡œë“œ ì™„ë£Œ")
            
            # EfficientNet-B4
            self.models["efficientnet_b4"] = models.efficientnet_b4(pretrained=True).to(DEVICE).eval()
            print("âœ… EfficientNet-B4 ë¡œë“œ ì™„ë£Œ")
            
            # ViT (HuggingFace)
            try:
                from transformers import ViTModel, ViTImageProcessor
                self.vit_processor = ViTImageProcessor.from_pretrained('google/vit-base-patch16-224')
                self.models["vit_base"] = ViTModel.from_pretrained('google/vit-base-patch16-224').to(DEVICE).eval()
                print("âœ… ViT-Base ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ ViT ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # DINOv2
            try:
                self.models["dinov2"] = torch.hub.load('facebookresearch/dinov2', 'dinov2_vitb14').to(DEVICE).eval()
                print("âœ… DINOv2 ë¡œë“œ ì™„ë£Œ")
            except Exception as e:
                print(f"âš ï¸ DINOv2 ë¡œë“œ ì‹¤íŒ¨: {e}")
                
        except Exception as e:
            print(f"âŒ ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    def preprocess_image(self, image, model_name):
        """ëª¨ë¸ë³„ ì´ë¯¸ì§€ ì „ì²˜ë¦¬"""
        if model_name == "vit_base" and hasattr(self, 'vit_processor'):
            # ViT ì „ìš© ì „ì²˜ë¦¬
            inputs = self.vit_processor(images=image, return_tensors="pt")
            return inputs['pixel_values'].to(DEVICE)
        else:
            # í‘œì¤€ ImageNet ì „ì²˜ë¦¬
            transform = transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
            ])
            
            if isinstance(image, Image.Image):
                tensor = transform(image).unsqueeze(0).to(DEVICE)
            else:
                tensor = image.to(DEVICE)
            
            return tensor
    
    def benchmark_single_model(self, model_name, image, num_runs=10):
        """ë‹¨ì¼ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬"""
        if model_name not in self.models:
            return {"error": f"ëª¨ë¸ {model_name}ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}
        
        model = self.models[model_name]
        
        try:
            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
            input_tensor = self.preprocess_image(image, model_name)
            
            # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
            times = []
            memory_usage = []
            
            # Warm-up
            with torch.no_grad():
                for _ in range(3):
                    _ = model(input_tensor)
            
            # ì‹¤ì œ ì¸¡ì •
            for _ in range(num_runs):
                if torch.cuda.is_available():
                    torch.cuda.reset_peak_memory_stats()
                
                start_time = time.time()
                
                with torch.no_grad():
                    output = model(input_tensor)
                
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                
                end_time = time.time()
                times.append((end_time - start_time) * 1000)  # ms
                
                if torch.cuda.is_available():
                    memory_usage.append(torch.cuda.max_memory_allocated() / (1024 * 1024))  # MB
            
            # ê²°ê³¼ ì •ë¦¬
            result = {
                "model": model_name,
                "model_name": self.model_info[model_name]["name"],
                "avg_time": round(np.mean(times), 2),
                "std_time": round(np.std(times), 2),
                "min_time": round(np.min(times), 2),
                "max_time": round(np.max(times), 2),
                "avg_memory": round(np.mean(memory_usage), 2) if memory_usage else "N/A",
                "output_shape": str(output.shape) if hasattr(output, 'shape') else "N/A",
                "success": True
            }
            
            return result
            
        except Exception as e:
            return {"error": str(e), "success": False}
    
    def run_comprehensive_benchmark(self, image):
        """ì¢…í•© ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        results = []
        
        for model_name in self.models.keys():
            print(f"ğŸ”„ {self.model_info[model_name]['name']} ë²¤ì¹˜ë§ˆí‚¹...")
            result = self.benchmark_single_model(model_name, image)
            
            if result.get("success", False):
                # ëª¨ë¸ ì •ë³´ ì¶”ê°€
                result.update(self.model_info[model_name])
                results.append(result)
                print(f"âœ… {result['model_name']}: {result['avg_time']}ms")
            else:
                print(f"âŒ {self.model_info[model_name]['name']}: {result.get('error', 'Unknown error')}")
        
        return results
    
    def create_comparison_chart(self, results):
        """ë¹„êµ ì°¨íŠ¸ ìƒì„±"""
        if not results:
            return None
        
        df = pd.DataFrame(results)
        
        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        # 1. ì¶”ë¡  ì‹œê°„ ë¹„êµ
        bars1 = axes[0, 0].bar(df['model_name'], df['avg_time'], 
                              yerr=df['std_time'], capsize=5, alpha=0.7, color='skyblue')
        axes[0, 0].set_title('í‰ê·  ì¶”ë¡  ì‹œê°„', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('ì‹œê°„ (ms)')
        axes[0, 0].tick_params(axis='x', rotation=45)
        
        for bar, time_val in zip(bars1, df['avg_time']):
            axes[0, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 2,
                           f'{time_val}ms', ha='center', va='bottom', fontweight='bold')
        
        # 2. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (CUDA ì‚¬ìš© ì‹œ)
        if df['avg_memory'].dtype != 'object':
            bars2 = axes[0, 1].bar(df['model_name'], df['avg_memory'], 
                                  alpha=0.7, color='lightcoral')
            axes[0, 1].set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰', fontsize=14, fontweight='bold')
            axes[0, 1].set_ylabel('ë©”ëª¨ë¦¬ (MB)')
            axes[0, 1].tick_params(axis='x', rotation=45)
            
            for bar, mem_val in zip(bars2, df['avg_memory']):
                axes[0, 1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 5,
                               f'{mem_val}MB', ha='center', va='bottom', fontweight='bold')
        else:
            axes[0, 1].text(0.5, 0.5, 'GPU ë©”ëª¨ë¦¬ ì •ë³´ ì—†ìŒ\n(CPU ëª¨ë“œ)', 
                           ha='center', va='center', transform=axes[0, 1].transAxes, fontsize=12)
            axes[0, 1].set_title('ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰')
        
        # 3. ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜
        param_counts = []
        for _, row in df.iterrows():
            param_str = row['params'].replace('M', '')
            param_counts.append(float(param_str))
        
        bars3 = axes[0, 2].bar(df['model_name'], param_counts, alpha=0.7, color='lightgreen')
        axes[0, 2].set_title('ëª¨ë¸ íŒŒë¼ë¯¸í„° ìˆ˜', fontsize=14, fontweight='bold')
        axes[0, 2].set_ylabel('íŒŒë¼ë¯¸í„° (M)')
        axes[0, 2].tick_params(axis='x', rotation=45)
        
        for bar, param_val in zip(bars3, param_counts):
            axes[0, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                           f'{param_val}M', ha='center', va='bottom', fontweight='bold')
        
        # 4. ì²˜ë¦¬ëŸ‰ (FPS)
        fps_values = [1000 / time_val for time_val in df['avg_time']]
        bars4 = axes[1, 0].bar(df['model_name'], fps_values, alpha=0.7, color='gold')
        axes[1, 0].set_title('ì²˜ë¦¬ëŸ‰ (FPS)', fontsize=14, fontweight='bold')
        axes[1, 0].set_ylabel('FPS')
        axes[1, 0].tick_params(axis='x', rotation=45)
        
        for bar, fps_val in zip(bars4, fps_values):
            axes[1, 0].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.5,
                           f'{fps_val:.1f}', ha='center', va='bottom', fontweight='bold')
        
        # 5. ëª¨ë¸ íƒ€ì…ë³„ ë¶„í¬
        type_counts = df['type'].value_counts()
        axes[1, 1].pie(type_counts.values, labels=type_counts.index, autopct='%1.1f%%', 
                      colors=['lightblue', 'lightcoral', 'lightgreen', 'gold'])
        axes[1, 1].set_title('ëª¨ë¸ íƒ€ì… ë¶„í¬', fontsize=14, fontweight='bold')
        
        # 6. ì¢…í•© ì„±ëŠ¥ ì ìˆ˜
        # ì ìˆ˜ = (FPS * 0.4) + (1/Memory * 0.3) + (1/Params * 0.3)
        composite_scores = []
        for i, row in df.iterrows():
            fps = fps_values[i]
            memory = row['avg_memory'] if isinstance(row['avg_memory'], (int, float)) else 100
            params = param_counts[i]
            
            score = (fps * 0.4) + (100/memory * 0.3) + (100/params * 0.3)
            composite_scores.append(score)
        
        bars6 = axes[1, 2].bar(df['model_name'], composite_scores, alpha=0.7, color='purple')
        axes[1, 2].set_title('ì¢…í•© ì„±ëŠ¥ ì ìˆ˜', fontsize=14, fontweight='bold')
        axes[1, 2].set_ylabel('ì ìˆ˜')
        axes[1, 2].tick_params(axis='x', rotation=45)
        
        for bar, score_val in zip(bars6, composite_scores):
            axes[1, 2].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                           f'{score_val:.1f}', ha='center', va='bottom', fontweight='bold')
        
        plt.tight_layout()
        
        # ì´ë¯¸ì§€ë¡œ ë³€í™˜
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=150, bbox_inches='tight')
        buf.seek(0)
        plt.close()
        
        return Image.open(buf)
    
    def generate_report(self, results):
        """ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸ ìƒì„±"""
        if not results:
            return "âŒ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        report = "# ğŸš€ Vision Model ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸\n\n"
        report += f"**í…ŒìŠ¤íŠ¸ ì¼ì‹œ**: {time.strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"**í…ŒìŠ¤íŠ¸ ë””ë°”ì´ìŠ¤**: {DEVICE}\n"
        report += f"**í…ŒìŠ¤íŠ¸ëœ ëª¨ë¸ ìˆ˜**: {len(results)}\n\n"
        
        report += "## ğŸ“Š ì„±ëŠ¥ ìš”ì•½\n\n"
        report += "| ëª¨ë¸ | íƒ€ì… | íŒŒë¼ë¯¸í„° | í‰ê·  ì‹œê°„ | ë©”ëª¨ë¦¬ | FPS |\n"
        report += "|------|------|----------|-----------|--------|-----|\n"
        
        for result in results:
            fps = round(1000 / result['avg_time'], 1)
            memory = result['avg_memory'] if isinstance(result['avg_memory'], (int, float)) else "N/A"
            
            report += f"| {result['model_name']} | {result['type']} | {result['params']} | "
            report += f"{result['avg_time']}ms | {memory} | {fps} |\n"
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ë“¤
        fastest_model = min(results, key=lambda x: x['avg_time'])
        most_efficient = min([r for r in results if isinstance(r['avg_memory'], (int, float))], 
                           key=lambda x: x['avg_memory'], default=fastest_model)
        
        report += f"\n## ğŸ† ì„±ëŠ¥ í•˜ì´ë¼ì´íŠ¸\n\n"
        report += f"**âš¡ ê°€ì¥ ë¹ ë¥¸ ëª¨ë¸**: {fastest_model['model_name']} ({fastest_model['avg_time']}ms)\n"
        report += f"**ğŸ’¾ ë©”ëª¨ë¦¬ íš¨ìœ¨ì **: {most_efficient['model_name']} ({most_efficient['avg_memory']}MB)\n"
        
        # ì¶”ì²œ ì‚¬í•­
        report += f"\n## ğŸ’¡ ì¶”ì²œ ì‚¬í•­\n\n"
        report += f"- **ì‹¤ì‹œê°„ ì²˜ë¦¬**: {fastest_model['model_name']} (ê°€ì¥ ë¹ ë¥¸ ì¶”ë¡ )\n"
        report += f"- **ëª¨ë°”ì¼/ì—£ì§€**: EfficientNet-B4 (íš¨ìœ¨ì„±ê³¼ ì„±ëŠ¥ì˜ ê· í˜•)\n"
        report += f"- **ê³ í’ˆì§ˆ íŠ¹ì§•**: DINOv2 (ìê¸°ì§€ë„í•™ìŠµìœ¼ë¡œ í•™ìŠµëœ ë²”ìš© íŠ¹ì§•)\n"
        report += f"- **ì „ì´í•™ìŠµ**: ViT-Base (Transformer ê¸°ë°˜ ìš°ìˆ˜í•œ ì „ì´ ì„±ëŠ¥)\n"
        
        return report

# ì „ì—­ ë²¤ì¹˜ë§ˆí¬ ì¸ìŠ¤í„´ìŠ¤
benchmark = ModelBenchmark()

def run_benchmark(image):
    """ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ í•¨ìˆ˜ (Gradio ì¸í„°í˜ì´ìŠ¤ìš©)"""
    if image is None:
        return "âŒ ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.", None, "ê²°ê³¼ ì—†ìŒ"
    
    try:
        # ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰
        results = benchmark.run_comprehensive_benchmark(image)
        
        if not results:
            return "âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì‹¤íŒ¨", None, "ê²°ê³¼ ì—†ìŒ"
        
        # ì°¨íŠ¸ ìƒì„±
        chart = benchmark.create_comparison_chart(results)
        
        # ë¦¬í¬íŠ¸ ìƒì„±
        report = benchmark.generate_report(results)
        
        # ê²°ê³¼ í…Œì´ë¸” HTML ìƒì„±
        df = pd.DataFrame(results)
        table_html = df[['model_name', 'type', 'params', 'avg_time', 'avg_memory']].to_html(
            index=False, classes='benchmark-table', escape=False,
            table_id='benchmark-results'
        )
        
        # CSS ìŠ¤íƒ€ì¼ ì¶”ê°€
        styled_table = f"""
        <style>
        .benchmark-table {{
            border-collapse: collapse;
            margin: 25px 0;
            font-size: 0.9em;
            font-family: sans-serif;
            min-width: 400px;
            border-radius: 5px 5px 0 0;
            overflow: hidden;
            box-shadow: 0 0 20px rgba(0, 0, 0, 0.15);
        }}
        .benchmark-table thead tr {{
            background-color: #009879;
            color: #ffffff;
            text-align: left;
        }}
        .benchmark-table th,
        .benchmark-table td {{
            padding: 12px 15px;
        }}
        .benchmark-table tbody tr {{
            border-bottom: 1px solid #dddddd;
        }}
        .benchmark-table tbody tr:nth-of-type(even) {{
            background-color: #f3f3f3;
        }}
        .benchmark-table tbody tr:last-of-type {{
            border-bottom: 2px solid #009879;
        }}
        </style>
        {table_html}
        """
        
        return styled_table, chart, report
        
    except Exception as e:
        error_msg = f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        return error_msg, None, error_msg

def create_sample_image():
    """ìƒ˜í”Œ ì´ë¯¸ì§€ ìƒì„±"""
    # ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ ìƒì„±
    img = Image.new('RGB', (224, 224), color='white')
    from PIL import ImageDraw
    draw = ImageDraw.Draw(img)
    
    # ë‹¤ì–‘í•œ íŒ¨í„´ ê·¸ë¦¬ê¸°
    draw.ellipse([50, 50, 174, 174], fill='red', outline='black', width=2)
    draw.rectangle([100, 100, 150, 150], fill='blue', outline='black', width=2)
    draw.polygon([(112, 180), (137, 140), (162, 180)], fill='green', outline='black')
    
    return img

def create_gradio_interface():
    """Gradio ì›¹ ì¸í„°í˜ì´ìŠ¤ ìƒì„±"""
    
    # ì»¤ìŠ¤í…€ CSS
    custom_css = """
    .gradio-container {
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
    }
    .main-header {
        text-align: center;
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        color: white;
        padding: 20px;
        border-radius: 10px;
        margin-bottom: 20px;
    }
    .benchmark-button {
        background: linear-gradient(45deg, #FE6B8B 30%, #FF8E53 90%);
        border: none;
        border-radius: 25px;
        color: white;
        padding: 15px 30px;
        font-size: 16px;
        font-weight: bold;
        cursor: pointer;
        transition: all 0.3s ease;
    }
    .benchmark-button:hover {
        transform: translateY(-2px);
        box-shadow: 0 5px 15px rgba(0,0,0,0.2);
    }
    """
    
    with gr.Blocks(title="ğŸš€ Vision Model Benchmark", theme=gr.themes.Soft(), css=custom_css) as demo:
        
        # í—¤ë”
        gr.HTML("""
        <div class="main-header">
            <h1>ğŸš€ Vision Model Benchmark</h1>
            <p>ì‹¤ì‹œê°„ìœ¼ë¡œ ë‹¤ì–‘í•œ Vision ëª¨ë¸ì˜ ì„±ëŠ¥ì„ ë¹„êµí•´ë³´ì„¸ìš”!</p>
        </div>
        """)
        
        # ëª¨ë¸ ì •ë³´ í‘œì‹œ
        with gr.Row():
            gr.Markdown(f"""
            ## ğŸ“‹ ì§€ì› ëª¨ë¸
            
            | ëª¨ë¸ | íƒ€ì… | íŒŒë¼ë¯¸í„° | ì„¤ëª… |
            |------|------|----------|------|
            | **ResNet-50** | CNN | 25.6M | ê¹Šì€ ì”ì°¨ ë„¤íŠ¸ì›Œí¬, ì´ë¯¸ì§€ ë¶„ë¥˜ì˜ ê¸°ì¤€ì  |
            | **EfficientNet-B4** | CNN | 19.3M | íš¨ìœ¨ì ì¸ CNN ì•„í‚¤í…ì²˜, ëª¨ë°”ì¼ ìµœì í™” |
            | **ViT-Base/16** | Transformer | 86.6M | Vision Transformer, íŒ¨ì¹˜ ê¸°ë°˜ ì–´í…ì…˜ |
            | **DINOv2-Base** | Self-Supervised | 86.6M | ìê¸°ì§€ë„í•™ìŠµ Vision Transformer |
            
            **ì¸¡ì • ì§€í‘œ**: ì¶”ë¡  ì‹œê°„, ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰, ì²˜ë¦¬ëŸ‰(FPS), ì¢…í•© ì„±ëŠ¥ ì ìˆ˜
            """)
        
        with gr.Row():
            # ì…ë ¥ ì„¹ì…˜
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ“¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ")
                
                image_input = gr.Image(
                    type="pil",
                    label="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
                    height=300
                )
                
                with gr.Row():
                    benchmark_btn = gr.Button(
                        "ğŸ”¥ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰",
                        variant="primary",
                        size="lg",
                        elem_classes=["benchmark-button"]
                    )
                    
                    sample_btn = gr.Button(
                        "ğŸ¨ ìƒ˜í”Œ ì´ë¯¸ì§€",
                        variant="secondary"
                    )
                
                # ì‹œìŠ¤í…œ ì •ë³´
                gr.Markdown(f"""
                ### ğŸ’» ì‹œìŠ¤í…œ ì •ë³´
                - **ë””ë°”ì´ìŠ¤**: {DEVICE}
                - **PyTorch**: {torch.__version__}
                - **ë¡œë“œëœ ëª¨ë¸**: {len(benchmark.models)}ê°œ
                """)
            
            # ê²°ê³¼ ì„¹ì…˜
            with gr.Column(scale=2):
                with gr.Tabs():
                    with gr.Tab("ğŸ“Š ì„±ëŠ¥ ì°¨íŠ¸"):
                        performance_chart = gr.Image(
                            label="ì„±ëŠ¥ ë¹„êµ ì°¨íŠ¸",
                            height=600
                        )
                    
                    with gr.Tab("ğŸ“‹ ê²°ê³¼ í…Œì´ë¸”"):
                        results_table = gr.HTML(
                            label="ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼",
                            value="<p>ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ë©´ ê²°ê³¼ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.</p>"
                        )
                    
                    with gr.Tab("ğŸ“ ìƒì„¸ ë¦¬í¬íŠ¸"):
                        detailed_report = gr.Markdown(
                            value="ë²¤ì¹˜ë§ˆí¬ë¥¼ ì‹¤í–‰í•˜ë©´ ìƒì„¸ ë¦¬í¬íŠ¸ê°€ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤."
                        )
        
        # ì˜ˆì œ ì´ë¯¸ì§€
        gr.Examples(
            examples=[
                [create_sample_image()],
            ],
            inputs=[image_input],
            label="ì˜ˆì œ ì´ë¯¸ì§€"
        )
        
        # ì¶”ê°€ ì •ë³´
        with gr.Accordion("â„¹ï¸ ì‚¬ìš© ê°€ì´ë“œ", open=False):
            gr.Markdown("""
            ### ğŸ”§ ì‚¬ìš© ë°©ë²•
            1. **ì´ë¯¸ì§€ ì—…ë¡œë“œ**: í…ŒìŠ¤íŠ¸í•  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
            2. **ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰**: 'ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰' ë²„íŠ¼ì„ í´ë¦­í•˜ì—¬ ì„±ëŠ¥ ì¸¡ì •ì„ ì‹œì‘í•˜ì„¸ìš”.
            3. **ê²°ê³¼ í™•ì¸**: ì°¨íŠ¸, í…Œì´ë¸”, ë¦¬í¬íŠ¸ íƒ­ì—ì„œ ê²°ê³¼ë¥¼ í™•ì¸í•˜ì„¸ìš”.
            
            ### ğŸ“ˆ ì¸¡ì • ì§€í‘œ ì„¤ëª…
            - **ì¶”ë¡  ì‹œê°„**: ë‹¨ì¼ ì´ë¯¸ì§€ ì²˜ë¦¬ì— ê±¸ë¦¬ëŠ” í‰ê·  ì‹œê°„ (ms)
            - **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB, CUDA ì‚¬ìš© ì‹œ)
            - **ì²˜ë¦¬ëŸ‰(FPS)**: ì´ˆë‹¹ ì²˜ë¦¬ ê°€ëŠ¥í•œ ì´ë¯¸ì§€ ìˆ˜
            - **ì¢…í•© ì ìˆ˜**: ì†ë„, ë©”ëª¨ë¦¬ íš¨ìœ¨ì„±, ëª¨ë¸ í¬ê¸°ë¥¼ ì¢…í•©í•œ ì ìˆ˜
            
            ### ğŸ’¡ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ
            - **ì‹¤ì‹œê°„ ì²˜ë¦¬**: ResNet-50 (ë¹ ë¥¸ ì¶”ë¡ )
            - **ëª¨ë°”ì¼/ì—£ì§€**: EfficientNet-B4 (íš¨ìœ¨ì„±)
            - **ê³ í’ˆì§ˆ íŠ¹ì§•**: DINOv2 (ìê¸°ì§€ë„í•™ìŠµ)
            - **ì „ì´í•™ìŠµ**: ViT-Base (Transformer)
            """)
        
        # ì´ë²¤íŠ¸ ì—°ê²°
        benchmark_btn.click(
            fn=run_benchmark,
            inputs=[image_input],
            outputs=[results_table, performance_chart, detailed_report],
            show_progress=True
        )
        
        sample_btn.click(
            fn=lambda: create_sample_image(),
            outputs=[image_input]
        )
    
    return demo

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸš€ Vision Model Benchmark App ì‹œì‘")
    print("=" * 50)
    
    # Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±
    demo = create_gradio_interface()
    
    # ì•± ì‹¤í–‰
    print("ğŸŒ ì›¹ ì¸í„°í˜ì´ìŠ¤ ì‹œì‘ ì¤‘...")
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=True,  # ê³µê°œ ë§í¬ ìƒì„±
        debug=True,
        show_error=True
    )

if __name__ == "__main__":
    main()
