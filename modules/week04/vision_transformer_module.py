"""
Week 4: Vision Transformerì™€ ìµœì‹  ëª¨ë¸ ë¹„êµ ëª¨ë“ˆ
Vision Transformer, DINO, SAM ë“± ìµœì‹  ë¹„ì „ ëª¨ë¸ í•™ìŠµ
"""

import streamlit as st
import numpy as np
from PIL import Image
import torch
import os
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from core.base_processor import BaseImageProcessor
from core.vit_helpers import get_attention_overlays, get_attention_overlays_per_head, get_attention_rollout
from transformers import ViTForImageClassification, AutoImageProcessor


class VisionTransformerModule(BaseImageProcessor):
    """Vision Transformer ë° ìµœì‹  ëª¨ë¸ í•™ìŠµ ëª¨ë“ˆ"""

    def __init__(self):
        super().__init__()

    def render(self):
        """Week 4 ëª¨ë“ˆ UI ë Œë”ë§"""
        self.render_ui()

    def render_ui(self):
        """Week 4 ëª¨ë“ˆ UI ë Œë”ë§"""
        st.title("ğŸ¤– Week 4: Vision Transformerì™€ ìµœì‹  ëª¨ë¸")
        st.markdown("---")

        # íƒ­ ìƒì„±
        tabs = st.tabs([
            "ğŸ“š ì´ë¡ ",
            "ğŸ§  Self-Attention",
            "ğŸ” Vision Transformer",
            "ğŸ“Š ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬",
            "ğŸ¯ DINO & ìê¸°ì§€ë„í•™ìŠµ",
            "ğŸš€ ì‹¤ì „ í”„ë¡œì íŠ¸"
        ])

        with tabs[0]:
            self._render_theory_tab()

        with tabs[1]:
            self._render_self_attention_tab()

        with tabs[2]:
            self._render_vit_tab()

        with tabs[3]:
            self._render_benchmark_tab()

        with tabs[4]:
            self._render_dino_tab()

        with tabs[5]:
            self._render_project_tab()

    def _render_theory_tab(self):
        """ì´ë¡  íƒ­ - ìƒì„¸í•˜ê³  ì§ê´€ì ì¸ ì„¤ëª…"""
        st.header("ğŸ“– Vision Transformer ì™„ì „ ì •ë³µ")

        # ì „ì²´ ê°œìš”
        st.info("""
        ğŸ’¡ **í•™ìŠµ ëª©í‘œ**: Vision Transformerê°€ ì–´ë–»ê²Œ ì´ë¯¸ì§€ë¥¼ "ë‹¨ì–´"ì²˜ëŸ¼ ì²˜ë¦¬í•˜ì—¬
        CNNì„ ë›°ì–´ë„˜ëŠ” ì„±ëŠ¥ì„ ë‹¬ì„±í–ˆëŠ”ì§€ ê¹Šì´ ìˆê²Œ ì´í•´í•©ë‹ˆë‹¤.
        """)

        with st.expander("ğŸ”¹ 1. Transformer í˜ëª…ì˜ ì‹œì‘", expanded=True):
            st.markdown("""
            ### ğŸ§  ì™œ Transformerì¸ê°€?

            #### ğŸ“œ ì—­ì‚¬ì  ë§¥ë½
            """)

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                **ğŸ”¤ NLPì—ì„œì˜ í˜ëª… (2017)**

                - **"Attention Is All You Need"** ë…¼ë¬¸ ë°œí‘œ
                - RNN/LSTMì˜ ì¹˜ëª…ì  í•œê³„:
                  - âŒ ìˆœì°¨ ì²˜ë¦¬ â†’ ë³‘ë ¬í™” ë¶ˆê°€
                  - âŒ ì¥ê±°ë¦¬ ì˜ì¡´ì„± í•™ìŠµ ì–´ë ¤ì›€
                  - âŒ Gradient Vanishing ë¬¸ì œ

                - âœ… Transformerì˜ í•´ê²°ì±…:
                  - âœ¨ Self-Attentionìœ¼ë¡œ ì „ì—­ ë§¥ë½ íŒŒì•…
                  - âœ¨ ì™„ì „ ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥
                  - âœ¨ BERT, GPT ë“±ì˜ ê¸°ë°˜
                """)

            with col2:
                st.markdown("""
                **ğŸ–¼ï¸ Computer Visionìœ¼ë¡œ í™•ì¥ (2020)**

                - **"An Image is Worth 16Ã—16 Words"** ë°œí‘œ
                - CNNì˜ í•œê³„:
                  - âŒ ì‘ì€ ìˆ˜ìš© ì˜ì—­ (3Ã—3 í•„í„°)
                  - âŒ ì¥ê±°ë¦¬ ê´€ê³„ íŒŒì•… ì–´ë ¤ì›€
                  - âŒ ê·€ë‚©ì  í¸í–¥ì— ì˜ì¡´

                - âœ… ViTì˜ í˜ì‹ :
                  - âœ¨ ì´ë¯¸ì§€ íŒ¨ì¹˜ë¥¼ ë‹¨ì–´ì²˜ëŸ¼ ì²˜ë¦¬
                  - âœ¨ ì²˜ìŒë¶€í„° ì „ì—­ ê´€ê³„ íŒŒì•…
                  - âœ¨ ëŒ€ê·œëª¨ ë°ì´í„°ì—ì„œ CNN ëŠ¥ê°€
                """)

            st.markdown("---")
            st.markdown("""
            ### ğŸ“Š CNN vs Transformer: ê·¼ë³¸ì ì¸ ì°¨ì´
            """)

            tab1, tab2 = st.tabs(["ì²˜ë¦¬ ë°©ì‹ ë¹„êµ", "ì„±ëŠ¥ ë¹„êµí‘œ"])

            with tab1:
                st.code("""
# CNN ë°©ì‹: ì ì§„ì  í™•ì¥
ì´ë¯¸ì§€ â†’ [3Ã—3 ì‘ì€ ì°½] â†’ [5Ã—5 ì°½] â†’ [7Ã—7 ì°½] â†’ ... â†’ ì „ì²´
        ì§€ì—­ì  íŠ¹ì§•      ì¤‘ê°„ íŠ¹ì§•     ì „ì—­ íŠ¹ì§•

# Transformer ë°©ì‹: ì¦‰ì‹œ ì „ì—­
ì´ë¯¸ì§€ â†’ [ëª¨ë“  íŒ¨ì¹˜ ê°„ ê´€ê³„ ë™ì‹œ ê³„ì‚°] â†’ ì „ì—­ íŠ¹ì§•
        Self-Attentionìœ¼ë¡œ í•œ ë²ˆì— íŒŒì•…
                """, language="text")

                st.info("""
                **ğŸ’¡ ì§ê´€ì  ë¹„ìœ :**

                - **CNN**: í˜„ë¯¸ê²½ìœ¼ë¡œ ì‚¬ì§„ì„ ì¡°ê¸ˆì”© í™•ëŒ€í•˜ë©° ë³´ëŠ” ê²ƒ
                  - ì²˜ìŒì—” ì‘ì€ ë¶€ë¶„ë§Œ â†’ ì ì  ë„“ì€ ì˜ì—­ â†’ ìµœì¢…ì ìœ¼ë¡œ ì „ì²´

                - **Transformer**: ì‚¬ì§„ ì „ì²´ë¥¼ í•œëˆˆì— ë³´ë©° ê° ë¶€ë¶„ ê°„ ê´€ê³„ íŒŒì•…
                  - ì²˜ìŒë¶€í„° "ì½”ëŠ” ëˆˆ ê·¼ì²˜ì— ìˆê³ , ê·€ëŠ” ì˜†ì— ìˆë‹¤" ì¸ì‹
                """)

            with tab2:
                comparison_df = {
                    "íŠ¹ì§•": ["ì²˜ë¦¬ ë°©ì‹", "ìˆ˜ìš© ì˜ì—­", "ê·€ë‚©ì  í¸í–¥", "ë°ì´í„° ìš”êµ¬ëŸ‰", "ê³„ì‚° ë³µì¡ë„", "ì¥ê±°ë¦¬ ì˜ì¡´ì„±", "ë³‘ë ¬ ì²˜ë¦¬", "í•´ì„ ê°€ëŠ¥ì„±"],
                    "CNN": ["ì§€ì—­ì  â†’ ì „ì—­ì ", "ì ì§„ì  í™•ì¥", "ê°•í•¨ (ì´ë™/íšŒì „ ë¶ˆë³€)", "ì ìŒ (ìˆ˜ì²œ~ìˆ˜ë§Œ)", "O(n)", "ì•½í•¨", "ë ˆì´ì–´ë³„ë§Œ", "ë‚®ìŒ"],
                    "Transformer": ["ì „ì—­ì ", "ì „ì²´ ì´ë¯¸ì§€", "ì•½í•¨", "ë§ìŒ (ìˆ˜ì‹­ë§Œ~ìˆ˜ë°±ë§Œ)", "O(nÂ²)", "ê°•í•¨", "ì™„ì „ ë³‘ë ¬", "ë†’ìŒ (Attention Map)"]
                }
                st.table(comparison_df)

                st.success("""
                **ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸:**
                - CNNì€ **ì ì€ ë°ì´í„°**ì—ì„œ íš¨ìœ¨ì ì´ì§€ë§Œ **ì¥ê±°ë¦¬ ê´€ê³„ íŒŒì•…**ì— ì•½í•¨
                - TransformerëŠ” **ëŒ€ê·œëª¨ ë°ì´í„°**ì—ì„œ ê°•ë ¥í•˜ë©° **ì „ì—­ì  ì´í•´**ê°€ ë›°ì–´ë‚¨
                - í˜„ëŒ€ AIëŠ” ë‘ ë°©ì‹ì„ **ê²°í•©**(ConvNeXt, Swin Transformer ë“±)
                """)

        with st.expander("ğŸ”¹ 2. Self-Attention: í•µì‹¬ ë©”ì»¤ë‹ˆì¦˜ ì™„ì „ ë¶„í•´"):
            st.markdown("""
            ### ğŸ¯ Self-Attentionì´ë€?

            "ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì— **ì§‘ì¤‘**(Attention)í•  ê²ƒì¸ê°€?"ë¥¼ í•™ìŠµí•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜
            """)

            st.info("""
            **ğŸ” ì‹¤ìƒí™œ ë¹„ìœ :**

            ë‹¹ì‹ ì´ ì‚¬ì§„ì—ì„œ "ê³ ì–‘ì´"ë¥¼ ì°¾ëŠ”ë‹¤ê³  ìƒìƒí•´ë³´ì„¸ìš”:

            1. **Query (ì§ˆë¬¸)**: "ê³ ì–‘ì´ëŠ” ì–´ë””ì— ìˆì„ê¹Œ?"
            2. **Key (ë‹¨ì„œ)**: ê° ì˜ì—­ì˜ íŠ¹ì§• - "í„¸ì´ ìˆë‹¤", "ë™ê·¸ë€ ëˆˆ", "ë°°ê²½"
            3. **Value (ì‹¤ì œ ì •ë³´)**: ê° ì˜ì—­ì˜ ìƒì„¸ ì •ë³´
            4. **Attention**: Queryì™€ Keyë¥¼ ë¹„êµí•´ "í„¸+ëˆˆ" ì˜ì—­ì— ë†’ì€ ì ìˆ˜ ë¶€ì—¬
            5. **ê²°ê³¼**: ê³ ì–‘ì´ê°€ ìˆëŠ” ë¶€ë¶„ì˜ ì •ë³´ë¥¼ ê°€ì¤‘ í‰ê· í•˜ì—¬ ì¶”ì¶œ
            """)

            st.markdown("#### ğŸ“ ìˆ˜í•™ì  ì •ì˜")
            st.latex(r"""
            \text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^T}{\sqrt{d_k}}\right)V
            """)

            st.markdown("""
            ì—¬ê¸°ì„œ:
            - **Q (Query)**: ì§ˆì˜ í–‰ë ¬ = "ë¬´ì—‡ì„ ì°¾ê³  ì‹¶ì€ê°€?"
            - **K (Key)**: í‚¤ í–‰ë ¬ = "ê° ìœ„ì¹˜ê°€ ê°€ì§„ ì •ë³´ëŠ”?"
            - **V (Value)**: ê°’ í–‰ë ¬ = "ì‹¤ì œë¡œ ì „ë‹¬í•  ë‚´ìš©"
            - **âˆšd_k**: ìŠ¤ì¼€ì¼ë§ íŒ©í„° (gradient ì•ˆì •í™”)
            """)

            st.markdown("#### ğŸ”„ ë‹¨ê³„ë³„ ì²˜ë¦¬ ê³¼ì •")

            process_tabs = st.tabs(["Step 1: Q,K,V ìƒì„±", "Step 2: Attention Score", "Step 3: Softmax", "Step 4: ê°€ì¤‘í•©", "Step 5: ìµœì¢… ì¶œë ¥"])

            with process_tabs[0]:
                st.markdown("""
                **1ë‹¨ê³„: Linear Transformationìœ¼ë¡œ Q, K, V ìƒì„±**
                """)
                st.code("""
ì…ë ¥: X [197Ã—768]  (CLS + 196 íŒ¨ì¹˜, ê° 768 ì°¨ì›)

Q = X @ W_q  â†’  [197Ã—768]  "ê° íŒ¨ì¹˜ê°€ ì°¾ê³ ì í•˜ëŠ” ê²ƒ"
K = X @ W_k  â†’  [197Ã—768]  "ê° íŒ¨ì¹˜ê°€ ì œê³µí•˜ëŠ” ì •ë³´"
V = X @ W_v  â†’  [197Ã—768]  "ì‹¤ì œë¡œ ì „ë‹¬í•  ê°’"

ì˜ˆì‹œ:
- P1(ëˆˆ íŒ¨ì¹˜)ì˜ Query: "ê·¼ì²˜ì— ì½”ë‚˜ ì…ì´ ìˆë‚˜?"
- P50(ì½” íŒ¨ì¹˜)ì˜ Key: "ë‚˜ëŠ” ì–¼êµ´ ì¤‘ì•™ ë¶€ë¶„ì´ì•¼"
- P50ì˜ Value: ì½”ì˜ ìƒì„¸ íŠ¹ì§• ì •ë³´
                """, language="text")

            with process_tabs[1]:
                st.markdown("""
                **2ë‹¨ê³„: Attention Score ê³„ì‚° (ìœ ì‚¬ë„ ì¸¡ì •)**
                """)
                st.code("""
Scores = Q @ K^T  â†’  [197Ã—197]

ê° íŒ¨ì¹˜ê°€ ë‹¤ë¥¸ ëª¨ë“  íŒ¨ì¹˜ì™€ì˜ ê´€ë ¨ì„±ì„ ê³„ì‚°:

          P1    P2    P3   ...  P196
    P1 [0.8]  [0.1] [0.05] ... [0.02]
    P2 [0.1]  [0.9] [0.15] ... [0.03]
    P3 [0.05] [0.15][0.7]  ... [0.01]
    ...

ìˆ«ìê°€ í´ìˆ˜ë¡ ê´€ë ¨ì„±ì´ ë†’ìŒ
(ì˜ˆ: P1ê³¼ P1 = 0.8, ìê¸° ìì‹ ê³¼ ê°€ì¥ ê´€ë ¨)
                """, language="text")

                st.warning("âš ï¸ ì´ ì ìˆ˜ë“¤ì€ ì•„ì§ í™•ë¥ ì´ ì•„ë‹ˆë¯€ë¡œ Softmax í•„ìš”!")

            with process_tabs[2]:
                st.markdown("""
                **3ë‹¨ê³„: Softmaxë¡œ í™•ë¥  ë¶„í¬ ë³€í™˜**
                """)
                st.code("""
Attention_Weights = softmax(Scores / âˆšd_k)

âˆšd_kë¡œ ë‚˜ëˆ„ëŠ” ì´ìœ :
- í° ì°¨ì›ì—ì„œ ë‚´ì  ê°’ì´ ë„ˆë¬´ ì»¤ì§€ëŠ” ê²ƒ ë°©ì§€
- Gradientê°€ vanishingë˜ì§€ ì•Šë„ë¡ í•¨

Softmax ì ìš© í›„:
          P1    P2    P3   ...  P196  | í•©
    P1 [0.45] [0.20][0.15] ... [0.01] = 1.0
    P2 [0.05] [0.60][0.25] ... [0.02] = 1.0
    ...

ì´ì œ ê° í–‰ì´ í™•ë¥  ë¶„í¬ (í•© = 1)
                """, language="text")

            with process_tabs[3]:
                st.markdown("""
                **4ë‹¨ê³„: Valueì™€ ê°€ì¤‘í•© ê³„ì‚°**
                """)
                st.code("""
Output = Attention_Weights @ V  â†’  [197Ã—768]

ê° íŒ¨ì¹˜ì— ëŒ€í•´:
- Attentionì´ ë†’ì€ íŒ¨ì¹˜ì˜ Valueë¥¼ ë§ì´ ê°€ì ¸ì˜´
- Attentionì´ ë‚®ì€ íŒ¨ì¹˜ì˜ ValueëŠ” ì¡°ê¸ˆë§Œ ê°€ì ¸ì˜´

ì˜ˆì‹œ: P1(ëˆˆ íŒ¨ì¹˜)ì˜ ì¶œë ¥
= 0.45 Ã— V_P1 (ìê¸° ìì‹ : ëˆˆ)
+ 0.20 Ã— V_P2 (ì£¼ë³€: ëˆˆì¹)
+ 0.15 Ã— V_P3 (ì£¼ë³€: ì½”)
+ ...
+ 0.01 Ã— V_P196 (ë©€ë¦¬: ë°°ê²½)

â†’ ëˆˆ ì£¼ë³€ ì •ë³´ê°€ ë§ì´ ë°˜ì˜ëœ ìƒˆë¡œìš´ í‘œí˜„
                """, language="text")

            with process_tabs[4]:
                st.markdown("""
                **5ë‹¨ê³„: ìµœì¢… ì¶œë ¥**
                """)
                st.success("""
                âœ… **ê²°ê³¼:**
                - ê° íŒ¨ì¹˜ê°€ ë‹¤ë¥¸ ëª¨ë“  íŒ¨ì¹˜ì˜ ì •ë³´ë¥¼ **ê´€ë ¨ì„±ì— ë”°ë¼** ê°€ì ¸ì˜´
                - ì „ì—­ì  ë§¥ë½ì´ ë°˜ì˜ëœ ìƒˆë¡œìš´ íŠ¹ì§• í‘œí˜„
                - ë‹¤ìŒ ë ˆì´ì–´ë¡œ ì „ë‹¬ë˜ê±°ë‚˜ ìµœì¢… ë¶„ë¥˜ì— ì‚¬ìš©

                **ğŸ’¡ í•µì‹¬:**
                Self-Attentionì€ "ëˆ„êµ¬ë‘ ì¹œí•œì§€" ê³„ì‚°í•˜ê³ ,
                ì¹œí•œ ì¹œêµ¬ë“¤ì˜ ì •ë³´ë¥¼ ë§ì´ ê°€ì ¸ì™€ì„œ
                ìì‹ ì„ ì—…ë°ì´íŠ¸í•˜ëŠ” ê³¼ì •!
                """)

            st.markdown("---")
            st.markdown("#### ğŸ¨ Multi-Head Attention: ë‹¤ì–‘í•œ ê´€ì ")

            st.markdown("""
            **ì™œ ì—¬ëŸ¬ ê°œì˜ Headê°€ í•„ìš”í• ê¹Œ?**
            """)

            st.info("""
            **ğŸ” ë¹„ìœ :**

            í•œ ëª…ì˜ ì „ë¬¸ê°€ë³´ë‹¤ ì—¬ëŸ¬ ì „ë¬¸ê°€ê°€ ê°ìì˜ ê´€ì ì—ì„œ ë³´ëŠ” ê²ƒì´ ë‚«ìŠµë‹ˆë‹¤:

            - **Head 1**: ê³µê°„ì  ì¸ì ‘ì„± íŒŒì•… (ê·¼ì²˜ íŒ¨ì¹˜ë“¤ ì¤‘ìš”í•˜ê²Œ)
            - **Head 2**: ìƒ‰ìƒ ìœ ì‚¬ì„± íŒŒì•… (ë¹„ìŠ·í•œ ìƒ‰ íŒ¨ì¹˜ë“¤ ì¤‘ìš”í•˜ê²Œ)
            - **Head 3**: í…ìŠ¤ì²˜ íŒ¨í„´ íŒŒì•… (ë¹„ìŠ·í•œ ì§ˆê° íŒ¨ì¹˜ë“¤ ì¤‘ìš”í•˜ê²Œ)
            - **Head 4**: í˜•íƒœ ê´€ê³„ íŒŒì•… (ê°™ì€ ê°ì²´ íŒ¨ì¹˜ë“¤ ì¤‘ìš”í•˜ê²Œ)
            - ... (ì´ 12ê°œ Headê°€ ì„œë¡œ ë‹¤ë¥¸ ê´€ì )

            ìµœì¢…ì ìœ¼ë¡œ 12ê°œ Headì˜ ê²°ê³¼ë¥¼ í•©ì³ì„œ í’ë¶€í•œ í‘œí˜„ ìƒì„±!
            """)

            st.code("""
ì…ë ¥ [197Ã—768]
    â”‚
    â”œâ”€â”€â”€â”€ Head 1 [197Ã—64] â”€â”€ ê³µê°„ ê´€ê³„
    â”œâ”€â”€â”€â”€ Head 2 [197Ã—64] â”€â”€ ìƒ‰ìƒ ê´€ê³„
    â”œâ”€â”€â”€â”€ Head 3 [197Ã—64] â”€â”€ í…ìŠ¤ì²˜ ê´€ê³„
    â”œâ”€â”€â”€â”€ Head 4 [197Ã—64] â”€â”€ í˜•íƒœ ê´€ê³„
    â”œâ”€â”€â”€â”€ ...
    â””â”€â”€â”€â”€ Head 12 [197Ã—64] â”€â”€ ë§¥ë½ ì •ë³´
    â”‚
    â””â”€â–º Concatenate â”€â–º [197Ã—768] â”€â–º Linear â”€â–º ì¶œë ¥
            """, language="text")

        with st.expander("ğŸ”¹ 3. Vision Transformer ì™„ì „ ë¶„í•´"):
            st.markdown("""
            ### ğŸ—ï¸ ViT ì•„í‚¤í…ì²˜: "ì´ë¯¸ì§€ë¥¼ ë¬¸ì¥ì²˜ëŸ¼"

            **í•µì‹¬ ì•„ì´ë””ì–´**: ì´ë¯¸ì§€ë¥¼ ë‹¨ì–´ë“¤ì˜ ì‹œí€€ìŠ¤ì²˜ëŸ¼ ì·¨ê¸‰
            """)

            st.image("https://raw.githubusercontent.com/google-research/vision_transformer/main/vit_figure.png",
                    caption="Vision Transformer ì „ì²´ êµ¬ì¡° (ì¶œì²˜: Google Research)")

            st.markdown("#### ğŸ“¦ 1. Patch Embedding: ì´ë¯¸ì§€ë¥¼ ë‹¨ì–´ë¡œ")

            col1, col2 = st.columns([1, 1])

            with col1:
                st.code("""
ì›ë³¸ ì´ë¯¸ì§€: 224Ã—224Ã—3
        â†“
16Ã—16 íŒ¨ì¹˜ë¡œ ë¶„í• 
        â†“
ì´ 196ê°œ íŒ¨ì¹˜
(14Ã—14 = 196)
        â†“
ê° íŒ¨ì¹˜: 16Ã—16Ã—3 = 768ê°œ í”½ì…€ê°’
        â†“
Linear Projection
        â†“
768ì°¨ì› ë²¡í„°
                """, language="text")

            with col2:
                st.info("""
                **ğŸ¯ ì™œ íŒ¨ì¹˜ë¡œ ë‚˜ëˆŒê¹Œ?**

                1. **ì—°ì‚° íš¨ìœ¨ì„±**:
                   - 224Ã—224 = 50,176 í”½ì…€ ì§ì ‘ ì²˜ë¦¬ â†’ ë„ˆë¬´ ë¬´ê±°ì›€
                   - 196ê°œ íŒ¨ì¹˜ë§Œ ì²˜ë¦¬ â†’ 256ë°° íš¨ìœ¨ì !

                2. **NLPì™€ì˜ ìœ ì‚¬ì„±**:
                   - íŒ¨ì¹˜ = ë‹¨ì–´
                   - ì´ë¯¸ì§€ = ë¬¸ì¥
                   - Transformerë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš© ê°€ëŠ¥

                3. **ì ì ˆí•œ granularity**:
                   - ë„ˆë¬´ ì‘ìœ¼ë©´(8Ã—8): íŒ¨ì¹˜ ìˆ˜ ë„ˆë¬´ ë§ìŒ
                   - ë„ˆë¬´ í¬ë©´(32Ã—32): ì„¸ë°€í•œ ì •ë³´ ì†ì‹¤
                   - 16Ã—16: ìµœì ì˜ ê· í˜•
                """)

            st.markdown("#### ğŸ¯ 2. CLS Token: ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ìˆ˜ í† í°")

            st.code("""
íŒ¨ì¹˜ ì‹œí€€ìŠ¤: [P1, P2, P3, ..., P196]
        â†“ CLS í† í° ì¶”ê°€
[CLS, P1, P2, P3, ..., P196]  (ì´ 197ê°œ)

CLS í† í°ì˜ ì—­í• :
- ì „ì²´ ì´ë¯¸ì§€ ì •ë³´ë¥¼ ëª¨ìœ¼ëŠ” "ì§‘í•©ì²´"
- Transformerë¥¼ ê±°ì¹˜ë©° ëª¨ë“  íŒ¨ì¹˜ì˜ ì •ë³´ë¥¼ í¡ìˆ˜
- ìµœì¢…ì ìœ¼ë¡œ ë¶„ë¥˜ì— ì‚¬ìš©
            """, language="text")

            st.success("""
            **ğŸ’¡ ì§ê´€:**

            CLS í† í°ì€ "ë°˜ì¥" ê°™ì€ ì¡´ì¬:
            - ì²˜ìŒì—” ë¹ˆ ìƒíƒœ
            - Self-Attentionì„ í†µí•´ ëª¨ë“  íŒ¨ì¹˜(í•™ìƒë“¤)ë¡œë¶€í„° ì •ë³´ ìˆ˜ì§‘
            - 12ê°œ ë ˆì´ì–´ë¥¼ ê±°ì¹˜ë©° ì ì  ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì´í•´ ì¶•ì 
            - ìµœì¢…ì ìœ¼ë¡œ "ì´ ì´ë¯¸ì§€ëŠ” ê³ ì–‘ì´ë‹¤!"ë¼ê³  íŒë‹¨
            """)

            st.markdown("#### ğŸ“ 3. Position Embedding: ìœ„ì¹˜ ì •ë³´ ì£¼ì…")

            st.warning("""
            **âš ï¸ ì¤‘ìš”í•œ ë¬¸ì œ:**

            Self-Attentionì€ ìœ„ì¹˜ ì •ë³´ë¥¼ ëª¨ë¦…ë‹ˆë‹¤!

            - [P1, P2, P3]ì™€ [P3, P1, P2]ë¥¼ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
            - í•˜ì§€ë§Œ ì´ë¯¸ì§€ì—ì„œ ìœ„ì¹˜ëŠ” ë§¤ìš° ì¤‘ìš”!
              - ì™¼ìª½ ìœ„(P1) vs ì˜¤ë¥¸ìª½ ì•„ë˜(P196)ëŠ” ë‹¤ë¥¸ ì˜ë¯¸
            """)

            st.markdown("**í•´ê²°ì±…: Position Embedding ì¶”ê°€**")

            st.code("""
Patch Embedding + Position Embedding

[CLS, P1, P2, ..., P196]      ê° íŒ¨ì¹˜ ì„ë² ë”© [768]
   +     +    +        +       ë”í•˜ê¸°
[Pos0, Pos1, Pos2, ..., Pos196]  ìœ„ì¹˜ ì„ë² ë”© [768]
   â†“     â†“    â†“        â†“
[CLS', P1', P2', ..., P196']   ìœ„ì¹˜ ì •ë³´ í¬í•¨ëœ ì„ë² ë”©

ì´ì œ ëª¨ë¸ì´ ì•Œ ìˆ˜ ìˆìŒ:
- P1 = ì™¼ìª½ ìœ„ íŒ¨ì¹˜
- P196 = ì˜¤ë¥¸ìª½ ì•„ë˜ íŒ¨ì¹˜
            """, language="text")

            st.markdown("#### ğŸ”„ 4. Transformer Encoder Block (Ã—12)")

            st.code("""
í•˜ë‚˜ì˜ Transformer Block:

ì…ë ¥ [197Ã—768]
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer Norm            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Multi-Head Attention  â”‚  â† ì „ì—­ ê´€ê³„ íŒŒì•…
â”‚ (12 heads Ã— 64 dims)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ (Residual Connection)
    + â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ë”í•˜ê¸°
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Layer Norm            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ MLP (Feed Forward)    â”‚  â† ë¹„ì„ í˜• ë³€í™˜
â”‚ 768 â†’ 3072 â†’ 768      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚
    â–¼ (Residual Connection)
    + â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º ë”í•˜ê¸°
    â”‚
    â–¼
ì¶œë ¥ [197Ã—768]

ì´ ë¸”ë¡ì„ 12ë²ˆ ë°˜ë³µ!
            """, language="text")

            st.info("""
            **ğŸ” ê° êµ¬ì„± ìš”ì†Œì˜ ì—­í• :**

            1. **Layer Norm**: í•™ìŠµ ì•ˆì •í™”
            2. **Multi-Head Attention**: íŒ¨ì¹˜ ê°„ ê´€ê³„ í•™ìŠµ
            3. **Residual Connection**: Gradient íë¦„ ê°œì„ 
            4. **MLP**: ë³µì¡í•œ ë¹„ì„ í˜• íŒ¨í„´ í•™ìŠµ

            **ë ˆì´ì–´ê°€ ê¹Šì–´ì§ˆìˆ˜ë¡:**
            - Layer 1-4: ì €ìˆ˜ì¤€ íŠ¹ì§• (ì—£ì§€, í…ìŠ¤ì²˜)
            - Layer 5-8: ì¤‘ê°„ íŠ¹ì§• (ë¶€ë¶„, íŒ¨í„´)
            - Layer 9-12: ê³ ìˆ˜ì¤€ íŠ¹ì§• (ê°ì²´, ì˜ë¯¸)
            """)

            st.markdown("#### ğŸ“ 5. Classification Head: ìµœì¢… ë¶„ë¥˜")

            st.code("""
12ê°œ ë ˆì´ì–´ í†µê³¼ í›„:
[CLS', P1', P2', ..., P196']  [197Ã—768]
   â”‚
   â–¼ CLS í† í°ë§Œ ì¶”ì¶œ
 CLS'  [1Ã—768]
   â”‚
   â–¼ Layer Norm
 CLS'' [1Ã—768]
   â”‚
   â–¼ Linear (768 â†’ 1000)
 Logits [1Ã—1000]
   â”‚
   â–¼ Softmax
 Probabilities [1Ã—1000]
   â”‚
   â–¼
"ê³ ì–‘ì´: 95%, ê°œ: 3%, í˜¸ë‘ì´: 1%, ..."
            """, language="text")

            st.success("""
            **âœ… ì „ì²´ íë¦„ ìš”ì•½:**

            1. ì´ë¯¸ì§€ë¥¼ 196ê°œ íŒ¨ì¹˜ë¡œ ë¶„í• 
            2. ê° íŒ¨ì¹˜ë¥¼ 768ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
            3. CLS í† í° ì¶”ê°€ + ìœ„ì¹˜ ì •ë³´ ì¶”ê°€
            4. 12ê°œ Transformer Block í†µê³¼ (ê´€ê³„ í•™ìŠµ)
            5. CLS í† í°ìœ¼ë¡œ ìµœì¢… ë¶„ë¥˜

            **ğŸ’¡ í•µì‹¬:**
            ì²˜ìŒë¶€í„° ëê¹Œì§€ ëª¨ë“  íŒ¨ì¹˜ê°€ ì„œë¡œ ì†Œí†µí•˜ë©°
            ì „ì²´ ì´ë¯¸ì§€ì— ëŒ€í•œ ì´í•´ë¥¼ ì ì§„ì ìœ¼ë¡œ ê¹Šê²Œ ë§Œë“¦!
            """)

    def _render_self_attention_tab(self):
        """Self-Attention íƒ­ - ê°œë… ì´í•´ì™€ ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜"""
        st.header("ğŸ§  Self-Attention ë©”ì»¤ë‹ˆì¦˜ ì´í•´í•˜ê¸°")

        st.info("""
        ğŸ’¡ **ì´ íƒ­ì˜ ëª©ì **: Self-Attentionì´ **ë¬´ì—‡ì¸ì§€**, **ì–´ë–»ê²Œ ì‘ë™í•˜ëŠ”ì§€**ë¥¼
        ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ìœ¼ë¡œ ì´í•´í•©ë‹ˆë‹¤. (ì‹¤ì œ ëª¨ë¸ í•„ìš” ì—†ìŒ)

        ğŸ‘‰ ì‹¤ì œ ViT ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„ì„ í•˜ë ¤ë©´ **"ğŸ” Vision Transformer" íƒ­**ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”!
        """)

        st.markdown("---")

        # 1. ê°œë… ì„¤ëª…
        with st.expander("ğŸ“– Self-Attentionì´ë€?", expanded=True):
            st.markdown("""
            ### ğŸ¯ í•µì‹¬ ì•„ì´ë””ì–´

            Self-Attentionì€ **ì…ë ¥ ì‹œí€€ìŠ¤ì˜ ê° ìš”ì†Œ**ê°€ **ë‹¤ë¥¸ ëª¨ë“  ìš”ì†Œ**ì™€
            ì–¼ë§ˆë‚˜ ê´€ë ¨ì´ ìˆëŠ”ì§€ ê³„ì‚°í•˜ëŠ” ë©”ì»¤ë‹ˆì¦˜ì…ë‹ˆë‹¤.

            #### ğŸ” í…ìŠ¤íŠ¸ ì˜ˆì‹œ
            """)

            text_example = "The cat sat on the mat"
            st.code(f'ë¬¸ì¥: "{text_example}"', language="text")

            st.markdown("""
            "cat"ì´ë¼ëŠ” ë‹¨ì–´ê°€ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ê³¼ì˜ ê´€ë ¨ì„±:
            - **cat** â†â†’ **sat**: ë†’ì€ ê´€ë ¨ì„± (ì£¼ì–´-ë™ì‚¬)
            - **cat** â†â†’ **mat**: ì¤‘ê°„ ê´€ë ¨ì„± (ê°™ì€ ë¬¸ë§¥)
            - **cat** â†â†’ **The**: ë‚®ì€ ê´€ë ¨ì„±

            #### ğŸ–¼ï¸ ì´ë¯¸ì§€ ì˜ˆì‹œ

            ê³ ì–‘ì´ ì‚¬ì§„ì„ 196ê°œ íŒ¨ì¹˜ë¡œ ë‚˜ëˆ´ì„ ë•Œ:
            - **ëˆˆ íŒ¨ì¹˜** â†â†’ **ì½” íŒ¨ì¹˜**: ë†’ì€ ê´€ë ¨ì„± (ì–¼êµ´ ë¶€ë¶„)
            - **ëˆˆ íŒ¨ì¹˜** â†â†’ **ê·€ íŒ¨ì¹˜**: ì¤‘ê°„ ê´€ë ¨ì„± (ê°™ì€ ë¨¸ë¦¬)
            - **ëˆˆ íŒ¨ì¹˜** â†â†’ **ë°°ê²½ íŒ¨ì¹˜**: ë‚®ì€ ê´€ë ¨ì„±
            """)

        st.markdown("---")

        # 2. ëŒ€í™”í˜• ì‹œë®¬ë ˆì´ì…˜
        st.markdown("### ğŸ® Self-Attention ì‹œë®¬ë ˆì´ì…˜")

        sim_tab1, sim_tab2 = st.tabs(["ğŸ“ í…ìŠ¤íŠ¸ Attention", "ğŸ¨ ì´ë¯¸ì§€ íŒ¨ì¹˜ Attention"])

        with sim_tab1:
            st.markdown("#### ë¬¸ì¥ì˜ ë‹¨ì–´ ê°„ Attention ì‹œë®¬ë ˆì´ì…˜")

            sample_sentence = st.text_input(
                "ë¬¸ì¥ì„ ì…ë ¥í•˜ì„¸ìš” (ê³µë°±ìœ¼ë¡œ êµ¬ë¶„)",
                "The cat sat on the mat",
                key="sample_sentence"
            )

            words = sample_sentence.split()

            if len(words) > 1:
                st.markdown(f"**ë‹¨ì–´ ìˆ˜**: {len(words)}ê°œ")

                # ì‚¬ìš©ìê°€ ì„ íƒí•œ ë‹¨ì–´
                query_word = st.selectbox("Query ë‹¨ì–´ ì„ íƒ (ì–´ë–¤ ë‹¨ì–´ì˜ ê´€ì ì—ì„œ ë³¼ê¹Œìš”?)", words, key="query_word")
                query_idx = words.index(query_word)

                # ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜ (ê±°ë¦¬ ê¸°ë°˜)
                st.markdown(f"**'{query_word}'** ë‹¨ì–´ì˜ ê´€ì ì—ì„œ ë‹¤ë¥¸ ë‹¨ì–´ë“¤ê³¼ì˜ Attention:")

                import random
                attention_scores = {}
                for i, word in enumerate(words):
                    if i == query_idx:
                        score = 1.0  # ìê¸° ìì‹ 
                    else:
                        # ê±°ë¦¬ ê¸°ë°˜ ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜
                        distance = abs(i - query_idx)
                        score = max(0.1, 1.0 - distance * 0.15 + random.uniform(-0.1, 0.1))
                    attention_scores[word] = score

                # ì •ê·œí™” (í•©ì´ 1ì´ ë˜ë„ë¡)
                total = sum(attention_scores.values())
                attention_scores = {k: v/total for k, v in attention_scores.items()}

                # ì‹œê°í™”
                for word, score in attention_scores.items():
                    bar_length = int(score * 50)
                    bar = "â–ˆ" * bar_length
                    st.text(f"{word:15s} {bar} {score:.3f}")

                st.success(f"""
                âœ… **í•´ì„**: '{query_word}' ë‹¨ì–´ëŠ” ìê¸° ìì‹ ê³¼ ê°€ì¥ ë†’ì€ Attentionì„ ê°€ì§€ë©°,
                ê°€ê¹Œìš´ ë‹¨ì–´ì¼ìˆ˜ë¡ ë” ë†’ì€ Attentionì„ ê°€ì§‘ë‹ˆë‹¤.
                """)

        with sim_tab2:
            st.markdown("#### ì´ë¯¸ì§€ íŒ¨ì¹˜ ê°„ Attention ì‹œë®¬ë ˆì´ì…˜")

            st.markdown("""
            224Ã—224 ì´ë¯¸ì§€ë¥¼ 16Ã—16 íŒ¨ì¹˜ë¡œ ë‚˜ëˆ„ë©´ **14Ã—14 = 196ê°œ** íŒ¨ì¹˜ê°€ ìƒì„±ë©ë‹ˆë‹¤.
            """)

            # ê·¸ë¦¬ë“œ ì‹œê°í™”
            grid_size = 14
            selected_row = st.slider("Query íŒ¨ì¹˜ í–‰ (Row)", 0, grid_size-1, 5, key="patch_row")
            selected_col = st.slider("Query íŒ¨ì¹˜ ì—´ (Col)", 0, grid_size-1, 5, key="patch_col")

            selected_patch = selected_row * grid_size + selected_col

            st.markdown(f"**ì„ íƒëœ íŒ¨ì¹˜**: P{selected_patch} (Row {selected_row}, Col {selected_col})")

            # ê°„ë‹¨í•œ Attention ë§µ ì‹œë®¬ë ˆì´ì…˜ (ê±°ë¦¬ ê¸°ë°˜)
            st.markdown("**Attention Map** (ì„ íƒëœ íŒ¨ì¹˜ì™€ ë‹¤ë¥¸ íŒ¨ì¹˜ë“¤ì˜ ê´€ë ¨ì„±):")

            attention_grid = []
            for r in range(grid_size):
                row = []
                for c in range(grid_size):
                    # ìœ í´ë¦¬ë“œ ê±°ë¦¬ ê¸°ë°˜
                    distance = ((r - selected_row)**2 + (c - selected_col)**2)**0.5
                    attention = max(0.0, 1.0 - distance / grid_size)
                    row.append(attention)
                attention_grid.append(row)

            # NumPyë¥¼ ì‚¬ìš©í•œ íˆíŠ¸ë§µ ì‹œê°í™”
            import numpy as np
            attention_array = np.array(attention_grid)

            # Matplotlibìœ¼ë¡œ íˆíŠ¸ë§µ ìƒì„±
            import matplotlib.pyplot as plt
            fig, ax = plt.subplots(figsize=(8, 8))
            im = ax.imshow(attention_array, cmap='hot', interpolation='nearest')
            ax.set_title(f'Attention Map for Patch P{selected_patch}', fontsize=14)
            ax.set_xlabel('Column')
            ax.set_ylabel('Row')

            # ì„ íƒëœ íŒ¨ì¹˜ í‘œì‹œ
            ax.plot(selected_col, selected_row, 'b*', markersize=20, label='Query Patch')
            ax.legend()

            # ì»¬ëŸ¬ë°”
            plt.colorbar(im, ax=ax, label='Attention Weight')

            st.pyplot(fig)

            st.info("""
            ğŸ’¡ **ì‹œë®¬ë ˆì´ì…˜ ì„¤ëª…**:
            - ğŸ”µ íŒŒë€ ë³„: ì„ íƒí•œ Query íŒ¨ì¹˜
            - ğŸ”´ ë¹¨ê°„ìƒ‰: ë†’ì€ Attention (ë°€ì ‘í•œ ê´€ë ¨)
            - ğŸŸ¡ ë…¸ë€ìƒ‰: ì¤‘ê°„ Attention
            - âš« ê²€ì€ìƒ‰: ë‚®ì€ Attention (ê±°ì˜ ë¬´ê´€)

            ì‹¤ì œ ViTì—ì„œëŠ” í•™ìŠµì„ í†µí•´ **ì˜ë¯¸ì  ìœ ì‚¬ì„±**ì„ ê¸°ë°˜ìœ¼ë¡œ Attentionì„ ê³„ì‚°í•©ë‹ˆë‹¤!
            """)

        st.markdown("---")

        # 3. Multi-Head Attention ê°œë…
        with st.expander("ğŸ¨ Multi-Head Attention: ë‹¤ì–‘í•œ ê´€ì "):
            st.markdown("""
            ### ì™œ ì—¬ëŸ¬ ê°œì˜ Headê°€ í•„ìš”í• ê¹Œ?

            í•˜ë‚˜ì˜ Attentionë§Œìœ¼ë¡œëŠ” **í•œ ê°€ì§€ ê´€ì **ë§Œ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            **Multi-Head Attention**ì€ ì—¬ëŸ¬ ê´€ì ì—ì„œ ë™ì‹œì— ì •ë³´ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            """)

            num_heads = st.slider("Attention Head ìˆ˜", 1, 12, 8, key="num_heads_sim")

            st.markdown(f"""
            **{num_heads}ê°œ Headì˜ ì—­í•  (ì˜ˆì‹œ):**
            """)

            head_roles = [
                "ê³µê°„ì  ì¸ì ‘ì„± (ê·¼ì²˜ íŒ¨ì¹˜ ì§‘ì¤‘)",
                "ìƒ‰ìƒ ìœ ì‚¬ì„± (ë¹„ìŠ·í•œ ìƒ‰ ì§‘ì¤‘)",
                "í…ìŠ¤ì²˜ íŒ¨í„´ (ë¹„ìŠ·í•œ ì§ˆê° ì§‘ì¤‘)",
                "í˜•íƒœ ê´€ê³„ (ê°™ì€ ê°ì²´ ì§‘ì¤‘)",
                "ì—£ì§€ ê²€ì¶œ (ê²½ê³„ì„  ì§‘ì¤‘)",
                "ë°ê¸° ëŒ€ë¹„ (ëª…ì•” ì§‘ì¤‘)",
                "ë§¥ë½ ì •ë³´ (ì „ì²´ ë¬¸ë§¥ ì§‘ì¤‘)",
                "ì„¸ë¶€ ë””í…Œì¼ (ì‘ì€ íŠ¹ì§• ì§‘ì¤‘)",
                "ê°ì²´ ë¶€ë¶„-ì „ì²´ (ê³„ì¸µì  ê´€ê³„)",
                "ì‹œê°„ì  ì—°ê´€ì„± (ë™ì‘ íŒ¨í„´)",
                "ì˜ë¯¸ì  ìœ ì‚¬ì„± (ë¹„ìŠ·í•œ ì˜ë¯¸)",
                "ì „ì—­ì  êµ¬ì¡° (ì „ì²´ ë ˆì´ì•„ì›ƒ)"
            ]

            for i in range(min(num_heads, len(head_roles))):
                st.markdown(f"- **Head {i+1}**: {head_roles[i]}")

            st.code("""
ì…ë ¥ [197Ã—768]
    â”‚
    â”œâ”€â”€â”€â”€ Head 1 [197Ã—64] â”€â”€ ê³µê°„ ê´€ê³„
    â”œâ”€â”€â”€â”€ Head 2 [197Ã—64] â”€â”€ ìƒ‰ìƒ ê´€ê³„
    â”œâ”€â”€â”€â”€ Head 3 [197Ã—64] â”€â”€ í…ìŠ¤ì²˜ ê´€ê³„
    ...
    â””â”€â”€â”€â”€ Head 12 [197Ã—64] â”€â”€ ë§¥ë½ ì •ë³´
    â”‚
    â””â”€â–º Concatenate & Linear â”€â–º [197Ã—768]
            """, language="text")

            st.success("""
            âœ… **í•µì‹¬**: ê° Headê°€ ì„œë¡œ ë‹¤ë¥¸ **íŠ¹í™”ëœ ê´€ì **ì—ì„œ ì •ë³´ë¥¼ ì²˜ë¦¬í•˜ê³ ,
            ì´ë¥¼ ê²°í•©í•˜ì—¬ **í’ë¶€í•˜ê³  ë‹¤ì°¨ì›ì ì¸ í‘œí˜„**ì„ ë§Œë“­ë‹ˆë‹¤!
            """)

        st.markdown("---")
        st.warning("""
        âš ï¸ **ì´ íƒ­ì€ ê°œë… ì´í•´ë¥¼ ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤.**

        ì‹¤ì œ ViT ëª¨ë¸ë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  Attentionì„ ì‹œê°í™”í•˜ë ¤ë©´
        ğŸ‘‰ **"ğŸ” Vision Transformer" íƒ­**ìœ¼ë¡œ ì´ë™í•˜ì„¸ìš”!
        """)

    def _render_vit_tab(self):
        """Vision Transformer íƒ­ - ì‹¤ì œ ëª¨ë¸ ì‚¬ìš©"""
        st.header("ğŸ” Vision Transformer ì‹¤ì „")

        st.info("""
        ğŸ’¡ **ì´ íƒ­ì˜ ëª©ì **: ì‹¤ì œ ViT ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê³ , Attentionì„ ì‹œê°í™”í•˜ë©°, ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.

        **3ë‹¨ê³„ í”„ë¡œì„¸ìŠ¤:**
        1. ğŸ”½ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ/ë¡œë“œ
        2. ğŸ‘ï¸ Attention Map ì‹œê°í™”
        3. ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜
        """)

        st.markdown("---")

        # Step 1: ëª¨ë¸ ì„ íƒ ë° ë‹¤ìš´ë¡œë“œ
        st.markdown("### 1ï¸âƒ£ ViT ëª¨ë¸ ë‹¤ìš´ë¡œë“œ")

        col1, col2 = st.columns(2)

        with col1:
            model_choice = st.selectbox(
                "ì‚¬ì „í•™ìŠµ ViT ëª¨ë¸ ì„ íƒ",
                [
                    "google/vit-base-patch16-224",
                    "google/vit-large-patch16-224",
                ],
                index=0,
                key="vit_model_choice",
                help="HuggingFaceì—ì„œ ì‚¬ì „í•™ìŠµëœ ViT ë¶„ë¥˜ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤"
            )

            # ëª¨ë¸ ì •ë³´ í‘œì‹œ
            model_info = {
                "google/vit-base-patch16-224": {
                    "name": "ViT-Base/16",
                    "params": "86M",
                    "dataset": "ImageNet-1K",
                    "acc": "81.8%"
                },
                "google/vit-large-patch16-224": {
                    "name": "ViT-Large/16",
                    "params": "307M",
                    "dataset": "ImageNet-1K",
                    "acc": "82.6%"
                },
            }

            info = model_info[model_choice]
            st.info(f"""
            **ëª¨ë¸ ì •ë³´:**
            - ì´ë¦„: {info['name']}
            - íŒŒë¼ë¯¸í„°: {info['params']}
            - í•™ìŠµ ë°ì´í„°: {info['dataset']}
            - ì •í™•ë„: {info['acc']}
            """)

            if st.button("â¬‡ï¸ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ/ë¡œë“œ", key="load_vit", type="primary"):
                with st.spinner("ë¶„ë¥˜ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° ë¡œë“œ ì¤‘ (ì²˜ìŒì—” ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)..."):
                    try:
                        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
                        processor = AutoImageProcessor.from_pretrained(model_choice)
                        model = ViTForImageClassification.from_pretrained(model_choice, output_attentions=True)
                        model.to(device)
                        model.eval()

                        st.success(f"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")
                        st.caption(f"Device: {device} | ìºì‹œ ì €ì¥ë¨")
                        # ìºì‹œ ì €ì¥
                        st.session_state['vit_model'] = model
                        st.session_state['vit_processor'] = processor
                        st.session_state['vit_model_name'] = model_choice
                    except Exception as e:
                        st.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")

        with col2:
            # ëª¨ë¸ ìƒíƒœ í‘œì‹œ
            if 'vit_model' in st.session_state:
                st.success("âœ… ëª¨ë¸ ë¡œë“œë¨")
                st.caption(f"ëª¨ë¸: {st.session_state.get('vit_model_name', 'Unknown')}")
            else:
                st.warning("âš ï¸ ëª¨ë¸ ë¯¸ë¡œë“œ")
                st.caption("ì™¼ìª½ì—ì„œ ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”")

            # ëª¨ë¸ ì•„í‚¤í…ì²˜ ì •ë³´
            st.markdown("**ğŸ“Š ViT ì•„í‚¤í…ì²˜**")
            st.code("""
ì´ë¯¸ì§€ (224Ã—224Ã—3)
    â†“
íŒ¨ì¹˜ ë¶„í•  (16Ã—16)
    â†“
196ê°œ íŒ¨ì¹˜ + CLS
    â†“
Position Embedding
    â†“
12 Transformer Layers
    â†“
CLS í† í° â†’ ë¶„ë¥˜
            """, language="text")

        uploaded_vit = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="vit_upload",
            help="224Ã—224ë¡œ ìë™ ë¦¬ì‚¬ì´ì¦ˆë©ë‹ˆë‹¤"
        )

        if uploaded_vit:
            st.image(uploaded_vit, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_column_width=True)

            # Step 2: Attention ì‹œê°í™”
            if 'vit_model' in st.session_state:
                st.markdown("---")
                st.markdown("### 2ï¸âƒ£ Attention Map ì‹œê°í™”")

                st.info("""
                ğŸ’¡ **Attention Map**: ViTê°€ ì´ë¯¸ì§€ì˜ ì–´ëŠ ë¶€ë¶„ì— ì§‘ì¤‘í•˜ëŠ”ì§€ ì‹œê°í™”í•©ë‹ˆë‹¤.
                - ë¹¨ê°„ìƒ‰/ë°ì€ ì˜ì—­ = ë†’ì€ Attention (ì¤‘ìš”í•œ ë¶€ë¶„)
                - íŒŒë€ìƒ‰/ì–´ë‘ìš´ ì˜ì—­ = ë‚®ì€ Attention (ëœ ì¤‘ìš”í•œ ë¶€ë¶„)
                """)

                viz_col1, viz_col2 = st.columns([1, 2])

                with viz_col1:
                    st.markdown("**ğŸ›ï¸ ì‹œê°í™” ì„¤ì •**")

                    viz_mode = st.radio(
                        "ì‹œê°í™” ëª¨ë“œ",
                        ["Layer-wise (ë ˆì´ì–´ë³„)", "Head-wise (í—¤ë“œë³„)", "Attention Rollout"],
                        key="viz_mode",
                        help="""
                        - Layer-wise: ê° ë ˆì´ì–´ì˜ í‰ê·  Attention
                        - Head-wise: íŠ¹ì • ë ˆì´ì–´ì˜ ê° í—¤ë“œë³„ Attention
                        - Attention Rollout: ëª¨ë“  ë ˆì´ì–´ë¥¼ ëˆ„ì í•œ ìµœì¢… Attention
                        """
                    )

                    alpha = st.slider("ì˜¤ë²„ë ˆì´ íˆ¬ëª…ë„", 0.0, 1.0, 0.6, 0.1, key="alpha_slider")

                    if viz_mode == "Layer-wise (ë ˆì´ì–´ë³„)":
                        max_layers = st.slider("í‘œì‹œí•  ë ˆì´ì–´ ìˆ˜", 1, 12, 6, key="max_layers")
                        st.caption(f"Layer 1ë¶€í„° {max_layers}ê¹Œì§€ í‘œì‹œ")

                    elif viz_mode == "Head-wise (í—¤ë“œë³„)":
                        layer_idx = st.slider("ë ˆì´ì–´ ì„ íƒ", 0, 11, 5, key="layer_idx")
                        st.caption(f"Layer {layer_idx+1}ì˜ 12ê°œ í—¤ë“œ í‘œì‹œ")

                    elif viz_mode == "Attention Rollout":
                        discard_ratio = st.slider(
                            "Discard Ratio",
                            0.0, 0.95, 0.9, 0.05,
                            key="discard_ratio",
                            help="ë‚®ì€ Attention ê°’ì„ ì œê±°í•˜ëŠ” ë¹„ìœ¨ (ë†’ì„ìˆ˜ë¡ ì¤‘ìš”í•œ ì˜ì—­ë§Œ í‘œì‹œ)"
                        )

                    if st.button("ğŸ‘ï¸ Attention Map ìƒì„±", key="vis_attn", type="primary"):
                        with st.spinner("Attention ê³„ì‚° ì¤‘... (ì‹œê°„ì´ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤)"):
                            try:
                                model = st.session_state['vit_model']
                                processor = st.session_state['vit_processor']
                                pil_img = Image.open(uploaded_vit).convert('RGB')

                                if viz_mode == "Layer-wise (ë ˆì´ì–´ë³„)":
                                    overlays = get_attention_overlays(pil_img, model, processor, alpha=alpha, max_layers=max_layers)
                                    st.session_state['attention_result'] = overlays
                                elif viz_mode == "Head-wise (í—¤ë“œë³„)":
                                    head_overlays = get_attention_overlays_per_head(pil_img, model, processor, layer_idx=layer_idx, alpha=alpha)
                                    st.session_state['attention_result'] = head_overlays
                                elif viz_mode == "Attention Rollout":
                                    rollout_overlay = get_attention_rollout(pil_img, model, processor, alpha=alpha, discard_ratio=discard_ratio)
                                    st.session_state['attention_result'] = rollout_overlay
                                
                                st.session_state['attention_viz_mode'] = viz_mode
                                st.success("âœ… Attention ì‹œê°í™” ì™„ë£Œ!")

                            except Exception as e:
                                st.error(f"Attention ê³„ì‚° ì‹¤íŒ¨: {e}")
                                import traceback
                                st.text(traceback.format_exc())

                with viz_col2:
                    st.markdown("**ğŸ–¼ï¸ Attention ì‹œê°í™” ê²°ê³¼**")
                    if 'attention_result' in st.session_state:
                        viz_mode = st.session_state['attention_viz_mode']
                        result = st.session_state['attention_result']

                        if viz_mode == "Layer-wise (ë ˆì´ì–´ë³„)":
                            cols_per_row = 3
                            for i in range(0, len(result), cols_per_row):
                                cols = st.columns(cols_per_row)
                                for j, col in enumerate(cols):
                                    idx = i + j
                                    if idx < len(result):
                                        with col:
                                            st.image(result[idx], caption=f"Layer {idx+1}", use_column_width=True)
                        elif viz_mode == "Head-wise (í—¤ë“œë³„)":
                            cols_per_row = 4
                            for i in range(0, len(result), cols_per_row):
                                cols = st.columns(cols_per_row)
                                for j, col in enumerate(cols):
                                    idx = i + j
                                    if idx < len(result):
                                        with col:
                                            st.image(result[idx], caption=f"Head {idx+1}", use_column_width=True)
                        elif viz_mode == "Attention Rollout":
                            st.image(result, caption="Attention Rollout (ëˆ„ì )", use_column_width=True)
                            st.success("âœ… Attention Rollout: ëª¨ë“  ë ˆì´ì–´ì˜ attentionì„ ëˆ„ì í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ëª¨ë¸ì´ ì§‘ì¤‘í•˜ëŠ” ì˜ì—­ì„ ë³´ì—¬ì¤ë‹ˆë‹¤!")
                    else:
                        st.caption("ì™¼ìª½ì—ì„œ ì„¤ì • í›„ 'Attention Map ìƒì„±' ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”")
                        st.image("https://via.placeholder.com/400x300?text=Attention+Map+will+appear+here",
                                caption="Attention Mapì´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤")

            # Step 3: ì´ë¯¸ì§€ ë¶„ë¥˜
            if 'vit_model' in st.session_state:
                st.markdown("---")
                st.markdown("### 3ï¸âƒ£ ì´ë¯¸ì§€ ë¶„ë¥˜")

                if st.button("ğŸ”® ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œì‘", key="classify_btn", type="primary"):
                    with st.spinner("ViT ëª¨ë¸ë¡œ ë¶„ì„ ì¤‘..."):
                        try:
                            model = st.session_state['vit_model']
                            processor = st.session_state['vit_processor']
                            pil_img = Image.open(uploaded_vit).convert('RGB')

                            inputs = processor(images=pil_img, return_tensors="pt")
                            
                            with torch.no_grad():
                                outputs = model(**inputs)
                                logits = outputs.logits

                            # Top-5 ì˜ˆì¸¡
                            probs = torch.nn.functional.softmax(logits, dim=-1)
                            top5_probs, top5_indices = torch.topk(probs, 5)

                            st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                            st.markdown("#### ğŸ¯ Top-5 ì˜ˆì¸¡ ê²°ê³¼")

                            for i, (prob, idx) in enumerate(zip(top5_probs[0], top5_indices[0])):
                                label = model.config.id2label[idx.item()]
                                confidence = prob.item() * 100
                                st.markdown(f"**{i+1}. {label}** (`{confidence:.2f}%`)")
                                st.progress(confidence / 100)
                            
                        except Exception as e:
                            st.error(f"ë¶„ë¥˜ ì‹¤íŒ¨: {e}")


    def _render_dino_tab(self):
        """DINO & ìê¸°ì§€ë„í•™ìŠµ íƒ­ - ìƒì„¸í•˜ê³  ì§ê´€ì ì¸ ì„¤ëª…"""
        st.header("ğŸ¦– DINO & ìê¸°ì§€ë„í•™ìŠµ ì™„ì „ ì •ë³µ")

        st.info("""
        ğŸ’¡ **í•™ìŠµ ëª©í‘œ**: DINOê°€ ì–´ë–»ê²Œ ë ˆì´ë¸” ì—†ì´ë„ ì´ë¯¸ì§€ì˜ ì˜ë¯¸ë¥¼ ì´í•´í•˜ê³ ,
        ì™œ ìê¸°ì§€ë„í•™ìŠµì´ ë¯¸ë˜ì˜ AI í•™ìŠµ ë°©ë²•ì¸ì§€ ê¹Šì´ ìˆê²Œ ì´í•´í•©ë‹ˆë‹¤.
        """)

        # 1. ìê¸°ì§€ë„í•™ìŠµì˜ í˜ëª…
        with st.expander("ğŸ”¹ 1. ìê¸°ì§€ë„í•™ìŠµ - ë ˆì´ë¸” ì—†ëŠ” í•™ìŠµì˜ í˜ëª…", expanded=True):
            st.markdown("""
            ### ğŸ§  ì™œ ìê¸°ì§€ë„í•™ìŠµì¸ê°€?

            #### ğŸ“Š ì „í†µì  ì§€ë„í•™ìŠµì˜ í•œê³„
            """)

            col1, col2 = st.columns(2)

            with col1:
                st.markdown("""
                **âŒ ì§€ë„í•™ìŠµì˜ ë¬¸ì œì **

                - ğŸ“ **ë ˆì´ë¸” ë¹„ìš©**:
                  - ImageNet: 1.4M ì´ë¯¸ì§€ì— ìˆ˜ë°±ë§Œ ë‹¬ëŸ¬ íˆ¬ì…
                  - ì „ë¬¸ê°€ ì‹œê°„: ì´ë¯¸ì§€ë‹¹ í‰ê·  1-5ë¶„
                  - Medical/ìœ„ì„± ì´ë¯¸ì§€: ì „ë¬¸ê°€ë§Œ ë ˆì´ë¸”ë§ ê°€ëŠ¥

                - ğŸ”’ **í™•ì¥ì„± ì œí•œ**:
                  - ì¸í„°ë„·ì—ëŠ” ìˆ˜ì‹­ì–µ ê°œ ì´ë¯¸ì§€ ì¡´ì¬
                  - ë ˆì´ë¸”ëœ ë°ì´í„°ëŠ” ê·¹íˆ ì¼ë¶€
                  - ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ë§ˆë‹¤ ì¬ë ˆì´ë¸”ë§ í•„ìš”

                - ğŸ¯ **í¸í–¥ ë¬¸ì œ**:
                  - ë ˆì´ë¸”ëŸ¬ì˜ ì£¼ê´€ì´ ê°œì…
                  - ë¬¸í™”ì /ì§€ì—­ì  í¸í–¥ ë°œìƒ
                """)

            with col2:
                st.markdown("""
                **âœ… ìê¸°ì§€ë„í•™ìŠµì˜ í•´ê²°ì±…**

                - ğŸŒŠ **ë¬´í•œí•œ ë°ì´í„°**:
                  - ì¸í„°ë„·ì˜ ëª¨ë“  ì´ë¯¸ì§€ í™œìš© ê°€ëŠ¥
                  - ë¹„ìš© ì œë¡œ: ìë™ìœ¼ë¡œ ë ˆì´ë¸” ìƒì„±
                  - YouTube, Instagram ë“± ì‹¤ì‹œê°„ ë°ì´í„°

                - ğŸ§© **ë³¸ì§ˆì  í•™ìŠµ**:
                  - ë°ì´í„°ì˜ ë‚´ì¬ì  êµ¬ì¡° ë°œê²¬
                  - ì¸ê°„ì˜ ê°œì… ìµœì†Œí™”
                  - ë” ì¼ë°˜í™”ëœ í‘œí˜„ í•™ìŠµ

                - ğŸš€ **í™•ì¥ ê°€ëŠ¥**:
                  - ëª¨ë¸ í¬ê¸°ì— ë¹„ë¡€í•œ ì„±ëŠ¥ í–¥ìƒ
                  - GPT-4, DALL-E ë“±ì˜ ê¸°ë°˜
                """)

            st.markdown("---")

            # ìê¸°ì§€ë„í•™ìŠµ ë¹„ìœ 
            st.markdown("""
            #### ğŸ“ ì§ê´€ì  ì´í•´: ì•„ê¸°ê°€ ì„¸ìƒì„ ë°°ìš°ëŠ” ë°©ë²•

            | í•™ìŠµ ë°©ë²• | ë¹„ìœ  | ì˜ˆì‹œ |
            |---------|------|-----|
            | **ì§€ë„í•™ìŠµ** | ë¶€ëª¨ê°€ "ì´ê±´ ê°œì•¼, ì´ê±´ ê³ ì–‘ì´ì•¼"ë¼ê³  ì¼ì¼ì´ ê°€ë¥´ì¹¨ | ImageNet ë ˆì´ë¸”ë§ |
            | **ìê¸°ì§€ë„í•™ìŠµ** | ì•„ê¸°ê°€ ìŠ¤ìŠ¤ë¡œ ê´€ì°°í•˜ë©° íŒ¨í„´ ë°œê²¬ | DINOê°€ ì´ë¯¸ì§€ êµ¬ì¡° í•™ìŠµ |
            | **ê²°ê³¼** | ì•„ê¸°ëŠ” ëª…ì‹œì ìœ¼ë¡œ ë°°ìš°ì§€ ì•Šì€ ê²ƒë„ ì´í•´ (ë¬¼ë¦¬ ë²•ì¹™, ì¤‘ë ¥ ë“±) | DINOëŠ” ê°ì²´ ê²½ê³„, ì˜ë¯¸ë¡ ì  ê·¸ë£¹ ìë™ ë°œê²¬ |
            """)

        # 2. DINO ì•„í‚¤í…ì²˜ ìƒì„¸ ì„¤ëª…
        with st.expander("ğŸ”¹ 2. DINO ì•„í‚¤í…ì²˜ - Teacherì™€ Studentì˜ ì§€ì‹ ì¦ë¥˜", expanded=False):
            st.markdown("""
            ### ğŸ—ï¸ DINOì˜ í•µì‹¬ êµ¬ì¡°

            #### ğŸ¯ Knowledge Distillation (ì§€ì‹ ì¦ë¥˜)ë€?
            """)

            st.info("""
            **ğŸ· ì™€ì¸ ì¦ë¥˜ ë¹„ìœ **:
            - ì™€ì¸(Teacher): ë³µì¡í•˜ê³  í’ë¶€í•œ ë§›
            - ì¦ë¥˜ì£¼(Student): í•µì‹¬ ë§›ë§Œ ë†ì¶•
            - **DINO**: Teacherì˜ ì§€ì‹ì„ Studentê°€ ì¦ë¥˜í•˜ì—¬ í•™ìŠµ
            """)

            st.markdown("""
            #### ğŸ”„ DINO í•™ìŠµ í”„ë¡œì„¸ìŠ¤ (ë‹¨ê³„ë³„)
            """)

            # DINO í”„ë¡œì„¸ìŠ¤ë¥¼ íƒ­ìœ¼ë¡œ êµ¬ì„±
            process_tabs = st.tabs(["1ï¸âƒ£ ì…ë ¥ ì¦ê°•", "2ï¸âƒ£ ì´ì¤‘ ë„¤íŠ¸ì›Œí¬", "3ï¸âƒ£ ì¶œë ¥ ë¹„êµ", "4ï¸âƒ£ ì—­ì „íŒŒ í•™ìŠµ", "5ï¸âƒ£ Teacher ì—…ë°ì´íŠ¸"])

            with process_tabs[0]:
                st.markdown("""
                ### ğŸ“¸ Step 1: ì…ë ¥ ì´ë¯¸ì§€ ì¦ê°• (Augmentation)

                **ê°™ì€ ì´ë¯¸ì§€, ë‹¤ë¥¸ ì‹œê°**

                ```
                ì›ë³¸ ì´ë¯¸ì§€ (ê³ ì–‘ì´)
                        â†“
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚                â”‚
                Global Crop 1    Local Crop 1
                (ì „ì²´ ë³´ê¸°)       (ì–¼êµ´ í´ë¡œì¦ˆì—…)
                    â†“                â†“
                Global Crop 2    Local Crop 2
                (ì•½ê°„ íšŒì „)      (ë°œ í´ë¡œì¦ˆì—…)
                ```

                **ğŸ’¡ ì™œ ì—¬ëŸ¬ Cropì„ ë§Œë“œë‚˜?**
                - **Global view (224Ã—224)**: ì „ì²´ ë§¥ë½ ì´í•´ (ê³ ì–‘ì´ê°€ ì•‰ì•„ìˆë‹¤)
                - **Local view (96Ã—96)**: ì„¸ë¶€ íŠ¹ì§• í•™ìŠµ (ê·€ê°€ ë¾°ì¡±í•˜ë‹¤, ìˆ˜ì—¼ì´ ìˆë‹¤)
                - **ì¼ê´€ì„± ê°•ì œ**: ê°™ì€ ê³ ì–‘ì´ì˜ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì´ ì¼ê´€ëœ í‘œí˜„ì„ ê°€ì ¸ì•¼ í•¨

                **ğŸ“Š ì¦ê°• ê¸°ë²•**:
                - Random Crop: ìœ„ì¹˜ ë¶ˆë³€ì„±
                - Color Jitter: ì¡°ëª… ë¶ˆë³€ì„±
                - Gaussian Blur: ë…¸ì´ì¦ˆ ê°•ê±´ì„±
                - Horizontal Flip: ë°©í–¥ ë¶ˆë³€ì„±
                """)

            with process_tabs[1]:
                st.markdown("""
                ### ğŸ‘¥ Step 2: Teacher-Student ì´ì¤‘ ë„¤íŠ¸ì›Œí¬

                **ê°™ì€ êµ¬ì¡°, ë‹¤ë¥¸ ì—­í• **

                ```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚         ì…ë ¥: ê³ ì–‘ì´ ì´ë¯¸ì§€              â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                 â”‚
                ğŸ“š Teacher          ğŸ“ Student
                (ì•ˆì •ëœ ì§€ì‹)        (ë°°ìš°ëŠ” ì¤‘)
                    â”‚                 â”‚
                ViT Backbone      ViT Backbone
                (ë™ì¼ êµ¬ì¡°)        (ë™ì¼ êµ¬ì¡°)
                    â”‚                 â”‚
                ì¶œë ¥ í™•ë¥  ë¶„í¬      ì¶œë ¥ í™•ë¥  ë¶„í¬
                [0.1, 0.8, 0.1]  [0.2, 0.6, 0.2]
                ```

                **ğŸ’¡ ì—­í•  êµ¬ë¶„**:

                | íŠ¹ì„± | Teacher ğŸ§‘â€ğŸ« | Student ğŸ“ |
                |------|------------|-----------|
                | **íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸** | EMA (ì²œì²œíˆ) | Gradient Descent (ë¹ ë¥´ê²Œ) |
                | **ì…ë ¥** | Global viewsë§Œ | Global + Local views |
                | **ì—­í• ** | ì•ˆì •ì  ì§€ì‹ ì œê³µ | ì ê·¹ì ìœ¼ë¡œ í•™ìŠµ |
                | **ë¹„ìœ ** | ê²½í—˜ ë§ì€ êµìˆ˜ | ì—´ì‹¬íˆ ë°°ìš°ëŠ” í•™ìƒ |

                **ğŸ”‘ í•µì‹¬ ì•„ì´ë””ì–´**:
                - TeacherëŠ” **ì•ˆì •ì ì¸ ëª©í‘œ**ë¥¼ ì œê³µ (Moving Target ë¬¸ì œ ë°©ì§€)
                - StudentëŠ” **ë‹¤ì–‘í•œ ê´€ì **ì—ì„œ ë°°ì›€ (Local crops í¬í•¨)
                - ê°™ì€ ì´ë¯¸ì§€ì— ëŒ€í•´ Teacherì™€ Studentì˜ ì¶œë ¥ì´ **ì¼ì¹˜**í•´ì•¼ í•¨
                """)

            with process_tabs[2]:
                st.markdown("""
                ### ğŸ“Š Step 3: ì¶œë ¥ í™•ë¥  ë¶„í¬ ë¹„êµ

                **Cross-Entropy Lossë¡œ ìœ ì‚¬ë„ ì¸¡ì •**

                ```
                Teacher ì¶œë ¥ (Global Crop 1):
                ê³ ì–‘ì´: 80% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                ê°œ:     10% â–ˆâ–ˆ
                ìƒˆ:     10% â–ˆâ–ˆ

                Student ì¶œë ¥ (Local Crop - ê·€ ë¶€ë¶„):
                ê³ ì–‘ì´: 60% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ
                ê°œ:     25% â–ˆâ–ˆâ–ˆ
                ìƒˆ:     15% â–ˆâ–ˆâ–ˆ

                âŒ Loss = 0.45 (ë¶ˆì¼ì¹˜!)
                â†’ Student ì—…ë°ì´íŠ¸ í•„ìš”
                ```

                **ğŸ’¡ Loss Function**:

                ```python
                # Cross-Entropy between Teacher and Student
                loss = -sum(teacher_prob * log(student_prob))

                # ì˜ˆì‹œ:
                teacher = [0.8, 0.1, 0.1]  # ê³ ì–‘ì´ì— í™•ì‹ 
                student = [0.6, 0.25, 0.15]  # ëœ í™•ì‹ 
                loss = -(0.8*log(0.6) + 0.1*log(0.25) + 0.1*log(0.15))
                     = 0.45  # ë†’ì€ loss â†’ ë§ì´ ë‹¤ë¦„
                ```

                **ğŸ¯ í•™ìŠµ ëª©í‘œ**:
                - Studentê°€ Local crop (ê·€ë§Œ ë³´ê³ )ë„ Teacherì²˜ëŸ¼ "ê³ ì–‘ì´"ë¼ê³  í™•ì‹ í•˜ë„ë¡
                - ë¶€ë¶„ë§Œ ë´ë„ ì „ì²´ë¥¼ ì´í•´í•˜ëŠ” ëŠ¥ë ¥ í•™ìŠµ
                """)

            with process_tabs[3]:
                st.markdown("""
                ### ğŸ”„ Step 4: Studentë§Œ ì—­ì „íŒŒ í•™ìŠµ

                **TeacherëŠ” ê³ ì •, Studentë§Œ ì—…ë°ì´íŠ¸**

                ```
                Loss = 0.45 (ë†’ìŒ)
                    â†“
                Gradient ê³„ì‚°
                    â†“
                Student íŒŒë¼ë¯¸í„° ì—…ë°ì´íŠ¸ âœ…
                    â†“
                ë‹¤ìŒ iteration:
                Student ì¶œë ¥ ê°œì„ 
                ê³ ì–‘ì´: 70% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (60%â†’70% í–¥ìƒ!)
                ê°œ:     18% â–ˆâ–ˆ
                ìƒˆ:     12% â–ˆâ–ˆ

                Loss = 0.25 (ê°ì†Œ!)
                ```

                **ğŸ’¡ ì™œ TeacherëŠ” ì—…ë°ì´íŠ¸ ì•ˆ í•˜ë‚˜?**

                - âŒ **ë§Œì•½ ë‘˜ ë‹¤ ì—…ë°ì´íŠ¸í•˜ë©´**:
                  - Moving Target ë¬¸ì œ ë°œìƒ
                  - Teacherë„ ê³„ì† ë°”ë€Œë©´ Studentê°€ ë­˜ ë”°ë¼ê°€ì•¼ í• ì§€ ëª¨ë¦„
                  - í•™ìŠµ ë¶ˆì•ˆì • (Collapse)

                - âœ… **Teacher ê³ ì • ì‹œ**:
                  - ì•ˆì •ì ì¸ í•™ìŠµ ëª©í‘œ ì œê³µ
                  - StudentëŠ” ëª…í™•í•œ ë°©í–¥ìœ¼ë¡œ ê°œì„ 
                  - ì ì§„ì  ì§€ì‹ ì¶•ì 

                **ğŸ“ˆ í•™ìŠµë¥  ì°¨ì´**:
                - Student: lr = 0.001 (ë¹ ë¥´ê²Œ ë³€í™”)
                - Teacher: EMAë¡œ ì²œì²œíˆ ë°˜ì˜
                """)

            with process_tabs[4]:
                st.markdown("""
                ### ğŸŒ Step 5: Teacherì˜ EMA ì—…ë°ì´íŠ¸

                **Exponential Moving Average (ì§€ìˆ˜ ì´ë™ í‰ê· )**

                ```python
                # TeacherëŠ” Studentì˜ 'ê³¼ê±° í‰ê· '
                teacher_params = 0.996 * teacher_params + 0.004 * student_params
                ```

                **ğŸ’¡ EMAì˜ ì˜ë¯¸**:

                | Iteration | Student Weight | Teacher Weight | ì„¤ëª… |
                |-----------|---------------|----------------|------|
                | 1 | 1.0 | 1.0 | ì‹œì‘ì  ë™ì¼ |
                | 2 | 1.5 (ê¸‰ë³€) | 1.002 | TeacherëŠ” ê±°ì˜ ì•ˆ ë³€í•¨ |
                | 3 | 1.3 (ìš”ë™) | 1.003 | |
                | ... | ... | ... | |
                | 100 | 2.1 | 1.8 | TeacherëŠ” í‰ê· ê°’ ìœ ì§€ |

                **ğŸ¯ ì™œ EMAë¥¼ ì“°ë‚˜?**

                1. **ì•ˆì •ì„±**: TeacherëŠ” Studentì˜ 'ìš”ë™'ì„ í‰í™œí™”
                2. **ê³¼ê±° ì§€ì‹ ë³´ì¡´**: ì´ì „ í•™ìŠµ ë‚´ìš©ì„ ì„œì„œíˆ ë°˜ì˜
                3. **Collapse ë°©ì§€**: ê¸‰ê²©í•œ ë³€í™” ë°©ì§€

                **ğŸ”¬ Momentum ê³„ìˆ˜ ì˜í–¥**:
                ```
                m = 0.99:  Teacherê°€ Studentë¥¼ ë¹ ë¥´ê²Œ ë”°ë¼ê° (ë¶ˆì•ˆì •)
                m = 0.996: ê· í˜•ì¡íŒ ì—…ë°ì´íŠ¸ (DINO ê¸°ë³¸ê°’)
                m = 0.999: Teacherê°€ ê±°ì˜ ì•ˆ ë³€í•¨ (í•™ìŠµ ëŠë¦¼)
                ```
                """)

        # 3. DINO vs ì§€ë„í•™ìŠµ ë¹„êµ
        with st.expander("ğŸ”¹ 3. DINOì˜ ë†€ë¼ìš´ ëŠ¥ë ¥ - ë ˆì´ë¸” ì—†ì´ ì˜ë¯¸ë¥¼ ë°œê²¬í•œë‹¤", expanded=False):
            st.markdown("""
            ### ğŸ¨ Self-Attentionìœ¼ë¡œ ë³¸ DINOì˜ ì‹œê°

            #### ğŸ“¸ ì‚¬ë¡€ ì—°êµ¬: ê°•ì•„ì§€ ì´ë¯¸ì§€
            """)

            comparison_tabs = st.tabs(["ì§€ë„í•™ìŠµ ViT", "DINO ViT", "ì°¨ì´ì  ë¶„ì„"])

            with comparison_tabs[0]:
                st.markdown("""
                ### ğŸ“š ì§€ë„í•™ìŠµ ViTì˜ Attention

                **ë ˆì´ë¸”: "ê°œ"ë¡œ í•™ìŠµë¨**

                ```
                Attention Map:
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   ğŸ• ê°•ì•„ì§€      â”‚  â†’ ê°•í•œ attention
                â”‚   (ì „ì²´ ì˜ì—­)    â”‚     (ë ˆì´ë¸”ì´ "ê°œ"ë¼ê³  ì•Œë ¤ì¤Œ)
                â”‚                 â”‚
                â”‚   ğŸŒ³ ë°°ê²½        â”‚  â†’ ì•½í•œ attention
                â”‚   ğŸŒ¿ í’€          â”‚     (ê´€ë ¨ ì—†ë‹¤ê³  í•™ìŠµ)
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                í•™ìŠµ ê³¼ì •:
                1. ë ˆì´ë¸” "ê°œ" ì œê³µ
                2. "ê°œ" ì˜ì—­ì— ì§‘ì¤‘í•˜ë„ë¡ í•™ìŠµ
                3. ë°°ê²½ì€ ë¬´ì‹œ
                ```

                **âŒ í•œê³„**:
                - ë ˆì´ë¸”ì— ëª…ì‹œëœ ê²ƒë§Œ í•™ìŠµ
                - ë°°ê²½ì˜ ì˜ë¯¸ë¡ ì  ì •ë³´ ì†ì‹¤
                - "í’€ë°­ ìœ„ì˜ ê°œ"ë¼ëŠ” ë§¥ë½ ì´í•´ ë¶€ì¡±
                """)

            with comparison_tabs[1]:
                st.markdown("""
                ### ğŸ¦– DINOì˜ Attention

                **ë ˆì´ë¸” ì—†ìŒ - ìŠ¤ìŠ¤ë¡œ ë°œê²¬**

                ```
                Attention Map:
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   ğŸ• ê°•ì•„ì§€      â”‚  â†’ ê°•í•œ attention (Group 1)
                â”‚   [ì–¼êµ´+ëª¸í†µ+ê¼¬ë¦¬]â”‚     ê°ì²´ ê²½ê³„ ìë™ ë°œê²¬!
                â”‚                 â”‚
                â”‚   ğŸŒ³ ë‚˜ë¬´        â”‚  â†’ ì¤‘ê°„ attention (Group 2)
                â”‚   ğŸŒ¿ í’€          â”‚  â†’ ì•½í•œ attention (Group 3)
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

                ë°œê²¬í•œ ê²ƒë“¤:
                âœ… ê°ì²´ ê²½ê³„ (ê°œì˜ ìœ¤ê³½ì„ )
                âœ… ë¶€ë¶„-ì „ì²´ ê´€ê³„ (ê·€, ë°œ, ê¼¬ë¦¬ê°€ í•˜ë‚˜ì˜ ê°œì²´)
                âœ… ì˜ë¯¸ë¡ ì  ê·¸ë£¹ (ê°œ/ë‚˜ë¬´/í’€ ê°ê° ë‹¤ë¥¸ ê·¸ë£¹)
                âœ… ì „ê²½-ë°°ê²½ ë¶„ë¦¬
                ```

                **âœ¨ ë†€ë¼ìš´ ì **:
                - **ëª…ì‹œì  ë ˆì´ë¸” ì—†ì´** ê°ì²´ ê²½ê³„ ë°œê²¬
                - **Segmentation ì •ë³´ ì—†ì´** ì˜ì—­ ë¶„í• 
                - **ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ì´** ì˜ë¯¸ë¡ ì  ê·¸ë£¹í™”
                """)

            with comparison_tabs[2]:
                st.markdown("""
                ### ğŸ”¬ ì™œ DINOê°€ ì´ëŸ° ëŠ¥ë ¥ì„ ê°–ê²Œ ë˜ë‚˜?

                #### ğŸ§© í•™ìŠµ ë©”ì»¤ë‹ˆì¦˜ ë¹„êµ

                | ì¸¡ë©´ | ì§€ë„í•™ìŠµ ViT | DINO |
                |------|-------------|------|
                | **í•™ìŠµ ì‹ í˜¸** | ì™¸ë¶€ ë ˆì´ë¸” | ë‚´ë¶€ ì¼ê´€ì„± |
                | **ëª©í‘œ** | ë ˆì´ë¸” ë§ì¶”ê¸° | ë‹¤ë¥¸ view ì¼ì¹˜ì‹œí‚¤ê¸° |
                | **ë°œê²¬ ë²”ìœ„** | ë ˆì´ë¸”ëœ ê²ƒë§Œ | ì´ë¯¸ì§€ì˜ ëª¨ë“  êµ¬ì¡° |
                | **ì¼ë°˜í™”** | ì œí•œì  | ê°•ë ¥í•¨ |

                #### ğŸ’¡ DINOì˜ í•™ìŠµ ì›ë¦¬

                ```
                Global View (ì „ì²´ ê°•ì•„ì§€):
                "ì´ ì´ë¯¸ì§€ëŠ” ê°œì²´ Aì™€ ë°°ê²½ Bë¡œ êµ¬ì„±"

                Local View (ê°•ì•„ì§€ ì–¼êµ´ë§Œ):
                "ì´ ë¶€ë¶„ì€ ê°œì²´ Aì˜ ì¼ë¶€"

                â†’ Teacher-Student ì¼ì¹˜ ì¡°ê±´:
                "Local viewë„ Global viewì™€ ê°™ì€ ê°œì²´ Aë¡œ ì¸ì‹í•´ì•¼"

                â†’ ê²°ê³¼:
                ê°œì²´ Aì˜ ëª¨ë“  ë¶€ë¶„ì´ ì¼ê´€ëœ í‘œí˜„ì„ ê°€ì§
                = ê°ì²´ ê²½ê³„ ìë™ ë°œê²¬!
                ```

                #### ğŸ¯ ì‹¤ì œ ëŠ¥ë ¥ ë¹„êµ

                **1. Zero-Shot Segmentation**:
                ```
                DINO: Attention mapì´ ê³§ segmentation mask
                ì§€ë„í•™ìŠµ: ë³„ë„ì˜ segmentation í•™ìŠµ í•„ìš”
                ```

                **2. ë¶€ë¶„-ì „ì²´ ì´í•´**:
                ```
                DINO: "ê°•ì•„ì§€ ê·€"ë¥¼ ë³´ê³  "ê°•ì•„ì§€ ì „ì²´" ì¶”ë¡ 
                ì§€ë„í•™ìŠµ: "ê°œ" ë ˆì´ë¸”ë§Œ í•™ìŠµ, ë¶€ë¶„ ê´€ê³„ ëª¨ë¦„
                ```

                **3. ìƒˆë¡œìš´ ì¹´í…Œê³ ë¦¬ ì ì‘**:
                ```
                DINO: ë³¸ ì  ì—†ëŠ” ê°ì²´ë„ ê²½ê³„ ë°œê²¬ ê°€ëŠ¥
                ì§€ë„í•™ìŠµ: ì¬í•™ìŠµ í•„ìš”
                ```
                """)

        # 4. DINO ì‹œë¦¬ì¦ˆ ë°œì „ì‚¬
        with st.expander("ğŸ”¹ 4. DINO ì§„í™” - v1ì—ì„œ v3ê¹Œì§€", expanded=False):
            st.markdown("""
            ### ğŸ“ˆ DINO ì‹œë¦¬ì¦ˆ ë°œì „ ê³¼ì •
            """)

            evolution_data = {
                "ëª¨ë¸": ["DINO (v1)", "DINOv2", "DINOv3"],
                "ì¶œì‹œ": ["2021.04", "2023.04", "2025.08"],
                "íŒŒë¼ë¯¸í„°": ["22M - 632M", "300M - 1B", "7B"],
                "í•™ìŠµ ë°ì´í„°": ["ImageNet (1.4M)", "LVD-142M", "Unlabeled Web (ìˆ˜ì–µ)"],
                "ì£¼ìš” í˜ì‹ ": [
                    "Self-distillation ë„ì…",
                    "ëŒ€ê·œëª¨ í•™ìŠµ, ë” ê°•í•œ íŠ¹ì§•",
                    "7B ê·œëª¨, SOTA ì„±ëŠ¥"
                ],
                "ImageNet Top-1": ["79.3%", "84.5%", "87.1%"],
                "íŠ¹ì§•": [
                    "ViT + ìê¸°ì§€ë„í•™ìŠµ",
                    "Improved data augmentation",
                    "ìµœì‹  SOTA"
                ]
            }

            st.table(evolution_data)

            st.markdown("""
            #### ğŸš€ ì£¼ìš” ê°œì„  ì‚¬í•­

            **DINO â†’ DINOv2**:
            1. **í•™ìŠµ ë°ì´í„° 100ë°° ì¦ê°€**: 1.4M â†’ 142M
            2. **ëª¨ë¸ í¬ê¸° í™•ëŒ€**: ìµœëŒ€ 632M â†’ 1B
            3. **ê°œì„ ëœ ì¦ê°• ê¸°ë²•**: Stronger augmentation
            4. **ì„±ëŠ¥ í–¥ìƒ**: ImageNet 79.3% â†’ 84.5%

            **DINOv2 â†’ DINOv3**:
            1. **ê±°ëŒ€ ëª¨ë¸**: 7B íŒŒë¼ë¯¸í„° (GPT-3ê¸‰)
            2. **ì›¹ ê·œëª¨ í•™ìŠµ**: ìˆ˜ì–µ ê°œ unlabeled ì´ë¯¸ì§€
            3. **SOTA ë‹¬ì„±**: 87.1% ImageNet ì •í™•ë„
            4. **ê°•ë ¥í•œ ì „ì´ í•™ìŠµ**: ê±°ì˜ ëª¨ë“  vision taskì—ì„œ ìš°ìˆ˜

            #### ğŸ’¡ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ (Scaling Law)

            ```
            ëª¨ë¸ í¬ê¸° â†‘ + ë°ì´í„° ì–‘ â†‘ = ì„±ëŠ¥ â†‘

            DINO v1:   22M params,  1.4M images  â†’ 79.3%
            DINOv2:    1B params,   142M images  â†’ 84.5%
            DINOv3:    7B params,   ìˆ˜ì–µ images  â†’ 87.1%

            â†’ ìê¸°ì§€ë„í•™ìŠµë„ ìŠ¤ì¼€ì¼ë§ ë²•ì¹™ ì ìš©!
            ```
            """)

        # 5. ì‹¤ìŠµ: DINO Attention ì‹œê°í™”
        with st.expander("ğŸ”¹ 5. ì‹¤ìŠµ: DINOì˜ ëˆˆìœ¼ë¡œ ì´ë¯¸ì§€ ë³´ê¸°", expanded=True):
            st.markdown("""
            ### ğŸ¨ DINO Attention Map ì‹œê°í™”

            **DINOê°€ ì´ë¯¸ì§€ì—ì„œ ë¬´ì—‡ì„ "ë³´ëŠ”ì§€" í™•ì¸í•´ë³´ì„¸ìš”!**

            #### ğŸ“Œ ê¸°ëŒ€ íš¨ê³¼:
            - âœ… ê°ì²´ ê²½ê³„ê°€ ìë™ìœ¼ë¡œ ë°œê²¬ë¨
            - âœ… ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ìœ ì‚¬í•œ ì˜ì—­ì´ ê·¸ë£¹í™”ë¨
            - âœ… ì „ê²½ê³¼ ë°°ê²½ì´ ëª…í™•íˆ ë¶„ë¦¬ë¨
            """)

            st.warning("""
            âš ï¸ **ì°¸ê³ **:
            - ì´ ë°ëª¨ëŠ” DINOì˜ ê°œë…ì„ ì„¤ëª…í•˜ê¸° ìœ„í•œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤
            - ì‹¤ì œ DINO ëª¨ë¸ êµ¬í˜„ì€ **ì‹¤ì „ í”„ë¡œì íŠ¸** íƒ­ì—ì„œ í™•ì¸í•˜ì„¸ìš”
            - HuggingFaceì˜ `facebook/dino-vits16` ëª¨ë¸ ì‚¬ìš© ì˜ˆì œ ì œê³µ
            """)

            st.markdown("---")

            uploaded_dino = st.file_uploader(
                "ğŸ–¼ï¸ ì´ë¯¸ì§€ ì—…ë¡œë“œ (DINO ë¶„ì„ìš©)",
                type=['png', 'jpg', 'jpeg'],
                key="dino_upload",
                help="ëª…í™•í•œ ê°ì²´ê°€ ìˆëŠ” ì´ë¯¸ì§€ë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤ (ì˜ˆ: ë™ë¬¼, ì‚¬ëŒ, ì°¨ëŸ‰ ë“±)"
            )

            if uploaded_dino:
                from PIL import Image
                import numpy as np
                import matplotlib.pyplot as plt

                col1, col2 = st.columns(2)

                with col1:
                    st.image(uploaded_dino, caption="ğŸ“¸ ì…ë ¥ ì´ë¯¸ì§€", use_container_width=True)

                with col2:
                    if st.button("ğŸ” DINO Attention ë¶„ì„", key="run_dino", type="primary"):
                        with st.spinner("ğŸ¦– DINOê°€ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ëŠ” ì¤‘..."):
                            # ê°„ë‹¨í•œ ì‹œë®¬ë ˆì´ì…˜: ì¤‘ì‹¬ ì˜ì—­ì— ë†’ì€ attention
                            image = Image.open(uploaded_dino).convert('RGB')
                            img_array = np.array(image)
                            h, w = img_array.shape[:2]

                            # ì¤‘ì‹¬ì— ê°€ìš°ì‹œì•ˆ attention map ìƒì„±
                            y, x = np.ogrid[0:h, 0:w]
                            center_y, center_x = h // 2, w // 2
                            attention_map = np.exp(-((x - center_x)**2 + (y - center_y)**2) / (min(h, w) * 30))

                            # ì‹œê°í™”
                            fig, ax = plt.subplots(figsize=(8, 8))
                            ax.imshow(img_array)
                            ax.imshow(attention_map, cmap='jet', alpha=0.5)
                            ax.set_title("DINO Attention Map (Simulated)", fontsize=14, pad=10)
                            ax.axis('off')
                            st.pyplot(fig)
                            plt.close()

                        st.success("âœ… ë¶„ì„ ì™„ë£Œ!")

                        st.info("""
                        ğŸ’¡ **DINOê°€ ë°œê²¬í•œ ê²ƒë“¤**:

                        ğŸ”´ **ë¹¨ê°„ìƒ‰ ì˜ì—­ (High Attention)**:
                        - ì£¼ìš” ê°ì²´ì˜ ì¤‘ì‹¬ë¶€
                        - ì˜ë¯¸ë¡ ì ìœ¼ë¡œ ì¤‘ìš”í•œ ë¶€ë¶„

                        ğŸ”µ **íŒŒë€ìƒ‰ ì˜ì—­ (Low Attention)**:
                        - ë°°ê²½ ë˜ëŠ” ëœ ì¤‘ìš”í•œ ì˜ì—­

                        **ğŸ¯ ì‹¤ì œ DINOì˜ ëŠ¥ë ¥**:
                        - ê°ì²´ ê²½ê³„ë¥¼ í”½ì…€ ë‹¨ìœ„ë¡œ ì •í™•íˆ ë°œê²¬
                        - ê°™ì€ ê°ì²´ì˜ ë‹¤ë¥¸ ë¶€ë¶„ë“¤ì„ í•˜ë‚˜ë¡œ ê·¸ë£¹í™”
                        - ì—¬ëŸ¬ ê°ì²´ê°€ ìˆì„ ë•Œ ê°ê°ì„ ë¶„ë¦¬
                        """)

                        st.markdown("""
                        #### ğŸš€ ë” ì•Œì•„ë³´ê¸°

                        **ì‹¤ì œ DINO êµ¬í˜„**:
                        - ğŸ‘‰ **ì‹¤ì „ í”„ë¡œì íŠ¸** íƒ­ì—ì„œ HuggingFace DINO ëª¨ë¸ ì‚¬ìš©ë²• í™•ì¸
                        - `facebook/dino-vits16` ë˜ëŠ” `facebook/dinov2-base` ì‚¬ìš©

                        **ì‘ìš© ë¶„ì•¼**:
                        - ğŸ¨ Zero-shot Semantic Segmentation
                        - ğŸ” Object Discovery (ê°ì²´ ë°œê²¬)
                        - ğŸ–¼ï¸ Image Retrieval (ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰)
                        - ğŸ¤– ë¡œë´‡ ë¹„ì „ (ë ˆì´ë¸” ì—†ì´ ê°ì²´ ì¸ì‹)
                        """)
            else:
                st.info("ğŸ‘† ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•˜ë©´ DINOì˜ Attentionì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

                # ì˜ˆì‹œ ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
                st.markdown("""
                #### ğŸ“š ì˜ˆì‹œ: DINO Attentionì˜ ì‹¤ì œ ëª¨ìŠµ

                **ê°•ì•„ì§€ ì´ë¯¸ì§€ ì˜ˆì‹œ**:
                ```
                ì…ë ¥ ì´ë¯¸ì§€:        DINO Attention:
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚  ğŸ•     â”‚   â†’   â”‚ ğŸ”´ğŸ”´ğŸ”´  â”‚  ê°•ì•„ì§€ ì˜ì—­: ê°•í•œ attention
                â”‚    ğŸŒ³   â”‚        â”‚ ğŸ”´ğŸ”´  ğŸ”µâ”‚  ë°°ê²½: ì•½í•œ attention
                â”‚  ğŸŒ¿ğŸŒ¿   â”‚        â”‚ ğŸ”µğŸ”µğŸ”µ  â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                ```

                **ğŸ’¡ ë†€ë¼ìš´ ì **:
                - ë ˆì´ë¸” ì—†ì´ë„ ê°•ì•„ì§€ ìœ¤ê³½ì„ ì„ ì •í™•íˆ ì°¾ì•„ëƒ„
                - ê°•ì•„ì§€ì˜ ê·€, ë°œ, ê¼¬ë¦¬ë¥¼ í•˜ë‚˜ì˜ ê°ì²´ë¡œ ì¸ì‹
                - ë°°ê²½(ë‚˜ë¬´, í’€)ì€ ìë™ìœ¼ë¡œ ì œì™¸
                """)

    def _render_benchmark_tab(self):
        """ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ íƒ­ - 2024-2025 ìµœì‹  ëª¨ë¸ í¬í•¨"""
        st.header("ğŸ“Š Vision ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ (2020-2025)")

        st.info("""
        ğŸ’¡ **Vision Transformerì˜ ì§„í™”**: 2020ë…„ ViT ë“±ì¥ ì´í›„ 5ë…„ê°„ ê¸‰ê²©í•œ ë°œì „!
        - 2020: ViT (86M)
        - 2021: DINO (22M)
        - 2023: SAM (632M), DINOv2 (300M)
        - 2024: EVA-CLIP-18B (18B), InternVL3 (78B), SAM 2
        - 2025: DINOv3 (7B), SigLIP 2
        """)

        st.markdown("---")

        # ì‹œëŒ€ë³„ íƒ­
        era_tabs = st.tabs(["ğŸ›ï¸ í´ë˜ì‹ (2020-2022)", "ğŸš€ ìµœì‹  (2024-2025)", "ğŸ“Š ì „ì²´ ë¹„êµ"])

        with era_tabs[0]:
            st.markdown("### ğŸ›ï¸ ì´ˆê¸° Vision Transformer ëª¨ë¸ (2020-2022)")

            classic_data = {
                "ëª¨ë¸": ["ResNet-50", "ViT-Base/16", "ViT-Large/16", "DINO ViT-S", "DeiT-Base"],
                "ì¶œì‹œë…„ë„": ["2015", "2020", "2020", "2021", "2021"],
                "íŒŒë¼ë¯¸í„°": ["25M", "86M", "307M", "22M", "86M"],
                "ImageNet Acc": ["76.2%", "81.8%", "82.6%", "79.3%", "81.8%"],
                "ì£¼ìš” íŠ¹ì§•": [
                    "CNN ê¸°ë°˜, ë¹ ë¥¸ ì¶”ë¡ ",
                    "ìµœì´ˆ ViT, ëŒ€ìš©ëŸ‰ ë°ì´í„° í•„ìš”",
                    "ë†’ì€ ì •í™•ë„, ë§ì€ íŒŒë¼ë¯¸í„°",
                    "ìê¸°ì§€ë„í•™ìŠµ, ë¼ë²¨ ë¶ˆí•„ìš”",
                    "ì§€ì‹ ì¦ë¥˜, íš¨ìœ¨ì  í•™ìŠµ"
                ]
            }

            st.table(classic_data)

            st.success("""
            **ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸:**
            - ViTê°€ CNNì„ ëŠ¥ê°€í•˜ë©° Transformer ì‹œëŒ€ ê°œë§‰
            - DINOë¡œ ìê¸°ì§€ë„í•™ìŠµì˜ ê°€ëŠ¥ì„± ì…ì¦
            - DeiTë¡œ íš¨ìœ¨ì  í•™ìŠµ ë°©ë²• ì œì‹œ
            """)

        with era_tabs[1]:
            st.markdown("### ğŸš€ ìµœì‹  SOTA ëª¨ë¸ (2024-2025)")

            modern_data = {
                "ëª¨ë¸": [
                    "DINOv3 (Meta)",
                    "SAM 2 (Meta)",
                    "InternVL3-78B",
                    "EVA-CLIP-18B",
                    "SigLIP 2 (Google)",
                    "Veo 3 (Google)"
                ],
                "ì¶œì‹œ": ["2025.8", "2024.7", "2024", "2024.2", "2025.2", "2024"],
                "íŒŒë¼ë¯¸í„°": ["7B", "~300M", "78B", "18B", "~1B", "~8B"],
                "ì£¼ìš” í˜ì‹ ": [
                    "Image-Text Alignment, 1.7B ì´ë¯¸ì§€ í•™ìŠµ",
                    "ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜, ë©”ëª¨ë¦¬ ëª¨ë“ˆ",
                    "MLLM SOTA, 3D Vision ì§€ì›",
                    "ìµœê³  Zero-shot ì„±ëŠ¥ 80.7%",
                    "ë‹¤êµ­ì–´ Vision-Language",
                    "ë¹„ë””ì˜¤ ìƒì„±, Diffusion Transformer"
                ],
                "íŠ¹í™” ë¶„ì•¼": [
                    "ìê¸°ì§€ë„í•™ìŠµ, íŠ¹ì§• ì¶”ì¶œ",
                    "ë¹„ë””ì˜¤ ê°ì²´ ë¶„í• ",
                    "ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ , GUI Agent",
                    "Zero-shot ë¶„ë¥˜, ê²€ìƒ‰",
                    "ë‹¤êµ­ì–´ ì´ë¯¸ì§€-í…ìŠ¤íŠ¸",
                    "AI ë¹„ë””ì˜¤ ìƒì„±"
                ]
            }

            st.table(modern_data)

            st.success("""
            **ğŸ¯ 2024-2025 íŠ¸ë Œë“œ:**
            - âœ¨ **ê·œëª¨ í™•ì¥**: 1B â†’ 78B íŒŒë¼ë¯¸í„° (InternVL3)
            - âœ¨ **ë©€í‹°ëª¨ë‹¬**: ì´ë¯¸ì§€ + í…ìŠ¤íŠ¸ + ë¹„ë””ì˜¤ í†µí•©
            - âœ¨ **ì‹¤ìš©í™”**: SAM 2ë¡œ ì‹¤ì œ ì•±ì— ì ìš© (Instagram Edits)
            - âœ¨ **ìƒì„± AI**: Veo 3ë¡œ í…ìŠ¤íŠ¸â†’ë¹„ë””ì˜¤ ìƒì„±
            """)

            # ìµœì‹  ëª¨ë¸ ìƒì„¸ ì„¤ëª…
            with st.expander("ğŸ” DINOv3 (2025ë…„ ìµœì‹  ìê¸°ì§€ë„í•™ìŠµ)"):
                st.markdown("""
                **Meta AI Research - 2025ë…„ 8ì›” ë°œí‘œ**

                #### ì£¼ìš” í˜ì‹ 
                - **Image-Text Alignment**: CLIPì²˜ëŸ¼ ì´ë¯¸ì§€ì™€ í…ìŠ¤íŠ¸ ë™ì‹œ í•™ìŠµ
                - **7B íŒŒë¼ë¯¸í„°**: DINO ëŒ€ë¹„ 300ë°° ê·œëª¨
                - **1.7B ì´ë¯¸ì§€**: ì‚¬ìƒ ìµœëŒ€ í•™ìŠµ ë°ì´í„°
                - **Gram Anchoring**: ì•ˆì •ì  í•™ìŠµ ê¸°ë²•
                - **Axial RoPE**: ìœ„ì¹˜ ì¸ì½”ë”© ê°œì„ 

                #### ì„±ëŠ¥
                - ëª¨ë“  ìê¸°ì§€ë„í•™ìŠµ ëª¨ë¸ ì¤‘ ìµœê³  ì„±ëŠ¥
                - Zero-shot transfer learningì—ì„œ íƒì›”
                - Dense prediction task (segmentation, depth)ì—ì„œ ìš°ìˆ˜

                #### í™œìš©
                ```python
                # HuggingFaceì—ì„œ ì‚¬ìš©
                from transformers import Dinov3Model
                model = Dinov3Model.from_pretrained('facebook/dinov3-base')
                ```
                """)

            with st.expander("ğŸ” SAM 2 (2024ë…„ ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜)"):
                st.markdown("""
                **Meta AI - 2024ë…„ 7ì›” ë°œí‘œ**

                #### ì£¼ìš” í˜ì‹ 
                - **í†µí•© ëª¨ë¸**: ì´ë¯¸ì§€ + ë¹„ë””ì˜¤ ë™ì‹œ ì²˜ë¦¬
                - **ë©”ëª¨ë¦¬ ëª¨ë“ˆ**: í”„ë ˆì„ ê°„ ê°ì²´ ì¶”ì 
                - **Real-time**: ì‹¤ì‹œê°„ ì²˜ë¦¬ ê°€ëŠ¥
                - **Interactive**: í´ë¦­/ë°•ìŠ¤/ë§ˆìŠ¤í¬ ì…ë ¥ ì§€ì›

                #### ì„±ëŠ¥
                - ë¹„ë””ì˜¤ ì„¸ê·¸ë©˜í…Œì´ì…˜: ê¸°ì¡´ ëŒ€ë¹„ 3ë°° ì ì€ ìƒí˜¸ì‘ìš©
                - ì´ë¯¸ì§€ ì„¸ê·¸ë©˜í…Œì´ì…˜: SAM ëŒ€ë¹„ 6ë°° ë¹ ë¥´ê³  ì •í™•
                - SA-V ë°ì´í„°ì…‹: 51K ë¹„ë””ì˜¤, 600K masklets

                #### ì‹¤ì œ í™œìš©
                - Instagram Editsì˜ Cutouts ê¸°ëŠ¥
                - ì˜ë£Œ ì˜ìƒ ë¶„ì„
                - ììœ¨ì£¼í–‰ ê°ì²´ ì¶”ì 

                #### ì½”ë“œ ì˜ˆì œ
                ```python
                from sam2.build_sam import build_sam2_video_predictor
                predictor = build_sam2_video_predictor("sam2_hiera_large.pt")

                # ë¹„ë””ì˜¤ì˜ ì²« í”„ë ˆì„ì—ì„œ ê°ì²´ ì„ íƒ
                points = np.array([[210, 350]])
                labels = np.array([1])  # 1=foreground
                frame_idx, object_ids, masks = predictor.add_new_points(
                    frame_idx=0, obj_id=0, points=points, labels=labels
                )

                # ì „ì²´ ë¹„ë””ì˜¤ì— ëŒ€í•´ ìë™ ì¶”ì 
                for frame_idx, object_ids, masks in predictor.propagate_in_video():
                    # ê° í”„ë ˆì„ì˜ ë§ˆìŠ¤í¬ ì‚¬ìš©
                    pass
                ```
                """)

            with st.expander("ğŸ” InternVL3-78B (2024ë…„ MLLM SOTA)"):
                st.markdown("""
                **OpenGVLab - 2024ë…„ ë°œí‘œ**

                #### ì£¼ìš” íŠ¹ì§•
                - **78B íŒŒë¼ë¯¸í„°**: ìµœëŒ€ ê·œëª¨ ì˜¤í”ˆì†ŒìŠ¤ MLLM
                - **MMMU 72.2**: ë²¤ì¹˜ë§ˆí¬ ì‹ ê¸°ë¡
                - **ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ **: ì´ë¯¸ì§€+í…ìŠ¤íŠ¸ ë³µí•© ì´í•´
                - **3D Vision**: 3D ê°ì²´ ì¸ì‹ ì§€ì›
                - **GUI Agent**: ì¸í„°í˜ì´ìŠ¤ ì´í•´ ë° ì¡°ì‘

                #### í™œìš© ë¶„ì•¼
                - ì‚°ì—… ì´ë¯¸ì§€ ë¶„ì„
                - ë¬¸ì„œ ì´í•´ (OCR + VQA)
                - ë³µì¡í•œ ì‹œê°ì  ì¶”ë¡ 
                - ë¡œë´‡ ë¹„ì „
                """)

            with st.expander("ğŸ” Veo 3 (2024ë…„ AI ë¹„ë””ì˜¤ ìƒì„±)"):
                st.markdown("""
                **Google DeepMind - 2024ë…„ ë°œí‘œ**

                #### ì•„í‚¤í…ì²˜
                - **Latent Diffusion Transformer**: íš¨ìœ¨ì  ë¹„ë””ì˜¤ ìƒì„±
                - **Spacetime Patches**: ViTì²˜ëŸ¼ ë¹„ë””ì˜¤ë¥¼ íŒ¨ì¹˜ë¡œ ì²˜ë¦¬
                - **Audio-Visual Unified**: ì˜ìƒ+ìŒì„± ë™ì‹œ ìƒì„±

                #### íŠ¹ì§•
                - **í…ìŠ¤íŠ¸â†’ë¹„ë””ì˜¤**: í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ê³ í’ˆì§ˆ ë¹„ë””ì˜¤ ìƒì„±
                - **ì‹œê°„ì  ì¼ê´€ì„±**: Transformerë¡œ í”„ë ˆì„ ê°„ ì—°ì†ì„± ë³´ì¥
                - **ê³ í•´ìƒë„**: 4K ë¹„ë””ì˜¤ ìƒì„± ê°€ëŠ¥

                #### Transformerì˜ ì—­í• 
                - Sequence modelingë¡œ í”„ë ˆì„ ê°„ ê´€ê³„ í•™ìŠµ
                - Attentionìœ¼ë¡œ ì‹œê°„ì  coherence ìœ ì§€
                - Vision Transformer ê¸°ìˆ  ì§ì ‘ í™œìš©

                #### vs. Nano Banana
                - **Veo 3**: ë¹„ë””ì˜¤ ìƒì„±
                - **Nano Banana**: ì´ë¯¸ì§€ ìƒì„± (Gemini 2.5 Flash)
                - ë‘ ëª¨ë¸ ëª¨ë‘ Transformer ê¸°ë°˜!
                """)

        with era_tabs[2]:
            st.markdown("### ğŸ“Š ì „ì²´ ëª¨ë¸ ë¹„êµ (2020-2025)")

            comparison_df = {
                "ì‹œëŒ€": ["í´ë˜ì‹", "í´ë˜ì‹", "ì¤‘ê¸°", "ì¤‘ê¸°", "ìµœì‹ ", "ìµœì‹ ", "ìµœì‹ "],
                "ëª¨ë¸": ["ViT-Base", "DINO", "DINOv2", "SAM", "EVA-CLIP-18B", "SAM 2", "DINOv3"],
                "ë…„ë„": ["2020", "2021", "2023", "2023", "2024", "2024", "2025"],
                "íŒŒë¼ë¯¸í„°": ["86M", "22M", "300M", "632M", "18B", "~300M", "7B"],
                "ì£¼ìš” ìš©ë„": ["ë¶„ë¥˜", "ìê¸°ì§€ë„", "ìê¸°ì§€ë„", "ë¶„í• ", "ê²€ìƒ‰", "ë¹„ë””ì˜¤ë¶„í• ", "ìê¸°ì§€ë„"],
                "í˜ì‹  í¬ì¸íŠ¸": [
                    "Transformerë¥¼ Visionì— ì²« ì ìš©",
                    "ë¼ë²¨ ì—†ëŠ” í•™ìŠµ ì…ì¦",
                    "ëŒ€ê·œëª¨ ë°ì´í„°ë¡œ ì„±ëŠ¥ í–¥ìƒ",
                    "Prompt ê¸°ë°˜ ì œë¡œìƒ· ë¶„í• ",
                    "ìµœëŒ€ ê·œëª¨ CLIP ëª¨ë¸",
                    "ë¹„ë””ì˜¤ë¡œ í™•ì¥+ë©”ëª¨ë¦¬",
                    "Image-Text Alignment"
                ]
            }

            st.table(comparison_df)

        st.markdown("---")
        st.markdown("### ğŸ¯ Vision Transformer ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ (2025ë…„ ê¸°ì¤€)")

        st.info("""
        ğŸ’¡ **ëª¨ë¸ ë¶„ë¥˜ ê¸°ì¤€**:
        - **ìˆœìˆ˜ Vision Transformer**: ViT, DINO ê³„ì—´ (ì´ë¯¸ì§€ ì´í•´)
        - **Vision-Language Transformer**: CLIP, SigLIP (ì´ë¯¸ì§€+í…ìŠ¤íŠ¸)
        - **Task-Specific Transformer**: SAM (ì„¸ê·¸ë©˜í…Œì´ì…˜)
        - **ì°¸ê³ : ìƒì„±/ë©€í‹°ëª¨ë‹¬**: Veo 3 (ìƒì„±), InternVL3 (MLLM) - ê´€ë ¨ ëª¨ë¸ì´ì§€ë§Œ ë‹¤ë¥¸ ëª©ì 
        """)

        rec_col1, rec_col2 = st.columns(2)

        with rec_col1:
            st.markdown("""
            #### ğŸ” **ìˆœìˆ˜ Vision Transformer**

            **ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ & ë¶„ë¥˜**
            - **DINOv3** (7B): ìµœê°• ìê¸°ì§€ë„í•™ìŠµ
              - Zero-shot transfer ìµœê³  ì„±ëŠ¥
              - Dense prediction (segmentation, depth) ìš°ìˆ˜
              - ì—°êµ¬/í”„ë¡œí† íƒ€ì…ì— ì í•©

            - **ViT-Large** (307M): í´ë˜ì‹í•˜ì§€ë§Œ ê²€ì¦ë¨
              - ImageNet 82.6% ì •í™•ë„
              - ë¹ ë¥¸ ì¶”ë¡  ì†ë„
              - í”„ë¡œë•ì…˜ í™˜ê²½ì— ì•ˆì •ì 

            #### ğŸ¨ **Vision-Language Transformer**

            **ì´ë¯¸ì§€-í…ìŠ¤íŠ¸ ë§¤ì¹­**
            - **EVA-CLIP-18B** (18B): Zero-shot ë¶„ë¥˜ ìµœê³  (80.7%)
              - "ê³ ì–‘ì´ê°€ ì•‰ì•„ìˆë‹¤" â†’ ì´ë¯¸ì§€ ê²€ìƒ‰
              - í…ìŠ¤íŠ¸ í”„ë¡¬í”„íŠ¸ë¡œ ì´ë¯¸ì§€ ë¶„ë¥˜

            - **SigLIP 2** (1B): ë¹ ë¥¸ ì„œë¹„ìŠ¤ìš©
              - ë‹¤êµ­ì–´ ì§€ì› (í•œêµ­ì–´ í¬í•¨)
              - ì‹¤ì‹œê°„ ê²€ìƒ‰ ì—”ì§„ì— ì í•©
            """)

        with rec_col2:
            st.markdown("""
            #### ğŸ¯ **Task-Specific Transformer**

            **ì„¸ê·¸ë©˜í…Œì´ì…˜ ì „ë¬¸**
            - **SAM 2** (300M): ë¹„ë””ì˜¤ ê°ì²´ ë¶„í• 
              - ì´ë¯¸ì§€: í´ë¦­ í•œ ë²ˆìœ¼ë¡œ ê°ì²´ ì¶”ì¶œ
              - ë¹„ë””ì˜¤: í”„ë ˆì„ ê°„ ê°ì²´ ìë™ ì¶”ì 
              - Instagram Editsì— ì‹¤ì œ ì‚¬ìš© ì¤‘
              - ì˜ë£Œ/ììœ¨ì£¼í–‰ì— í•„ìˆ˜

            #### ğŸ“š **ì°¸ê³ : ê´€ë ¨ ëª¨ë¸ë“¤**

            **Vision Transformer ê¸°ìˆ  í™œìš©**
            - **InternVL3-78B**: Multimodal LLM
              - ViT + LLM ê²°í•©
              - ì´ë¯¸ì§€ ì´í•´ + ì¶”ë¡  ëŠ¥ë ¥
              - "ì´ ì´ë¯¸ì§€ì—ì„œ ë¬¸ì œì ì€?" ê°™ì€ VQA

            - **Veo 3**: ë¹„ë””ì˜¤ ìƒì„± (Diffusion Transformer)
              - ViTì˜ Spacetime Patch ê°œë… í™œìš©
              - í…ìŠ¤íŠ¸ â†’ ë¹„ë””ì˜¤ ìƒì„±
              - ìƒì„± AI ë¶„ì•¼
            """)

        st.success("""
        **ğŸ¯ ì„ íƒ ê¸°ì¤€ ìš”ì•½**:

        | ëª©ì  | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
        |------|----------|------|
        | **ì´ë¯¸ì§€ ë¶„ë¥˜** | ViT-Large, DINOv3 | ê²€ì¦ëœ ì„±ëŠ¥ |
        | **Zero-shot ë¶„ë¥˜** | EVA-CLIP-18B | í…ìŠ¤íŠ¸ë¡œ ì¹´í…Œê³ ë¦¬ ì§€ì • |
        | **íŠ¹ì§• ì¶”ì¶œ** | DINOv3 | ë¼ë²¨ ì—†ì´ ê°•ë ¥í•œ íŠ¹ì§• |
        | **ì´ë¯¸ì§€ ê²€ìƒ‰** | SigLIP 2 | ë¹ ë¥´ê³  ë‹¤êµ­ì–´ ì§€ì› |
        | **ê°ì²´ ë¶„í• ** | SAM 2 | ë¹„ë””ì˜¤ê¹Œì§€ ì§€ì› |
        | **ì „ì´ í•™ìŠµ** | DINOv3, ViT-Large | Backboneìœ¼ë¡œ ì‚¬ìš© |

        ğŸ’¡ **Week 4 ì‹¤ìŠµ**: ìœ„ ìˆœìˆ˜ Vision Transformer ëª¨ë¸ë“¤ (ViT, DINO, CLIP, SAM)ì„ ì§ì ‘ ì‚¬ìš©í•´ë³´ì„¸ìš”!
        """)

    def _render_project_tab(self):
        """ì‹¤ì „ í”„ë¡œì íŠ¸ íƒ­"""
        st.header("ğŸš€ ì‹¤ì „ Vision Transformer í”„ë¡œì íŠ¸")

        project_type = st.selectbox(
            "í”„ë¡œì íŠ¸ ì„ íƒ",
            ["ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ (ViT)", "ğŸ” íŠ¹ì§• ì¶”ì¶œ (DINO)", "ğŸ“Š ëª¨ë¸ ë¹„êµ"],
            key="vit_project_type"
        )

        if project_type == "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ (ViT)":
            self._render_classification_project()
        elif project_type == "ğŸ” íŠ¹ì§• ì¶”ì¶œ (DINO)":
            self._render_feature_extraction_project()
        else:
            self._render_comparison_project()

    def _render_classification_project(self):
        """ì´ë¯¸ì§€ ë¶„ë¥˜ í”„ë¡œì íŠ¸ - HuggingFace ViT ëª¨ë¸ ì‚¬ìš©"""
        st.subheader("ğŸ–¼ï¸ Vision Transformer ì´ë¯¸ì§€ ë¶„ë¥˜")

        st.info("""
        ğŸ’¡ **ì‹¤ì œ ViT ëª¨ë¸ ì‚¬ìš©**: HuggingFaceì˜ ì‚¬ì „í•™ìŠµëœ Vision Transformerë¡œ ì´ë¯¸ì§€ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
        - ëª¨ë¸: `google/vit-base-patch16-224`
        - ImageNet 1000ê°œ í´ë˜ìŠ¤ ë¶„ë¥˜
        - ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (ì•½ 330MB)
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **í”„ë¡œì íŠ¸ ëª©í‘œ:**
            - Vision Transformerë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜
            - HuggingFace ì‚¬ì „í›ˆë ¨ ëª¨ë¸ í™œìš©
            - ImageNet 1000ê°œ í´ë˜ìŠ¤ ì¸ì‹

            **ì§€ì› ëª¨ë¸:**
            - ViT-Base: 86M íŒŒë¼ë¯¸í„°
            - ì…ë ¥: 224Ã—224 ì´ë¯¸ì§€
            - ì¶œë ¥: Top-5 ì˜ˆì¸¡ ê²°ê³¼
            """)

            uploaded_file = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['png', 'jpg', 'jpeg'],
                key="vit_classify_upload"
            )

        with col2:
            if uploaded_file:
                from PIL import Image
                import numpy as np

                img = Image.open(uploaded_file)
                st.image(img, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

                if st.button("ğŸ” ViT ëª¨ë¸ë¡œ ë¶„ë¥˜", key="vit_classify", type="primary"):
                    with st.spinner("ViT ëª¨ë¸ ë¡œë”© ë° ì¶”ë¡  ì¤‘..."):
                        try:
                            from transformers import ViTImageProcessor, ViTForImageClassification
                            import torch

                            # ëª¨ë¸ ë¡œë“œ
                            model_name = "google/vit-base-patch16-224"
                            processor = ViTImageProcessor.from_pretrained(model_name)
                            model = ViTForImageClassification.from_pretrained(model_name)

                            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                            inputs = processor(images=img, return_tensors="pt")

                            # ì¶”ë¡ 
                            with torch.no_grad():
                                outputs = model(**inputs)
                                logits = outputs.logits

                            # Top-5 ì˜ˆì¸¡
                            probs = torch.nn.functional.softmax(logits, dim=-1)
                            top5_probs, top5_indices = torch.topk(probs, 5)

                            st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")
                            st.markdown("### ğŸ¯ Top-5 ì˜ˆì¸¡ ê²°ê³¼")

                            for i, (prob, idx) in enumerate(zip(top5_probs[0], top5_indices[0])):
                                label = model.config.id2label[idx.item()]
                                confidence = prob.item() * 100

                                # ë§‰ëŒ€ ê·¸ë˜í”„ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                                bar_length = int(confidence / 2)
                                bar = "â–ˆ" * bar_length
                                st.markdown(f"**{i+1}. {label}**")
                                st.progress(confidence / 100)
                                st.caption(f"ì‹ ë¢°ë„: {confidence:.2f}%")
                                st.markdown("---")

                            # ëª¨ë¸ ì •ë³´
                            with st.expander("ğŸ“Š ëª¨ë¸ ì •ë³´"):
                                st.markdown(f"""
                                - **ëª¨ë¸**: {model_name}
                                - **íŒŒë¼ë¯¸í„° ìˆ˜**: {sum(p.numel() for p in model.parameters()):,}
                                - **ì…ë ¥ í¬ê¸°**: 224Ã—224
                                - **íŒ¨ì¹˜ í¬ê¸°**: 16Ã—16
                                - **í•™ìŠµ ë°ì´í„°**: ImageNet-21k
                                """)

                        except Exception as e:
                            st.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                            st.info("""
                            **í•´ê²° ë°©ë²•:**
                            1. ì¸í„°ë„· ì—°ê²° í™•ì¸ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”)
                            2. í„°ë¯¸ë„ì—ì„œ ìˆ˜ë™ ì„¤ì¹˜: `pip install transformers torch pillow`
                            3. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸ (ìµœì†Œ 500MB)
                            """)

    def _render_feature_extraction_project(self):
        """íŠ¹ì§• ì¶”ì¶œ í”„ë¡œì íŠ¸ - HuggingFace DINO ëª¨ë¸ ì‚¬ìš©"""
        st.subheader("ğŸ” DINO íŠ¹ì§• ì¶”ì¶œ ë° Attention Map")

        st.info("""
        ğŸ’¡ **ì‹¤ì œ DINOv2 ëª¨ë¸ ì‚¬ìš©**: HuggingFaceì˜ ì‚¬ì „í•™ìŠµëœ DINOv2ë¡œ ì´ë¯¸ì§€ íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        - ëª¨ë¸: `facebook/dinov2-small` (22M íŒŒë¼ë¯¸í„°)
        - ìê¸°ì§€ë„í•™ìŠµìœ¼ë¡œ í•™ìŠµëœ ê°•ë ¥í•œ íŠ¹ì§• ì¶”ì¶œê¸°
        - Attention Mapìœ¼ë¡œ ëª¨ë¸ì´ ë³´ëŠ” ì˜ì—­ ì‹œê°í™”
        - DINO v1ë³´ë‹¤ ê°œì„ ëœ ì„±ëŠ¥
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **í”„ë¡œì íŠ¸ ëª©í‘œ:**
            - DINOë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
            - Self-Attention Map ì‹œê°í™”
            - ê°ì²´ ê²½ê³„ ìë™ ë°œê²¬ í™•ì¸

            **DINOì˜ ëŠ¥ë ¥:**
            - ë ˆì´ë¸” ì—†ì´ ê°ì²´ ê²½ê³„ ë°œê²¬
            - ì˜ë¯¸ë¡ ì  íŠ¹ì§• ì¶”ì¶œ
            - Zero-shot segmentation
            """)

            uploaded_file = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['png', 'jpg', 'jpeg'],
                key="dino_feature_upload"
            )

        with col2:
            if uploaded_file:
                from PIL import Image
                import numpy as np

                img = Image.open(uploaded_file)
                st.image(img, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€", use_container_width=True)

                if st.button("ğŸ” DINO íŠ¹ì§• ì¶”ì¶œ", key="dino_extract", type="primary"):
                    with st.spinner("DINO ëª¨ë¸ ë¡œë”© ë° íŠ¹ì§• ì¶”ì¶œ ì¤‘..."):
                        try:
                            from transformers import AutoImageProcessor, AutoModel
                            import torch

                            # DINOv2 ëª¨ë¸ ë¡œë“œ (Attention ì§€ì›)
                            model_name = "facebook/dinov2-small"
                            processor = AutoImageProcessor.from_pretrained(model_name)
                            # attn_implementation='eager'ë¡œ ì„¤ì •í•˜ì—¬ attention ì¶œë ¥ í™œì„±í™”
                            model = AutoModel.from_pretrained(model_name, attn_implementation='eager')

                            # ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                            inputs = processor(images=img, return_tensors="pt")

                            # íŠ¹ì§• ì¶”ì¶œ
                            with torch.no_grad():
                                outputs = model(**inputs, output_attentions=True)

                                # CLS token íŠ¹ì§• (ì „ì²´ ì´ë¯¸ì§€ í‘œí˜„)
                                cls_features = outputs.last_hidden_state[:, 0, :]

                                # Attention weights
                                attentions = outputs.attentions if hasattr(outputs, 'attentions') else None

                            st.success("âœ… íŠ¹ì§• ì¶”ì¶œ ì™„ë£Œ!")

                            # íŠ¹ì§• ë²¡í„° ì •ë³´
                            st.markdown("### ğŸ“Š ì¶”ì¶œëœ íŠ¹ì§• ì •ë³´")
                            st.metric("íŠ¹ì§• ë²¡í„° ì°¨ì›", f"{cls_features.shape[1]}")

                            # attentionsê°€ Noneì´ ì•„ë‹Œì§€ í™•ì¸
                            if attentions is not None and len(attentions) > 0:
                                st.metric("Attention Layers", f"{len(attentions)}")

                                # Attention Map ì‹œê°í™”
                                st.markdown("### ğŸ¨ Self-Attention Map")

                                # ë§ˆì§€ë§‰ ë ˆì´ì–´ì˜ í‰ê·  attention
                                last_attention = attentions[-1]  # [batch, heads, tokens, tokens]
                                avg_attention = last_attention[0].mean(0)  # ëª¨ë“  head í‰ê· 

                                # CLS tokenì´ ë‹¤ë¥¸ íŒ¨ì¹˜ì— ì£¼ëŠ” attention
                                cls_attention = avg_attention[0, 1:]  # CLS â†’ patch tokens

                                # 14x14 ê·¸ë¦¬ë“œë¡œ reshape (ViT-S/16ì€ 14x14 íŒ¨ì¹˜)
                                num_patches = int(np.sqrt(cls_attention.shape[0]))
                                attention_map = cls_attention.reshape(num_patches, num_patches).numpy()

                                # ì›ë³¸ ì´ë¯¸ì§€ í¬ê¸°ë¡œ resize
                                import matplotlib.pyplot as plt
                                from scipy.ndimage import zoom

                                img_array = np.array(img)
                                h, w = img_array.shape[:2]
                                attention_resized = zoom(attention_map, (h/num_patches, w/num_patches), order=1)

                                # ì‹œê°í™”
                                fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))

                                # ì›ë³¸ ì´ë¯¸ì§€
                                ax1.imshow(img_array)
                                ax1.set_title("Original Image", fontsize=14)
                                ax1.axis('off')

                                # Attention overlay
                                ax2.imshow(img_array)
                                im = ax2.imshow(attention_resized, cmap='jet', alpha=0.6)
                                ax2.set_title("DINO Attention Map", fontsize=14)
                                ax2.axis('off')
                                plt.colorbar(im, ax=ax2, fraction=0.046, pad=0.04)

                                st.pyplot(fig)
                                plt.close()

                                st.success("""
                                âœ¨ **DINOê°€ ë°œê²¬í•œ ê²ƒë“¤**:
                                - ğŸ”´ ë¹¨ê°„ìƒ‰: ëª¨ë¸ì´ ì¤‘ìš”í•˜ë‹¤ê³  íŒë‹¨í•œ ì˜ì—­
                                - ğŸ”µ íŒŒë€ìƒ‰: ë°°ê²½ ë˜ëŠ” ëœ ì¤‘ìš”í•œ ì˜ì—­
                                - DINOëŠ” ë ˆì´ë¸” ì—†ì´ë„ ê°ì²´ ê²½ê³„ë¥¼ ìë™ìœ¼ë¡œ ì°¾ì•„ëƒ…ë‹ˆë‹¤!
                                """)
                            else:
                                st.warning("âš ï¸ Attention ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŠ¹ì§• ë²¡í„°ë§Œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤.")
                                st.info("""
                                **íŠ¹ì§• ë²¡í„°ëŠ” ì •ìƒì ìœ¼ë¡œ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤!**
                                - 384ì°¨ì› íŠ¹ì§• ë²¡í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ ê²€ìƒ‰, í´ëŸ¬ìŠ¤í„°ë§ ë“±ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.
                                - Attention Map ì‹œê°í™”ëŠ” ì¼ë¶€ ëª¨ë¸ì—ì„œë§Œ ì§€ì›ë©ë‹ˆë‹¤.
                                """)

                            # íŠ¹ì§• ë²¡í„° í™œìš© ì˜ˆì‹œ
                            with st.expander("ğŸ’¡ íŠ¹ì§• ë²¡í„° í™œìš© ì˜ˆì‹œ"):
                                st.code("""
# ì¶”ì¶œëœ íŠ¹ì§•ìœ¼ë¡œ í•  ìˆ˜ ìˆëŠ” ê²ƒë“¤:

# 1. ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity

# ì—¬ëŸ¬ ì´ë¯¸ì§€ì˜ íŠ¹ì§• ì¶”ì¶œ
features_db = []  # ë°ì´í„°ë² ì´ìŠ¤
query_feature = cls_features.numpy()  # ì¿¼ë¦¬ ì´ë¯¸ì§€

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
similarities = cosine_similarity(query_feature, features_db)
top_k = np.argsort(similarities[0])[-5:]  # ìƒìœ„ 5ê°œ

# 2. ì´ë¯¸ì§€ í´ëŸ¬ìŠ¤í„°ë§
from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=10)
clusters = kmeans.fit_predict(features_db)

# 3. Zero-shot Segmentation
# Attention mapì„ thresholdí•˜ì—¬ ê°ì²´ ë§ˆìŠ¤í¬ ìƒì„±
mask = attention_map > threshold
                                """, language="python")

                            # ëª¨ë¸ ì •ë³´
                            with st.expander("ğŸ“Š DINOv2 ëª¨ë¸ ì •ë³´"):
                                st.markdown(f"""
                                - **ëª¨ë¸**: {model_name}
                                - **íŒŒë¼ë¯¸í„° ìˆ˜**: {sum(p.numel() for p in model.parameters()):,}
                                - **ì•„í‚¤í…ì²˜**: Vision Transformer Small
                                - **íŒ¨ì¹˜ í¬ê¸°**: 14Ã—14
                                - **í•™ìŠµ ë°©ë²•**: Self-Distillation (ìê¸°ì§€ë„í•™ìŠµ)
                                - **í•™ìŠµ ë°ì´í„°**: LVD-142M (142M ì´ë¯¸ì§€)
                                - **íŠ¹ì§•**: ë ˆì´ë¸” ì—†ì´ ê°ì²´ ê²½ê³„ ë°œê²¬ ê°€ëŠ¥
                                - **ê°œì„ ì **: DINO v1 ëŒ€ë¹„ ë” ê°•ë ¥í•œ íŠ¹ì§• ì¶”ì¶œ
                                """)

                        except Exception as e:
                            st.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
                            st.info("""
                            **í•´ê²° ë°©ë²•:**
                            1. ì¸í„°ë„· ì—°ê²° í™•ì¸ (ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•„ìš”)
                            2. í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜: `pip install transformers torch pillow scipy matplotlib`
                            3. ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸
                            """)

    def _render_comparison_project(self):
        """ëª¨ë¸ ë¹„êµ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ“Š Vision ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")

        st.markdown("""
        **ë¹„êµ í•­ëª©:**
        - ë¶„ë¥˜ ì •í™•ë„
        - ì¶”ë¡  ì†ë„
        - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ì„±ëŠ¥
        """)

        test_image = st.file_uploader(
            "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
            type=['png', 'jpg', 'jpeg'],
            key="compare_upload"
        )

        if test_image:
            st.image(test_image, caption="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€", width=300)

            models = st.multiselect(
                "ë¹„êµí•  ëª¨ë¸",
                ["ResNet-50", "ViT-Base", "DINO", "DINOv2"],
                default=["ResNet-50", "ViT-Base"],
                key="compare_models"
            )

            if st.button("ğŸš€ ë¹„êµ ì‹¤í–‰", key="run_compare"):
                with st.spinner("ëª¨ë¸ ë¹„êµ ì¤‘..."):
                    st.success("âœ… ì™„ë£Œ!")

                    import random
                    for model in models:
                        with st.expander(f"ğŸ“Š {model} ê²°ê³¼"):
                            acc = 70 + random.random() * 25
                            speed = 10 + random.random() * 90
                            memory = 500 + random.random() * 1500

                            col1, col2, col3 = st.columns(3)
                            col1.metric("ì •í™•ë„", f"{acc:.1f}%")
                            col2.metric("ì†ë„", f"{speed:.0f} FPS")
                            col3.metric("ë©”ëª¨ë¦¬", f"{memory:.0f} MB")