"""
Week 4: Vision Transformerì™€ ìµœì‹  ëª¨ë¸ ë¹„êµ ëª¨ë“ˆ
Vision Transformer, DINO, SAM ë“± ìµœì‹  ë¹„ì „ ëª¨ë¸ í•™ìŠµ
"""

import streamlit as st
import numpy as np
from PIL import Image
import torch
import os
import sys

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from core.base_processor import BaseImageProcessor


class VisionTransformerModule(BaseImageProcessor):
    """Vision Transformer ë° ìµœì‹  ëª¨ë¸ í•™ìŠµ ëª¨ë“ˆ"""

    def __init__(self):
        super().__init__()

    def render(self):
        """Week 4 ëª¨ë“ˆ UI ë Œë”ë§"""
        self.render_ui()

    def render_ui(self):
        """Week 4 ëª¨ë“ˆ UI ë Œë”ë§"""
        st.title("ğŸ¤– Week 4: Vision Transformerì™€ ìµœì‹  ëª¨ë¸")
        st.markdown("---")

        # íƒ­ ìƒì„±
        tabs = st.tabs([
            "ğŸ“š ì´ë¡ ",
            "ğŸ§  Self-Attention",
            "ğŸ” Vision Transformer",
            "ğŸ¯ DINO & ìê¸°ì§€ë„í•™ìŠµ",
            "ğŸ“Š ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬",
            "ğŸš€ ì‹¤ì „ í”„ë¡œì íŠ¸"
        ])

        with tabs[0]:
            self._render_theory_tab()

        with tabs[1]:
            self._render_self_attention_tab()

        with tabs[2]:
            self._render_vit_tab()

        with tabs[3]:
            self._render_dino_tab()

        with tabs[4]:
            self._render_benchmark_tab()

        with tabs[5]:
            self._render_project_tab()

    def _render_theory_tab(self):
        """ì´ë¡  íƒ­"""
        st.header("ğŸ“– Vision Transformer ì´ë¡ ")

        with st.expander("ğŸ”¹ Transformerì˜ ë“±ì¥ê³¼ ì»´í“¨í„° ë¹„ì „ í˜ëª…", expanded=True):
            st.markdown("""
            ### ğŸ§  Transformerì˜ ì—­ì‚¬

            #### NLPì—ì„œ ì‹œì‘ëœ í˜ëª…
            - **2017ë…„ "Attention Is All You Need"** ë…¼ë¬¸ìœ¼ë¡œ ì‹œì‘
            - RNN/LSTMì˜ ìˆœì°¨ ì²˜ë¦¬ í•œê³„ ê·¹ë³µ
            - ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ Self-Attention ë©”ì»¤ë‹ˆì¦˜ ë„ì…
            - BERT, GPT ë“± ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ ê¸°ë°˜

            #### ì»´í“¨í„° ë¹„ì „ìœ¼ë¡œì˜ í™•ì¥
            - **2020ë…„ "An Image is Worth 16x16 Words"** (ViT ë…¼ë¬¸)
            - CNNì˜ ê·€ë‚©ì  í¸í–¥ ì—†ì´ë„ ìš°ìˆ˜í•œ ì„±ëŠ¥
            - ëŒ€ìš©ëŸ‰ ë°ì´í„°ì—ì„œ CNNì„ ëŠ¥ê°€í•˜ëŠ” ì„±ëŠ¥
            - ë©€í‹°ëª¨ë‹¬ AIì˜ í•µì‹¬ êµ¬ì„± ìš”ì†Œ

            ### ğŸ“Š CNN vs Transformer ë¹„êµ

            | íŠ¹ì§• | CNN | Transformer |
            |------|-----|-------------|
            | ì²˜ë¦¬ ë°©ì‹ | ì§€ì—­ì  (Local) | ì „ì—­ì  (Global) |
            | ê·€ë‚©ì  í¸í–¥ | ê°•í•¨ (í‰í–‰ì´ë™ ë¶ˆë³€ì„±) | ì•½í•¨ |
            | ë°ì´í„° ìš”êµ¬ëŸ‰ | ì ìŒ | ë§ìŒ |
            | ê³„ì‚° ë³µì¡ë„ | O(n) | O(nÂ²) |
            | ì¥ê±°ë¦¬ ì˜ì¡´ì„± | ì•½í•¨ | ê°•í•¨ |
            """)

        with st.expander("ğŸ”¹ Self-Attention ë©”ì»¤ë‹ˆì¦˜"):
            st.markdown("""
            ### ğŸ¯ Self-Attentionì˜ í•µì‹¬ ì›ë¦¬

            **Query, Key, Value (Q, K, V) ê°œë…:**
            ```python
            # Self-Attention ê³„ì‚°
            Q = X @ W_q  # Query: "ë¬´ì—‡ì„ ì°¾ì„ê¹Œ?"
            K = X @ W_k  # Key: "ë‚˜ëŠ” ë¬´ì—‡ì„ ê°€ì§€ê³  ìˆë‚˜?"
            V = X @ W_v  # Value: "ì‹¤ì œ ì •ë³´"

            # Attention Score ê³„ì‚°
            attention_scores = (Q @ K.T) / sqrt(d_k)
            attention_weights = softmax(attention_scores)

            # ìµœì¢… ì¶œë ¥
            output = attention_weights @ V
            ```

            ### ğŸ’¡ ì£¼ìš” íŠ¹ì§•
            1. **ì „ì—­ì  ë¬¸ë§¥ ì´í•´**: ëª¨ë“  ìœ„ì¹˜ ê°„ì˜ ê´€ê³„ íŒŒì•…
            2. **ë³‘ë ¬ ì²˜ë¦¬**: GPU íš¨ìœ¨ì  í™œìš©
            3. **ê°€ì¤‘ í‰ê· **: ì¤‘ìš”í•œ ì •ë³´ì— ë” ì§‘ì¤‘
            """)

        with st.expander("ğŸ”¹ Vision Transformer (ViT) ì•„í‚¤í…ì²˜"):
            st.markdown("""
            ### ğŸ—ï¸ ViT êµ¬ì¡°

            ```
            ì…ë ¥ ì´ë¯¸ì§€ (224Ã—224Ã—3)
            â†“
            Patch Embedding (16Ã—16 íŒ¨ì¹˜ë¡œ ë¶„í• )
            â†“
            Positional Encoding (ìœ„ì¹˜ ì •ë³´ ì¶”ê°€)
            â†“
            Transformer Encoder (12 layers)
            â”œâ”€ Multi-Head Attention
            â”œâ”€ Layer Normalization
            â”œâ”€ MLP (Feed-Forward)
            â””â”€ Residual Connection
            â†“
            Classification Head
            ```

            ### ğŸ“ í•µì‹¬ ì„¤ê³„ ìš”ì†Œ
            1. **Patch Embedding**: ì´ë¯¸ì§€ë¥¼ 16Ã—16 íŒ¨ì¹˜ë¡œ ë¶„í• 
            2. **Position Encoding**: íŒ¨ì¹˜ì˜ ìœ„ì¹˜ ì •ë³´ ì¸ì½”ë”©
            3. **[CLS] Token**: ë¶„ë¥˜ë¥¼ ìœ„í•œ íŠ¹ìˆ˜ í† í°
            4. **Multi-Head Attention**: ë‹¤ì–‘í•œ ê´€ì ì—ì„œ ì •ë³´ ì²˜ë¦¬
            """)

    def _render_self_attention_tab(self):
        """Self-Attention íƒ­"""
        st.header("ğŸ§  Self-Attention ë©”ì»¤ë‹ˆì¦˜")

        st.markdown("""
        ### ğŸ¯ Self-Attention ì‹œê°í™”

        Self-Attentionì€ ì…ë ¥ì˜ ê° ë¶€ë¶„ì´ ë‹¤ë¥¸ ëª¨ë“  ë¶€ë¶„ê³¼ ì–´ë–»ê²Œ ê´€ë ¨ë˜ëŠ”ì§€ë¥¼ í•™ìŠµí•©ë‹ˆë‹¤.
        """)

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**ğŸ”¢ Attention ë©”ì»¤ë‹ˆì¦˜**")
            uploaded_file = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ (Attention ì‹œê°í™”)",
                type=['png', 'jpg', 'jpeg'],
                key="attention_upload"
            )

            if uploaded_file:
                st.image(uploaded_file, caption="ì…ë ¥ ì´ë¯¸ì§€", use_container_width=True)

                if st.button("ğŸ” Attention Map ìƒì„±", key="gen_attention"):
                    with st.spinner("Attention ê³„ì‚° ì¤‘..."):
                        st.success("âœ… ì™„ë£Œ!")
                        st.info("""
                        ğŸ’¡ ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” ì‚¬ì „í›ˆë ¨ëœ ViT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬
                        ê° ë ˆì´ì–´ì˜ Attention Mapì„ ì‹œê°í™”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                        """)

        with col2:
            st.markdown("**ğŸ“Š Multi-Head Attention**")
            num_heads = st.slider("Attention Head ìˆ˜", 1, 12, 8, key="num_heads")

            st.info(f"""
            **Multi-Head Attention ì„¤ì •:**
            - Head ìˆ˜: {num_heads}
            - ê° HeadëŠ” ì„œë¡œ ë‹¤ë¥¸ ê´€ì ì—ì„œ ì •ë³´ë¥¼ ì²˜ë¦¬
            - ìµœì¢… ê²°ê³¼ëŠ” ëª¨ë“  Headì˜ ì¶œë ¥ì„ ê²°í•©
            """)

            st.code("""
# Multi-Head Attention êµ¬í˜„
class MultiHeadAttention:
    def __init__(self, d_model, num_heads):
        self.num_heads = num_heads
        self.d_k = d_model // num_heads

    def forward(self, Q, K, V):
        # ì—¬ëŸ¬ Headë¡œ ë¶„í• 
        Q_heads = split_heads(Q, self.num_heads)
        K_heads = split_heads(K, self.num_heads)
        V_heads = split_heads(V, self.num_heads)

        # ê° Headì—ì„œ Attention ê³„ì‚°
        attention_outputs = []
        for q, k, v in zip(Q_heads, K_heads, V_heads):
            attn = scaled_dot_product_attention(q, k, v)
            attention_outputs.append(attn)

        # ê²°í•©
        return concat(attention_outputs)
            """, language="python")

    def _render_vit_tab(self):
        """Vision Transformer íƒ­"""
        st.header("ğŸ” Vision Transformer (ViT)")

        st.markdown("""
        ### ğŸ—ï¸ ViT ì•„í‚¤í…ì²˜ ì´í•´í•˜ê¸°

        Vision TransformerëŠ” ì´ë¯¸ì§€ë¥¼ **íŒ¨ì¹˜ ì‹œí€€ìŠ¤**ë¡œ ë³€í™˜í•˜ì—¬ ì²˜ë¦¬í•©ë‹ˆë‹¤.
        """)

        # ViT ì„¤ì •
        col1, col2 = st.columns(2)

        with col1:
            st.markdown("**âš™ï¸ ViT ëª¨ë¸ ì„¤ì •**")
            model_size = st.selectbox(
                "ëª¨ë¸ í¬ê¸°",
                ["ViT-Tiny", "ViT-Small", "ViT-Base", "ViT-Large"],
                index=2,
                key="vit_size"
            )

            patch_size = st.selectbox(
                "Patch í¬ê¸°",
                [8, 16, 32],
                index=1,
                key="patch_size"
            )

            st.info(f"""
            **ì„ íƒëœ ì„¤ì •:**
            - ëª¨ë¸: {model_size}
            - Patch í¬ê¸°: {patch_size}Ã—{patch_size}
            - ì´ë¯¸ì§€ í¬ê¸°: 224Ã—224
            - Patch ìˆ˜: {(224//patch_size)**2}ê°œ
            """)

        with col2:
            st.markdown("**ğŸ“Š ëª¨ë¸ ì‚¬ì–‘**")
            model_specs = {
                "ViT-Tiny": {"Layers": 12, "Hidden": 192, "Heads": 3, "Params": "5M"},
                "ViT-Small": {"Layers": 12, "Hidden": 384, "Heads": 6, "Params": "22M"},
                "ViT-Base": {"Layers": 12, "Hidden": 768, "Heads": 12, "Params": "86M"},
                "ViT-Large": {"Layers": 24, "Hidden": 1024, "Heads": 16, "Params": "307M"}
            }

            specs = model_specs[model_size]
            for key, value in specs.items():
                st.metric(key, value)

        # ViT ì‹œì—°
        st.markdown("---")
        st.markdown("### ğŸ¯ ViT ì´ë¯¸ì§€ ë¶„ë¥˜ ì‹œì—°")

        uploaded_vit = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ (ViT ë¶„ë¥˜)",
            type=['png', 'jpg', 'jpeg'],
            key="vit_upload"
        )

        if uploaded_vit:
            col1, col2 = st.columns(2)

            with col1:
                st.image(uploaded_vit, caption="ì…ë ¥ ì´ë¯¸ì§€", use_container_width=True)

            with col2:
                if st.button("ğŸ” ViT ë¶„ë¥˜ ì‹¤í–‰", key="run_vit"):
                    with st.spinner(f"{model_size} ëª¨ë¸ ì¶”ë¡  ì¤‘..."):
                        st.success("âœ… ë¶„ë¥˜ ì™„ë£Œ!")

                        # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
                        import random
                        classes = ["ê³ ì–‘ì´", "ê°œ", "ìë™ì°¨", "ë¹„í–‰ê¸°", "ìƒˆ"]
                        probs = [random.random() for _ in range(5)]
                        total = sum(probs)
                        probs = [p/total for p in probs]

                        st.markdown("**ì˜ˆì¸¡ ê²°ê³¼:**")
                        for cls, prob in zip(classes, probs):
                            st.write(f"{cls}: {prob*100:.1f}%")
                            st.progress(prob)

    def _render_dino_tab(self):
        """DINO & ìê¸°ì§€ë„í•™ìŠµ íƒ­"""
        st.header("ğŸ¯ DINO & ìê¸°ì§€ë„í•™ìŠµ")

        st.markdown("""
        ### ğŸ¦– DINO (Self-Distillation with No Labels)

        **DINO**ëŠ” ë ˆì´ë¸” ì—†ì´ ì´ë¯¸ì§€ì˜ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ëŠ” ìê¸°ì§€ë„í•™ìŠµ ë°©ë²•ì…ë‹ˆë‹¤.
        """)

        with st.expander("ğŸ”¹ DINOì˜ í•µì‹¬ ì›ë¦¬", expanded=True):
            st.markdown("""
            ### ğŸ“š ìê¸°ì§€ë„í•™ìŠµì´ë€?

            - **ì§€ë„í•™ìŠµ**: ë ˆì´ë¸”ì´ í•„ìš” (ê³ ì–‘ì´, ê°œ, ìë™ì°¨ ë“±)
            - **ìê¸°ì§€ë„í•™ìŠµ**: ë ˆì´ë¸” ë¶ˆí•„ìš”, ë°ì´í„° ìì²´ì—ì„œ í•™ìŠµ
            - **DINO**: Teacher-Student êµ¬ì¡°ë¡œ ì§€ì‹ ì¦ë¥˜

            ### ğŸ”„ DINO í•™ìŠµ ê³¼ì •

            ```
            ì…ë ¥ ì´ë¯¸ì§€
            â†“
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  Student Network â”‚  Teacher Network â”‚
            â”‚  (í•™ìŠµë¨)         â”‚  (EMA ì—…ë°ì´íŠ¸)   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â†“
            Knowledge Distillation Loss
            ```

            ### ğŸ’¡ ì£¼ìš” íŠ¹ì§•
            1. **ë ˆì´ë¸” ë¶ˆí•„ìš”**: ëŒ€ê·œëª¨ unlabeled ë°ì´í„° í™œìš©
            2. **ê°•ë ¥í•œ íŠ¹ì§•**: Semantic Segmentation ê°€ëŠ¥
            3. **ì „ì´ í•™ìŠµ**: ë‹¤ì–‘í•œ ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ì— í™œìš©
            """)

        # DINO ì‹œì—°
        st.markdown("### ğŸ¨ DINO íŠ¹ì§• ì‹œê°í™”")

        uploaded_dino = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ (DINO ë¶„ì„)",
            type=['png', 'jpg', 'jpeg'],
            key="dino_upload"
        )

        if uploaded_dino:
            col1, col2 = st.columns(2)

            with col1:
                st.image(uploaded_dino, caption="ì…ë ¥ ì´ë¯¸ì§€", use_container_width=True)

            with col2:
                if st.button("ğŸ” DINO íŠ¹ì§• ì¶”ì¶œ", key="run_dino"):
                    with st.spinner("DINO ë¶„ì„ ì¤‘..."):
                        st.success("âœ… ì™„ë£Œ!")
                        st.info("""
                        ğŸ’¡ DINOëŠ” ì´ë¯¸ì§€ì˜ ì˜ë¯¸ë¡ ì  êµ¬ì¡°ë¥¼ ìë™ìœ¼ë¡œ ë°œê²¬í•©ë‹ˆë‹¤.
                        - ê°ì²´ ê²½ê³„ ê°ì§€
                        - ë¶€ë¶„-ì „ì²´ ê´€ê³„ ì´í•´
                        - ì˜ë¯¸ë¡ ì  ê·¸ë£¹í™”
                        """)

    def _render_benchmark_tab(self):
        """ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬ íƒ­"""
        st.header("ğŸ“Š ìµœì‹  ë¹„ì „ ëª¨ë¸ ë²¤ì¹˜ë§ˆí¬")

        st.markdown("""
        ### ğŸ† ì£¼ìš” ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ

        ìµœì‹  ë¹„ì „ ëª¨ë¸ë“¤ì˜ ì„±ëŠ¥ì„ ë‹¤ì–‘í•œ ì§€í‘œë¡œ ë¹„êµí•©ë‹ˆë‹¤.
        """)

        # ë²¤ì¹˜ë§ˆí¬ ë°ì´í„°
        benchmark_data = {
            "ëª¨ë¸": ["ResNet-50", "ViT-Base", "DINO ViT-S", "DINOv2 ViT-B", "SAM ViT-H"],
            "ImageNet Top-1": ["76.2%", "84.5%", "79.3%", "86.5%", "-"],
            "íŒŒë¼ë¯¸í„°": ["25M", "86M", "22M", "86M", "632M"],
            "ì¶”ë¡  ì†ë„": ["ë¹ ë¦„", "ë³´í†µ", "ë³´í†µ", "ë³´í†µ", "ëŠë¦¼"],
            "íŠ¹í™” ë¶„ì•¼": ["ë²”ìš©", "ë¶„ë¥˜", "ìê¸°ì§€ë„", "ìê¸°ì§€ë„", "ë¶„í• "]
        }

        st.table(benchmark_data)

        st.markdown("""
        ### ğŸ“ˆ ëª¨ë¸ ì„ íƒ ê°€ì´ë“œ

        #### ğŸ¯ ìš©ë„ë³„ ì¶”ì²œ ëª¨ë¸

        | ìš©ë„ | ì¶”ì²œ ëª¨ë¸ | ì´ìœ  |
        |------|-----------|------|
        | ì´ë¯¸ì§€ ë¶„ë¥˜ | ViT-Base | ë†’ì€ ì •í™•ë„, ì•ˆì •ì  |
        | ì‹¤ì‹œê°„ ì²˜ë¦¬ | ResNet-50 | ë¹ ë¥¸ ì¶”ë¡  ì†ë„ |
        | ì „ì´ í•™ìŠµ | DINOv2 | ê°•ë ¥í•œ ì‚¬ì „í•™ìŠµ íŠ¹ì§• |
        | ê°ì²´ ë¶„í•  | SAM | ì œë¡œìƒ· ë¶„í•  ëŠ¥ë ¥ |
        | ì ì€ ë°ì´í„° | DINO | ìê¸°ì§€ë„í•™ìŠµìœ¼ë¡œ ì¼ë°˜í™” |
        """)

        # ì„±ëŠ¥ ë¹„êµ ì‹œë®¬ë ˆì´ì…˜
        st.markdown("---")
        st.markdown("### ğŸ”¬ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸")

        test_dataset = st.selectbox(
            "í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹",
            ["ImageNet", "CIFAR-100", "Custom Dataset"],
            key="test_dataset"
        )

        models_to_compare = st.multiselect(
            "ë¹„êµí•  ëª¨ë¸",
            ["ResNet-50", "ViT-Base", "DINO ViT-S", "DINOv2 ViT-B"],
            default=["ResNet-50", "ViT-Base"],
            key="models_compare"
        )

        if st.button("ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰", key="run_benchmark"):
            with st.spinner("ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘..."):
                st.success("âœ… ì™„ë£Œ!")

                # ì‹œë®¬ë ˆì´ì…˜ ê²°ê³¼
                import random
                for model in models_to_compare:
                    accuracy = 70 + random.random() * 20
                    fps = 50 + random.random() * 100
                    st.metric(f"{model}", f"{accuracy:.1f}% accuracy, {fps:.0f} FPS")

    def _render_project_tab(self):
        """ì‹¤ì „ í”„ë¡œì íŠ¸ íƒ­"""
        st.header("ğŸš€ ì‹¤ì „ Vision Transformer í”„ë¡œì íŠ¸")

        project_type = st.selectbox(
            "í”„ë¡œì íŠ¸ ì„ íƒ",
            ["ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ (ViT)", "ğŸ¨ ê°ì²´ ë¶„í•  (SAM)", "ğŸ” íŠ¹ì§• ì¶”ì¶œ (DINO)", "ğŸ“Š ëª¨ë¸ ë¹„êµ"],
            key="vit_project_type"
        )

        if project_type == "ğŸ–¼ï¸ ì´ë¯¸ì§€ ë¶„ë¥˜ (ViT)":
            self._render_classification_project()
        elif project_type == "ğŸ¨ ê°ì²´ ë¶„í•  (SAM)":
            self._render_segmentation_project()
        elif project_type == "ğŸ” íŠ¹ì§• ì¶”ì¶œ (DINO)":
            self._render_feature_extraction_project()
        else:
            self._render_comparison_project()

    def _render_classification_project(self):
        """ì´ë¯¸ì§€ ë¶„ë¥˜ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ–¼ï¸ Vision Transformer ì´ë¯¸ì§€ ë¶„ë¥˜")

        # API ì‚¬ìš© ì˜µì…˜
        use_api = st.checkbox("ğŸ¤– Google Gemini API ì‚¬ìš© (ì‹¤ì œ ë¶„ì„)", key="use_api_vit")

        col1, col2 = st.columns(2)

        with col1:
            st.markdown("""
            **í”„ë¡œì íŠ¸ ëª©í‘œ:**
            - Vision Transformerë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ë¥˜
            - ì‚¬ì „í›ˆë ¨ ëª¨ë¸ í™œìš©
            - ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ ì¸ì‹
            """)

            uploaded_file = st.file_uploader(
                "ì´ë¯¸ì§€ ì—…ë¡œë“œ",
                type=['png', 'jpg', 'jpeg'],
                key="vit_classify_upload"
            )

        with col2:
            if uploaded_file:
                st.image(uploaded_file, caption="ì—…ë¡œë“œëœ ì´ë¯¸ì§€")

                if st.button("ğŸ” ë¶„ë¥˜ ì‹œì‘", key="vit_classify"):
                    with st.spinner("ViT ëª¨ë¸ ë¶„ì„ ì¤‘..."):
                        if use_api:
                            try:
                                import os
                                import google.generativeai as genai
                                from PIL import Image

                                api_key = os.getenv('GOOGLE_API_KEY')
                                if api_key:
                                    genai.configure(api_key=api_key)
                                    model = genai.GenerativeModel('gemini-2.5-pro')

                                    img = Image.open(uploaded_file)
                                    prompt = """
                                    ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ê³  ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
                                    1. ì£¼ìš” ê°ì²´/ì¹´í…Œê³ ë¦¬ (ìƒìœ„ 5ê°œ)
                                    2. ê° ì¹´í…Œê³ ë¦¬ë³„ ì‹ ë¢°ë„ (%)
                                    3. ì´ë¯¸ì§€ì˜ ì£¼ìš” íŠ¹ì§•
                                    """

                                    response = model.generate_content([prompt, img])
                                    st.success("âœ… API ë¶„ì„ ì™„ë£Œ!")
                                    st.write("**Gemini ë¶„ì„ ê²°ê³¼:**")
                                    st.info(response.text)
                                else:
                                    st.error("API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                            except Exception as e:
                                st.error(f"API ì˜¤ë¥˜: {str(e)}")
                        else:
                            # ì‹œë®¬ë ˆì´ì…˜
                            import random
                            st.success("ë¶„ë¥˜ ì™„ë£Œ!")
                            categories = ["ê³ ì–‘ì´", "ê°œ", "ìë™ì°¨", "ë¹„í–‰ê¸°", "ìƒˆ", "ê½ƒ", "ê±´ë¬¼"]
                            for cat in random.sample(categories, 5):
                                conf = random.randint(60, 99)
                                st.metric(cat, f"{conf}%")

    def _render_segmentation_project(self):
        """ê°ì²´ ë¶„í•  í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ¨ SAM (Segment Anything Model)")

        st.info("""
        ğŸ’¡ **SAM (Segment Anything Model)**
        - Meta AIê°€ ê°œë°œí•œ ì œë¡œìƒ· ì´ë¯¸ì§€ ë¶„í•  ëª¨ë¸
        - ì‚¬ìš©ìê°€ í´ë¦­/ë°•ìŠ¤/í…ìŠ¤íŠ¸ë¡œ ë¶„í•  ì˜ì—­ ì§€ì •
        - 11ì–µ ê°œì˜ ë§ˆìŠ¤í¬ë¡œ í•™ìŠµëœ ê°•ë ¥í•œ ëª¨ë¸
        """)

        uploaded_sam = st.file_uploader(
            "ì´ë¯¸ì§€ ì—…ë¡œë“œ (SAM ë¶„í• )",
            type=['png', 'jpg', 'jpeg'],
            key="sam_upload"
        )

        if uploaded_sam:
            col1, col2 = st.columns(2)

            with col1:
                st.image(uploaded_sam, caption="ì›ë³¸ ì´ë¯¸ì§€")

            with col2:
                mode = st.radio("ë¶„í•  ëª¨ë“œ", ["ìë™ ë¶„í• ", "í´ë¦­ ë¶„í• ", "ë°•ìŠ¤ ë¶„í• "], key="sam_mode")

                if st.button("ğŸ¨ ë¶„í•  ì‹¤í–‰", key="run_sam"):
                    with st.spinner("SAM ë¶„í•  ì¤‘..."):
                        st.success("âœ… ì™„ë£Œ!")
                        st.image(uploaded_sam, caption="ë¶„í•  ê²°ê³¼ (ì‹œë®¬ë ˆì´ì…˜)")
                        st.caption("âš ï¸ ì‹¤ì œ SAM ëª¨ë¸ êµ¬í˜„ì´ ì•„ë‹Œ ì‹œë®¬ë ˆì´ì…˜ì…ë‹ˆë‹¤.")

    def _render_feature_extraction_project(self):
        """íŠ¹ì§• ì¶”ì¶œ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ” DINO íŠ¹ì§• ì¶”ì¶œ ë° ìœ ì‚¬ë„ ê²€ìƒ‰")

        st.markdown("""
        **í”„ë¡œì íŠ¸ ëª©í‘œ:**
        - DINOë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ íŠ¹ì§• ì¶”ì¶œ
        - ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰
        - í´ëŸ¬ìŠ¤í„°ë§ ë° ì‹œê°í™”
        """)

        uploaded_query = st.file_uploader(
            "ì¿¼ë¦¬ ì´ë¯¸ì§€ ì—…ë¡œë“œ",
            type=['png', 'jpg', 'jpeg'],
            key="dino_query"
        )

        if uploaded_query:
            st.image(uploaded_query, caption="ì¿¼ë¦¬ ì´ë¯¸ì§€", width=300)

            if st.button("ğŸ” ìœ ì‚¬ ì´ë¯¸ì§€ ê²€ìƒ‰", key="dino_search"):
                with st.spinner("DINO íŠ¹ì§• ì¶”ì¶œ ë° ê²€ìƒ‰ ì¤‘..."):
                    st.success("âœ… ìœ ì‚¬ ì´ë¯¸ì§€ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤!")
                    st.info("""
                    ğŸ’¡ ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ”:
                    1. DINOë¡œ ì´ë¯¸ì§€ íŠ¹ì§• ë²¡í„° ì¶”ì¶œ
                    2. ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                    3. ìƒìœ„ Kê°œ ìœ ì‚¬ ì´ë¯¸ì§€ ë°˜í™˜
                    """)

    def _render_comparison_project(self):
        """ëª¨ë¸ ë¹„êµ í”„ë¡œì íŠ¸"""
        st.subheader("ğŸ“Š Vision ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ")

        st.markdown("""
        **ë¹„êµ í•­ëª©:**
        - ë¶„ë¥˜ ì •í™•ë„
        - ì¶”ë¡  ì†ë„
        - ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
        - ë‹¤ìš´ìŠ¤íŠ¸ë¦¼ íƒœìŠ¤í¬ ì„±ëŠ¥
        """)

        test_image = st.file_uploader(
            "í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€",
            type=['png', 'jpg', 'jpeg'],
            key="compare_upload"
        )

        if test_image:
            st.image(test_image, caption="í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€", width=300)

            models = st.multiselect(
                "ë¹„êµí•  ëª¨ë¸",
                ["ResNet-50", "ViT-Base", "DINO", "DINOv2"],
                default=["ResNet-50", "ViT-Base"],
                key="compare_models"
            )

            if st.button("ğŸš€ ë¹„êµ ì‹¤í–‰", key="run_compare"):
                with st.spinner("ëª¨ë¸ ë¹„êµ ì¤‘..."):
                    st.success("âœ… ì™„ë£Œ!")

                    import random
                    for model in models:
                        with st.expander(f"ğŸ“Š {model} ê²°ê³¼"):
                            acc = 70 + random.random() * 25
                            speed = 10 + random.random() * 90
                            memory = 500 + random.random() * 1500

                            col1, col2, col3 = st.columns(3)
                            col1.metric("ì •í™•ë„", f"{acc:.1f}%")
                            col2.metric("ì†ë„", f"{speed:.0f} FPS")
                            col3.metric("ë©”ëª¨ë¦¬", f"{memory:.0f} MB")